<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>再谈类别不平衡问题：调节权重与魔改Loss的对比联系 | ML & Math Blog Posts</title>
    <meta name="description" content="再谈类别不平衡问题：调节权重与魔改Loss的对比联系&para;
原文链接: https://spaces.ac.cn/archives/7708
发布日期: 

类别不平衡问题，也称为长尾分布问题，在本博客里已经有好几次相关讨论了，比如《从loss的硬截断、软化到focal loss》、《将“Softmax+交叉熵”推广到多标签分类问题》、《通过互信息思想来缓解类别不平衡问题》。对于缓解类别不平...">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css">

    <!-- Google Fonts -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="../assets/css/main.css">
    <link rel="stylesheet" href="../assets/css/post.css">

    <!-- Custom JS -->
    <script src="../assets/js/collapsible.js" defer></script>

    <!-- MathJax for math rendering with equation numbering -->
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true,
        tags: 'ams',  // Enable equation numbering with AMS style
        tagSide: 'right',  // Place equation numbers on the right
        tagIndent: '0.8em',  // Indentation for equation numbers
        multlineWidth: '85%'
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Syntax highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/styles/github.min.css">
    <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/highlight.min.js"></script>
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light bg-light border-bottom">
        <div class="container">
            <a class="navbar-brand" href="../index.html">
                <i class="fas fa-brain"></i> ML & Math Blog
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="../index.html"><i class="fas fa-home"></i> 首页</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Post Content -->
    <article class="container post-container my-5">
        <!-- Breadcrumb Navigation -->
        <nav aria-label="breadcrumb">
            <ol class="breadcrumb">
                <li class="breadcrumb-item"><a href="../index.html"><i class="fas fa-home"></i> 首页</a></li>
                
                <li class="breadcrumb-item"><a href="../index.html?tags=优化">优化</a></li>
                
                <li class="breadcrumb-item active" aria-current="page">
                    #75 再谈类别不平衡问题：调节权重与魔改Loss的对比联系
                </li>
            </ol>
        </nav>

        <!-- Post Header -->
        <header class="post-header mb-4">
            <h1 class="post-title">
                <span class="post-number">#75</span>
                再谈类别不平衡问题：调节权重与魔改Loss的对比联系
            </h1>
            <div class="post-meta">
                <span><i class="far fa-calendar"></i> </span>
                
                <span class="ms-3">
                    <i class="fas fa-link"></i>
                    <a href="https://spaces.ac.cn/archives/7708" target="_blank" rel="noopener">原文链接</a>
                </span>
                
            </div>
            
            <div class="post-tags mt-3">
                
                <a href="../index.html?tags=优化" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 优化</span>
                </a>
                
                <a href="../index.html?tags=损失函数" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 损失函数</span>
                </a>
                
                <a href="../index.html?tags=光滑" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 光滑</span>
                </a>
                
                <a href="../index.html?tags=生成模型" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 生成模型</span>
                </a>
                
                <a href="../index.html?tags=attention" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> attention</span>
                </a>
                
            </div>
            
        </header>

        <div class="row">
            <!-- Main Content -->
            <div class="col-lg-9">
                <!-- Post Body -->
                <div class="post-content">
                    <h1 id="loss">再谈类别不平衡问题：调节权重与魔改Loss的对比联系<a class="toc-link" href="#loss" title="Permanent link">&para;</a></h1>
<p><strong>原文链接</strong>: <a href="https://spaces.ac.cn/archives/7708">https://spaces.ac.cn/archives/7708</a></p>
<p><strong>发布日期</strong>: </p>
<hr />
<p>类别不平衡问题，也称为长尾分布问题，在本博客里已经有好几次相关讨论了，比如<a href="/archives/4733">《从loss的硬截断、软化到focal loss》</a>、<a href="/archives/7359">《将“Softmax+交叉熵”推广到多标签分类问题》</a>、<a href="/archives/7615">《通过互信息思想来缓解类别不平衡问题》</a>。对于缓解类别不平衡，比较基本的方法就是调节样本权重，看起来“高端”一点的方法则是各种魔改loss了（比如Focal Loss、Dice Loss、Logits Adjustment等），本文希望比较系统地理解一下它们之间的联系。</p>
<p><a href="/usr/uploads/2020/08/2288869465.png" title="点击查看原图"><img alt="长尾分布：少数类别的样本数目非常多，多数类别的样本数目非常少。" src="/usr/uploads/2020/08/2288869465.png" /></a></p>
<p>长尾分布：少数类别的样本数目非常多，多数类别的样本数目非常少。</p>
<h2 id="_1">从光滑准确率到交叉熵<a class="toc-link" href="#_1" title="Permanent link">&para;</a></h2>
<p>这里的分析主要以sigmoid的2分类为主，但多数结论可以平行推广到softmax的多分类。设$x$为输入，$y\in\{0,1\}$为目标，$p_{\theta}(x) \in [0, 1]$为模型。理想情况下，当然是要评测什么指标，我们就去优化那个指标。对于分类问题来说，最朴素的指标当然就是准确率，但准确率并没有办法提供有效的梯度，所以不能直接来训练。</p>
<p>为此，我们一个光滑化的指标。从之前的文章<a href="/archives/6620">《函数光滑化杂谈：不可导函数的可导逼近》</a>，准确率的光滑化近似是<br />
\begin{equation}\text{ACC}<em _x_y_sim_mathcal_D="(x,y)\sim\mathcal{D">{\text{smooth}}=\mathbb{E}</em>}}\big[y p_{\theta}(x) + (1 - y)(1 - p_{\theta}(x))\big]\end{equation
其中$\mathcal{D}$是训练数据集合。所以按道理，我们应该以$-\text{ACC}<em _x_y_sim_mathcal_D="(x,y)\sim\mathcal{D">{\text{smooth}}$为最小化的目标。但事实上，直接优化这个目标的效果并不好，更好的是去优化交叉熵<br />
\begin{equation}\text{cross_entropy}=\mathbb{E}</em>}}\big[-y \log p_{\theta}(x) - (1 - y)\log(1 - p_{\theta}(x))\big]\end{equation
这就有点耐人寻味了，明明$\text{ACC}_{\text{smooth}}$更接近我们的评测指标，为什么用交叉熵反而对评测指标更有利呢？</p>
<p>这需要用梯度来解释。对于$p_{\theta}(x)$，它通常是经过了sigmoid激活的，也就是$p_{\theta}(x)=\sigma(z_{\theta}(x))$，其中$\sigma(t)=\frac{1}{1+e^{-t}}$，它的导数$\sigma'(t)=\sigma(t)(1 - \sigma(t))$，而$z_{\theta}(x)$就是我们通常称的“logits”。</p>
<p>假设$y$是1，那么对应的$-\text{ACC}<em _theta="\theta">{\text{smooth}}$就是$-p</em>(x))$，它的梯度是}(x)=-\sigma(z_{\theta<br />
\begin{equation}-\nabla_{\theta} p_{\theta}(x) = - p_{\theta}(x) (1 - p_{\theta}(x))\nabla_{\theta}z_{\theta}(x)\end{equation}<br />
刚才说了，$y$是1，所以训练目标是$p_{\theta}(x)\to 1$，因此我们期望当$p_{\theta}(x)$接近于0时（误差较大），会带来一个较大的梯度，当$p_{\theta}(x)$接近于1时（误差较小），会带来一个较小的梯度。但上述$-\nabla_{\theta} p_{\theta}(x)$显然不是如此，它的调节项$p_{\theta}(x) (1 - p_{\theta}(x))$在0.5处取到最大值，至于0和1都是最小值，这就意味着如果误差太大了，梯度反而也小，这就带来优化效率的低下，最终导致整体效果不好。相反，对于交叉熵来说，有<br />
\begin{equation}-\nabla_{\theta} \log p_{\theta}(x) = - (1 - p_{\theta}(x))\nabla_{\theta}z_{\theta}(x)\end{equation}<br />
刚好把梯度里边带来负面作用的$p_{\theta}(x)$因子去掉了，因此优化效率更高，最终效果也好些。上述分析针对的是$y=1$，如果$y=0$，那么结论也是一样的。</p>
<h2 id="f1">从光滑F1到加权交叉熵<a class="toc-link" href="#f1" title="Permanent link">&para;</a></h2>
<p>从这个过程中，我们可以感觉到，对loss的各种魔改，本质上来说都只是在调整梯度，得到更合理的梯度，我们就能实现更有效的优化，得到更好的模型。此外，我们再思考上述转换过程，本来近似目标的梯度是$-\nabla_{\theta}p_{\theta}(x)$，结果$-\nabla_{\theta}\log p_{\theta}(x)$效果更好。如果我们不去仔细分析背后的原因，直接把$p\to \log p$当作一个“公理”来使用，那能否成立呢？会不会带来一些有意思的结果呢？</p>
<p>举个例子，当负样本远远多于正样本时，我们的评测指标通常都不再是准确率了（不然直接全部输出0准确率就很高了），我们通常关心正类的F1，而F1的直接优化也是不容易的，所以我们也需要一个光滑版，文章<a href="/archives/6620">《函数光滑化杂谈：不可导函数的可导逼近》</a>同样也给出了结果：<br />
\begin{equation}\text{F1}<em _x_y_sim_mathcal_D="(x,y)\sim\mathcal{D">{\text{smooth}}=\frac{2 \mathbb{E}</em>}}\big[y p_{\theta}(x)\big]}{\mathbb{E<em _theta="\theta">{(x,y)\sim\mathcal{D}}\big[y + p</em>}(x)\big]}\end{equation
所以我们的最小化目标原本是$-\text{F1}<em _text_smooth="\text{smooth">{\text{smooth}}$。根据上述“公理”，我们先直接对$-\text{F1}</em>$求梯度：}<br />
\begin{equation}\begin{aligned}&amp;-\nabla_{\theta}\frac{2 \mathbb{E}<em _theta="\theta">{(x,y)\sim\mathcal{D}}\big[y p</em>}(x)\big]}{\mathbb{E<em _theta="\theta">{(x,y)\sim\mathcal{D}}\big[y + p</em>\\}(x)\big]
=&amp;-2\frac{\mathbb{E}<em _theta="\theta">{(x,y)\sim\mathcal{D}}\big[y \nabla</em>}p_{\theta}(x)\big]}{\mathbb{E<em _theta="\theta">{(x,y)\sim\mathcal{D}}\big[y + p</em>}(x)\big]} + 2\frac{\mathbb{E<em _theta="\theta">{(x,y)\sim\mathcal{D}}\big[y p</em>}(x)\big]\mathbb{E<em _theta="\theta">{(x,y)\sim\mathcal{D}}\big[\nabla</em>}p_{\theta}(x)\big]}{\left(\mathbb{E<em _theta="\theta">{(x,y)\sim\mathcal{D}}\big[y + p</em>\\}(x)\big]\right)^2
=&amp;-\frac{2\mathbb{E}<em _text_smooth="\text{smooth">{(x,y)\sim\mathcal{D}}\big[\big(y-\text{F1}</em>}}/2\big)\nabla_{\theta}p_{\theta}(x)\big]}{\mathbb{E<em _theta="\theta">{(x,y)\sim\mathcal{D}}\big[y + p</em>}(x)\big]
\end{aligned}\end{equation}<br />
其中$\frac{2}{\mathbb{E}<em _theta="\theta">{(x,y)\sim\mathcal{D}}[y + p</em>$是整体的一个缩放因子，我们主要关心的还是每个样本的梯度，所以结果是}(x)]<br />
\begin{equation}-\mathbb{E}<em _text_smooth="\text{smooth">{(x,y)\sim\mathcal{D}}\big[\big(y-\text{F1}</em>}}/2\big)\nabla_{\theta}p_{\theta}(x)\big]\end{equation
根据$p\to \log p$“公理”（负样本则是$-p\to\log(1-p)$），我们得到最后的梯度为
\begin{equation}-\mathbb{E}<em _text_smooth="\text{smooth">{(x,y)\sim\mathcal{D}}\big[y\cdot\big(1-\text{F1}</em>}}/2\big)\cdot\nabla_{\theta}\log p_{\theta}(x) + (1 - y)\cdot\text{F1<em _theta="\theta">{\text{smooth}}/2\cdot\nabla</em>}\log (1-p_{\theta}(x))\big]\end{equation<br />
这等价于优化目标<br />
\begin{equation}-\mathbb{E}<em _text_smooth="\text{smooth">{(x,y)\sim\mathcal{D}}\big[y\cdot\big(1-\text{F1}</em>}}/2\big)\cdot\log p_{\theta}(x) + (1 - y)\cdot\text{F1<em _theta="\theta">{\text{smooth}}/2\cdot\log (1-p</em>}(x))\big]\end{equation
的梯度（其中$\text{F1}<em _text_smooth="\text{smooth">{\text{smooth}}$不求梯度），所以这其实就是用$1-\text{F1}</em>/2$调节负样本的交叉熵。}}/2$调节正样本的交叉熵，用$\text{F1}_{\text{smooth}</p>
<h2 id="logits">从扩大边界到Logits调整<a class="toc-link" href="#logits" title="Permanent link">&para;</a></h2>
<p>其实无论评测指标是什么，我们肯定都是希望每一个样本都尽可能预测对。问题在于，样本数目比较少的类别，因为学习得不够充分，所以泛化性能不会太好。</p>
<p>让我们从几何角度来思考这个问题。理想情况下，在编码空间里边，每一类样本都占据着自己的一个“地盘”，不同类的“地盘”是互不相交的。样本数目较少的类别泛化性能不大好，主要就体现为其类别所占据的“地盘”比较小，而且往往还会受到类别数目较多的样本的“打压”，因此“生存”几乎都成了问题，更不用说照顾到训练集没有出现过的新样本了。</p>
<p>怎么解决这个问题呢？其实也很形象，如果样本数目少的类别，里边的样本个个都是“大佬”，一个打十个的那种，那么就算样本少，也能在“地盘之争”中不落下风。让我们考虑一个$n$分类问题，某个样本的编码向量为$f_{\theta}(x)$，类别向量为$u_y$，那么该样本与类别向量的相似度，一般用内积$\langle f_{\theta}(x), u_y\rangle$来度量。假设每个样本能占据半径为$r_y$的“地盘”，这样就是说，满足$\Vert z - f_{\theta}(x)\Vert \leq r_y$的任意$z$都算是该样本的编码向量，这也就意味着，满足这个条件的任意$z$，它跟$u_y$的相似度都应该大于它跟其他类别的相似度。</p>
<p>现在我们考虑<br />
\begin{equation}\langle z, u_y\rangle = \langle f_{\theta}(x), u_y\rangle + \langle z - f_{\theta}(x), u_y\rangle\end{equation}<br />
由于$\Vert z - f_{\theta}(x)\Vert \leq r_y$，所以显然有<br />
\begin{equation}\langle f_{\theta}(x), u_y\rangle - r_y\Vert u_y\Vert\leq\langle z, u_y\rangle \leq \langle f_{\theta}(x), u_y\rangle + r_y\Vert u_y\Vert\end{equation}<br />
所以，为了达到“$z$跟$u_y$的相似度都应该大于它跟其他类别的相似度”这个目的，只需要“$z$跟$u_y$的最小相似度都应该大于它跟其他类别的最大相似度”，因此我们的优化目标变为<br />
\begin{equation}-\log\frac{e^{\langle f_{\theta}(x), u_y\rangle - r_y\Vert u_y\Vert}}{e^{\langle f_{\theta}(x), u_y\rangle - r_y\Vert u_y\Vert}+\sum\limits_{i\neq y} e^{\langle f_{\theta}(x), u_i\rangle + r_y\Vert u_i\Vert}}\end{equation}<br />
可以看到，这其实就相当于am-softmax、circle loss等带有margin的softmax变种，具体形式其实不重要，只需要为类别小的类设置更大的margin就好（样本少的类别每个样本都更“能打”）。那怎么设计每个类的margin呢？之前的文章<a href="/archives/7615">《通过互信息思想来缓解类别不平衡问题》</a>就提供了一个方案：$m_y=-\tau\log p(y)$，这里的$p(y)$是先验分布，那么就有<br />
\begin{equation}-\log\frac{e^{\langle f_{\theta}(x), u_y\rangle + \tau \log p(y)}}{\sum\limits_{i} e^{\langle f_{\theta}(x), u_i\rangle + \tau \log p(i)}}\end{equation}<br />
这样我们就联系到了logit adjustment loss了，或者说给logit adjustment loss提供了一种几何直观理解。本质上来说，logit adjustment也是在调节权重，只不过一般的调节权重是在损失函数的$\log$之后调整，而logit adjustment则是在$\log$之前调整。</p>
<h2 id="_2">感觉上可以小结一下了<a class="toc-link" href="#_2" title="Permanent link">&para;</a></h2>
<p>本文就类别不平衡现象及其对策做了一些思考，主要是希望通过一些相对直观的引导，来揭示一些魔改loss的思路，从中我们也可以发现，其实这些方案本质上都算是在调节样本权重或者类权重。本文的分析思路相对来说比较散漫，基本上是笔者的头脑风暴内容，如果错漏之处，请读者见谅并指出。</p>
<p><em><strong>转载到请包括本文地址：</strong><a href="https://spaces.ac.cn/archives/7708">https://spaces.ac.cn/archives/7708</a></em></p>
<p><em><strong>更详细的转载事宜请参考：</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="《科学空间FAQ》">《科学空间FAQ》</a></p>
<p><strong>如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。</strong></p>
<p><strong>如果您觉得本文还不错，欢迎分享/打赏本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！</strong></p>
<p>打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>微信打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>支付宝打赏</p>
<p>因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>点击这里</strong></a>或在下方评论区留言来告知你的建议或需求。</p>
<p><strong>如果您需要引用本文，请参考：</strong></p>
<p>苏剑林. (Aug. 31, 2020). 《再谈类别不平衡问题：调节权重与魔改Loss的对比联系 》[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/7708">https://spaces.ac.cn/archives/7708</a></p>
<p>@online{kexuefm-7708,<br />
title={再谈类别不平衡问题：调节权重与魔改Loss的对比联系},<br />
author={苏剑林},<br />
year={2020},<br />
month={Aug},<br />
url={\url{https://spaces.ac.cn/archives/7708}},<br />
} </p>
<hr />
<h2 id="_3">公式推导与注释<a class="toc-link" href="#_3" title="Permanent link">&para;</a></h2>
<p>TODO: 添加详细的数学公式推导和注释</p>
                </div>

                <!-- Previous/Next Navigation -->
                <nav class="post-navigation" aria-label="文章导航">
                    <div class="row g-3">
                        <div class="col-6">
                            
                            <a href="realformer把残差转移到attention矩阵上面去.html" class="nav-link-prev">
                                <div class="nav-direction"><i class="fas fa-chevron-left"></i> 上一篇</div>
                                <div class="nav-title">#74 RealFormer：把残差转移到Attention矩阵上面去</div>
                            </a>
                            
                        </div>
                        <div class="col-6">
                            
                            <a href="搜出来的文本一从文本生成到搜索采样.html" class="nav-link-next">
                                <div class="nav-direction">下一篇 <i class="fas fa-chevron-right"></i></div>
                                <div class="nav-title">#76 【搜出来的文本】⋅（一）从文本生成到搜索采样</div>
                            </a>
                            
                        </div>
                    </div>
                </nav>

                <!-- Back to Home -->
                <div class="text-center mt-4 mb-4">
                    <a href="../index.html" class="btn btn-outline-primary">
                        <i class="fas fa-arrow-left"></i> 返回首页
                    </a>
                </div>
            </div>

            <!-- Sidebar (TOC) -->
            <div class="col-lg-3">
                <aside class="sidebar">
                    
                    <div class="toc-sidebar">
                        <h5 class="toc-title"><i class="fas fa-list"></i> 目录</h5>
                        <div class="toc-content">
                            <div class="toc">
<ul>
<li><a href="#loss">再谈类别不平衡问题：调节权重与魔改Loss的对比联系</a><ul>
<li><a href="#_1">从光滑准确率到交叉熵</a></li>
<li><a href="#f1">从光滑F1到加权交叉熵</a></li>
<li><a href="#logits">从扩大边界到Logits调整</a></li>
<li><a href="#_2">感觉上可以小结一下了</a></li>
<li><a href="#_3">公式推导与注释</a></li>
</ul>
</li>
</ul>
</div>

                        </div>
                        <div class="toc-actions">
                            <button class="btn btn-sm btn-outline-secondary" onclick="expandAll()">
                                <i class="fas fa-expand"></i> 全部展开
                            </button>
                            <button class="btn btn-sm btn-outline-secondary" onclick="collapseAll()">
                                <i class="fas fa-compress"></i> 全部折叠
                            </button>
                        </div>
                    </div>
                    

                    <!-- Back to Top Button -->
                    <button id="backToTop" class="back-to-top" title="回到顶部">
                        <i class="fas fa-arrow-up"></i>
                    </button>
                </aside>
            </div>
        </div>
    </article>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>
                博客来源: <a href="https://spaces.ac.cn" target="_blank">科学空间</a> |
                内容经过整理并添加详细数学推导
            </p>
            <p>
                Powered by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>
            </p>
        </div>
    </footer>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>

    <!-- Syntax highlighting -->
    <script>hljs.highlightAll();</script>

    <!-- Back to top functionality -->
    <script>
        // Show/hide back to top button based on scroll position
        window.addEventListener('scroll', function() {
            const backToTop = document.getElementById('backToTop');
            if (window.pageYOffset > 300) {
                backToTop.classList.add('show');
            } else {
                backToTop.classList.remove('show');
            }
        });

        // Smooth scroll to top
        document.getElementById('backToTop').addEventListener('click', function() {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        });

        // Sticky TOC sidebar
        window.addEventListener('scroll', function() {
            const sidebar = document.querySelector('.sidebar');
            if (!sidebar) return;

            const sidebarTop = sidebar.offsetTop;
            const scrollTop = window.pageYOffset;

            if (scrollTop > sidebarTop - 20) {
                sidebar.classList.add('sticky');
            } else {
                sidebar.classList.remove('sticky');
            }
        });
    </script>
</body>
</html>