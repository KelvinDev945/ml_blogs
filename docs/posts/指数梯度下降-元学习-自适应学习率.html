<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>指数梯度下降 + 元学习 = 自适应学习率 | ML & Math Blog Posts</title>
    <meta name="description" content="指数梯度下降 + 元学习 = 自适应学习率
原文链接: https://spaces.ac.cn/archives/8968
发布日期: 

前两天刷到了Google的一篇论文《Step-size Adaptation Using Exponentiated Gradient Updates》，在其中学到了一些新的概念，所以在此记录分享一下。主要的内容有两个，一是非负优化的指数梯度下降，二是基于元...">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css">

    <!-- Google Fonts -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="../assets/css/main.css">
    <link rel="stylesheet" href="../assets/css/post.css">

    <!-- MathJax for math rendering -->
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Syntax highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/styles/github.min.css">
    <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/highlight.min.js"></script>
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light bg-light border-bottom">
        <div class="container">
            <a class="navbar-brand" href="../index.html">
                <i class="fas fa-brain"></i> ML & Math Blog
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="../index.html"><i class="fas fa-home"></i> 首页</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Post Content -->
    <article class="container post-container my-5">
        <!-- Post Header -->
        <header class="post-header mb-4">
            <h1 class="post-title">指数梯度下降 + 元学习 = 自适应学习率</h1>
            <div class="post-meta">
                <span><i class="far fa-calendar"></i> </span>
                
                <span class="ms-3">
                    <i class="fas fa-link"></i>
                    <a href="https://spaces.ac.cn/archives/8968" target="_blank">原文链接</a>
                </span>
                
            </div>
            
            <div class="post-tags mt-3">
                
                <span class="tag"><i class="fas fa-tag"></i> 优化</span>
                <span class="tag"><i class="fas fa-tag"></i> 梯度</span>
                <span class="tag"><i class="fas fa-tag"></i> 优化器</span>
                <span class="tag"><i class="fas fa-tag"></i> 生成模型</span>
                <span class="tag"><i class="fas fa-tag"></i> attention</span>
                
            </div>
            
        </header>

        <!-- Post Body -->
        <div class="post-content">
            <h1 id="_1">指数梯度下降 + 元学习 = 自适应学习率</h1>
<p><strong>原文链接</strong>: <a href="https://spaces.ac.cn/archives/8968">https://spaces.ac.cn/archives/8968</a></p>
<p><strong>发布日期</strong>: </p>
<hr />
<p>前两天刷到了Google的一篇论文<a href="https://papers.cool/arxiv/2202.00145">《Step-size Adaptation Using Exponentiated Gradient Updates》</a>，在其中学到了一些新的概念，所以在此记录分享一下。主要的内容有两个，一是非负优化的指数梯度下降，二是基于元学习思想的学习率调整算法，两者都颇有意思，有兴趣的读者也可以了解一下。</p>
<h2 id="_2">指数梯度下降</h2>
<p>梯度下降大家可能听说得多了，指的是对于无约束函数$\mathcal{L}(\boldsymbol{\theta})$的最小化，我们用如下格式进行更新：<br />
\begin{equation}\boldsymbol{\theta}<em _boldsymbol_theta="\boldsymbol{\theta">{t+1} = \boldsymbol{\theta}_t - \eta\nabla</em>}}\mathcal{L}(\boldsymbol{\theta<em t_1="t+1">t)\end{equation}<br />
其中$\eta$是学习率。然而很多任务并非总是无约束的，对于最简单的非负约束，我们可以改为如下格式更新：<br />
\begin{equation}\boldsymbol{\theta}</em>} = \boldsymbol{\theta<em _boldsymbol_theta="\boldsymbol{\theta">t \odot \exp\left(- \eta\nabla</em>}}\mathcal{L}(\boldsymbol{\theta}_t)\right)\label{eq:egd}\end{equation<br />
这里的$\odot$是逐位对应相乘（Hadamard积）。容易看到，只要初始化的$\boldsymbol{\theta}_0$是非负的，那么在整个更新过程中$\boldsymbol{\theta}_t$都会保持非负，这就是用于非负约束优化的“指数梯度下降”。</p>
<p>怎么理解这个“指数梯度下降”呢？也不难，转化为无约束的情形进行推导就行了。如果$\boldsymbol{\theta}$是非负的，那么$\boldsymbol{\varphi}=\log\boldsymbol{\theta}$就是可正可负的了，因此可以设$\boldsymbol{\theta}=e^{\boldsymbol{\varphi}}$转化为关于$\boldsymbol{\varphi}$的无约束优化问题，继而就可以用梯度下降解决：<br />
\begin{equation}\boldsymbol{\varphi}<em _boldsymbol_varphi="\boldsymbol{\varphi">{t+1} = \boldsymbol{\varphi}_t - \eta\nabla</em>}}\mathcal{L}(e^{\boldsymbol{\varphi<em e_boldsymbol_varphi="e^{\boldsymbol{\varphi">t}) = \boldsymbol{\varphi}_t - \eta e^{\boldsymbol{\varphi}_t}\odot\nabla</em>}}}\mathcal{L}(e^{\boldsymbol{\varphi<em t_1="t+1">t})\end{equation}<br />
我们认为梯度的$e^{\boldsymbol{\varphi}_t}\odot$这部分只起到了调节学习率的作用，所以它不是本质重要的，我们将它舍去得到<br />
\begin{equation}\boldsymbol{\varphi}</em>} = \boldsymbol{\varphi<em e_boldsymbol_varphi="e^{\boldsymbol{\varphi">t - \eta \nabla</em>}}}\mathcal{L}(e^{\boldsymbol{\varphi<em t_1="t+1">t})\end{equation}<br />
两边取指数得<br />
\begin{equation}e^{\boldsymbol{\varphi}</em>}} = e^{\boldsymbol{\varphi<em e_boldsymbol_varphi="e^{\boldsymbol{\varphi">t}\odot\exp\left( - \eta \nabla</em>}}}\mathcal{L}(e^{\boldsymbol{\varphi}_t})\right)\end{equation<br />
换回$\boldsymbol{\theta}=e^{\boldsymbol{\varphi}}$就得到式$\eqref{eq:egd}$。</p>
<h2 id="_3">元学习调学习率</h2>
<p>对于元学习（Meta Learning），可能多数读者都跟笔者一样听得多，但几乎没接触过。简单来说，普通机器学习跟元学习的关系，就像是数学中“函数”跟“泛函”的关系，泛函是“函数的函数”，元学习则是“学习如何学习（Learning How to Learn）”，也就是说它是关于“学习”本身的方法论，比如接下来要介绍的，就是“用梯度下降去调整梯度下降”。</p>
<p>我们从一般的梯度下降出发，记目标函数$\mathcal{L}$的梯度为$\boldsymbol{g}$，那么更新公式为<br />
\begin{equation}\boldsymbol{\theta}<em t_1="t+1">{t+1} = \boldsymbol{\theta}_t - \eta\boldsymbol{g}_t\end{equation}<br />
我们希望给每个分量都调节一下学习率，所以我们引入跟参数一样大小的非负变量$\boldsymbol{\nu}$，修改更新公式为<br />
\begin{equation}\boldsymbol{\theta}</em>} = \boldsymbol{\theta<em t_1="t+1">t - \eta\boldsymbol{\nu}</em>}\odot\boldsymbol{g<em t_1="t+1">t\label{eq:update}\end{equation}<br />
那么，$\boldsymbol{\nu}$要按照什么规则迭代呢？记住我们最终的目的是最小化$\mathcal{L}$，所以$\boldsymbol{\nu}$的更新规则应该也要是梯度下降，而这里$\boldsymbol{\nu}$要求是非负的，所以我们用指数梯度下降：<br />
\begin{equation}\boldsymbol{\nu}</em>} = \boldsymbol{\nu<em _boldsymbol_nu="\boldsymbol{\nu">t \odot\exp\left(- \gamma\nabla</em><em t-1="t-1">t}\mathcal{L}\right)\label{eq:update-nu}\end{equation}<br />
注意$\mathcal{L}$本来只是$\boldsymbol{\theta}$的函数，但根据$\eqref{eq:update}$，在$t$时刻我们有$\boldsymbol{\theta}_t = \boldsymbol{\theta}</em>} - \eta\boldsymbol{\nu<em t-1="t-1">t\odot\boldsymbol{g}</em>$，所以根据链式法则有<br />
\begin{equation}\nabla_{\boldsymbol{\nu}<em t-1="t-1">t}\mathcal{L} = -\eta\boldsymbol{g}</em>} \odot\nabla_{\boldsymbol{\theta<em t-1="t-1">t}\mathcal{L}= -\eta\boldsymbol{g}</em>} \odot\boldsymbol{g<em t_1="t+1">t\end{equation}<br />
代入到$\nu$的更新公式$\eqref{eq:update-nu}$，得到<br />
\begin{equation}\boldsymbol{\nu}</em>} = \boldsymbol{\nu<em t-1="t-1">t \odot\exp\left( \gamma\eta\boldsymbol{g}</em>} \odot\boldsymbol{g<em t_1="t+1">t\right)\end{equation}<br />
将$\gamma\eta$合成一个参数$\gamma$，于是整个模型的更新公式是：<br />
\begin{equation}\begin{aligned}&amp;\boldsymbol{\nu}</em>} = \boldsymbol{\nu<em t-1="t-1">t \odot\exp\left( \gamma\boldsymbol{g}</em>} \odot\boldsymbol{g<em t_1="t+1">t\right) \\<br />
&amp;\boldsymbol{\theta}</em>} = \boldsymbol{\theta<em t_1="t+1">t - \eta\boldsymbol{\nu}</em>}\odot\boldsymbol{g<em t_1="t+1">t\end{aligned}\end{equation}<br />
如果$\boldsymbol{\nu}$初始化为全1，那么将有<br />
\begin{equation}\boldsymbol{\nu}</em>} = \exp\left(\gamma\sum_{k=1}^t\boldsymbol{g}_{k-1} \odot\boldsymbol{g}_k\right)\end{equation<br />
可以看到，该方法的学习率调节思路是：如果某分量相邻两步的梯度经常同号，那么对应项的累加结果就是正的，意味着我们可以适当扩大一下学习率；如果相邻两步的梯度经常异号，那么对应项的累加结果很可能是负的，意味着我们可以适当缩小一下学习率。</p>
<p>注意这跟Adam调学习率的思想是不一样的，Adam调节学习率的思想是如果某个分量的梯度长时间很小，那么就意味着该参数可能没学好，所以尝试放大它的学习率。两者也算是各有各的道理吧。</p>
<h2 id="_4">简单做个小结</h2>
<p>本文主要对“指数梯度下降”和“元学习调学习率”两个概念做了简单笔记，“指数梯度下降”是非负约束优化的一个简单有效的方案，而“元学习调学习率”则是元学习的一个简单易懂的应用。其中在介绍“元学习调学习率”时笔者做了一些简化，相比原论文的形式更为简单一些，但思想是一致的。</p>
<p><em><strong>转载到请包括本文地址：</strong><a href="https://spaces.ac.cn/archives/8968">https://spaces.ac.cn/archives/8968</a></em></p>
<p><em><strong>更详细的转载事宜请参考：</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="《科学空间FAQ》">《科学空间FAQ》</a></p>
<p><strong>如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。</strong></p>
<p><strong>如果您觉得本文还不错，欢迎分享/打赏本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！</strong></p>
<p>打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>微信打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>支付宝打赏</p>
<p>因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>点击这里</strong></a>或在下方评论区留言来告知你的建议或需求。</p>
<p><strong>如果您需要引用本文，请参考：</strong></p>
<p>苏剑林. (Mar. 03, 2022). 《指数梯度下降 + 元学习 = 自适应学习率 》[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/8968">https://spaces.ac.cn/archives/8968</a></p>
<p>@online{kexuefm-8968,<br />
title={指数梯度下降 + 元学习 = 自适应学习率},<br />
author={苏剑林},<br />
year={2022},<br />
month={Mar},<br />
url={\url{https://spaces.ac.cn/archives/8968}},<br />
} </p>
<hr />
<h2 id="_5">公式推导与注释</h2>
<p>TODO: 添加详细的数学公式推导和注释</p>
        </div>

        <!-- Back to Home -->
        <div class="text-center mt-5 mb-4">
            <a href="../index.html" class="btn btn-outline-primary">
                <i class="fas fa-arrow-left"></i> 返回首页
            </a>
        </div>
    </article>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>
                博客来源: <a href="https://spaces.ac.cn" target="_blank">科学空间</a> |
                内容经过整理并添加详细数学推导
            </p>
            <p>
                Powered by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>
            </p>
        </div>
    </footer>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>

    <!-- Syntax highlighting -->
    <script>hljs.highlightAll();</script>
</body>
</html>
