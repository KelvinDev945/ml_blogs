<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>通过互信息思想来缓解类别不平衡问题 | ML & Math Blog Posts</title>
    <meta name="description" content="通过互信息思想来缓解类别不平衡问题&para;
原文链接: https://spaces.ac.cn/archives/7615
发布日期: 

类别不平衡问题，也叫“长尾问题”，是机器学习面临的常见问题之一，尤其是来源于真实场景下的数据集，几乎都是类别不平衡的。大概在两年前，笔者也思考过这个问题，当时正好对“互信息”相关的内容颇有心得，所以构思了一种基于互信息思想的解决办法，但又想了一下，那思路...">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css">

    <!-- Google Fonts -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="../assets/css/main.css">
    <link rel="stylesheet" href="../assets/css/post.css">

    <!-- Custom JS -->
    <script src="../assets/js/collapsible.js" defer></script>

    <!-- MathJax for math rendering with equation numbering -->
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true,
        tags: 'ams',  // Enable equation numbering with AMS style
        tagSide: 'right',  // Place equation numbers on the right
        tagIndent: '0.8em',  // Indentation for equation numbers
        multlineWidth: '85%'
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Syntax highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/styles/github.min.css">
    <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/highlight.min.js"></script>
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light bg-light border-bottom">
        <div class="container">
            <a class="navbar-brand" href="../index.html">
                <i class="fas fa-brain"></i> ML & Math Blog
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="../index.html"><i class="fas fa-home"></i> 首页</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Post Content -->
    <article class="container post-container my-5">
        <!-- Breadcrumb Navigation -->
        <nav aria-label="breadcrumb">
            <ol class="breadcrumb">
                <li class="breadcrumb-item"><a href="../index.html"><i class="fas fa-home"></i> 首页</a></li>
                
                <li class="breadcrumb-item"><a href="../index.html?tags=优化">优化</a></li>
                
                <li class="breadcrumb-item active" aria-current="page">
                    #22 通过互信息思想来缓解类别不平衡问题
                </li>
            </ol>
        </nav>

        <!-- Post Header -->
        <header class="post-header mb-4">
            <h1 class="post-title">
                <span class="post-number">#22</span>
                通过互信息思想来缓解类别不平衡问题
            </h1>
            <div class="post-meta">
                <span><i class="far fa-calendar"></i> </span>
                
                <span class="ms-3">
                    <i class="fas fa-link"></i>
                    <a href="https://spaces.ac.cn/archives/7615" target="_blank" rel="noopener">原文链接</a>
                </span>
                
            </div>
            
            <div class="post-tags mt-3">
                
                <a href="../index.html?tags=优化" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 优化</span>
                </a>
                
                <a href="../index.html?tags=互信息" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 互信息</span>
                </a>
                
                <a href="../index.html?tags=损失函数" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 损失函数</span>
                </a>
                
                <a href="../index.html?tags=生成模型" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 生成模型</span>
                </a>
                
                <a href="../index.html?tags=attention" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> attention</span>
                </a>
                
            </div>
            
        </header>

        <div class="row">
            <!-- Main Content -->
            <div class="col-lg-9">
                <!-- Post Body -->
                <div class="post-content">
                    <h1 id="_1">通过互信息思想来缓解类别不平衡问题<a class="toc-link" href="#_1" title="Permanent link">&para;</a></h1>
<p><strong>原文链接</strong>: <a href="https://spaces.ac.cn/archives/7615">https://spaces.ac.cn/archives/7615</a></p>
<p><strong>发布日期</strong>: </p>
<hr />
<p>类别不平衡问题，也叫“长尾问题”，是机器学习面临的常见问题之一，尤其是来源于真实场景下的数据集，几乎都是类别不平衡的。大概在两年前，笔者也思考过这个问题，当时正好对“互信息”相关的内容颇有心得，所以构思了一种基于互信息思想的解决办法，但又想了一下，那思路似乎过于平凡，所以就没有深究。然而，前几天在arxiv上刷到Google的一篇文章<a href="https://papers.cool/arxiv/2007.07314">《Long-tail learning via logit adjustment》</a>，意外地发现里边包含了跟笔者当初的构思几乎一样的方法，这才意识到当初放弃的思路原来还能达到SOTA的水平～于是结合这篇论文，将笔者当初的构思过程整理于此，希望不会被读者嫌弃“马后炮”。</p>
<h2 id="_2">问题描述<a class="toc-link" href="#_2" title="Permanent link">&para;</a></h2>
<p>这里主要关心的是单标签的多分类问题，假设有$1,2,\cdots,K$共$K$个候选类别，训练数据为$(x,y)\sim\mathcal{D}$，建模的分布为$p_{\theta}(y|x)$，那么我们的优化目标是最大似然，或者说最小化交叉熵，即<br />
\begin{equation}\mathop{\text{argmin}}<em _x_y_sim_mathcal_D="(x,y)\sim\mathcal{D">{\theta}\,\mathbb{E}</em>}}[-\log p_{\theta}(y|x)]\end{equation
通常来说，我们建立的概率模型最后一步都是softmax，假设softmax之前的结果为$f(x;\theta)$（即logits），那么
\begin{equation}-\log p_{\theta}(y|x)=-\log \frac{e^{f_y(x;\theta)}}{\sum\limits_{i=1}^K e^{f_i(x;\theta)}}=\log\left[1 + \sum_{i\neq y}e^{f_i(x;\theta) - f_y(x;\theta)}\right]\label{eq:loss-1}\end{equation}<br />
所谓类别不均衡，就是指某些类别的样本特别多，就好比“20%的人占据了80%的财富”一样，剩下的类别数很多，但是总样本数很少，如果从高到低排序的话，就好像带有一条很长的“尾巴”，所以叫做长尾现象。这种情况下，我们训练的时候采样一个batch，很少有机会采样到低频类别，因此很容易被模型忽略了低频类。但评测的时候，通常我们又更关心低频类别的识别效果，这便是矛盾之处。</p>
<h2 id="_3">常见思路<a class="toc-link" href="#_3" title="Permanent link">&para;</a></h2>
<p>常见的思路大家应该也有所听说，大概就是三个方向：</p>
<blockquote>
<p>1、从数据入手，通过过采样或降采样等手段，使得每个batch内的类别变得更为均衡一些；</p>
<p>2、从loss入手，经典的做法就是类别$y$的样本loss除以类别出现的频率$p(y)$；</p>
<p>3、从结果入手，对正常训练完的模型在预测阶段做些调整，更偏向于低频类别，比如正样本远少于负样本，我们可以把预测结果大于0.2（而不是0.5）都视为正样本。</p>
</blockquote>
<p>Google的原论文中对这三个方向的思路也列举了不少参考文献，有兴趣调研的读者可以直接阅读原论文，另外，知乎上的文章<a href="https://zhuanlan.zhihu.com/p/158638078">《Long-Tailed Classification (2) 长尾分布下分类问题的最新研究》</a>也对该问题进行了介绍，读者也可以参考阅读。</p>
<h2 id="_4">学习互信息<a class="toc-link" href="#_4" title="Permanent link">&para;</a></h2>
<p>回想一下，我们是怎么断定某个分类问题是不均衡的呢？显然，一般的思路是从整个训练集里边统计出各个类别的频率$p(y)$，然后发现$p(y)$集中在某几个类别中。所以，解决类别不平衡问题的重点，就是如何把这个先验知识$p(y)$融入模型之中。</p>
<p>在之前构思词向量模型（如文章<a href="/archives/4669">《更别致的词向量模型(二)：对语言进行建模》</a>）的时候，我们就强调过，相比拟合条件概率，如果模型能直接拟合互信息，那么将会学习到更本质的知识，因为互信息才是揭示核心关联的指标。但是拟合互信息没那么容易训练，容易训练的是条件概率，直接用交叉熵$-\log p_{\theta}(y|x)$进行训练就行了。所以，一个比较理想的想法就是：如何使得模型依然使用交叉熵为loss，但本质上是在拟合互信息？</p>
<p>在公式$\eqref{eq:loss-1}$中，我们是建模了<br />
\begin{equation}p_{\theta}(y|x)=\frac{e^{f_y(x;\theta)}}{\sum\limits_{i=1}^K e^{f_i(x;\theta)}}\end{equation}<br />
现在我们改为建模互信息，那么也就是希望<br />
\begin{equation}\log \frac{p_{\theta}(y|x)}{p(y)}\sim f_y(x;\theta)\quad \Leftrightarrow\quad \log p_{\theta}(y|x)\sim f_y(x;\theta) + \log p(y)\end{equation}<br />
按照右端的形式重新进行softmax归一化，那么就有$p_{\theta}(y|x)=\frac{e^{f_y(x;\theta)+\log p(y)}}{\sum\limits_{i=1}^K e^{f_i(x;\theta)+\log p(i)}}$，或者写成loss形式：<br />
\begin{equation}-\log p_{\theta}(y|x)=-\log \frac{e^{f_y(x;\theta)+\log p(y)}}{\sum\limits_{i=1}^K e^{f_i(x;\theta)+\log p(i)}}=\log\left[1 + \sum_{i\neq y}\frac{p(i)}{p(y)}e^{f_i(x;\theta) - f_y(x;\theta)}\right]\label{eq:loss-2}\end{equation}<br />
原论文称之为logit adjustment loss。如果更加一般化，那么还可以加个调节因子$\tau$：<br />
\begin{equation}-\log p_{\theta}(y|x)=-\log \frac{e^{f_y(x;\theta)+\tau\log p(y)}}{\sum\limits_{i=1}^K e^{f_i(x;\theta)+\tau\log p(i)}}=\log\left[1 + \sum_{i\neq y}\left(\frac{p(i)}{p(y)}\right)^{\tau}e^{f_i(x;\theta) - f_y(x;\theta)}\right]\label{eq:loss-3}\end{equation}<br />
一般情况下，$\tau=1$的效果就已经接近最优了。如果$f_y(x;\theta)$的最后一层有bias项的话，那么最简单的实现方式就是将bias项初始化为$\tau\log p(y)$。也可以写在损失函数中：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">keras.backend</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">K</span>


<span class="k">def</span><span class="w"> </span><span class="nf">categorical_crossentropy_with_prior</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;带先验分布的交叉熵</span>
<span class="sd">    注：y_pred不用加softmax</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">xxxxxx</span>  <span class="c1"># 自己定义好prior，shape为[num_classes]</span>
    <span class="n">log_prior</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="kp">log</span><span class="p">(</span><span class="n">prior</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="kp">ndim</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">log_prior</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="kp">expand_dims</span><span class="p">(</span><span class="n">log_prior</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">+</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">log_prior</span>
    <span class="k">return</span> <span class="n">K</span><span class="o">.</span><span class="n">categorical_crossentropy</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">sparse_categorical_crossentropy_with_prior</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;带先验分布的稀疏交叉熵</span>
<span class="sd">    注：y_pred不用加softmax</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">xxxxxx</span>  <span class="c1"># 自己定义好prior，shape为[num_classes]</span>
    <span class="n">log_prior</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="kp">log</span><span class="p">(</span><span class="n">prior</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="kp">ndim</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">log_prior</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="kp">expand_dims</span><span class="p">(</span><span class="n">log_prior</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">+</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">log_prior</span>
    <span class="k">return</span> <span class="n">K</span><span class="o">.</span><span class="n">sparse_categorical_crossentropy</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<h2 id="_5">结果分析<a class="toc-link" href="#_5" title="Permanent link">&para;</a></h2>
<p>很明显logit adjustment loss也属于调整loss方案之一，不同的是它是在$\log$里边调整权重，而常规的思路则是在$\log$外调整。至于它的好处，就是互信息的好处：互信息揭示了真正重要的关联，所以给logits补上先验分布的bias，能让模型做到“能靠先验解决的就靠先验解决，先验解决不了的本质部分才由模型解决”。</p>
<p>在预测阶段，根据不同的评测指标，我们可以制定不同的预测方案。从<a href="/archives/6620">《函数光滑化杂谈：不可导函数的可导逼近》</a>可以知道，对于整体准确率而言，我们有近似<br />
\begin{equation}\text{整体准确率} \approx \frac{1}{N}\sum_{i=1}^N p_{\theta}(y_i|x_i)\end{equation}<br />
其中$\{(x_i,y_i)\}<em _theta="\theta">{i=1}^N$是验证集。所以如果不考虑类别不均衡情况，追求更高的整体准确率，那么对于每个$x$我们直接输出$p</em>(y|x)$最大的类别即可。但如果我们希望每个类的准确率都尽可能高，那么我们将上式改写成<br />
\begin{equation}\text{整体准确率} \approx \frac{1}{N}\sum_{i=1}^N \frac{p_{\theta}(y_i|x_i)}{p(y_i)}\times p(y_i)=\sum_{y=1}^K p(y)\left(\frac{1}{N}\sum_{x_i\in\Omega_y} \frac{p_{\theta}(y|x_i)}{p(y)}\right)\end{equation}<br />
其中$\Omega_y=\{x_i|y_i=y,i=1,2,\cdots,N\}$，也标签为$y$的$x$的集合，等号右边事实上就是先将同一个$y$的项合并起来。我们知道“整体准确率=每一类的准确率的加权平均”，而上式正好具有同样的形式，所以括号里边的$\frac{1}{N}\sum\limits_{x_i\in\Omega_y} \frac{p_{\theta}(y|x_i)}{p(y)}$就是“每一类的准确率”的一个近似了，因此，如果我们希望每一类的准确率都尽可能高，我们则要输出使得$\frac{p_{\theta}(y|x)}{p(y)}$最大的类别（不加权）。结合$p_{\theta}(y|x)$的形式，我们有结论<br />
\begin{equation}y^{*}=\left\{\begin{aligned}&amp;\mathop{\text{argmax}}\limits_y\, f_y(x;\theta)+\tau\log p(y),\quad(\text{追求整体准确率})\\
&amp;\mathop{\text{argmax}}\limits_y\, f_y(x;\theta),\quad(\text{希望每一类的准确率都尽可能均匀})
\end{aligned}\right.\end{equation}<br />
第一种其实就是输出条件概率最大者，而第二种就是输出互信息最大者，按具体需求选择。</p>
<p>至于详细的实验结果，大家可以自行看论文，总之就是好到有点意外：  </p>
<p><a href="/usr/uploads/2020/07/3807618516.png" title="点击查看原图"><img alt="原论文的实验结果" src="/usr/uploads/2020/07/3807618516.png" /></a></p>
<p>原论文的实验结果</p>
<h2 id="_6">文章小结<a class="toc-link" href="#_6" title="Permanent link">&para;</a></h2>
<p>本文简单介绍了一种基于互信息思想的类别不平衡处理办法，该方案以前笔者也曾经构思过，不过没有深究，而最近Google的一篇论文也给出了同样的方法，遂在此简单记录分析一下，最后Google给出的实验结果显示该方法能达到SOTA的水平。</p>
<p><em><strong>转载到请包括本文地址：</strong><a href="https://spaces.ac.cn/archives/7615">https://spaces.ac.cn/archives/7615</a></em></p>
<p><em><strong>更详细的转载事宜请参考：</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="《科学空间FAQ》">《科学空间FAQ》</a></p>
<p><strong>如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。</strong></p>
<p><strong>如果您觉得本文还不错，欢迎分享/打赏本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！</strong></p>
<p>打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>微信打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>支付宝打赏</p>
<p>因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>点击这里</strong></a>或在下方评论区留言来告知你的建议或需求。</p>
<p><strong>如果您需要引用本文，请参考：</strong></p>
<p>苏剑林. (Jul. 19, 2020). 《通过互信息思想来缓解类别不平衡问题 》[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/7615">https://spaces.ac.cn/archives/7615</a></p>
<p>@online{kexuefm-7615,<br />
title={通过互信息思想来缓解类别不平衡问题},<br />
author={苏剑林},<br />
year={2020},<br />
month={Jul},<br />
url={\url{https://spaces.ac.cn/archives/7615}},<br />
} </p>
<hr />
<h2 id="_7">公式推导与注释<a class="toc-link" href="#_7" title="Permanent link">&para;</a></h2>
<p>TODO: 添加详细的数学公式推导和注释</p>
                </div>

                <!-- Previous/Next Navigation -->
                <nav class="post-navigation" aria-label="文章导航">
                    <div class="row g-3">
                        <div class="col-6">
                            
                            <a href="我们真的需要把训练集的损失降低到零吗.html" class="nav-link-prev">
                                <div class="nav-direction"><i class="fas fa-chevron-left"></i> 上一篇</div>
                                <div class="nav-title">#21 我们真的需要把训练集的损失降低到零吗？</div>
                            </a>
                            
                        </div>
                        <div class="col-6">
                            
                            <a href="殊途同归的策略梯度与零阶优化.html" class="nav-link-next">
                                <div class="nav-direction">下一篇 <i class="fas fa-chevron-right"></i></div>
                                <div class="nav-title">#23 殊途同归的策略梯度与零阶优化</div>
                            </a>
                            
                        </div>
                    </div>
                </nav>

                <!-- Back to Home -->
                <div class="text-center mt-4 mb-4">
                    <a href="../index.html" class="btn btn-outline-primary">
                        <i class="fas fa-arrow-left"></i> 返回首页
                    </a>
                </div>
            </div>

            <!-- Sidebar (TOC) -->
            <div class="col-lg-3">
                <aside class="sidebar">
                    
                    <div class="toc-sidebar">
                        <h5 class="toc-title"><i class="fas fa-list"></i> 目录</h5>
                        <div class="toc-content">
                            <div class="toc">
<ul>
<li><a href="#_1">通过互信息思想来缓解类别不平衡问题</a><ul>
<li><a href="#_2">问题描述</a></li>
<li><a href="#_3">常见思路</a></li>
<li><a href="#_4">学习互信息</a></li>
<li><a href="#_5">结果分析</a></li>
<li><a href="#_6">文章小结</a></li>
<li><a href="#_7">公式推导与注释</a></li>
</ul>
</li>
</ul>
</div>

                        </div>
                        <div class="toc-actions">
                            <button class="btn btn-sm btn-outline-secondary" onclick="expandAll()">
                                <i class="fas fa-expand"></i> 全部展开
                            </button>
                            <button class="btn btn-sm btn-outline-secondary" onclick="collapseAll()">
                                <i class="fas fa-compress"></i> 全部折叠
                            </button>
                        </div>
                    </div>
                    

                    <!-- Back to Top Button -->
                    <button id="backToTop" class="back-to-top" title="回到顶部">
                        <i class="fas fa-arrow-up"></i>
                    </button>
                </aside>
            </div>
        </div>
    </article>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>
                博客来源: <a href="https://spaces.ac.cn" target="_blank">科学空间</a> |
                内容经过整理并添加详细数学推导
            </p>
            <p>
                Powered by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>
            </p>
        </div>
    </footer>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>

    <!-- Syntax highlighting -->
    <script>hljs.highlightAll();</script>

    <!-- Back to top functionality -->
    <script>
        // Show/hide back to top button based on scroll position
        window.addEventListener('scroll', function() {
            const backToTop = document.getElementById('backToTop');
            if (window.pageYOffset > 300) {
                backToTop.classList.add('show');
            } else {
                backToTop.classList.remove('show');
            }
        });

        // Smooth scroll to top
        document.getElementById('backToTop').addEventListener('click', function() {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        });

        // Sticky TOC sidebar
        window.addEventListener('scroll', function() {
            const sidebar = document.querySelector('.sidebar');
            if (!sidebar) return;

            const sidebarTop = sidebar.offsetTop;
            const scrollTop = window.pageYOffset;

            if (scrollTop > sidebarTop - 20) {
                sidebar.classList.add('sticky');
            } else {
                sidebar.classList.remove('sticky');
            }
        });
    </script>
</body>
</html>