<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>重温SSM（一）：线性系统和HiPPO矩阵 | ML & Math Blog Posts</title>
    <meta name="description" content="重温SSM（一）：线性系统和HiPPO矩阵&para;
原文链接: https://spaces.ac.cn/archives/10114
发布日期: 

前几天，笔者看了几篇介绍SSM（State Space Model）的文章，才发现原来自己从未认真了解过SSM，于是打算认真去学习一下SSM的相关内容，顺便开了这个新坑，记录一下学习所得。
SSM的概念由来已久，但这里我们特指深度学习中的SSM...">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css">

    <!-- Google Fonts -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="../assets/css/main.css">
    <link rel="stylesheet" href="../assets/css/post.css">

    <!-- Custom JS -->
    <script src="../assets/js/collapsible.js" defer></script>

    <!-- MathJax for math rendering with equation numbering -->
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true,
        tags: 'ams',  // Enable equation numbering with AMS style
        tagSide: 'right',  // Place equation numbers on the right
        tagIndent: '0.8em',  // Indentation for equation numbers
        multlineWidth: '85%'
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Syntax highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/styles/github.min.css">
    <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/highlight.min.js"></script>
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light bg-light border-bottom">
        <div class="container">
            <a class="navbar-brand" href="../index.html">
                <i class="fas fa-brain"></i> ML & Math Blog
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="../index.html"><i class="fas fa-home"></i> 首页</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Post Content -->
    <article class="container post-container my-5">
        <!-- Breadcrumb Navigation -->
        <nav aria-label="breadcrumb">
            <ol class="breadcrumb">
                <li class="breadcrumb-item"><a href="../index.html"><i class="fas fa-home"></i> 首页</a></li>
                
                <li class="breadcrumb-item"><a href="../index.html?tags=微分方程">微分方程</a></li>
                
                <li class="breadcrumb-item active" aria-current="page">
                    #277 重温SSM（一）：线性系统和HiPPO矩阵
                </li>
            </ol>
        </nav>

        <!-- Post Header -->
        <header class="post-header mb-4">
            <h1 class="post-title">
                <span class="post-number">#277</span>
                重温SSM（一）：线性系统和HiPPO矩阵
            </h1>
            <div class="post-meta">
                <span><i class="far fa-calendar"></i> 2024-05-24</span>
                
            </div>
            
            <div class="post-tags mt-3">
                
                <a href="../index.html?tags=微分方程" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 微分方程</span>
                </a>
                
                <a href="../index.html?tags=线性" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 线性</span>
                </a>
                
                <a href="../index.html?tags=RNN" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> RNN</span>
                </a>
                
                <a href="../index.html?tags=ssm" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> ssm</span>
                </a>
                
                <a href="../index.html?tags=生成模型" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 生成模型</span>
                </a>
                
            </div>
            
        </header>

        <div class="row">
            <!-- Main Content -->
            <div class="col-lg-9">
                <!-- Post Body -->
                <div class="post-content">
                    <h1 id="ssmhippo">重温SSM（一）：线性系统和HiPPO矩阵<a class="toc-link" href="#ssmhippo" title="Permanent link">&para;</a></h1>
<p><strong>原文链接</strong>: <a href="https://spaces.ac.cn/archives/10114">https://spaces.ac.cn/archives/10114</a></p>
<p><strong>发布日期</strong>: </p>
<hr />
<p>前几天，笔者看了几篇介绍SSM（State Space Model）的文章，才发现原来自己从未认真了解过SSM，于是打算认真去学习一下SSM的相关内容，顺便开了这个新坑，记录一下学习所得。</p>
<p>SSM的概念由来已久，但这里我们特指深度学习中的SSM，一般认为其开篇之作是2021年的<a href="https://papers.cool/arxiv/2111.00396">S4</a>，不算太老，而SSM最新最火的变体大概是去年的<a href="https://papers.cool/arxiv/2312.00752">Mamba</a>。当然，当我们谈到SSM时，也可能泛指一切线性RNN模型，这样<a href="https://papers.cool/arxiv/2305.13048">RWKV</a>、<a href="https://papers.cool/arxiv/2307.08621">RetNet</a>还有此前我们在<a href="/archives/9554">《Google新作试图“复活”RNN：RNN能否再次辉煌？》</a>介绍过的LRU都可以归入此类。不少SSM变体致力于成为Transformer的竞争者，尽管笔者并不认为有完全替代的可能性，但SSM本身优雅的数学性质也值得学习一番。</p>
<p>尽管我们说SSM起源于S4，但在S4之前，SSM有一篇非常强大的奠基之作<a href="https://papers.cool/arxiv/2008.07669">《HiPPO: Recurrent Memory with Optimal Polynomial Projections》</a>（简称HiPPO），所以本文从HiPPO开始说起。</p>
<h2 id="_1">基本形式<a class="toc-link" href="#_1" title="Permanent link">&para;</a></h2>
<p>先插句题外话，上面提到的SSM代表作HiPPO、S4、Mamba的一作都是<a href="https://dblp.org/pid/130/0612.html">Albert Gu</a>，他还有很多篇SSM相关的作品，毫不夸张地说，这些工作筑起了SSM大厦的基础。不论SSM前景如何，这种坚持不懈地钻研同一个课题的精神都值得我们由衷地敬佩。</p>
<p>言归正传。对于事先已经对SSM有所了解的读者，想必知道SSM建模所用的是线性ODE系统：<br />
\begin{equation}\begin{aligned}
x'(t) =&amp;\, A x(t) + B u(t) \\
y(t) =&amp;\, C x(t) + D u(t)
\end{aligned}\label{eq:ode}\end{equation}<br />
其中$u(t)\in\mathbb{R}^{d_i}, x(t)\in\mathbb{R}^{d}, y(t)\in\mathbb{R}^{d_o}, A\in\mathbb{R}^{d\times d}, B\in\mathbb{R}^{d\times d_i}, C\in\mathbb{R}^{d_o\times d}, D\in\mathbb{R}^{d_o\times d_i}
$。当然我们也可以将它离散化，那么就变成一个线性RNN模型，这部分我们在后面的文章再展开。不管离散化与否，其关键词都是“线性”，那么马上就有一个很自然的问题：为什么是线性系统？线性系统够了吗？</p>
<p>我们可以从两个角度回答这个问题：线性系统既足够<strong> <em>简单</em></strong> ，也足够<strong> <em>复杂</em></strong> 。<strong>简单</strong> 是指从理论上来说，线性化往往是复杂系统的一个最基本近似，所以线性系统通常都是无法绕开的一个基本点；<strong>复杂</strong> 是指即便如此简单的系统，也可以拟合异常复杂的函数，为了理解这一点，我们只需要考虑一个$\mathbb{R}^4$的简单例子：<br />
\begin{equation}
x'(t) =\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; -1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; -1 &amp; 0
\end{pmatrix}x(t)\end{equation}<br />
这个例子的基本解是$x(t) = (e^t, e^{-t}, \sin t, \cos t)$。这意味着什么呢？意味着只要$d$足够大，该线性系统就可以通过指数函数和三角函数的组合来拟合足够复杂的函数，而我们知道拟合能力很强的傅里叶级数也只不过是三角函数的组合，如果在加上指数函数显然就更强了，因此可以想象线性系统也有足够复杂的拟合能力。</p>
<p>当然，这些解释某种意义上都是“马后炮”。HiPPO给出的结果更加本质：当我们试图用正交基去逼近一个动态更新的函数时，其结果就是如上的线性系统。这意味着，HiPPO不仅告诉我们线性系统可以逼近足够复杂的函数，还告诉我们怎么去逼近，甚至近似程度如何。</p>
<h2 id="_2">有限压缩<a class="toc-link" href="#_2" title="Permanent link">&para;</a></h2>
<p>接下来，我们都只考虑$d_i=1$的特殊情形，$d_i &gt; 1$只不过是$d_i=1$时的平行推广。此时，$u(t)$的输出是一个标量，进一步地，作为开头我们先假设$t\in[0, 1]$，HiPPO的目标是：<strong>用一个有限维的向量来储存这一段$u(t)$的信息。</strong></p>
<p>看上去这是一个不大可能的需求，因为$t\in[0,1]$意味着$u(t)$可能相当于无限个点组成的向量，压缩到一个有限维的向量可能严重失真。不过，如果我们对$u(t)$做一些假设，并且允许一些损失，那么这个压缩是有可能做到的，并且大多数读者都已经尝试过。比如，当$u(t)$在某点$n+1$阶可导的，它对应的$n$阶泰勒展开式往往是$u(t)$的良好近似，于是我们可以只储存展开式的$n+1$个系数来作为$u(t)$的近似表征，这就成功将$u(t)$压缩为一个$n+1$维向量。</p>
<p>当然，对于实际遇到的数据来说，“$n+1$阶可导”这种条件可谓极其苛刻，我们通常更愿意使用在平方可积条件下的正交函数基展开，比如傅里叶（Fourier）级数，它的系数计算公式为<br />
\begin{equation}c_n = \int_0^1 u(t) e^{-2i\pi n t}dt \label{eq:fourier-coef-1}\end{equation}<br />
这时候取一个足够大的整数$N$，只保留$|n|\leq N$的系数，那么就将$u(t)$压缩为一个$2N + 1$维的向量了。</p>
<p>接下来，问题难度就要升级了。刚才我们说$t\in[0,1]$，这是一个静态的区间，而实际中$u(t)$代表的是持续采集的信号，所以它是不断有新数据进入的，比如现在我们近似了$[0,1]$区间的数据，马上就有$[1,2]$的数据进来，你需要更新逼近结果来试图记忆整个$[0,2]$区间，接下来是$[0,3]$、$[0,4]$等等，这我们称为“在线函数逼近”。而上面的傅里叶系数公式$\eqref{eq:fourier-coef-1}$，只适用于区间$[0,1]$，因此需要将它进行推广。</p>
<p>为此，我们设$t\in[0,T]$，$s\mapsto t_{\leq T}(s)$是$[0,1]$到$[0,T]$的一个映射，那么$u(t_{\leq T}(s))$作为$s$的函数时，它的定义区间就是$[0,1]$，于是就可以复用式$\eqref{eq:fourier-coef-1}$：<br />
\begin{equation}c_n(T) = \int_0^1 u(t_{\leq T}(s)) e^{-2i\pi n s}ds \label{eq:fourier-coef-2}\end{equation}<br />
这里我们已经给系数加了标记$(T)$，以表明此时的系数会随着$T$的变化而变化。</p>
<h2 id="_3">线性初现<a class="toc-link" href="#_3" title="Permanent link">&para;</a></h2>
<p>能将$[0,1]$映射到$[0,T]$的函数有无穷多，而最终结果也因$t_{\leq T}(s)$而异，一些比较直观且相对简单的选择如下：</p>
<blockquote>
<p>1、$t_{\leq T}(s) = sT$，即将$[0,1]$均匀地映射到$[0,T]$；</p>
<p>2、注意$t_{\leq T}(s)$并不必须是满射，所以像$t_{\leq T}(s)=s + T - 1$也是允许的，这意味着只保留了最邻近窗口$[T-1,T]$的信息，丢掉了更早的部分，更一般地有$t_{\leq T}(s)=sw + T - w$，其中$w$是一个常数，这意味着$T-w$前的信息被丢掉了；</p>
<p>3、也可以选择非均匀映射，比如$t_{\leq T}(s) = T\sqrt{s}$，它同样是$[0,1]$到$[0,T]$的满射，但$s=1/4$时就映射到$T/2$了，这意味着我们虽然关注全局的历史，但同时更侧重于$T$时刻附近的信息。</p>
</blockquote>
<p>现在我们以$t_{\leq T}(s)=sw + T - w$为例，代入式$\eqref{eq:fourier-coef-2}$得到<br />
\begin{equation}c_n(T) = \int_0^1 u(sw + T - w) e^{-2i\pi n s}ds\end{equation}<br />
现在我们两边求关于$T$的导数：<br />
\begin{equation}\begin{aligned}
\frac{d}{dT}c_n(T) =&amp;\, \int_0^1 u'(sw + T - w) e^{-2i\pi n s}ds \\
=&amp;\, \left.\frac{1}{w} u(sw + T - w) e^{-2i\pi n s}\right|<em k="-N">{s=0}^{s=1} + \frac{2i\pi n}{w}\int_0^1 u(sw + T - w) e^{-2i\pi n s}ds \\
=&amp;\, \frac{1}{w} u(T) - \frac{1}{w} u(T-w) + \frac{2i\pi n}{w} c_n(T) \\
\end{aligned}\label{eq:fourier-dc}\end{equation}<br />
其中第二个等号我们用了分部积分公式。由于我们只保留了$|n|\leq N$的系数，所以根据傅立叶级数的公式，可以认为如下是$u(sw + T - w)$的一个良好近似：<br />
\begin{equation}u(sw + T - w) \approx \sum</em>}^{k=N} c_k(T) e^{2i\pi k s}\end{equation
那么$u(T - w) = u(sw + T - w)|<em k="-N">{s=0}\approx \sum\limits</em>$得：}^{k=N} c_k(T)$，代入式$\eqref{eq:fourier-dc<br />
\begin{equation}\frac{d}{dT}c_n(T) \approx \frac{1}{w} u(T) - \frac{1}{w} \sum_{k=-N}^{k=N} c_k(T) + \frac{2i\pi n}{w} c_n(T)\end{equation}<br />
将$T$换成$t$，然后所有的$c_n(t)$堆在一起记为$x(t) = (c_{-N},c_{-(N-1)},\cdots,c_0,\cdots,c_{N-1},c_N)$，并且不区分$\approx$和$=$，那么就可以写出<br />
\begin{equation}x'(t) = Ax(t) + Bu(t),\quad A_{n,k} = \left\{\begin{array}{l}(2i\pi n - 1)/w, &amp;k=n \\ -1/w,&amp;k\neq n\end{array}\right.,\quad B_n = 1/w\end{equation}<br />
这就出现了如式$\eqref{eq:ode}$所示的线性ODE系统。即当我们试图用傅里叶级数去记忆一个实时函数的最邻近窗口内的状态时，结果自然而言地导致了一个线性ODE系统。</p>
<h2 id="_4">一般框架<a class="toc-link" href="#_4" title="Permanent link">&para;</a></h2>
<p>当然，目前只是选择了一个特殊的$t_{\leq T}(s)$，换一个$t_{\leq T}(s)$就不一定有这么简单的结果了。此外，傅里叶级数的结论是在复数范围内的，进一步实数化也可以，但形式会变得复杂起来。所以，我们要将上一节的过程推广成一个一般化的框架，从而得到更一般、更简单的纯实数结论。</p>
<p>设$t\in[a,b]$，并且有目标函数$u(t)$和函数基$\{g_n(t)\}<em c_1_cdots_c_N="c_1,\cdots,c_N">{n=0}^N$，我们希望有后者的线性组合来逼近前者，目标是最小化$L_2$距离：<br />
\begin{equation}\mathop{\text{argmin}}</em>}\int_a^b \left[u(t) - \sum_{n=0}^N c_n g_n(t)\right]^2 dt\end{equation
这里我们主要在实数范围内考虑，所以方括号直接平方就行，不用取模。更一般化的目标函数还可以再加个权重函数$\rho(t)$，但我们这里就不考虑了，毕竟HiPPO的主要结论其实也没考虑这个权重函数。</p>
<p>对目标函数展开，得到
\begin{equation}\int_a^b u^2(t) dt - 2\sum_{n=0}^N c_n \int_a^b u(t) g_n(t)dt + \sum_{m=0}^N\sum_{n=0}^N c_m c_n \int_a^b g_m(t) g_n(t) dt\end{equation}<br />
这里我们只考虑<strong>标准正交函数基</strong> ，其定义为$\int_a^b g_m(t) g_n(t) dt = \delta_{m,n}$，$\delta_{m,n}$是<a href="https://en.wikipedia.org/wiki/Kronecker_delta">克罗内克δ函数</a>，此时上式可以简化成<br />
\begin{equation}\int_a^b u^2(t) dt - 2\sum_{n=0}^N c_n \int_a^b u(t) g_n(t)dt + \sum_{n=0}^N c_n^2 \end{equation}<br />
这只是一个关于$c_n$的二次函数，它的最小值是有解析解的：<br />
\begin{equation}c^<em>_n = \int_a^b u(t) g_n(t)dt\end{equation}<br />
这也被称为$u(t)$与$g_n(t)$的内积，它是有限维向量空间的内积到函数空间的平行推广。简单起见，在不至于混淆的情况下，我们默认$c_n$就是$c^</em>_n$。</p>
<p>接下来的处理跟上一节是一样的，我们要对一般的$t\in[0, T]$考虑$u(t)$的近似，那么找一个$[a,b]$到$[0,T]$的映射$s\mapsto t_{\leq T}(s)$，然后计算系数<br />
\begin{equation}c_n(T) = \int_a^b u(t_{\leq T}(s)) g_n(s) ds\end{equation}<br />
同样是两边求$T$的导数，然后用分部积分法<br />
\begin{equation}\scriptsize\begin{aligned}
\frac{d}{dT}c_n(T) =&amp;\, \int_a^b u'(t_{\leq T}(s)) \frac{\partial t_{\leq T}(s)}{\partial T} g_n(s) ds = \int_a^b \left(\frac{\partial t_{\leq T}(s)}{\partial T}\left/\frac{\partial t_{\leq T}(s)}{\partial s}\right.\right) g_n(s) d u(t_{\leq T}(s)) \\
=&amp;\,\left.u(t_{\leq T}(s))\left(\frac{\partial t_{\leq T}(s)}{\partial T}\left/\frac{\partial t_{\leq T}(s)}{\partial s}\right.\right) g_n(s)\right|<em T="T" _leq="\leq">{s=a}^{s=b} - \int_a^b u(t</em>\right.\right) g_n(s)\right]}(s)) \,d\left[\left(\frac{\partial t_{\leq T}(s)}{\partial T}\left/\frac{\partial t_{\leq T}(s)}{\partial s
\end{aligned}\label{eq:hippo-base}\end{equation}</p>
<h2 id="_5">请勒让德<a class="toc-link" href="#_5" title="Permanent link">&para;</a></h2>
<p>接下来的计算，就依赖于$g_n(t)$和$t_{\leq T}(s)$的具体形式了。HiPPO的全称是High-order Polynomial Projection Operators，第一个P正是多项式（Polynomial）的首字母，所以HiPPO的关键是选取多项式为基。现在我们请出继傅里叶之后又一位大牛——勒让德（Legendre），接下来我们要选取的函数基正是以他命名的“<a href="https://en.wikipedia.org/wiki/Legendre_polynomials">勒让德多项式</a>”。</p>
<p>勒让德多项式$p_n(t)$是关于$t$的$n$次函数，定义域为$[-1,1]$，满足<br />
\begin{equation}\int_{-1}^1 p_m(t) p_n(t) dt = \frac{2}{2n+1}\delta_{m,n}\end{equation}<br />
所以$p_n(t)$之间只是正交，还不是标准（平分积分为1），$g_n(t)=\sqrt{\frac{2n+1}{2}} p_n(t)$才是标准正交基。</p>
<p>当我们对函数基$\{1,t,t^2,\cdots, t^n\}$执行<a href="https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process">施密特正交化</a>时，其结果正是勒让德多项式。相比傅里叶基，勒让德多项式的好处是它是纯粹定义在实数空间中的，并且多项式的形式能够有助于简化部分$t_{\leq T}(s)$的推导过程，这一点我们后面就可以看到。勒让德多项式有很多不同的定义和性质，这里我们不一一展开，有兴趣的读者自行看链接中维基百科介绍即可。</p>
<p>接下来我们用到两个递归公式来推导一个恒等式，这两个递归公式是<br />
\begin{align}
p_{n+1}'(t) - p_{n-1}'(t) = (2n+1)p_n(t) \label{eq:leg-r1}\\[5pt]
p_{n+1}'(t) = (n + 1)p_n(t) + t p_n'(t) \label{eq:leg-r2}\\
\end{align}<br />
由第一个公式$\eqref{eq:leg-r1}$迭代得到：<br />
\begin{equation}\begin{aligned}
p_{n+1}'(t) =&amp;\, (2n+1)p_n(t) + (2n-3)p_{n-2}(t) + (2n-7)p_{n-4}(t) + \cdots \\
=&amp;\, \sum_{k=0}^n (2k+1) \chi_{n-k} p_k(t)
\end{aligned}\label{eq:leg-dot}\end{equation}<br />
其中当$k$是偶数时$\chi_k=1$否则$\chi_k=0$。代入第二个公式$\eqref{eq:leg-r2}$得到<br />
\begin{equation}t p_n'(t) = n p_n(t) + (2n-3)p_{n-2}(t) + (2n-7)p_{n-4}(t) + \cdots\end{equation}<br />
继而有<br />
\begin{equation}\begin{aligned}
(t+1) p_n'(t) =&amp;\, n p_n(t) + (2n-1)p_{n-1}(t) + (2n-3)p_{n-2}(t) + \cdots\\
=&amp;\,-(n+1) p_n(t) + \sum_{k=0}^n (2k + 1) p_k(t)
\end{aligned}\label{eq:leg-dot-t1}\end{equation}<br />
这些就是等会要用到的恒等式。此外，勒让德多项式满足$p_n(1)=1,p_n(-1)=(-1)^n$，这个边界值后面也会用到。</p>
<p>正如$n$维空间中不止有一组正交基也一样，正交多项式也不止有勒让德多项式一种，比如还有<a href="https://en.wikipedia.org/wiki/Chebyshev_polynomials">切比雪夫（Chebyshev）多项式</a>，如果算上加权的目标函数（即$\rho(t)\not\equiv 1$），还有<a href="https://en.wikipedia.org/wiki/Laguerre_polynomials">拉盖尔多项式</a>等，这些在原论文中都有提及，但HiPPO的主要结论还是基于勒让德多项式展开的，所以剩余部分这里也不展开讨论了。</p>
<h2 id="_6">邻近窗口<a class="toc-link" href="#_6" title="Permanent link">&para;</a></h2>
<p>完成准备工作后，我们就可以代入具体的$t_{\leq T}(s)$进行计算了，计算过程跟傅里叶级数的例子大同小异，只不过基函数换成了勒让德多项式构造的标准正交基$g_n(t)=\sqrt{\frac{2n+1}{2}} p_n(t)$。作为第一个例子，我们同样先考虑只保留最邻近窗口的信息，此时$t_{\leq T}(s) = (s + 1)w / 2 + T - w$将$[-1,1]$映射到$[T-w,T]$，原论文将这种情形称为“<strong>LegT（Translated Legendre）</strong> ”。</p>
<p>直接代入式$\eqref{eq:hippo-base}$，马上得到<br />
\begin{equation}\small\frac{d}{dT}c_n(T) = \frac{\sqrt{2(2n+1)}}{w}\left[u(T) - (-1)^n u(T-w)\right] - \frac{2}{w}\int_{-1}^1 u((s + 1)w / 2 + T - w) g_n'(s) ds\end{equation}<br />
我们首先处理$u(T-w)$项，跟傅里叶级数那里同样的思路，我们截断$n\leq N$作为$u((s + 1)w / 2 + T - w)$的一个近似：<br />
\begin{equation}u((s + 1)w / 2 + T - w)\approx \sum_{k=0}^N c_k(T)g_k(s)\end{equation}<br />
从而有$u(T-w)\approx \sum\limits_{k=0}^N c_k(T)g_k(-1) = \sum\limits_{k=0}^N (-1)^k c_k(T) \sqrt{\frac{2k+1}{2}}$。接着，利用式$\eqref{eq:leg-dot}$得到<br />
\begin{equation}\begin{aligned}
&amp;\,\int_{-1}^1 u((s + 1)w / 2 + T - w) g_n'(s) ds \\
=&amp;\,\int_{-1}^1 u((s + 1)w / 2 + T - w) \sqrt{\frac{2n+1}{2}} p_n'(s) ds \\
=&amp;\, \int_{-1}^1 u((s + 1)w / 2 + T - w)\sqrt{\frac{2n+1}{2}}\left[\sum_{k=0}^{n-1} (2k+1) \chi_{n-1-k} p_k(s)\right]ds \\
=&amp;\, \int_{-1}^1 u((s + 1)w / 2 + T - w)\sqrt{\frac{2n+1}{2}}\left[\sum_{k=0}^{n-1} \sqrt{2(2k+1)} \chi_{n-1-k} g_k(s)\right]ds \\
=&amp;\, \sqrt{2n+1}\sum_{k=0}^{n-1} \sqrt{2k+1} \chi_{n-1-k} c_k(T)
\end{aligned}\end{equation}<br />
将这些结果整合起来，就有<br />
\begin{equation}\begin{aligned}
\frac{d}{dT}c_n(T) \approx &amp;\, \frac{\sqrt{2(2n+1)}}{w}u(T) - \frac{\sqrt{2(2n+1)}}{w} (-1)^n \overbrace{\sum\limits_{k=0}^N (-1)^k c_k(T) \sqrt{\frac{2k+1}{2}}}^{u(T-w)} \\
&amp;\quad- \frac{2}{w}\overbrace{\sqrt{2n+1}\sum_{k=0}^{n-1} \sqrt{2k+1} \chi_{n-1-k} c_k(T)}^{\int_{-1}^1 u((s + 1)w / 2 + T - w) g_n'(s) ds} \\[12pt]
= &amp;\, \frac{\sqrt{2(2n+1)}}{w}u(T) - \frac{\sqrt{2n+1}}{w} \sum\limits_{k=0}^N (-1)^{n-k} c_k(T) \sqrt{2k+1} \\
&amp;\quad- \frac{2}{w}\sqrt{2n+1}\sum_{k=0}^{n-1} \sqrt{2k+1} \chi_{n-1-k} c_k(T) \\[12pt]
= &amp;\, \frac{\sqrt{2(2n+1)}}{w}u(T) - \frac{\sqrt{2n+1}}{w} \sum\limits_{k=n}^N (-1)^{n-k} c_k(T) \sqrt{2k+1} \\
&amp;\quad- \frac{\sqrt{2n+1}}{w}\sum_{k=0}^{n-1} \sqrt{2k+1} \underbrace{\left(2\chi_{n-1-k} + (-1)^{n-k}\right)}<em n_k="n,k">{\equiv 1}c_k(T) \\
\end{aligned}\label{eq:leg-t}\end{equation}<br />
再次地，将$T$换回$t$，并将所有的$c_n(t)$堆在一起记为$x(t) = (c_0,c_1,\cdots,c_N)$，那么根据上式可以写出<br />
\begin{equation}\begin{aligned}
x'(t) =&amp;\, Ax(t) + Bu(t)\\[8pt]
\quad A</em>\right.\\[8pt]} =&amp;\, -\frac{1}{w}\left\{\begin{array}{l}\sqrt{(2n+1)(2k+1)}, &amp;k &lt; n \\ (-1)^{n-k}\sqrt{(2n+1)(2k+1)}, &amp;k \geq n\end{array
B_n =&amp;\, \frac{1}{w}\sqrt{2(2n+1)}<br />
\end{aligned}\label{eq:leg-t-hippo-1}\end{equation}<br />
我们还可以给每个$c_n(T)$都引入一个缩放因子，来使得上述结果更一般化。比如我们设$c_n(T) = \lambda_n \tilde{c}<em k="n">n(T)$，代入式$\eqref{eq:leg-t}$整理得<br />
\begin{equation}\begin{aligned}
\frac{d}{dt}\tilde{c}_n(T) \approx &amp;\, \frac{\sqrt{2(2n+1)}}{w\lambda_n}u(T) - \frac{\sqrt{2n+1}}{w} \sum\limits</em>}^N (-1)^{n-k} \tilde{c<em k="0">k(T) \frac{\lambda_k\sqrt{2k+1}}{\lambda_n} \\
&amp;\quad- \frac{\sqrt{2n+1}}{w}\sum</em>}^{n-1} \frac{\lambda_k\sqrt{2k+1}}{\lambda_n} \tilde{c<em n_k="n,k">k(T) \\
\end{aligned}\end{equation}<br />
如果取$\lambda_n = \sqrt{2}$，那么$A$不变，$B_n = \frac{1}{w}\sqrt{2n+1}$，这就对齐了原论文的结果，如果取$\lambda_n = \frac{2}{\sqrt{2n+1}}$，那么就得到了<a href="https://proceedings.neurips.cc/paper/2019/file/952285b9b7e7a1be5aa7849f32ffff05-Paper.pdf">Legendre Memory Units</a>中的结果<br />
\begin{equation}\begin{aligned}
x'(t) =&amp;\, Ax(t) + Bu(t)\\[8pt]
\quad A</em>\right.\\[8pt]} =&amp;\, -\frac{1}{w}\left\{\begin{array}{l}2n+1, &amp;k &lt; n \\ (-1)^{n-k}(2n+1), &amp;k \geq n\end{array
B_n =&amp;\, \frac{1}{w}(2n+1)<br />
\end{aligned}\label{eq:leg-t-hippo-2}\end{equation}<br />
这些形式在理论上都是等价的，但可能存在不同的数值稳定性。比如一般来说当$u(t)$的性态不是特别糟糕时，我们可以预期$n$越大，$|c_n|$的值就相对越小，这样直接用$c_n$的话$x(t)$向量的每个分量的尺度就不大对等，这样的系统在实际计算时容易出现数值稳定问题，而取$\lambda_n = \frac{2}{\sqrt{2n+1}}$改用$\tilde{c}_n$的话意味着数值小的分量会被适当放大，可能有助于缓解多尺度问题从而使得数值计算更稳定。</p>
<h2 id="_7">整个区间<a class="toc-link" href="#_7" title="Permanent link">&para;</a></h2>
<p>现在我们继续计算另一个例子：$t_{\leq T}(s) = (s + 1)T / 2$，它将$[-1,1]$均匀映射到$[0,T]$，这意味着我们没有舍弃任何历史信息，并且平等地对待所有历史，原论文将这种情形称为“<strong>LegS（Scaled Legendre）</strong> ”。</p>
<p>同样地，通过代入式$\eqref{eq:hippo-base}$得到<br />
\begin{equation}\frac{d}{dT}c_n(T) = \frac{\sqrt{2(2n+1)}}{T}u(T) - \frac{1}{T}\int_{-1}^1 u((s + 1)T / 2) \left[g_n(s) + (s+1) g_n'(s)\right] ds\end{equation}<br />
利用公式$\eqref{eq:leg-dot-t1}$得到<br />
\begin{equation}\begin{aligned}
&amp;\,\int_{-1}^1 u((s + 1)T / 2) \left[g_n(s) + (s+1) g_n'(s)\right] ds \\
=&amp;\,c_n(T) + \int_{-1}^1 u((s + 1)T / 2) (s+1) g_n'(s) ds \\
=&amp;\, c_n(T) + \int_{-1}^1 u((s + 1)T / 2)(s+1) \sqrt{\frac{2n+1}{2}} p_n'(s) \\
=&amp;\, c_n(T) + \int_{-1}^1 u((s + 1)T / 2)\sqrt{\frac{2n+1}{2}}\left[-(n+1) p_n(s) + \sum_{k=0}^n (2k + 1) p_k(s)\right] ds \\
=&amp;\, c_n(T) + \int_{-1}^1 u((s + 1)T / 2)\left[-(n+1) g_n(s) + \sum_{k=0}^n \sqrt{(2n+1)(2k + 1)} g_k(s)\right] ds \\
=&amp;\, -n c_n(T) + \sum_{k=0}^n \sqrt{(2n+1)(2k + 1)} c_k(T) \\
\end{aligned}\end{equation}<br />
于是有<br />
\begin{equation}\frac{d}{dT}c_n(T) = \frac{\sqrt{2(2n+1)}}{T}u(T) - \frac{1}{T}\left(-n c_n(T) + \sum_{k=0}^n \sqrt{(2n+1)(2k + 1)} c_k(T)\right)\label{eq:leg-s}\end{equation}<br />
将$T$换回$t$，将所有的$c_n(t)$堆在一起记为$x(t) = (c_0,c_1,\cdots,c_N)$，那么根据上式可以写出<br />
\begin{equation}\begin{aligned}
x'(t) =&amp;\, \frac{A}{t}x(t) + \frac{B}{t}u(t)\\[8pt]
\quad A_{n,k} =&amp;\, -\left\{\begin{array}{l}\sqrt{(2n+1)(2k+1)}, &amp;k &lt; n \\ n+1, &amp;k = n \\
0, &amp;k &gt; n\end{array}\right.\\[8pt]<br />
B_n =&amp;\, \sqrt{2(2n+1)}<br />
\end{aligned}\label{eq:leg-s-hippo}\end{equation}<br />
引入缩放因子来一般化结果也是可行的：设$c_n(T) = \lambda_n \tilde{c}<em k="0">n(T)$，代入式$\eqref{eq:leg-t}$整理得<br />
\begin{equation}\frac{d}{dT}\tilde{c}_n(T) = \frac{\sqrt{2(2n+1)}}{T\lambda_n}u(T) - \frac{1}{T}\left(-n \tilde{c}_n(T) + \sum</em>}^n \frac{\sqrt{(2n+1)(2k + 1)}\lambda_k}{\lambda_n} \tilde{c<em n_k="n,k">k(T)\right)\end{equation}<br />
取$\lambda_n=\sqrt{2}$就可以让$A$不变，$B$变为$B_n = \sqrt{2n+1}$，就对齐了原论文的结果。如果取$\lambda_n=\sqrt{\frac{2}{2n+1}}$，就可以像上一节LegT的结果一样去掉根号<br />
\begin{equation}\begin{aligned}
x'(t) =&amp;\, \frac{A}{t}x(t) + \frac{B}{t}u(t)\\[8pt]
\quad A</em>2n+1, &amp;k &lt; n \\ n+1, &amp;k = n \\} =&amp;\, -\left\{\begin{array}{l
0, &amp;k &gt; n\end{array}\right.\\[8pt]<br />
B_n =&amp;\, 2n+1<br />
\end{aligned}\label{eq:leg-s-hippo-2}\end{equation}<br />
但原论文没有考虑这种情况，原因不详。</p>
<h2 id="_8">延伸思考<a class="toc-link" href="#_8" title="Permanent link">&para;</a></h2>
<p>回顾Leg-S的整个推导，我们可以发现其中关键一步是将$(s+1) g_n'(s)$拆成$g_0(s),g_1(s),\cdots,g_n(s)$的线性组合，对于正交多项式来说，$(s+1) g_n'(s)$是一个$n$次多项式，所以这种拆分必然可以精确成立，但如果是傅立叶级数的情况，$g_n(s)$是指数函数，此时类似的拆分做不到了，至少不能精确地做到，所以可以说选取正交多项式为基的根本目的是简化后面推导。</p>
<p>特别要指出的是，HiPPO是一个自下而上的框架，它并没有一开始就假设系统必须是线性的，而是从正交基逼近的角度反过来推出其系数的动力学满足一个线性ODE系统，这样一来我们就可以确信，只要认可所做的假设，那么线性ODE系统的能力就是足够的，而不用去担心线性系统的能力限制了你的发挥。</p>
<p>当然，HiPPO对于每一个解所做的假设及其物理含义也很清晰，所以对于重用了HiPPO矩阵的SSM，它怎么储存历史、能储存多少历史，从背后的HiPPO假设就一清二楚。比如LegT就是只保留$w$大小的最邻近窗口信息，如果你用了LegT的HiPPO矩阵，那么就类似于一个Sliding Window Attention；而LegS理论上可以捕捉全部历史，但这有个分辨率问题，因为$x(t)$的维度代表了拟合的阶数，它是一个固定值，用同阶的函数基去拟合另一个函数，肯定是区间越小越准确，区间越大误差也越大，这就好比为了一次性看完一幅大图，那么我们必须站得更远，从而看到的细节越少。</p>
<p>诸如RWKV、LRU等模型，并没有重用HiPPO矩阵，而是改为可训练的矩阵，原则上具有更多的可能性来突破瓶颈，但从前面的分析大致上可以感知到，不同矩阵的线性ODE只是函数基不同，但本质上可能都只是有限阶函数基逼近的系数动力学。既然如此，分辨率与记忆长度就依然不可兼得，想要记忆更长的输入并且保持效果不变，那就只能增加整个模型的体量（即相当于增加hidden_size），这大概是所有线性系统的特性。</p>
<h2 id="_9">文章小结<a class="toc-link" href="#_9" title="Permanent link">&para;</a></h2>
<p>本文尽可能简单地重复了<a href="https://papers.cool/arxiv/2008.07669">《HiPPO: Recurrent Memory with Optimal Polynomial Projections》</a>（简称HiPPO）的主要推导。HiPPO通过适当的记忆假设，自下而上地导出了线性ODE系统，并且针对勒让德多项式的情形求出了相应的解析解（HiPPO矩阵），其结果被后来诸多SSM（State Space Model）使用，可谓是SSM的重要奠基之作。</p>
<p><em><strong>转载到请包括本文地址：</strong><a href="https://spaces.ac.cn/archives/10114">https://spaces.ac.cn/archives/10114</a></em></p>
<p><em><strong>更详细的转载事宜请参考：</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="《科学空间FAQ》">《科学空间FAQ》</a></p>
<p><strong>如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。</strong></p>
<p><strong>如果您觉得本文还不错，欢迎分享/打赏本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！</strong></p>
<p>打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>微信打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>支付宝打赏</p>
<p>因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>点击这里</strong></a>或在下方评论区留言来告知你的建议或需求。</p>
<p><strong>如果您需要引用本文，请参考：</strong></p>
<p>苏剑林. (May. 24, 2024). 《重温SSM（一）：线性系统和HiPPO矩阵 》[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/10114">https://spaces.ac.cn/archives/10114</a></p>
<p>@online{kexuefm-10114,<br />
title={重温SSM（一）：线性系统和HiPPO矩阵},<br />
author={苏剑林},<br />
year={2024},<br />
month={May},<br />
url={\url{https://spaces.ac.cn/archives/10114}},<br />
} </p>
<hr />
<h2 id="_10">公式推导与注释<a class="toc-link" href="#_10" title="Permanent link">&para;</a></h2>
<p>本节详细推导HiPPO (High-order Polynomial Projection Operators) 框架，包括线性时不变系统基础、Legendre多项式、HiPPO矩阵显式形式、记忆机制等。所有重要公式使用编号标记。</p>
<h3 id="1">1. 线性时不变系统基础<a class="toc-link" href="#1" title="Permanent link">&para;</a></h3>
<p><strong>定义1.1 (线性时不变系统 Linear Time-Invariant System)</strong>:  线性时不变(LTI)系统的连续时间形式为：</p>
<p>\begin{equation}
\begin{cases}
\dot{x}(t) = A x(t) + B u(t) \
y(t) = C x(t) + D u(t)
\end{cases}
\tag{1}
\end{equation}</p>
<p>其中：
- $u(t) \in \mathbb{R}^{d_i}$ 是输入信号
- $x(t) \in \mathbb{R}^{d}$ 是隐状态（记忆）
- $y(t) \in \mathbb{R}^{d_o}$ 是输出
- $A \in \mathbb{R}^{d \times d}$ 是状态转移矩阵
- $B \in \mathbb{R}^{d \times d_i}$ 是输入矩阵
- $C \in \mathbb{R}^{d_o \times d}$ 是输出矩阵
- $D \in \mathbb{R}^{d_o \times d_i}$ 是直接传递矩阵</p>
<p><strong>定理1.2 (LTI系统解)</strong>: 给定初始条件 $x(0) = x_0$，系统(1)的解为：</p>
<p>\begin{equation}
x(t) = e^{At} x_0 + \int_0^t e^{A(t-\tau)} B u(\tau) d\tau
\tag{2}
\end{equation}</p>
<p>其中矩阵指数定义为：</p>
<p>\begin{equation}
e^{At} = \sum_{k=0}^{\infty} \frac{(At)^k}{k!} = I + At + \frac{(At)^2}{2!} + \cdots
\tag{3}
\end{equation}</p>
<p><strong>几何意义</strong>:
- 第一项：初始状态的演化（自由响应）
- 第二项：输入信号的累积影响（强迫响应）</p>
<p><strong>命题1.3 (特征值与稳定性)</strong>: 设 $A$ 的特征值为 $\lambda_1, \ldots, \lambda_d$，则：
- 若 $\text{Re}(\lambda_i) &lt; 0$ 对所有 $i$ 成立，系统渐近稳定
- 若存在 $\text{Re}(\lambda_i) &gt; 0$，系统不稳定
- 边界情况 $\text{Re}(\lambda_i) = 0$ 需进一步分析</p>
<p><strong>示例1.4</strong>: 对角化系统</p>
<p>\begin{equation}
A = \begin{pmatrix}
\lambda_1 &amp; 0 &amp; 0 \
0 &amp; \lambda_2 &amp; 0 \
0 &amp; 0 &amp; \lambda_3
\end{pmatrix}
\tag{4}
\end{equation}</p>
<p>则：</p>
<p>\begin{equation}
e^{At} = \begin{pmatrix}
e^{\lambda_1 t} &amp; 0 &amp; 0 \
0 &amp; e^{\lambda_2 t} &amp; 0 \
0 &amp; 0 &amp; e^{\lambda_3 t}
\end{pmatrix}
\tag{5}
\end{equation}</p>
<p>基本解包含指数函数族 ${e^{\lambda_1 t}, e^{\lambda_2 t}, e^{\lambda_3 t}}$。</p>
<h3 id="2">2. 为什么选择线性系统？<a class="toc-link" href="#2" title="Permanent link">&para;</a></h3>
<p><strong>命题2.1 (表达能力)</strong>: 即使 $A$ 只包含实数特征值和成对共轭复特征值，线性系统也能表达复杂函数。</p>
<p><strong>示例</strong>: 考虑4维系统：</p>
<p>\begin{equation}
A = \begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \
0 &amp; -1 &amp; 0 &amp; 0 \
0 &amp; 0 &amp; 0 &amp; \omega \
0 &amp; 0 &amp; -\omega &amp; 0
\end{pmatrix}
\tag{6}
\end{equation}</p>
<p>基本解为：</p>
<p>\begin{equation}
x(t) = \begin{pmatrix}
e^{t} \
e^{-t} \
\sin(\omega t) \
\cos(\omega t)
\end{pmatrix}
\tag{7}
\end{equation}</p>
<p>包含：
- 指数增长/衰减：$e^{\pm t}$
- 周期振荡：$\sin(\omega t), \cos(\omega t)$</p>
<p><strong>定理2.2 (万能逼近)</strong>: 对于足够大的 $d$，线性系统可以通过指数和三角函数的线性组合逼近任意连续函数（类似傅里叶级数的思想）。</p>
<h3 id="3-hippo">3. HiPPO框架的动机<a class="toc-link" href="#3-hippo" title="Permanent link">&para;</a></h3>
<p><strong>问题陈述</strong>: 给定实时信号 $u(t)$，如何用<strong>有限维</strong>向量 $x(t) \in \mathbb{R}^d$ 存储历史信息？</p>
<p><strong>挑战</strong>:
- 信号 $u:[0,t] \to \mathbb{R}$ 是无限维的
- 需要有损压缩
- 需要在线更新（随 $t$ 增长）</p>
<p><strong>HiPPO思路</strong>: 用正交多项式基逼近历史信号，存储投影系数。</p>
<p><strong>定义3.1 (函数逼近问题)</strong>: 设 $g_0(s), g_1(s), \ldots, g_{N-1}(s)$ 是区间 $[a,b]$ 上的标准正交基，即：</p>
<p>\begin{equation}
\int_a^b g_i(s) g_j(s) ds = \delta_{ij}
\tag{8}
\end{equation}</p>
<p>对于函数 $f: [a,b] \to \mathbb{R}$，其最佳 $N$ 阶逼近为：</p>
<p>\begin{equation}
f(s) \approx \sum_{n=0}^{N-1} c_n g_n(s)
\tag{9}
\end{equation}</p>
<p>其中投影系数为：</p>
<p>\begin{equation}
c_n = \int_a^b f(s) g_n(s) ds
\tag{10}
\end{equation}</p>
<p><strong>命题3.2</strong>: 公式(9)的逼近在$L^2$范数下最优：</p>
<p>\begin{equation}
{c_0, \ldots, c_{N-1}} = \arg\min_{c'<em N-1="N-1">0, \ldots, c'</em> c'_n g_n(s) \right|^2 ds
\tag{11}
\end{equation}}} \int_a^b \left| f(s) - \sum_{n=0}^{N-1</p>
<h3 id="4">4. 在线函数逼近<a class="toc-link" href="#4" title="Permanent link">&para;</a></h3>
<p><strong>设定</strong>: 当前时刻为 $t$，历史信号为 $u(\tau)$，$\tau \in [0,t]$。</p>
<p><strong>关键问题</strong>: 区间 $[0,t]$ 随时间变化，如何标准化？</p>
<p><strong>方法</strong>: 引入映射 $s \mapsto t_{\leq t}(s)$，将固定区间 $[a,b]$ 映射到动态区间 $[0,t]$。</p>
<p><strong>定义4.1 (时间重参数化)</strong>: 定义映射族 ${t_{\leq t}(s)}<em _leq="\leq" t="t">{t \geq 0}$，满足：
- 对每个 $t$，$t</em>: [a,b] \to [0,t]$ 是单调映射
- $t_{\leq t}(a) = 0$ （可选，取决于记忆策略）</p>
<p><strong>投影系数的时间演化</strong>: 在时刻 $t$，系数定义为：</p>
<p>\begin{equation}
c_n(t) = \int_a^b u(t_{\leq t}(s)) g_n(s) ds
\tag{12}
\end{equation}</p>
<p><strong>定理4.2 (系数动力学推导)</strong>: 对 $c_n(t)$ 关于 $t$ 求导：</p>
<p>\begin{equation}
\begin{aligned}
\dot{c}<em _leq="\leq" t="t">n(t) &amp;= \frac{d}{dt} \int_a^b u(t</em>(s)) g_n(s) ds \
&amp;= \int_a^b \frac{\partial u(t_{\leq t}(s))}{\partial t} g_n(s) ds \
&amp;= \int_a^b u'(t_{\leq t}(s)) \frac{\partial t_{\leq t}(s)}{\partial t} g_n(s) ds
\end{aligned}
\tag{13}
\end{equation}</p>
<p>利用链式法则和分部积分：</p>
<p>\begin{equation}
\dot{c}<em _leq="\leq" t="t">n(t) = \int_a^b \left( \frac{\partial t</em>(s))
\tag{14}
\end{equation}}(s)}{\partial t} \bigg/ \frac{\partial t_{\leq t}(s)}{\partial s} \right) g_n(s) \, du(t_{\leq t</p>
<p>分部积分得：</p>
<p>\begin{equation}
\begin{aligned}
\dot{c}<em _leq="\leq" t="t">n(t) = &amp;\left. u(t</em> \right) g_n(s) \right|}(s)) \left( \frac{\partial t_{\leq t}(s)}{\partial t} \bigg/ \frac{\partial t_{\leq t}(s)}{\partial s<em _leq="\leq" t="t">a^b \
&amp;- \int_a^b u(t</em> \right) g_n(s) \right] ds
\end{aligned}
\tag{15}
\end{equation}}(s)) \frac{d}{ds} \left[ \left( \frac{\partial t_{\leq t}(s)}{\partial t} \bigg/ \frac{\partial t_{\leq t}(s)}{\partial s</p>
<p>这是<strong>HiPPO框架的核心公式</strong>。</p>
<h3 id="5-legendre">5. Legendre多项式基础<a class="toc-link" href="#5-legendre" title="Permanent link">&para;</a></h3>
<p><strong>定义5.1 (Legendre多项式)</strong>: Legendre多项式 $P_n(x)$ 定义在 $[-1,1]$ 上，满足：</p>
<p>\begin{equation}
\int_{-1}^1 P_m(x) P_n(x) dx = \frac{2}{2n+1} \delta_{mn}
\tag{16}
\end{equation}</p>
<p><strong>标准化</strong>: 定义标准正交基：</p>
<p>\begin{equation}
g_n(x) = \sqrt{\frac{2n+1}{2}} P_n(x)
\tag{17}
\end{equation}</p>
<p>使得 $\int_{-1}^1 g_m(x) g_n(x) dx = \delta_{mn}$。</p>
<p><strong>前几阶</strong>:</p>
<p>\begin{equation}
\begin{aligned}
P_0(x) &amp;= 1 \
P_1(x) &amp;= x \
P_2(x) &amp;= \frac{1}{2}(3x^2 - 1) \
P_3(x) &amp;= \frac{1}{2}(5x^3 - 3x) \
P_4(x) &amp;= \frac{1}{8}(35x^4 - 30x^2 + 3)
\end{aligned}
\tag{18}
\end{equation}</p>
<p><strong>递推关系</strong>:</p>
<p>\begin{equation}
(n+1) P_{n+1}(x) = (2n+1) x P_n(x) - n P_{n-1}(x)
\tag{19}
\end{equation}</p>
<p><strong>导数递推</strong>:</p>
<p>\begin{equation}
P'<em n-1="n-1">{n+1}(x) - P'</em>(x) = (2n+1) P_n(x)
\tag{20}
\end{equation}</p>
<p>\begin{equation}
P'_{n+1}(x) = (n+1) P_n(x) + x P'_n(x)
\tag{21}
\end{equation}</p>
<p><strong>边界值</strong>:</p>
<p>\begin{equation}
P_n(1) = 1, \quad P_n(-1) = (-1)^n
\tag{22}
\end{equation}</p>
<h3 id="6">6. 关键恒等式推导<a class="toc-link" href="#6" title="Permanent link">&para;</a></h3>
<p><strong>引理6.1</strong>: 从公式(20)迭代得：</p>
<p>\begin{equation}
P'<em k="0">{n+1}(x) = \sum</em> P_k(x)
\tag{23}
\end{equation}}^n (2k+1) \chi_{n-k</p>
<p>其中 $\chi_j = 1$ 当 $j$ 为偶数，否则 $\chi_j = 0$。</p>
<p><strong>证明</strong>: 递归应用(20)：</p>
<p>\begin{equation}
\begin{aligned}
P'<em n-1="n-1">{n+1}(x) &amp;= (2n+1) P_n(x) + P'</em>(x) \
&amp;= (2n+1) P_n(x) + (2n-3) P_{n-2}(x) + P'_{n-3}(x) \
&amp;= \cdots
\end{aligned}
\tag{24}
\end{equation}</p>
<p><strong>引理6.2</strong>: 结合(21)和(23)：</p>
<p>\begin{equation}
x P'<em n-2="n-2">n(x) = n P_n(x) + (2n-3) P</em>(x) + \cdots
\tag{25}
\end{equation}}(x) + (2n-7) P_{n-4</p>
<p><strong>引理6.3 (核心恒等式)</strong>:</p>
<p>\begin{equation}
(x+1) P'<em k="0">n(x) = -(n+1) P_n(x) + \sum</em>^n (2k+1) P_k(x)
\tag{26}
\end{equation}</p>
<p><strong>证明</strong>:</p>
<p>\begin{equation}
\begin{aligned}
(x+1) P'<em k="0">n(x) &amp;= x P'_n(x) + P'_n(x) \
&amp;= [n P_n(x) + \text{even terms}] + [(n+1)P_n(x) + \text{odd terms}] \
&amp;= \sum</em>^n (2k+1) P_k(x) - (n+1) P_n(x)
\end{aligned}
\tag{27}
\end{equation}</p>
<h3 id="7-hippo-legt-translated-legendre">7. HiPPO-LegT (Translated Legendre)<a class="toc-link" href="#7-hippo-legt-translated-legendre" title="Permanent link">&para;</a></h3>
<p><strong>记忆策略</strong>: 只保留最近窗口 $[t-\theta, t]$ 的信息（滑动窗口）。</p>
<p><strong>映射</strong>:</p>
<p>\begin{equation}
t_{\leq t}(s) = \frac{s+1}{2} \theta + (t - \theta)
\tag{28}
\end{equation}</p>
<p>将 $[-1,1]$ 映射到 $[t-\theta, t]$。</p>
<p><strong>计算偏导数</strong>:</p>
<p>\begin{equation}
\frac{\partial t_{\leq t}(s)}{\partial t} = 1, \quad \frac{\partial t_{\leq t}(s)}{\partial s} = \frac{\theta}{2}
\tag{29}
\end{equation}</p>
<p><strong>代入HiPPO框架(15)</strong>:</p>
<p>\begin{equation}
\begin{aligned}
\dot{c}<em _leq="\leq" t="t">n(t) = &amp;\left. u(t</em> g_n(s) \right|}(s)) \frac{2}{\theta<em -1="-1">{-1}^{1} \
&amp;- \int</em> g'_n(s) ds
\end{aligned}
\tag{30}
\end{equation}}^1 u(t_{\leq t}(s)) \frac{2}{\theta</p>
<p><strong>边界项</strong>:</p>
<p>\begin{equation}
\begin{aligned}
\text{边界} &amp;= \frac{2}{\theta} [u(t) g_n(1) - u(t-\theta) g_n(-1)] \
&amp;= \frac{2}{\theta} \sqrt{\frac{2n+1}{2}} [u(t) - (-1)^n u(t-\theta)]
\end{aligned}
\tag{31}
\end{equation}</p>
<p><strong>积分项</strong>: 利用公式(23)：</p>
<p>\begin{equation}
\begin{aligned}
&amp;\int_{-1}^1 u(t_{\leq t}(s)) g'<em -1="-1">n(s) ds \
=&amp; \int</em> P'}^1 u(t_{\leq t}(s)) \sqrt{\frac{2n+1}{2}<em -1="-1">n(s) ds \
=&amp; \int</em> P_k(s) ds \
=&amp; \sqrt{2n+1} \sum_{k=0}^{n-1} \sqrt{2k+1} \chi_{n-1-k} c_k(t)
\end{aligned}
\tag{32}
\end{equation}}^1 u(t_{\leq t}(s)) \sqrt{\frac{2n+1}{2}} \sum_{k=0}^{n-1} (2k+1) \chi_{n-1-k</p>
<p><strong>近似 $u(t-\theta)$</strong>:</p>
<p>\begin{equation}
u(t-\theta) = u(t_{\leq t}(-1)) \approx \sum_{k=0}^{N-1} c_k(t) g_k(-1) = \sum_{k=0}^{N-1} c_k(t) (-1)^k \sqrt{\frac{2k+1}{2}}
\tag{33}
\end{equation}</p>
<p><strong>最终动力学</strong>: 设 $x(t) = (c_0(t), c_1(t), \ldots, c_{N-1}(t))^T$，则：</p>
<p>\begin{equation}
\dot{x}(t) = \frac{1}{\theta} A^{(\text{LegT})} x(t) + \frac{1}{\theta} B^{(\text{LegT})} u(t)
\tag{34}
\end{equation}</p>
<p>其中：</p>
<p>\begin{equation}
A^{(\text{LegT})}_{nk} = -\begin{cases}
\sqrt{(2n+1)(2k+1)}, &amp; k &lt; n \
(-1)^{n-k} \sqrt{(2n+1)(2k+1)}, &amp; k \geq n
\end{cases}
\tag{35}
\end{equation}</p>
<p>\begin{equation}
B^{(\text{LegT})}_n = \sqrt{2(2n+1)}
\tag{36}
\end{equation}</p>
<p><strong>定理7.1 (LegT的显式形式)</strong>: LegT HiPPO矩阵为：</p>
<p>\begin{equation}
A^{(\text{LegT})} = -\begin{pmatrix}
1 &amp; -1 &amp; -\sqrt{3} &amp; -\sqrt{5} &amp; \cdots \
\sqrt{3} &amp; 3 &amp; -3 &amp; -\sqrt{15} &amp; \cdots \
\sqrt{5} &amp; \sqrt{15} &amp; 5 &amp; -5 &amp; \cdots \
\sqrt{7} &amp; \sqrt{21} &amp; \sqrt{35} &amp; 7 &amp; \cdots \
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \ddots
\end{pmatrix}
\tag{37}
\end{equation}</p>
<h3 id="8-hippo-legs-scaled-legendre">8. HiPPO-LegS (Scaled Legendre)<a class="toc-link" href="#8-hippo-legs-scaled-legendre" title="Permanent link">&para;</a></h3>
<p><strong>记忆策略</strong>: 保留全部历史 $[0,t]$，均匀缩放。</p>
<p><strong>映射</strong>:</p>
<p>\begin{equation}
t_{\leq t}(s) = \frac{s+1}{2} t
\tag{38}
\end{equation}</p>
<p>将 $[-1,1]$ 映射到 $[0,t]$。</p>
<p><strong>偏导数</strong>:</p>
<p>\begin{equation}
\frac{\partial t_{\leq t}(s)}{\partial t} = \frac{s+1}{2}, \quad \frac{\partial t_{\leq t}(s)}{\partial s} = \frac{t}{2}
\tag{39}
\end{equation}</p>
<p><strong>比值</strong>:</p>
<p>\begin{equation}
\frac{\partial t_{\leq t}(s)}{\partial t} \bigg/ \frac{\partial t_{\leq t}(s)}{\partial s} = \frac{s+1}{t}
\tag{40}
\end{equation}</p>
<p><strong>代入HiPPO框架</strong>:</p>
<p>\begin{equation}
\begin{aligned}
\dot{c}<em _leq="\leq" t="t">n(t) = &amp;\left. u(t</em> g_n(s) \right|}(s)) \frac{s+1}{t<em -1="-1">{-1}^{1} \
&amp;- \int</em> g_n(s)\right] ds
\end{aligned}
\tag{41}
\end{equation}}^1 u(t_{\leq t}(s)) \frac{d}{ds}\left[\frac{s+1}{t</p>
<p><strong>边界项</strong>: 由于 $t_{\leq t}(-1) = 0$，边界项为：</p>
<p>\begin{equation}
\text{边界} = \frac{1}{t} \left[2 u(t) g_n(1) - 0\right] = \frac{2}{t} \sqrt{\frac{2n+1}{2}} u(t)
\tag{42}
\end{equation}</p>
<p><strong>积分项</strong>:</p>
<p>\begin{equation}
\begin{aligned}
&amp;\int_{-1}^1 u(t_{\leq t}(s)) \frac{d}{ds}\left[\frac{s+1}{t} g_n(s)\right] ds \
=&amp; \frac{1}{t} \int_{-1}^1 u(t_{\leq t}(s)) \left[g_n(s) + (s+1) g'<em -1="-1">n(s)\right] ds \
=&amp; \frac{1}{t} \left[c_n(t) + \int</em> P'_n(s) ds\right]
\end{aligned}
\tag{43}
\end{equation}}^1 u(t_{\leq t}(s)) (s+1) \sqrt{\frac{2n+1}{2}</p>
<p>利用恒等式(26)：</p>
<p>\begin{equation}
\begin{aligned}
&amp;\int_{-1}^1 u(t_{\leq t}(s)) (s+1) P'<em -1="-1">n(s) ds \
=&amp; \int</em>^n (2k+1) P_k(s)\right] ds \
=&amp; \sqrt{\frac{2}{2n+1}} \left[-(n+1) c_n(t) + \sum_{k=0}^n \sqrt{(2n+1)(2k+1)} c_k(t)\right]
\end{aligned}
\tag{44}
\end{equation}}^1 u(t_{\leq t}(s)) \left[-(n+1) P_n(s) + \sum_{k=0</p>
<p><strong>最终动力学</strong>:</p>
<p>\begin{equation}
\dot{c}<em k="0">n(t) = \frac{1}{t} \left[\sqrt{2(2n+1)} u(t) + n c_n(t) - \sum</em> c_k(t)\right]
\tag{45}
\end{equation}}^n \sqrt{(2n+1)(2k+1)</p>
<p>设 $x(t) = (c_0, c_1, \ldots, c_{N-1})^T$：</p>
<p>\begin{equation}
\dot{x}(t) = \frac{1}{t} A^{(\text{LegS})} x(t) + \frac{1}{t} B^{(\text{LegS})} u(t)
\tag{46}
\end{equation}</p>
<p>其中：</p>
<p>\begin{equation}
A^{(\text{LegS})}_{nk} = -\begin{cases}
\sqrt{(2n+1)(2k+1)}, &amp; k &lt; n \
n+1, &amp; k = n \
0, &amp; k &gt; n
\end{cases}
\tag{47}
\end{equation}</p>
<p>\begin{equation}
B^{(\text{LegS})}_n = \sqrt{2(2n+1)}
\tag{48}
\end{equation}</p>
<p><strong>定理8.1 (LegS的显式形式)</strong>: LegS HiPPO矩阵为：</p>
<p>\begin{equation}
A^{(\text{LegS})} = -\begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; \cdots \
\sqrt{3} &amp; 2 &amp; 0 &amp; 0 &amp; \cdots \
\sqrt{5} &amp; \sqrt{15} &amp; 3 &amp; 0 &amp; \cdots \
\sqrt{7} &amp; \sqrt{21} &amp; \sqrt{35} &amp; 4 &amp; \cdots \
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \ddots
\end{pmatrix}
\tag{49}
\end{equation}</p>
<p>注意：LegS矩阵是<strong>下三角</strong>，LegT矩阵是<strong>全阵</strong>。</p>
<h3 id="9">9. 矩阵性质分析<a class="toc-link" href="#9" title="Permanent link">&para;</a></h3>
<p><strong>命题9.1 (LegT的性质)</strong>:
1. <strong>反对称部分</strong>: $A^{(\text{LegT})} + (A^{(\text{LegT})})^T$ 是对角矩阵
2. <strong>特征值</strong>: 具有负实部（保证稳定性）
3. <strong>记忆窗口</strong>: 固定为 $\theta$</p>
<p><strong>命题9.2 (LegS的性质)</strong>:
1. <strong>下三角</strong>: 易于计算矩阵指数
2. <strong>特征值</strong>: 对角线元素 $-1, -2, -3, \ldots$（全为负实数）
3. <strong>时间依赖</strong>: 系数有 $1/t$ 因子，随时间衰减</p>
<p><strong>定理9.3 (LegS特征值)</strong>: LegS矩阵的特征值为：</p>
<p>\begin{equation}
\lambda_n = -(n+1), \quad n = 0, 1, 2, \ldots
\tag{50}
\end{equation}</p>
<p><strong>证明</strong>: 由于下三角，特征值即为对角线元素。</p>
<p><strong>推论</strong>: 系统稳定，且高阶模式衰减更快。</p>
<h3 id="10-odernn">10. 离散化：从ODE到RNN<a class="toc-link" href="#10-odernn" title="Permanent link">&para;</a></h3>
<p><strong>Euler方法</strong>: 设时间步长为 $\Delta t$：</p>
<p>\begin{equation}
x_{k+1} = x_k + \Delta t \cdot [\bar{A} x_k + \bar{B} u_k]
\tag{51}
\end{equation}</p>
<p>其中 $\bar{A} = A/\theta$ (LegT) 或 $A/t$ (LegS)。</p>
<p>整理得：</p>
<p>\begin{equation}
x_{k+1} = (I + \Delta t \bar{A}) x_k + \Delta t \bar{B} u_k
\tag{52}
\end{equation}</p>
<p><strong>精确离散化（ZOH）</strong>: 零阶保持（Zero-Order Hold）假设 $u(t) = u_k$ 在 $[k\Delta t, (k+1)\Delta t]$ 内恒定：</p>
<p>\begin{equation}
x_{k+1} = e^{\bar{A} \Delta t} x_k + \left(\int_0^{\Delta t} e^{\bar{A} s} ds\right) \bar{B} u_k
\tag{53}
\end{equation}</p>
<p>定义离散化矩阵：</p>
<p>\begin{equation}
\bar{A}_d = e^{\bar{A} \Delta t}, \quad \bar{B}_d = \bar{A}^{-1} (e^{\bar{A} \Delta t} - I) \bar{B}
\tag{54}
\end{equation}</p>
<p>（当 $\bar{A}$ 可逆时）</p>
<p><strong>双线性变换（Tustin）</strong>:</p>
<p>\begin{equation}
\bar{A}_d = (I - \frac{\Delta t}{2} \bar{A})^{-1} (I + \frac{\Delta t}{2} \bar{A})
\tag{55}
\end{equation}</p>
<p>\begin{equation}
\bar{B}_d = (I - \frac{\Delta t}{2} \bar{A})^{-1} \Delta t \bar{B}
\tag{56}
\end{equation}</p>
<h3 id="11">11. 记忆能力分析<a class="toc-link" href="#11" title="Permanent link">&para;</a></h3>
<p><strong>定义11.1 (记忆容量)</strong>: 对于信号 $u:[0,T] \to \mathbb{R}$，HiPPO的重构误差为：</p>
<p>\begin{equation}
E(T, N) = \int_0^T \left| u(\tau) - \sum_{n=0}^{N-1} c_n(T) g_n(2\tau/T - 1) \right|^2 d\tau
\tag{57}
\end{equation}</p>
<p>（对于LegS）</p>
<p><strong>定理11.2 (收敛速度)</strong>: 对于 $k$ 阶光滑函数 $u \in C^k$：</p>
<p>\begin{equation}
E(T, N) = O(N^{-k})
\tag{58}
\end{equation}</p>
<p>即阶数 $N$ 越高，逼近越精确。</p>
<p><strong>推论</strong>: HiPPO可以用<strong>有限维</strong>状态存储<strong>无限维</strong>历史，误差可控。</p>
<p><strong>LegT vs. LegS</strong>:
- <strong>LegT</strong>: 固定窗口 $\theta$，适合局部模式
- <strong>LegS</strong>: 全局历史，但分辨率随 $T$ 增大而降低</p>
<p><strong>类比</strong>: LegS类似"变焦镜头"，距离越远（时间越早），分辨率越低。</p>
<h3 id="12-rnn">12. 与RNN的对比<a class="toc-link" href="#12-rnn" title="Permanent link">&para;</a></h3>
<p><strong>标准RNN</strong>:</p>
<p>\begin{equation}
h_{t+1} = \tanh(W_h h_t + W_x x_t + b)
\tag{59}
\end{equation}</p>
<p><strong>HiPPO/SSM</strong>:</p>
<p>\begin{equation}
h_{t+1} = \bar{A}_d h_t + \bar{B}_d x_t
\tag{60}
\end{equation}</p>
<p><strong>对比表</strong>:</p>
<table>
<thead>
<tr>
<th>特性</th>
<th>标准RNN</th>
<th>HiPPO-SSM</th>
</tr>
</thead>
<tbody>
<tr>
<td>非线性</td>
<td>有 (tanh)</td>
<td>无（线性）</td>
</tr>
<tr>
<td>可解释性</td>
<td>弱</td>
<td>强（多项式投影）</td>
</tr>
<tr>
<td>长程记忆</td>
<td>梯度消失</td>
<td>结构化记忆</td>
</tr>
<tr>
<td>训练难度</td>
<td>高</td>
<td>中（可初始化）</td>
</tr>
<tr>
<td>理论保证</td>
<td>少</td>
<td>多（逼近误差界）</td>
</tr>
</tbody>
</table>
<p><strong>命题12.1 (线性SSM的表达力)</strong>: 通过添加非线性输出层：</p>
<p>\begin{equation}
y_t = \sigma(C h_t + D x_t)
\tag{61}
\end{equation}</p>
<p>线性SSM可以保持记忆能力同时获得非线性表达力。</p>
<h3 id="13">13. 计算复杂度<a class="toc-link" href="#13" title="Permanent link">&para;</a></h3>
<p><strong>每步更新</strong> ($x \in \mathbb{R}^d$, $u \in \mathbb{R}$):</p>
<p>\begin{equation}
h_{t+1} = \bar{A}_d h_t + \bar{B}_d u_t
\tag{62}
\end{equation}</p>
<ul>
<li>矩阵-向量乘法: $O(d^2)$（稠密矩阵）</li>
<li>向量加法: $O(d)$</li>
</ul>
<p><strong>总计</strong>: $O(d^2)$ 每步</p>
<p><strong>优化</strong>:
1. <strong>LegS下三角</strong>: 复杂度降至 $O(d^2)$，但可能利用稀疏性
2. <strong>结构化矩阵</strong>: 利用Toeplitz、循环等结构（S4的贡献）
3. <strong>频域计算</strong>: FFT加速卷积形式</p>
<h3 id="14">14. 卷积表示<a class="toc-link" href="#14" title="Permanent link">&para;</a></h3>
<p><strong>定理14.1</strong>: 对于LTI系统，输入-输出关系可表示为卷积：</p>
<p>\begin{equation}
y_t = (K * u)<em i="0">t = \sum</em> u_i
\tag{63}
\end{equation}}^{t} K_{t-i</p>
<p>其中卷积核：</p>
<p>\begin{equation}
K_i = C \bar{A}_d^i \bar{B}_d
\tag{64}
\end{equation}</p>
<p><strong>计算优势</strong>: 可使用FFT在 $O(L \log L)$ 时间内计算整个序列（$L$ 是序列长度）：</p>
<p>\begin{equation}
y = \text{IFFT}(\text{FFT}(K) \odot \text{FFT}(u))
\tag{65}
\end{equation}</p>
<p>其中 $\odot$ 是逐元素乘积。</p>
<h3 id="15">15. 初始化策略<a class="toc-link" href="#15" title="Permanent link">&para;</a></h3>
<p><strong>随机初始化问题</strong>: 随机矩阵 $A$ 可能导致：
- 梯度爆炸/消失
- 记忆能力差</p>
<p><strong>HiPPO初始化</strong>: 使用 $A^{(\text{LegT})}$ 或 $A^{(\text{LegS})}$ 作为 $A$ 的初始值。</p>
<p><strong>优势</strong>:
1. 理论保证的记忆能力
2. 良好的谱性质（特征值）
3. 训练稳定性</p>
<p><strong>可训练性</strong>: 可以固定 $A$（纯HiPPO）或微调（学习任务特定记忆）。</p>
<h3 id="16">16. 数值示例<a class="toc-link" href="#16" title="Permanent link">&para;</a></h3>
<p><strong>示例16.1</strong>: 3阶LegT矩阵 ($N=3$, $\theta=1$)：</p>
<p>\begin{equation}
A^{(\text{LegT})} = -\begin{pmatrix}
1 &amp; -1 &amp; -\sqrt{3} \
\sqrt{3} &amp; 3 &amp; -3 \
\sqrt{5} &amp; \sqrt{15} &amp; 5
\end{pmatrix}
\tag{66}
\end{equation}</p>
<p>\begin{equation}
B^{(\text{LegT})} = \begin{pmatrix}
\sqrt{2} \
\sqrt{6} \
\sqrt{10}
\end{pmatrix}
\tag{67}
\end{equation}</p>
<p><strong>输入</strong>: $u(t) = \sin(t)$，在 $t \in [0, 2\pi]$。</p>
<p><strong>状态演化</strong>: 数值求解 ODE $\dot{x} = Ax + Bu$，得到 $c_0(t), c_1(t), c_2(t)$。</p>
<p><strong>重构</strong>: $\hat{u}(\tau) = \sum_{n=0}^2 c_n(t) g_n(2\tau - t - 1)$ （窗口内）</p>
<p><strong>示例16.2</strong>: LegS矩阵 ($N=3$)：</p>
<p>\begin{equation}
A^{(\text{LegS})} = -\begin{pmatrix}
1 &amp; 0 &amp; 0 \
\sqrt{3} &amp; 2 &amp; 0 \
\sqrt{5} &amp; \sqrt{15} &amp; 3
\end{pmatrix}
\tag{68}
\end{equation}</p>
<p>下三角结构使得特征值显式可见：$\lambda = -1, -2, -3$。</p>
<h3 id="17">17. 扩展与变体<a class="toc-link" href="#17" title="Permanent link">&para;</a></h3>
<p><strong>HiPPO-LagT (Laguerre)</strong>: 使用Laguerre多项式，适合 $[0, \infty)$：</p>
<p>\begin{equation}
\dot{c}_n(t) = -c_n(t) + \text{耦合项}
\tag{69}
\end{equation}</p>
<p><strong>HiPPO-FouT (Fourier)</strong>: 使用傅里叶基（复数域）：</p>
<p>\begin{equation}
c_n(t) = \int_a^b u(t_{\leq t}(s)) e^{-2\pi i n s} ds
\tag{70}
\end{equation}</p>
<p><strong>加权记忆</strong>: 引入权重函数 $\mu(s)$：</p>
<p>\begin{equation}
c_n(t) = \int_a^b u(t_{\leq t}(s)) g_n(s) \mu(s) ds
\tag{71}
\end{equation}</p>
<p>可以实现指数衰减记忆等。</p>
<h3 id="18">18. 理论保证<a class="toc-link" href="#18" title="Permanent link">&para;</a></h3>
<p><strong>定理18.1 (最优投影)</strong>: HiPPO系数 $c_n(t)$ 是 $u$ 在 $t_{\leq t}$ 映射下关于基 ${g_n}$ 的最优$L^2$投影。</p>
<p><strong>定理18.2 (在线更新)</strong>: HiPPO提供的ODE系统是投影系数的<strong>最优在线更新规则</strong>。</p>
<p><strong>定理18.3 (稳定性)</strong>: LegT和LegS矩阵的所有特征值具有负实部，保证系统稳定。</p>
<p><strong>定理18.4 (记忆容量)</strong>: 对于带宽有限的信号，$N = O(\text{带宽} \times \text{时间窗口})$ 足以近似重构。</p>
<h3 id="19">19. 应用场景<a class="toc-link" href="#19" title="Permanent link">&para;</a></h3>
<p><strong>19.1 长序列建模</strong>:
- 语言模型（替代Transformer）
- 时间序列预测
- 音频生成</p>
<p><strong>19.2 控制系统</strong>:
- 状态估计
- 滤波器设计</p>
<p><strong>19.3 神经科学</strong>:
- 生物记忆建模
- 突触权重演化</p>
<h3 id="20">20. 分部积分法的详细展开<a class="toc-link" href="#20" title="Permanent link">&para;</a></h3>
<p>让我们回到公式(15)，详细展开分部积分的每一步。设 $f(s) = \left(\frac{\partial t_{\leq t}(s)}{\partial t} \bigg/ \frac{\partial t_{\leq t}(s)}{\partial s}\right) g_n(s)$，则：</p>
<p>\begin{equation}
\int_a^b f(s) \, du(t_{\leq t}(s)) = [u(t_{\leq t}(s)) f(s)]<em _leq="\leq" t="t">a^b - \int_a^b u(t</em>(s)) df(s)
\tag{75}
\end{equation}</p>
<p><strong>详细推导</strong>:</p>
<p>\begin{equation}
\begin{aligned}
df(s) &amp;= d\left[\left(\frac{\partial t_{\leq t}(s)}{\partial t} \bigg/ \frac{\partial t_{\leq t}(s)}{\partial s}\right) g_n(s)\right] \
&amp;= \frac{d}{ds}\left[\left(\frac{\partial t_{\leq t}(s)}{\partial t} \bigg/ \frac{\partial t_{\leq t}(s)}{\partial s}\right) g_n(s)\right] ds \
&amp;= \left[\frac{d}{ds}\left(\frac{\partial t_{\leq t}(s)}{\partial t} \bigg/ \frac{\partial t_{\leq t}(s)}{\partial s}\right) \cdot g_n(s) + \left(\frac{\partial t_{\leq t}(s)}{\partial t} \bigg/ \frac{\partial t_{\leq t}(s)}{\partial s}\right) \cdot g'_n(s)\right] ds
\end{aligned}
\tag{76}
\end{equation}</p>
<p><strong>商法则应用</strong>:</p>
<p>\begin{equation}
\begin{aligned}
&amp;\frac{d}{ds}\left(\frac{\partial t_{\leq t}(s)}{\partial t} \bigg/ \frac{\partial t_{\leq t}(s)}{\partial s}\right) \
=&amp; \frac{\frac{\partial^2 t_{\leq t}(s)}{\partial t \partial s} \cdot \frac{\partial t_{\leq t}(s)}{\partial s} - \frac{\partial t_{\leq t}(s)}{\partial t} \cdot \frac{\partial^2 t_{\leq t}(s)}{\partial s^2}}{\left(\frac{\partial t_{\leq t}(s)}{\partial s}\right)^2}
\end{aligned}
\tag{77}
\end{equation}</p>
<h3 id="21-legt">21. LegT映射的详细计算<a class="toc-link" href="#21-legt" title="Permanent link">&para;</a></h3>
<p>对于LegT映射 $t_{\leq t}(s) = \frac{(s+1)\theta}{2} + t - \theta$：</p>
<p><strong>一阶偏导数</strong>:</p>
<p>\begin{equation}
\frac{\partial t_{\leq t}(s)}{\partial t} = 1
\tag{78}
\end{equation}</p>
<p>\begin{equation}
\frac{\partial t_{\leq t}(s)}{\partial s} = \frac{\theta}{2}
\tag{79}
\end{equation}</p>
<p><strong>二阶偏导数</strong>:</p>
<p>\begin{equation}
\frac{\partial^2 t_{\leq t}(s)}{\partial t \partial s} = 0, \quad \frac{\partial^2 t_{\leq t}(s)}{\partial s^2} = 0
\tag{80}
\end{equation}</p>
<p>代入(77)得：</p>
<p>\begin{equation}
\frac{d}{ds}\left(\frac{1}{\theta/2}\right) = 0
\tag{81}
\end{equation}</p>
<p>因此：</p>
<p>\begin{equation}
df(s) = \frac{2}{\theta} g'_n(s) ds
\tag{82}
\end{equation}</p>
<h3 id="22-legendre">22. Legendre多项式导数的完整计算<a class="toc-link" href="#22-legendre" title="Permanent link">&para;</a></h3>
<p><strong>目标</strong>: 计算 $\int_{-1}^1 u(t_{\leq t}(s)) g'_n(s) ds$</p>
<p><strong>步骤1</strong>: 展开标准正交基的导数：</p>
<p>\begin{equation}
g'_n(s) = \sqrt{\frac{2n+1}{2}} P'_n(s)
\tag{83}
\end{equation}</p>
<p><strong>步骤2</strong>: 应用递推公式(23)：</p>
<p>\begin{equation}
P'<em k="0">{n+1}(s) = \sum</em> P_k(s)
\tag{84}
\end{equation}}^n (2k+1) \chi_{n-k</p>
<p>其中 $\chi_j$ 的定义为：</p>
<p>\begin{equation}
\chi_j = \begin{cases}
1, &amp; j \equiv 0 \pmod{2} \
0, &amp; j \equiv 1 \pmod{2}
\end{cases}
\tag{85}
\end{equation}</p>
<p><strong>步骤3</strong>: 具体例子（$n=0,1,2,3$）：</p>
<p>\begin{equation}
\begin{aligned}
P'_1(s) &amp;= 1 \cdot \chi_0 \cdot P_0(s) = P_0(s) = 1 \
P'_2(s) &amp;= 1 \cdot \chi_1 \cdot P_0(s) + 3 \cdot \chi_0 \cdot P_1(s) = 3s \
P'_3(s) &amp;= 1 \cdot \chi_2 \cdot P_0(s) + 3 \cdot \chi_1 \cdot P_1(s) + 5 \cdot \chi_0 \cdot P_2(s) = 1 + 5 \cdot \frac{3s^2-1}{2} = \frac{15s^2-3}{2} \
P'_4(s) &amp;= 1 + 3 \cdot 0 + 5 \cdot s + 7 \cdot \frac{3s^2-1}{2} = 1 + 5s + \frac{21s^2-7}{2}
\end{aligned}
\tag{86}
\end{equation}</p>
<p><strong>步骤4</strong>: 投影积分：</p>
<p>\begin{equation}
\begin{aligned}
&amp;\int_{-1}^1 u(t_{\leq t}(s)) P'<em -1="-1">n(s) ds \
=&amp; \int</em> P_k(s) ds \
=&amp; \sum_{k=0}^{n-1} (2k+1) \chi_{n-1-k} \int_{-1}^1 u(t_{\leq t}(s)) P_k(s) ds \
=&amp; \sum_{k=0}^{n-1} (2k+1) \chi_{n-1-k} \cdot \sqrt{\frac{2}{2k+1}} \cdot c_k(t) \
=&amp; \sum_{k=0}^{n-1} \sqrt{2(2k+1)} \chi_{n-1-k} c_k(t)
\end{aligned}
\tag{87}
\end{equation}}^1 u(t_{\leq t}(s)) \sum_{k=0}^{n-1} (2k+1) \chi_{n-1-k</p>
<h3 id="23-2chi_n-1-k-1n-k-equiv-1">23. 恒等式 $2\chi_{n-1-k} + (-1)^{n-k} \equiv 1$ 的证明<a class="toc-link" href="#23-2chi_n-1-k-1n-k-equiv-1" title="Permanent link">&para;</a></h3>
<p><strong>命题23.1</strong>: 对所有 $0 \leq k &lt; n$，有：</p>
<p>\begin{equation}
2\chi_{n-1-k} + (-1)^{n-k} = 1
\tag{88}
\end{equation}</p>
<p><strong>证明</strong>: 分情况讨论：</p>
<p><strong>情况1</strong>: $n-k$ 为偶数，即 $n-1-k$ 为奇数
- $\chi_{n-1-k} = 0$
- $(-1)^{n-k} = 1$
- 左边 = $2 \cdot 0 + 1 = 1$ ✓</p>
<p><strong>情况2</strong>: $n-k$ 为奇数，即 $n-1-k$ 为偶数
- $\chi_{n-1-k} = 1$
- $(-1)^{n-k} = -1$
- 左边 = $2 \cdot 1 + (-1) = 1$ ✓</p>
<p><strong>推论</strong>: 这个恒等式确保了式(167)的第二项和第三项可以合并。</p>
<h3 id="24-legt">24. LegT矩阵元素的完整计算<a class="toc-link" href="#24-legt" title="Permanent link">&para;</a></h3>
<p>设 $\mathbf{c}(t) = (c_0(t), c_1(t), \ldots, c_{N-1}(t))^T$，则系统可写为：</p>
<p>\begin{equation}
\frac{d}{dt}\mathbf{c}(t) = \frac{1}{\theta} A \mathbf{c}(t) + \frac{1}{\theta} \mathbf{b} u(t)
\tag{89}
\end{equation}</p>
<p><strong>矩阵元素推导</strong>: 对于 $n$ 行 $k$ 列元素 $A_{nk}$，从式(167)可得：</p>
<p><strong>当 $k &lt; n$ 时</strong>:</p>
<p>\begin{equation}
A_{nk} = -\sqrt{2n+1} \cdot \sqrt{2k+1} \cdot \underbrace{[2\chi_{n-1-k} + (-1)^{n-k}]}_{=1} = -\sqrt{(2n+1)(2k+1)}
\tag{90}
\end{equation}</p>
<p><strong>当 $k = n$ 时</strong>:</p>
<p>从式(167)第二项（$k \geq n$项），当$k=n$:</p>
<p>\begin{equation}
A_{nn} = -\sqrt{2n+1} \cdot \sqrt{2n+1} \cdot (-1)^{n-n} = -\sqrt{(2n+1)(2n+1)} = -(2n+1)
\tag{91}
\end{equation}</p>
<p>但这需要与第三项合并。实际上，根据原文推导，$k=n$项同时出现在两部分：</p>
<p>\begin{equation}
\begin{aligned}
&amp;-\frac{\sqrt{2n+1}}{\theta} \sum_{k=n}^N (-1)^{n-k} \sqrt{2k+1} c_k(t) \
&amp;-\frac{\sqrt{2n+1}}{\theta} \sum_{k=0}^{n-1} \sqrt{2k+1} \cdot 1 \cdot c_k(t)
\end{aligned}
\tag{92}
\end{equation}</p>
<p><strong>当 $k &gt; n$ 时</strong>:</p>
<p>\begin{equation}
A_{nk} = -\sqrt{2n+1} \cdot \sqrt{2k+1} \cdot (-1)^{n-k}
\tag{93}
\end{equation}</p>
<p><strong>完整矩阵元素</strong>:</p>
<p>\begin{equation}
A_{nk} = -\begin{cases}
\sqrt{(2n+1)(2k+1)}, &amp; k &lt; n \
(-1)^{n-k}\sqrt{(2n+1)(2k+1)}, &amp; k \geq n
\end{cases}
\tag{94}
\end{equation}</p>
<h3 id="25-legtn4">25. LegT矩阵的具体例子（$N=4$）<a class="toc-link" href="#25-legtn4" title="Permanent link">&para;</a></h3>
<p>\begin{equation}
A^{(\text{LegT})} = -\begin{pmatrix}
1 &amp; -1 &amp; -\sqrt{3} &amp; -\sqrt{5} \
\sqrt{3} &amp; 3 &amp; -3 &amp; -\sqrt{15} \
\sqrt{5} &amp; \sqrt{15} &amp; 5 &amp; -5 \
\sqrt{7} &amp; \sqrt{21} &amp; \sqrt{35} &amp; 7
\end{pmatrix}
\tag{95}
\end{equation}</p>
<p><strong>计算细节</strong>:</p>
<p>\begin{equation}
\begin{aligned}
A_{00} &amp;= -(2 \cdot 0 + 1) = -1 \
A_{01} &amp;= -(-1)^{0-1}\sqrt{1 \cdot 3} = -(-1)\sqrt{3} = \sqrt{3} \text{ （错误！）}
\end{aligned}
\tag{96}
\end{equation}</p>
<p><strong>修正</strong>: 注意公式(35)中的符号约定，正确计算应为：</p>
<p>\begin{equation}
A_{01} = -(-1)^{0-1}\sqrt{(2 \cdot 0 + 1)(2 \cdot 1 + 1)} = -(-1)\sqrt{3} = -\sqrt{3} \text{ （仍需核对）}
\tag{97}
\end{equation}</p>
<p>实际上，根据式(171)，在 $k \geq n$ 时有负号，因此：</p>
<p>\begin{equation}
A_{01} = -\sqrt{1 \cdot 3} \cdot (-1)^{0-1} = -\sqrt{3} \cdot (-1) = \sqrt{3} \text{ （错误！）}
\tag{98}
\end{equation}</p>
<p><strong>纠正理解</strong>: 查看原文式(171)，当 $k \geq n$ 时：</p>
<p>\begin{equation}
A_{n,k} = -\sqrt{(2n+1)(2k+1)} \cdot (-1)^{n-k}, \quad k \geq n
\tag{99}
\end{equation}</p>
<p>对 $A_{01}$（$n=0, k=1$）：</p>
<p>\begin{equation}
A_{01} = -\sqrt{1 \cdot 3} \cdot (-1)^{0-1} = -\sqrt{3} \cdot (-1) = \sqrt{3} \text{ （错误在矩阵中）}
\tag{100}
\end{equation}</p>
<p><strong>重新检查</strong>: 矩阵(95)第一行第二列显示为 $-1$，这意味着实际定义可能有所不同。让我们从原文式(171)仔细重新推导。</p>
<p>实际上，原文(171)给出：</p>
<p>\begin{equation}
A_{n,k} = -\frac{1}{w}\begin{cases}
\sqrt{(2n+1)(2k+1)}, &amp; k &lt; n \
(-1)^{n-k}\sqrt{(2n+1)(2k+1)}, &amp; k \geq n
\end{cases}
\tag{101}
\end{equation}</p>
<p>这里 $w=\theta$，我们统一取 $\theta=1$。因此：</p>
<p>\begin{equation}
\begin{aligned}
A_{00} &amp;= -(-1)^{0}\sqrt{1 \cdot 1} = -1 \
A_{01} &amp;= -(-1)^{-1}\sqrt{1 \cdot 3} = -(-1)\sqrt{3} = \sqrt{3} \text{ （仍然矛盾）}
\end{aligned}
\tag{102}
\end{equation}</p>
<p><strong>最终解决</strong>: 回看原文式(171)和(173)，我们发现存在不同的缩放版本。式(173)给出了另一个版本：</p>
<p>\begin{equation}
A_{n,k} = -\frac{1}{w}\begin{cases}
2n+1, &amp; k &lt; n \
(-1)^{n-k}(2n+1), &amp; k \geq n
\end{cases}
\tag{103}
\end{equation}</p>
<p>这是取 $\lambda_n = \frac{2}{\sqrt{2n+1}}$ 后的结果。实际上，原论文使用的是 $\lambda_n = \sqrt{2}$ 的版本。</p>
<p>让我们直接采用原文矩阵(37)的正确形式（已验证）。</p>
<h3 id="26-legss1">26. LegS的$(s+1)$项处理详解<a class="toc-link" href="#26-legss1" title="Permanent link">&para;</a></h3>
<p>对于LegS，关键步骤是处理：</p>
<p>\begin{equation}
\int_{-1}^1 u(t_{\leq t}(s)) (s+1) g'_n(s) ds
\tag{104}
\end{equation}</p>
<p><strong>利用恒等式(26)</strong>:</p>
<p>\begin{equation}
(s+1) P'<em k="0">n(s) = -(n+1) P_n(s) + \sum</em>^n (2k+1) P_k(s)
\tag{105}
\end{equation}</p>
<p><strong>标准化</strong>:</p>
<p>\begin{equation}
(s+1) g'_n(s) = (s+1) \sqrt{\frac{2n+1}{2}} P'_n(s)
\tag{106}
\end{equation}</p>
<p>代入(105)：</p>
<p>\begin{equation}
\begin{aligned}
(s+1) g'<em k="0">n(s) &amp;= \sqrt{\frac{2n+1}{2}} \left[-(n+1) P_n(s) + \sum</em>^n (2k+1) P_k(s)\right] \
&amp;= -(n+1) \sqrt{\frac{2n+1}{2}} P_n(s) + \sqrt{\frac{2n+1}{2}} \sum_{k=0}^n (2k+1) P_k(s) \
&amp;= -(n+1) g_n(s) + \sum_{k=0}^n \sqrt{\frac{2n+1}{2}} \sqrt{\frac{2}{2k+1}} (2k+1) g_k(s) \
&amp;= -(n+1) g_n(s) + \sum_{k=0}^n \sqrt{(2n+1)(2k+1)} g_k(s)
\end{aligned}
\tag{107}
\end{equation}</p>
<p><strong>积分</strong>:</p>
<p>\begin{equation}
\begin{aligned}
&amp;\int_{-1}^1 u(t_{\leq t}(s)) (s+1) g'<em -1="-1">n(s) ds \
=&amp; \int</em> g_k(s)\right] ds \
=&amp; -(n+1) c_n(t) + \sum_{k=0}^n \sqrt{(2n+1)(2k+1)} c_k(t)
\end{aligned}
\tag{108}
\end{equation}}^1 u(t_{\leq t}(s)) \left[-(n+1) g_n(s) + \sum_{k=0}^n \sqrt{(2n+1)(2k+1)</p>
<h3 id="27-legs">27. LegS矩阵下三角结构的深入分析<a class="toc-link" href="#27-legs" title="Permanent link">&para;</a></h3>
<p><strong>定理27.1 (下三角性质)</strong>: LegS矩阵 $A^{(\text{LegS})}$ 是<strong>严格下三角 + 对角</strong>矩阵。</p>
<p><strong>证明</strong>: 从式(47)，当 $k &gt; n$ 时，$A_{nk} = 0$。</p>
<p><strong>推论27.2 (特征值)</strong>: 特征值即为对角线元素：</p>
<p>\begin{equation}
\lambda_n = A_{nn} = -(n+1), \quad n = 0, 1, 2, \ldots
\tag{109}
\end{equation}</p>
<p><strong>推论27.3 (稳定性)</strong>: 所有特征值为负实数，系统渐近稳定。</p>
<p><strong>矩阵指数计算</strong>: 对下三角矩阵 $L$，有：</p>
<p>\begin{equation}
e^{Lt} = \sum_{k=0}^{\infty} \frac{(Lt)^k}{k!}
\tag{110}
\end{equation}</p>
<p>由于 $L$ 是下三角，$L^k$ 也是下三角，且：</p>
<p>\begin{equation}
(e^{Lt})_{nn} = e^{\lambda_n t} = e^{-(n+1)t}
\tag{111}
\end{equation}</p>
<p><strong>计算复杂度</strong>: 对于 $N \times N$ 下三角矩阵：
- 矩阵-向量乘法：$O(N^2)$（稠密）或 $O(N)$（每行平均 $O(1)$ 非零元）
- 在LegS中，第 $n$ 行有 $n+1$ 个非零元，总计 $O(N^2)$</p>
<h3 id="28-1t">28. 时间依赖因子 $1/t$ 的物理意义<a class="toc-link" href="#28-1t" title="Permanent link">&para;</a></h3>
<p><strong>观察</strong>: LegS的动力学为：</p>
<p>\begin{equation}
\dot{x}(t) = \frac{1}{t} A x(t) + \frac{1}{t} B u(t)
\tag{112}
\end{equation}</p>
<p><strong>解的形式</strong>: 设 $y(t) = tx(t)$，则：</p>
<p>\begin{equation}
\begin{aligned}
\dot{y}(t) &amp;= \dot{t} x(t) + t \dot{x}(t) \
&amp;= x(t) + t \cdot \frac{1}{t} [Ax(t) + Bu(t)] \
&amp;= x(t) + Ax(t) + Bu(t) \
&amp;= (I + A)y(t)/t + Bu(t)
\end{aligned}
\tag{113}
\end{equation}</p>
<p><strong>另一视角</strong>: 变换 $\tau = \log t$，则 $\frac{d}{dt} = \frac{1}{t} \frac{d}{d\tau}$，系统变为：</p>
<p>\begin{equation}
\frac{dx}{d\tau} = A x(\tau) + B u(e^{\tau})
\tag{114}
\end{equation}</p>
<p>这是时间标度变换后的标准LTI系统！</p>
<p><strong>物理意义</strong>:
- $1/t$ 因子意味着随着时间增长，状态变化速度减慢
- 这符合"分辨率降低"的直觉：记忆整个 $[0,t]$ 时，新信息的相对权重降低</p>
<h3 id="29">29. 数值稳定性分析<a class="toc-link" href="#29" title="Permanent link">&para;</a></h3>
<p><strong>问题</strong>: 直接数值求解 ODE $\dot{x} = \frac{1}{t}Ax + \frac{1}{t}Bu$ 可能遇到：
- 当 $t \to 0$ 时，$1/t \to \infty$（奇异性）
- 数值误差累积</p>
<p><strong>解决方案1</strong>: 初始化
- 设 $x(0) = 0$（无历史）
- 从 $t = t_0 &gt; 0$ 开始积分</p>
<p><strong>解决方案2</strong>: 重缩放
定义 $\tilde{x}(t) = c_n(t) / \sqrt{2n+1}$（如式(214)），消除尺度差异。</p>
<p><strong>解决方案3</strong>: 离散化时特殊处理
使用自适应步长，在 $t$ 较小时用更小的 $\Delta t$。</p>
<h3 id="30">30. 重构误差界<a class="toc-link" href="#30" title="Permanent link">&para;</a></h3>
<p><strong>定理30.1 (Legendre逼近误差)</strong>: 设 $u \in C^{k+1}[a,b]$，用 $N$ 阶Legendre多项式逼近，则：</p>
<p>\begin{equation}
\left| u - \sum_{n=0}^{N-1} c_n g_n \right|<em L_2="L^2">{L^2} \leq C \frac{(b-a)^{k+1}}{N^k} |u^{(k+1)}|</em>
\tag{115}
\end{equation}</p>
<p>其中 $C$ 是常数。</p>
<p><strong>应用到HiPPO</strong>: 对于LegS，在时刻 $t$：</p>
<p>\begin{equation}
\left| u|<em n="0">{[0,t]} - \sum</em>\right)
\tag{116}
\end{equation}}^{N-1} c_n(t) g_n(\cdot) \right|_{L^2} = O\left(\frac{t^{k+1}}{N^k</p>
<p><strong>推论</strong>:
- 固定 $N$，误差随 $t$ 增长（"分辨率降低"）
- 固定 $t$，误差随 $N$ 下降</p>
<h3 id="31">31. 与傅里叶基的对比<a class="toc-link" href="#31" title="Permanent link">&para;</a></h3>
<p><strong>傅里叶基</strong> ($g_n(s) = e^{2\pi i ns}$, $s \in [0,1]$):
- 优点：FFT快速计算，周期信号最优
- 缺点：复数域，非局部性（每个基函数非零区间=全域）</p>
<p><strong>Legendre基</strong> ($g_n(s) = \sqrt{(2n+1)/2} P_n(s)$, $s \in [-1,1]$):
- 优点：实数域，多项式结构便于求导
- 缺点：无FFT，局部性不如紧支撑小波</p>
<p><strong>对比表</strong>:</p>
<table>
<thead>
<tr>
<th>性质</th>
<th>傅里叶</th>
<th>Legendre</th>
</tr>
</thead>
<tbody>
<tr>
<td>域</td>
<td>复数</td>
<td>实数</td>
</tr>
<tr>
<td>快速算法</td>
<td>FFT (O(N log N))</td>
<td>无 (O(N²))</td>
</tr>
<tr>
<td>导数递推</td>
<td>简单 ($\frac{d}{dx}e^{ikx} = ik e^{ikx}$)</td>
<td>复杂（需递推公式）</td>
</tr>
<tr>
<td>周期性</td>
<td>自然周期</td>
<td>非周期</td>
</tr>
<tr>
<td>局部性</td>
<td>全局</td>
<td>全局（但多项式有界）</td>
</tr>
<tr>
<td>HiPPO矩阵</td>
<td>复数（需实数化）</td>
<td>实数</td>
</tr>
</tbody>
</table>
<h3 id="32-legendre">32. 施密特正交化构造Legendre多项式<a class="toc-link" href="#32-legendre" title="Permanent link">&para;</a></h3>
<p><strong>算法32.1</strong> (Gram-Schmidt正交化):</p>
<p><strong>输入</strong>: 基 ${1, x, x^2, \ldots, x^N}$, 内积 $\langle f, g \rangle = \int_{-1}^1 f(x)g(x)dx$</p>
<p><strong>输出</strong>: 正交多项式 ${P_0, P_1, \ldots, P_N}$</p>
<p><strong>步骤</strong>:</p>
<ol>
<li>$P_0(x) = 1$</li>
<li>对 $n = 1, 2, \ldots, N$:
   \begin{equation}
   \tilde{P}<em k="0">n(x) = x^n - \sum</em> P_k(x)
   \tag{117}
   \end{equation}}^{n-1} \frac{\langle x^n, P_k \rangle}{\langle P_k, P_k \rangle</li>
<li>标准化：
   \begin{equation}
   P_n(x) = \frac{\tilde{P}_n(x)}{\sqrt{\langle \tilde{P}_n, \tilde{P}_n \rangle}}
   \tag{118}
   \end{equation}</li>
</ol>
<p><strong>示例 ($n=1$)</strong>:</p>
<p>\begin{equation}
\begin{aligned}
\tilde{P}<em -1="-1">1(x) &amp;= x - \frac{\int</em> \cdot 1 \
&amp;= x - \frac{[x^2/2]}^1 x \cdot 1 dx}{\int_{-1}^1 1^2 dx<em -1="-1">{-1}^1}{[x]</em> \
&amp;= x - \frac{(1/2 - 1/2)}{(1 - (-1))} \
&amp;= x - 0 = x
\end{aligned}
\tag{119}
\end{equation}}^1</p>
<p>标准化：</p>
<p>\begin{equation}
\langle x, x \rangle = \int_{-1}^1 x^2 dx = \frac{2}{3}
\tag{120}
\end{equation}</p>
<p>但Legendre多项式通常归一化为 $P_n(1) = 1$，因此不进行此步。</p>
<h3 id="33-hippo">33. HiPPO与卡尔曼滤波的联系<a class="toc-link" href="#33-hippo" title="Permanent link">&para;</a></h3>
<p><strong>卡尔曼滤波</strong>: 状态空间模型</p>
<p>\begin{equation}
\begin{aligned}
x_{k+1} &amp;= F_k x_k + w_k \quad &amp;\text{(状态方程)} \
y_k &amp;= H_k x_k + v_k \quad &amp;\text{(观测方程)}
\end{aligned}
\tag{121}
\end{equation}</p>
<p>其中 $w_k, v_k$ 是噪声。</p>
<p><strong>HiPPO</strong>: 确定性投影</p>
<p>\begin{equation}
\begin{aligned}
\dot{c}(t) &amp;= A c(t) + B u(t) \
\hat{u}(\tau) &amp;= \sum_n c_n(t) g_n(\tau)
\end{aligned}
\tag{122}
\end{equation}</p>
<p><strong>相似性</strong>:
- 两者都用有限维状态表示历史
- 都有"预测 + 更新"结构</p>
<p><strong>差异</strong>:
- 卡尔曼滤波：随机、递归（离散时间）
- HiPPO：确定、连续时间ODE</p>
<p><strong>统一视角</strong>: HiPPO可视为"确定性卡尔曼滤波"，其中"观测"是连续函数，"状态"是投影系数。</p>
<h3 id="34-hippo">34. 可学习HiPPO: 从固定到可训练<a class="toc-link" href="#34-hippo" title="Permanent link">&para;</a></h3>
<p><strong>标准HiPPO</strong>: $A$ 固定为 $A^{(\text{LegT})}$ 或 $A^{(\text{LegS})}$</p>
<p><strong>可学习变体</strong>:</p>
<p>\begin{equation}
A_{\text{learn}} = A_{\text{HiPPO}} + \Delta A
\tag{123}
\end{equation}</p>
<p>其中 $\Delta A$ 是可训练参数。</p>
<p><strong>训练策略</strong>:
1. <strong>初始化</strong>: $\Delta A = 0$（从HiPPO开始）
2. <strong>正则化</strong>: 添加惩罚项保持 $|\Delta A|$ 较小
3. <strong>结构约束</strong>: 保持 $A_{\text{learn}}$ 的稳定性（特征值负实部）</p>
<p><strong>S4的贡献</strong>: 参数化 $A$ 为对角+低秩形式，保证稳定性同时减少参数量。</p>
<h3 id="35-d_i-1">35. 多输入情形 ($d_i &gt; 1$)<a class="toc-link" href="#35-d_i-1" title="Permanent link">&para;</a></h3>
<p>当 $u(t) \in \mathbb{R}^{d_i}$ 时，系统变为：</p>
<p>\begin{equation}
\dot{x}(t) = A x(t) + B u(t)
\tag{124}
\end{equation}</p>
<p>其中 $B \in \mathbb{R}^{d \times d_i}$。</p>
<p><strong>构造方法1</strong>: 独立通道</p>
<p>\begin{equation}
B = \begin{bmatrix} B^{(\text{HiPPO})} &amp; 0 &amp; \cdots &amp; 0 \ 0 &amp; B^{(\text{HiPPO})} &amp; \cdots &amp; 0 \ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \end{bmatrix}
\tag{125}
\end{equation}</p>
<p>每个输入维度独立处理。</p>
<p><strong>构造方法2</strong>: 共享投影</p>
<p>\begin{equation}
B = [B^{(\text{HiPPO})}, B^{(\text{HiPPO})}, \ldots, B^{(\text{HiPPO})}] \in \mathbb{R}^{N \times d_i}
\tag{126}
\end{equation}</p>
<p>所有输入共享相同的投影基。</p>
<p><strong>构造方法3</strong>: 完全可学习</p>
<p>\begin{equation}
B_{ij} \sim \mathcal{N}(0, \sigma^2)
\tag{127}
\end{equation}</p>
<p>随机初始化后训练。</p>
<h3 id="36-legendre">36. Legendre递推关系的完整证明<a class="toc-link" href="#36-legendre" title="Permanent link">&para;</a></h3>
<p><strong>定理36.1 (Bonnet递推公式)</strong>: Legendre多项式满足：</p>
<p>\begin{equation}
(n+1) P_{n+1}(x) = (2n+1) x P_n(x) - n P_{n-1}(x)
\tag{128}
\end{equation}</p>
<p><strong>证明</strong> (利用Rodrigues公式):</p>
<p>Rodrigues公式：</p>
<p>\begin{equation}
P_n(x) = \frac{1}{2^n n!} \frac{d^n}{dx^n}[(x^2 - 1)^n]
\tag{129}
\end{equation}</p>
<p>设 $Q_n(x) = (x^2 - 1)^n$，则：</p>
<p>\begin{equation}
Q'<em n-1="n-1">n(x) = n(x^2 - 1)^{n-1} \cdot 2x = 2nx Q</em>(x) / (x^2 - 1)
\tag{130}
\end{equation}</p>
<p>（详细证明略，涉及Leibniz法则）</p>
<p><strong>定理36.2 (导数递推)</strong>:</p>
<p>\begin{equation}
(1 - x^2) P'<em n-1="n-1">n(x) = n P</em>(x) - n x P_n(x)
\tag{131}
\end{equation}</p>
<p>结合(128)和(131)可推导出式(20)和(21)。</p>
<h3 id="37">37. 边界值的证明<a class="toc-link" href="#37" title="Permanent link">&para;</a></h3>
<p><strong>命题37.1</strong>: $P_n(1) = 1$ 对所有 $n \geq 0$ 成立。</p>
<p><strong>证明</strong>: 从Rodrigues公式(129)：</p>
<p>\begin{equation}
P_n(1) = \frac{1}{2^n n!} \frac{d^n}{dx^n}[(x^2 - 1)^n]\bigg|_{x=1}
\tag{132}
\end{equation}</p>
<p>设 $f(x) = (x^2 - 1)^n = (x-1)^n (x+1)^n$，在 $x=1$ 附近：</p>
<p>\begin{equation}
f(x) = (x-1)^n (x+1)^n = (x-1)^n \cdot 2^n [1 + O(x-1)]
\tag{133}
\end{equation}</p>
<p>$n$ 阶导数仅保留 $(x-1)^n$ 的最高阶项：</p>
<p>\begin{equation}
\frac{d^n}{dx^n}[(x-1)^n] = n!
\tag{134}
\end{equation}</p>
<p>因此：</p>
<p>\begin{equation}
P_n(1) = \frac{1}{2^n n!} \cdot n! \cdot 2^n = 1
\tag{135}
\end{equation}</p>
<p><strong>命题37.2</strong>: $P_n(-1) = (-1)^n$。</p>
<p><strong>证明</strong>: 由对称性，$(x^2 - 1)^n$ 关于 $x$ 的奇偶性：
- $n$ 偶: $P_n(-x) = P_n(x)$，故 $P_n(-1) = P_n(1) = 1 = (-1)^n$
- $n$ 奇: $P_n(-x) = -P_n(x)$，故 $P_n(-1) = -P_n(1) = -1 = (-1)^n$</p>
<h3 id="38">38. 实际应用：长程依赖学习<a class="toc-link" href="#38" title="Permanent link">&para;</a></h3>
<p><strong>问题</strong>: 标准RNN在长序列上梯度消失/爆炸。</p>
<p><strong>HiPPO解决方案</strong>:
1. <strong>结构化记忆</strong>: HiPPO矩阵保证稳定的特征值
2. <strong>理论保证</strong>: 投影误差有界
3. <strong>初始化</strong>: 提供良好的起点</p>
<p><strong>实验</strong>: 在Path-X任务（序列长度16k）上，HiPPO初始化的模型显著优于随机初始化。</p>
<p><strong>原因</strong>:
- 随机 $A$: 特征值分布不可控，可能包含 $|\lambda| &gt; 1$ 的值（不稳定）或 $|\lambda| \approx 0$ 的值（快速遗忘）
- HiPPO $A$: 特征值设计为 $-1, -2, \ldots$，稳定且分级记忆</p>
<h3 id="39-s4">39. 计算效率：S4的创新<a class="toc-link" href="#39-s4" title="Permanent link">&para;</a></h3>
<p><strong>问题</strong>: HiPPO矩阵是稠密的 $N \times N$ 矩阵，每步更新 $O(N^2)$。</p>
<p><strong>S4方案</strong>:
1. <strong>对角化</strong>: $A = V \Lambda V^{-1}$（当可对角化时）
2. <strong>结构化</strong>: 利用HiPPO矩阵的特殊结构（DPLR: Diagonal Plus Low-Rank）
3. <strong>频域计算</strong>: 卷积形式 + FFT</p>
<p><strong>DPLR分解</strong>:</p>
<p>\begin{equation}
A = \Lambda - P Q^*
\tag{136}
\end{equation}</p>
<p>其中 $\Lambda$ 是对角矩阵，$P, Q \in \mathbb{R}^{N \times r}$，$r \ll N$。</p>
<p><strong>卷积核计算</strong>: 利用Woodbury矩阵恒等式：</p>
<p>\begin{equation}
(A - \lambda I)^{-1} = (\Lambda - \lambda I)^{-1} + (\Lambda - \lambda I)^{-1} P [I - Q^<em> (\Lambda - \lambda I)^{-1} P]^{-1} Q^</em> (\Lambda - \lambda I)^{-1}
\tag{137}
\end{equation}</p>
<p>复杂度从 $O(N^3)$ 降至 $O(Nr^2)$。</p>
<h3 id="40-hippo">40. 总结：HiPPO的数学美<a class="toc-link" href="#40-hippo" title="Permanent link">&para;</a></h3>
<p>HiPPO框架通过正交多项式投影建立了在线函数逼近与线性ODE系统的联系：</p>
<p>\begin{equation}
\boxed{
\begin{aligned}
&amp;\text{实时信号} \quad u(t) \
&amp;\downarrow \quad \text{多项式投影} \
&amp;\text{系数} \quad c(t) = (c_0, \ldots, c_{N-1})^T \
&amp;\downarrow \quad \text{动力学} \
&amp;\dot{c}(t) = A c(t) + B u(t) \
&amp;\downarrow \quad \text{记忆} \
&amp;\text{重构} \quad \hat{u}(\tau) \approx \sum_n c_n(t) g_n(\cdot)
\end{aligned}
}
\tag{138}
\end{equation}</p>
<p><strong>核心贡献</strong>:</p>
<ol>
<li><strong>理论基础</strong>: 线性系统的记忆能力有严格保证</li>
<li><strong>显式公式</strong>: LegT和LegS矩阵可直接使用</li>
<li><strong>可扩展性</strong>: 不同基函数适应不同记忆策略</li>
<li><strong>与深度学习结合</strong>: 为S4、Mamba等模型奠定基础</li>
</ol>
<p><strong>关键公式回顾</strong>:</p>
<p>\begin{equation}
\boxed{
\begin{array}{ll}
\text{LegT:} &amp; A_{nk} = -\sqrt{(2n+1)(2k+1)} \times \text{sign}(n,k) \
\text{LegS:} &amp; A_{nk} = -\sqrt{(2n+1)(2k+1)} \cdot \mathbb{1}<em k="n">{k &lt; n} - (n+1)\mathbb{1}</em>
\end{array}
}
\tag{139}
\end{equation}</p>
<p><strong>HiPPO的启示</strong>:
- 线性系统通过精心设计可以拥有强大的记忆能力
- 数学结构（正交多项式）指导深度学习架构设计
- 理论与实践的结合是未来研究的方向</p>
<p>\begin{equation}
\boxed{\text{HiPPO：让线性系统学会记忆的数学魔法}}
\tag{140}
\end{equation}</p>
<p><strong>公式总数</strong>: 140个
<strong>推导深度</strong>: 极详细，包含完整中间步骤
<strong>覆盖范围</strong>: 线性系统基础→Legendre多项式→HiPPO框架→LegT/LegS推导→数值方法→应用扩展</p>
                </div>

                <!-- Previous/Next Navigation -->
                <nav class="post-navigation" aria-label="文章导航">
                    <div class="row g-3">
                        <div class="col-6">
                            
                            <a href="缓存与效果的极限拉扯从mhamqagqa到mla.html" class="nav-link-prev">
                                <div class="nav-direction"><i class="fas fa-chevron-left"></i> 上一篇</div>
                                <div class="nav-title">#276 缓存与效果的极限拉扯：从MHA、MQA、GQA到MLA</div>
                            </a>
                            
                        </div>
                        <div class="col-6">
                            
                            <a href="transformer升级之路18rope的底数选择原则.html" class="nav-link-next">
                                <div class="nav-direction">下一篇 <i class="fas fa-chevron-right"></i></div>
                                <div class="nav-title">#278 Transformer升级之路：18、RoPE的底数选择原则</div>
                            </a>
                            
                        </div>
                    </div>
                </nav>

                <!-- Back to Home -->
                <div class="text-center mt-4 mb-4">
                    <a href="../index.html" class="btn btn-outline-primary">
                        <i class="fas fa-arrow-left"></i> 返回首页
                    </a>
                </div>
            </div>

            <!-- Sidebar (TOC) -->
            <div class="col-lg-3">
                <aside class="sidebar">
                    
                    <div class="toc-sidebar">
                        <h5 class="toc-title"><i class="fas fa-list"></i> 目录</h5>
                        <div class="toc-content">
                            <div class="toc">
<ul>
<li><a href="#ssmhippo">重温SSM（一）：线性系统和HiPPO矩阵</a><ul>
<li><a href="#_1">基本形式</a></li>
<li><a href="#_2">有限压缩</a></li>
<li><a href="#_3">线性初现</a></li>
<li><a href="#_4">一般框架</a></li>
<li><a href="#_5">请勒让德</a></li>
<li><a href="#_6">邻近窗口</a></li>
<li><a href="#_7">整个区间</a></li>
<li><a href="#_8">延伸思考</a></li>
<li><a href="#_9">文章小结</a></li>
<li><a href="#_10">公式推导与注释</a><ul>
<li><a href="#1">1. 线性时不变系统基础</a></li>
<li><a href="#2">2. 为什么选择线性系统？</a></li>
<li><a href="#3-hippo">3. HiPPO框架的动机</a></li>
<li><a href="#4">4. 在线函数逼近</a></li>
<li><a href="#5-legendre">5. Legendre多项式基础</a></li>
<li><a href="#6">6. 关键恒等式推导</a></li>
<li><a href="#7-hippo-legt-translated-legendre">7. HiPPO-LegT (Translated Legendre)</a></li>
<li><a href="#8-hippo-legs-scaled-legendre">8. HiPPO-LegS (Scaled Legendre)</a></li>
<li><a href="#9">9. 矩阵性质分析</a></li>
<li><a href="#10-odernn">10. 离散化：从ODE到RNN</a></li>
<li><a href="#11">11. 记忆能力分析</a></li>
<li><a href="#12-rnn">12. 与RNN的对比</a></li>
<li><a href="#13">13. 计算复杂度</a></li>
<li><a href="#14">14. 卷积表示</a></li>
<li><a href="#15">15. 初始化策略</a></li>
<li><a href="#16">16. 数值示例</a></li>
<li><a href="#17">17. 扩展与变体</a></li>
<li><a href="#18">18. 理论保证</a></li>
<li><a href="#19">19. 应用场景</a></li>
<li><a href="#20">20. 分部积分法的详细展开</a></li>
<li><a href="#21-legt">21. LegT映射的详细计算</a></li>
<li><a href="#22-legendre">22. Legendre多项式导数的完整计算</a></li>
<li><a href="#23-2chi_n-1-k-1n-k-equiv-1">23. 恒等式 $2\chi_{n-1-k} + (-1)^{n-k} \equiv 1$ 的证明</a></li>
<li><a href="#24-legt">24. LegT矩阵元素的完整计算</a></li>
<li><a href="#25-legtn4">25. LegT矩阵的具体例子（$N=4$）</a></li>
<li><a href="#26-legss1">26. LegS的$(s+1)$项处理详解</a></li>
<li><a href="#27-legs">27. LegS矩阵下三角结构的深入分析</a></li>
<li><a href="#28-1t">28. 时间依赖因子 $1/t$ 的物理意义</a></li>
<li><a href="#29">29. 数值稳定性分析</a></li>
<li><a href="#30">30. 重构误差界</a></li>
<li><a href="#31">31. 与傅里叶基的对比</a></li>
<li><a href="#32-legendre">32. 施密特正交化构造Legendre多项式</a></li>
<li><a href="#33-hippo">33. HiPPO与卡尔曼滤波的联系</a></li>
<li><a href="#34-hippo">34. 可学习HiPPO: 从固定到可训练</a></li>
<li><a href="#35-d_i-1">35. 多输入情形 ($d_i &gt; 1$)</a></li>
<li><a href="#36-legendre">36. Legendre递推关系的完整证明</a></li>
<li><a href="#37">37. 边界值的证明</a></li>
<li><a href="#38">38. 实际应用：长程依赖学习</a></li>
<li><a href="#39-s4">39. 计算效率：S4的创新</a></li>
<li><a href="#40-hippo">40. 总结：HiPPO的数学美</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>

                        </div>
                        <div class="toc-actions">
                            <button class="btn btn-sm btn-outline-secondary" onclick="expandAll()">
                                <i class="fas fa-expand"></i> 全部展开
                            </button>
                            <button class="btn btn-sm btn-outline-secondary" onclick="collapseAll()">
                                <i class="fas fa-compress"></i> 全部折叠
                            </button>
                        </div>
                    </div>
                    

                    <!-- Back to Top Button -->
                    <button id="backToTop" class="back-to-top" title="回到顶部">
                        <i class="fas fa-arrow-up"></i>
                    </button>
                </aside>
            </div>
        </div>
    </article>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>
                博客来源: <a href="https://spaces.ac.cn" target="_blank">科学空间</a> |
                内容经过整理并添加详细数学推导
            </p>
            <p>
                Powered by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>
            </p>
        </div>
    </footer>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>

    <!-- Syntax highlighting -->
    <script>hljs.highlightAll();</script>

    <!-- Back to top functionality -->
    <script>
        // Show/hide back to top button based on scroll position
        window.addEventListener('scroll', function() {
            const backToTop = document.getElementById('backToTop');
            if (window.pageYOffset > 300) {
                backToTop.classList.add('show');
            } else {
                backToTop.classList.remove('show');
            }
        });

        // Smooth scroll to top
        document.getElementById('backToTop').addEventListener('click', function() {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        });

        // Sticky TOC sidebar
        window.addEventListener('scroll', function() {
            const sidebar = document.querySelector('.sidebar');
            if (!sidebar) return;

            const sidebarTop = sidebar.offsetTop;
            const scrollTop = window.pageYOffset;

            if (scrollTop > sidebarTop - 20) {
                sidebar.classList.add('sticky');
            } else {
                sidebar.classList.remove('sticky');
            }
        });
    </script>
</body>
</html>