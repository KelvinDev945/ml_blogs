<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>梯度流：探索通向最小值之路 | ML & Math Blog Posts</title>
    <meta name="description" content="梯度流：探索通向最小值之路&para;
原文链接: https://spaces.ac.cn/archives/9660
发布日期: 

在这篇文章中，我们将探讨一个被称为“梯度流（Gradient Flow）”的概念。简单来说，梯度流是将我们在用梯度下降法中寻找最小值的过程中的各个点连接起来，形成一条随（虚拟的）时间变化的轨迹，这条轨迹便被称作“梯度流”。在文章的后半部分，我们将重点讨论如何将梯...">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css">

    <!-- Google Fonts -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="../assets/css/main.css">
    <link rel="stylesheet" href="../assets/css/post.css">

    <!-- Custom JS -->
    <script src="../assets/js/collapsible.js" defer></script>

    <!-- MathJax for math rendering with equation numbering -->
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true,
        tags: 'ams',  // Enable equation numbering with AMS style
        tagSide: 'right',  // Place equation numbers on the right
        tagIndent: '0.8em',  // Indentation for equation numbers
        multlineWidth: '85%'
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Syntax highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/styles/github.min.css">
    <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/highlight.min.js"></script>
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light bg-light border-bottom">
        <div class="container">
            <a class="navbar-brand" href="../index.html">
                <i class="fas fa-brain"></i> ML & Math Blog
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="../index.html"><i class="fas fa-home"></i> 首页</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Post Content -->
    <article class="container post-container my-5">
        <!-- Breadcrumb Navigation -->
        <nav aria-label="breadcrumb">
            <ol class="breadcrumb">
                <li class="breadcrumb-item"><a href="../index.html"><i class="fas fa-home"></i> 首页</a></li>
                
                <li class="breadcrumb-item"><a href="../index.html?tags=泛函">泛函</a></li>
                
                <li class="breadcrumb-item active" aria-current="page">
                    #236 梯度流：探索通向最小值之路
                </li>
            </ol>
        </nav>

        <!-- Post Header -->
        <header class="post-header mb-4">
            <h1 class="post-title">
                <span class="post-number">#236</span>
                梯度流：探索通向最小值之路
            </h1>
            <div class="post-meta">
                <span><i class="far fa-calendar"></i> 2023-06-16</span>
                
            </div>
            
            <div class="post-tags mt-3">
                
                <a href="../index.html?tags=泛函" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 泛函</span>
                </a>
                
                <a href="../index.html?tags=动力学" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 动力学</span>
                </a>
                
                <a href="../index.html?tags=优化" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 优化</span>
                </a>
                
                <a href="../index.html?tags=梯度" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 梯度</span>
                </a>
                
                <a href="../index.html?tags=生成模型" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 生成模型</span>
                </a>
                
            </div>
            
        </header>

        <div class="row">
            <!-- Main Content -->
            <div class="col-lg-9">
                <!-- Post Body -->
                <div class="post-content">
                    <h1 id="_1">梯度流：探索通向最小值之路<a class="toc-link" href="#_1" title="Permanent link">&para;</a></h1>
<p><strong>原文链接</strong>: <a href="https://spaces.ac.cn/archives/9660">https://spaces.ac.cn/archives/9660</a></p>
<p><strong>发布日期</strong>: </p>
<hr />
<p>在这篇文章中，我们将探讨一个被称为“梯度流（Gradient Flow）”的概念。简单来说，梯度流是将我们在用梯度下降法中寻找最小值的过程中的各个点连接起来，形成一条随（虚拟的）时间变化的轨迹，这条轨迹便被称作“梯度流”。在文章的后半部分，我们将重点讨论如何将梯度流的概念扩展到概率空间，从而形成“Wasserstein梯度流”，为我们理解连续性方程、Fokker-Planck方程等内容提供一个新的视角。</p>
<h2 id="_2">梯度下降<a class="toc-link" href="#_2" title="Permanent link">&para;</a></h2>
<p>假设我们想搜索光滑函数$f(\boldsymbol{x})$的最小值，常见的方案是梯度下降（Gradient Descent），即按照如下格式进行迭代：<br />
\begin{equation}\boldsymbol{x}<em _boldsymbol_x="\boldsymbol{x">{t+1} = \boldsymbol{x}_t -\alpha \nabla</em>}_t}f(\boldsymbol{x}_t)\label{eq:gd-d}\end{equation
如果$f(\boldsymbol{x})$关于$\boldsymbol{x}$是凸的，那么梯度下降通常能够找到最小值点；相反，则通常只能收敛到一个“驻点”——即梯度为0的点，比较理想的情况下能收敛到一个极小值（局部最小值）点。这里没有对极小值和最小值做严格区分，因为在深度学习中，即便是收敛到一个极小值点也是很难得的了。</p>
<p>如果将$\alpha$记为$\Delta t$，将$\boldsymbol{x}<em t="t" t_Delta="t+\Delta">{t+1}$记为$\boldsymbol{x}</em>$将变为一个ODE：}$，那么考虑$\Delta t\to 0$的极限，那么式$\eqref{eq:gd-d<br />
\begin{equation}\frac{d\boldsymbol{x}<em _boldsymbol_x="\boldsymbol{x">t}{dt} = -\nabla</em><em _boldsymbol_x="\boldsymbol{x">t}f(\boldsymbol{x}_t)\label{eq:gd-c}\end{equation}<br />
求解这个ODE所得到的轨迹$\boldsymbol{x}_t$，我们就称为“梯度流（Gradient Flow）”，也就是说，梯度流是梯度下降在寻找最小值过程中的轨迹。在式$\eqref{eq:gd-c}$成立前提下，我们还有：<br />
\begin{equation}\frac{df(\boldsymbol{x}_t)}{dt} = \left\langle\nabla</em><em _boldsymbol_x="\boldsymbol{x">t}f(\boldsymbol{x}_t),\frac{d\boldsymbol{x}_t}{dt}\right\rangle = -\Vert\nabla</em><em _boldsymbol_x="\boldsymbol{x">t}f(\boldsymbol{x}_t)\Vert^2 \leq 0\end{equation}<br />
这就意味着，只要$\nabla</em>)$变小的方向前进。}_t}f(\boldsymbol{x}_t)\neq\boldsymbol{0}$，那么当学习率足够小时，梯度下降总能往让$f(\boldsymbol{x</p>
<p>更多相关讨论，可以参考之前的优化算法系列，如<a href="/archives/5655">《从动力学角度看优化算法（一）：从SGD到动量加速》</a>、<a href="/archives/6261">《从动力学角度看优化算法（三）：一个更整体的视角》</a>等。</p>
<h2 id="_3">最速方向<a class="toc-link" href="#_3" title="Permanent link">&para;</a></h2>
<p>为什么要用梯度下降？一个主流的说法是“梯度的负方向是局部下降最快的方向”，直接搜这句话就可以搜到很多内容。这个说法不能说错，但有点不严谨，因为没说明前提条件——“最快”的“最”必然涉及到定量比较，只有先确定比较的指标，才能确定“最”的结果。</p>
<p>如果只关心下降最快的方向的话，梯度下降的目标应该是：<br />
\begin{equation}\boldsymbol{x}<em _boldsymbol_x="\boldsymbol{x">{t+1} = \mathop{\text{argmin}}</em>},\Vert\boldsymbol{x} - \boldsymbol{x<em _boldsymbol_x="\boldsymbol{x">t\Vert = \epsilon} f(\boldsymbol{x})\label{eq:gd-min-co}\end{equation}<br />
假设一阶近似够用，那么有<br />
\begin{equation}\begin{aligned}
f(\boldsymbol{x})&amp;\,=f(\boldsymbol{x}_t) + \langle \nabla</em><em _boldsymbol_x="\boldsymbol{x">t}f(\boldsymbol{x}_t),\boldsymbol{x} - \boldsymbol{x}_t\rangle\\
&amp;\,\geq f(\boldsymbol{x}_t) - \Vert\nabla</em><em _boldsymbol_x="\boldsymbol{x">t}f(\boldsymbol{x}_t)\Vert \Vert\boldsymbol{x} - \boldsymbol{x}_t\Vert\\
&amp;\,= f(\boldsymbol{x}_t) - \Vert\nabla</em><em _boldsymbol_x="\boldsymbol{x">t}f(\boldsymbol{x}_t)\Vert \epsilon\\
\end{aligned}\end{equation}<br />
等号成立的条件是<br />
\begin{equation}\boldsymbol{x} - \boldsymbol{x}_t = -\epsilon\frac{\nabla</em><em _boldsymbol_x="\boldsymbol{x">t}f(\boldsymbol{x}_t)}{\Vert\nabla</em><em t_1="t+1">t}f(\boldsymbol{x}_t)\Vert}\quad\Rightarrow\quad\boldsymbol{x}</em>} = \boldsymbol{x<em _boldsymbol_x="\boldsymbol{x">t - \epsilon\frac{\nabla</em><em _boldsymbol_x="\boldsymbol{x">t}f(\boldsymbol{x}_t)}{\Vert\nabla</em>}_t}f(\boldsymbol{x}_t)\Vert}\label{eq:gd-d-norm
\end{equation}<br />
可以看到，更新方向正好是梯度的负方向，所以说它是局部下降最快的方向。然而，别忘了这是在约束条件$\Vert\boldsymbol{x} - \boldsymbol{x}_t\Vert = \epsilon$下得到的，其中$\Vert\cdot\Vert$是欧氏空间的模长，如果换一个模长的定义，或者干脆换一个约束条件，那么结果就不一样了。所以，严谨来说应该是“在欧氏空间中，梯度的负方向是局部下降最快的方向”。</p>
<h2 id="_4">优化视角<a class="toc-link" href="#_4" title="Permanent link">&para;</a></h2>
<p>式$\eqref{eq:gd-min-co}$是一个带约束优化，推广和求解起来都会比较麻烦。此外，式$\eqref{eq:gd-min-co}$的求解结果是式$\eqref{eq:gd-d-norm}$，也不是原始的梯度下降$\eqref{eq:gd-d}$。事实上，可以证明式$\eqref{eq:gd-d}$对应的优化目标是<br />
\begin{equation}\boldsymbol{x}<em _boldsymbol_x="\boldsymbol{x">{t+1} = \mathop{\text{argmin}}</em>}} \frac{\Vert\boldsymbol{x} - \boldsymbol{x<em _boldsymbol_x="\boldsymbol{x">t\Vert^2}{2\alpha} + f(\boldsymbol{x})\label{eq:gd-min}\end{equation}<br />
也就是说，将约束当成惩罚项加入到优化目标，这样就不用考虑求解约束，也容易推广。而且，即便加入了额外的$\frac{\Vert\boldsymbol{x} - \boldsymbol{x}_t\Vert^2}{2\alpha}$，也能保证上式的优化不会朝着让更糟糕的方向走，因为代入$\boldsymbol{x} = \boldsymbol{x}_t$后很明显上述目标函数正好是$f(\boldsymbol{x}_t)$，所以$\min</em>_t)$。}}$的结果至少不会大于$f(\boldsymbol{x</p>
<p>当$\alpha$足够小时，第一项占主导，因此$\Vert\boldsymbol{x} - \boldsymbol{x}<em t_1="t+1">t\Vert$需要足够小时第一项才会变得足够小，即最优点应该是很接近$\boldsymbol{x}_t$的，于是我们可以在$\boldsymbol{x}_t$处将$f(\boldsymbol{x})$展开，得到<br />
\begin{equation}\boldsymbol{x}</em>} = \mathop{\text{argmin}<em _boldsymbol_x="\boldsymbol{x">{\boldsymbol{x}} \frac{\Vert\boldsymbol{x} - \boldsymbol{x}_t\Vert^2}{2\alpha} + f(\boldsymbol{x}_t)+\langle\nabla</em>}_t}f(\boldsymbol{x}_t),\boldsymbol{x}-\boldsymbol{x}_t\rangle\end{equation
此时只是一个二次函数最小值问题，求解结果正是式$\eqref{eq:gd-d}$。</p>
<p>很明显，除了模长平方外，我们还可以考虑别的正则项，从而形成不同的梯度下降方案。比如，自然梯度下降（Natural Gradient Descent）使用的是KL散度作为正则项：<br />
\begin{equation}\boldsymbol{x}<em _boldsymbol_x="\boldsymbol{x">{t+1} = \mathop{\text{argmin}}</em>}} \frac{KL(p(\boldsymbol{y}|\boldsymbol{x})\Vert p(\boldsymbol{y}|\boldsymbol{x<em t_1="t+1">t))}{\alpha} + f(\boldsymbol{x})\end{equation}<br />
其中$p(\boldsymbol{y}|\boldsymbol{x})$是某个与$f(\boldsymbol{x})$相关的概率分布。为了求解上式，同样在$f(\boldsymbol{x})$处进行展开，$f(\boldsymbol{x})$同样展开到一阶，但是KL散度比较特殊，它展开到一阶还是零（参考<a href="/archives/7466#%E5%8B%87%E6%95%A2%E5%9C%B0%E7%AE%97">这里</a>），所以至少要展开到二阶，总的结果是<br />
\begin{equation}\boldsymbol{x}</em>} = \mathop{\text{argmin}<em _boldsymbol_x="\boldsymbol{x">{\boldsymbol{x}} \frac{(\boldsymbol{x}-\boldsymbol{x}_t)^{\top}\boldsymbol{F}(\boldsymbol{x}-\boldsymbol{x}_t)}{2\alpha} + f(\boldsymbol{x}_t)+\langle\nabla</em><em t_1="t+1">t}f(\boldsymbol{x}_t),\boldsymbol{x}-\boldsymbol{x}_t\rangle\end{equation}<br />
这里的$\boldsymbol{F}$是<a href="https://en.wikipedia.org/wiki/Fisher_information">Fisher信息矩阵</a>，计算细节就不展开了，过程也可以参考<a href="/archives/7466#%E5%8B%87%E6%95%A2%E5%9C%B0%E7%AE%97">这里</a>。现在上式本质上也是二次函数的最小值问题，结果为<br />
\begin{equation}\boldsymbol{x}</em>} = \boldsymbol{x<em _boldsymbol_x="\boldsymbol{x">t -\alpha \boldsymbol{F}^{-1}\nabla</em>}_t}f(\boldsymbol{x}_t)\end{equation
这就是所谓的“自然梯度下降”。</p>
<h2 id="_5">泛函入门<a class="toc-link" href="#_5" title="Permanent link">&para;</a></h2>
<p>式$\eqref{eq:gd-min}$不仅可以将正则项一般化，还可以将求解目标一般化，比如推广到泛函。</p>
<p>“泛函”看起来让人“犯寒”，但事实上对于本站的老读者来说应该接触多次了。简单来说，普通多元函数就是输入一个向量，输出一个标量，泛函则是输入一个函数，输出一个标量，比如定积分运算：<br />
\begin{equation}\mathcal{I}[f] = \int_a^b f(x)dx\end{equation}<br />
对于任意一个函数$f$，$\mathcal{I}[f]$的计算结果就是一个标量，所以$\mathcal{I}[f]$就是一个泛函。又比如前面提到的KL散度，它定义为<br />
\begin{equation}KL(p\Vert q) = \int p(\boldsymbol{x})\log \frac{p(\boldsymbol{x})}{q(\boldsymbol{x})}d\boldsymbol{x}\end{equation}<br />
这里积分默认为全空间积分，如果固定$p(\boldsymbol{x})$，那么它就是关于$q(\boldsymbol{x})$的泛函，因为$q(\boldsymbol{x})$是一个函数，输入一个满足条件的函数，$KL(p\Vert q)$将输出一个标量。更一般地，<a href="/archives/6016">《f-GAN简介：GAN模型的生产车间》</a>所介绍的$f$散度，也是泛函的一种，这些都是比较简单的泛函，更复杂的泛函可能包含输入函数的导数，如理论物理的<a href="/archives/1304">最小作用量</a>。</p>
<p>下面我们主要关注的泛函的定义域为全体概率密度函数的集合，即研究输入一个概率密度、输出一个标量的泛函。</p>
<h2 id="_6">概率之流<a class="toc-link" href="#_6" title="Permanent link">&para;</a></h2>
<p>假如我们有一个泛函$\mathcal{F}[q]$，想要计算它的最小值，那么模仿梯度下降的思路，只要我们能求出它的某种梯度，那么就可以沿着它的负方向进行迭代。</p>
<p>为了确定迭代格式，我们沿着前面的思考，考虑推广式$\eqref{eq:gd-min}$，其中$f(\boldsymbol{x})$自然是替换为$\mathcal{F}[q]$，那么第一项正则应该替换成什么呢？在式$\eqref{eq:gd-min}$中它是欧氏距离的平方，那么很自然想到这里也应该替换为某种距离的平方，对于概率分布来说，性态比较好的距离是Wasserstein距离（准确来说是“2-Wasserstein距离”）：<br />
\begin{equation}\mathcal{W}<em _Pi_p_q_="\Pi[p,q]" _gamma_in="\gamma\in">2[p,q]=\sqrt{\inf</em>} \iint \gamma(\boldsymbol{x},\boldsymbol{y}) \Vert\boldsymbol{x}-\boldsymbol{y}\Vert^2 d\boldsymbol{x}d\boldsymbol{y}}\end{equation
关于它的介绍，这里就不详细展开了，有兴趣的读者请参考<a href="/archives/6280">《从Wasserstein距离、对偶理论到WGAN》</a>。如果进一步将式$\eqref{eq:gd-min}$中的欧氏距离替换为Wasserstein距离，那么最终目标就是<br />
\begin{equation}q_{t+1} = \mathop{\text{argmin}}<em t_1="t+1">{q} \frac{\mathcal{W}_2^2[q,q_t]}{2\alpha} + \mathcal{F}[q]\end{equation}<br />
很抱歉，笔者没法简明给出上述目标的求解过程，甚至笔者自己也没完全理解它的求解过程，只能根据<a href="https://abdulfatir.com/blog/2020/Gradient-Flows/">《Introduction to Gradient Flows in the 2-Wasserstein Space》</a>、<a href="https://papers.cool/arxiv/1609.03890">《{ Euclidean, Metric, and Wasserstein } Gradient Flows: an overview》</a>等文献，直接给出它的求解结果为<br />
\begin{equation}q</em>}(\boldsymbol{x}) = q_t(\boldsymbol{x}) + \alpha \nabla_{\boldsymbol{x}}\cdot\left(q_t(\boldsymbol{x})\nabla_{\boldsymbol{x}}\frac{\delta \mathcal{F}[q_t(\boldsymbol{x})]}{\delta q_t(\boldsymbol{x})}\right)\end{equation
或者取极限后得到
\begin{equation}\frac{\partial q_t(\boldsymbol{x})}{\partial t} = \nabla_{\boldsymbol{x}}\cdot\left(q_t(\boldsymbol{x})\nabla_{\boldsymbol{x}}\frac{\delta \mathcal{F}[q_t(\boldsymbol{x})]}{\delta q_t(\boldsymbol{x})}\right)\end{equation}<br />
这就是“Wasserstein梯度流（Wasserstein Gradient Flow）”，其中$\frac{\delta \mathcal{F}[q]}{\delta q}$是$\mathcal{F}[q]$的变分导数，对于定积分泛函来说，变分导数就是被积函数的导数：<br />
\begin{equation}\mathcal{F}[q] = \int F(q(\boldsymbol{x}))d\boldsymbol{x} \quad\Rightarrow\quad \frac{\delta \mathcal{F}[q(\boldsymbol{x})]}{\delta q(\boldsymbol{x})} = \frac{\partial F(q(\boldsymbol{x}))}{\partial q(\boldsymbol{x})}\end{equation}</p>
<h2 id="_7">一些例子<a class="toc-link" href="#_7" title="Permanent link">&para;</a></h2>
<p>根据<a href="/archives/6016">《f-GAN简介：GAN模型的生产车间》</a>，$f$散度的定义为<br />
\begin{equation}\mathcal{D}<em _boldsymbol_x="\boldsymbol{x">f(p\Vert q) = \int q(\boldsymbol{x}) f\left(\frac{p(\boldsymbol{x})}{q(\boldsymbol{x})}\right)d\boldsymbol{x}\end{equation}<br />
将$p$固定，设$\mathcal{F}[q]=\mathcal{D}_f(p\Vert q)$，那么得到<br />
\begin{equation}\frac{\partial q_t(\boldsymbol{x})}{\partial t} = \nabla</em>}}\cdot\Big(q_t(\boldsymbol{x})\nabla_{\boldsymbol{x}}\big(f(r_t(\boldsymbol{x})) - r_t(\boldsymbol{x}) f'(r_t(\boldsymbol{x}))\big)\Big)\label{eq:wgd}\end{equation
其中$r_t(\boldsymbol{x}) = \frac{p(\boldsymbol{x})}{q_t(\boldsymbol{x})}$。根据<a href="/archives/9461">《测试函数法推导连续性方程和Fokker-Planck方程》</a>的内容，上式具备连续性方程的形式，所以通过ODE<br />
\begin{equation}\frac{d\boldsymbol{x}}{dt} = -\nabla_{\boldsymbol{x}}\big(f(r_t(\boldsymbol{x})) - r_t(\boldsymbol{x}) f'(r_t(\boldsymbol{x}))\big)\end{equation}<br />
可以实现从分布$q_t$中采样，而根据前面的讨论，式$\eqref{eq:wgd}$是最小化$p,q$的$f$散度的Wasserstein梯度流，当$t\to\infty$时$f$散度为零，即$q_t=p$，所以$t\to\infty$时，上述ODE实现了从分布$p$采样。不过，这个结果目前来说只有形式上的意义，并没有实际作用，因为这意味着我们要知道分布$p$的表达式，还要从式$\eqref{eq:wgd}$中解出$q_t$的表达式，然后才能算出ODE右端式子，从而完成采样，这个计算难度非常大，通常是没法完成的。</p>
<p>一个相对简单的例子是（逆）KL散度，此时$f=-\log$，代入式$\eqref{eq:wgd}$得到<br />
\begin{equation}\begin{aligned}\frac{\partial q_t(\boldsymbol{x})}{\partial t} =&amp;\, - \nabla_{\boldsymbol{x}}\cdot\left(q_t(\boldsymbol{x})\nabla_{\boldsymbol{x}}\log \frac{p(\boldsymbol{x})}{q_t(\boldsymbol{x})}\right)\\
=&amp;\, - \nabla_{\boldsymbol{x}}\cdot\Big(q_t(\boldsymbol{x})\nabla_{\boldsymbol{x}}\big(\log p(\boldsymbol{x}) - \log q_t(\boldsymbol{x})\big)\Big)\\
=&amp;\, - \nabla_{\boldsymbol{x}}\cdot\big(q_t(\boldsymbol{x})\nabla_{\boldsymbol{x}}\log p(\boldsymbol{x})\big) + \nabla_{\boldsymbol{x}}\cdot\nabla_{\boldsymbol{x}} q_t(\boldsymbol{x})
\end{aligned}\end{equation}<br />
再次对比<a href="/archives/9461">《测试函数法推导连续性方程和Fokker-Planck方程》</a>的结果，这正好是个Fokker-Planck方程，对应于SDE：<br />
\begin{equation}d\boldsymbol{x} = \nabla_{\boldsymbol{x}}\log p(\boldsymbol{x}) dt + \sqrt{2}dw\end{equation}<br />
也就是说，如果我们知道$\log p(\boldsymbol{x})$，那么就可以实现用上式实现从$p(\boldsymbol{x})$中采样，相比前面的ODE，免除了求解$q_t(\boldsymbol{x})$的过程，是一个相对可用的方案。</p>
<h2 id="_8">文章小结<a class="toc-link" href="#_8" title="Permanent link">&para;</a></h2>
<p>本文介绍了梯度下降求最小值过程中的“梯度流”概念，其中包括向量空间的梯度流到概率空间的Wasserstein梯度流的拓展，以及它们与连续性方程、Fokker-Planck方程和ODE/SDE采样之间的联系。</p>
<p><em><strong>转载到请包括本文地址：</strong><a href="https://spaces.ac.cn/archives/9660">https://spaces.ac.cn/archives/9660</a></em></p>
<p><em><strong>更详细的转载事宜请参考：</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="《科学空间FAQ》">《科学空间FAQ》</a></p>
<p><strong>如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。</strong></p>
<p><strong>如果您觉得本文还不错，欢迎分享/打赏本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！</strong></p>
<p>打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>微信打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>支付宝打赏</p>
<p>因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>点击这里</strong></a>或在下方评论区留言来告知你的建议或需求。</p>
<p><strong>如果您需要引用本文，请参考：</strong></p>
<p>苏剑林. (Jun. 16, 2023). 《梯度流：探索通向最小值之路 》[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/9660">https://spaces.ac.cn/archives/9660</a></p>
<p>@online{kexuefm-9660,<br />
title={梯度流：探索通向最小值之路},<br />
author={苏剑林},<br />
year={2023},<br />
month={Jun},<br />
url={\url{https://spaces.ac.cn/archives/9660}},<br />
} </p>
<hr />
<h2 id="_9">公式推导与注释<a class="toc-link" href="#_9" title="Permanent link">&para;</a></h2>
<h3 id="1-ode">1. 梯度下降的ODE视角<a class="toc-link" href="#1-ode" title="Permanent link">&para;</a></h3>
<h4 id="11">1.1 从离散到连续<a class="toc-link" href="#11" title="Permanent link">&para;</a></h4>
<p>标准梯度下降迭代：
\begin{equation}\boldsymbol{x}_{t+1} = \boldsymbol{x}_t - \alpha \nabla f(\boldsymbol{x}_t)\tag{1}\end{equation}</p>
<p>改写为差分形式：
\begin{equation}\frac{\boldsymbol{x}_{t+1} - \boldsymbol{x}_t}{\alpha} = -\nabla f(\boldsymbol{x}_t)\tag{2}\end{equation}</p>
<p><strong>连续化</strong>：令$\alpha = \Delta t \to 0$，$t$变为连续时间参数：
\begin{equation}\frac{d\boldsymbol{x}(t)}{dt} = -\nabla f(\boldsymbol{x}(t))\tag{3}\end{equation}</p>
<p><strong>数学直觉</strong>：梯度下降轨迹${\boldsymbol{x}_t}$可视为ODE解曲线的离散采样。</p>
<h4 id="12">1.2 解的存在唯一性<a class="toc-link" href="#12" title="Permanent link">&para;</a></h4>
<p><strong>定理1</strong>（Picard-Lindelöf）：若$\nabla f$连续且局部Lipschitz连续，即$\exists L &gt; 0$使得：
\begin{equation}|\nabla f(\boldsymbol{x}) - \nabla f(\boldsymbol{y})| \leq L |\boldsymbol{x} - \boldsymbol{y}|\tag{4}\end{equation}</p>
<p>则对任意初值$\boldsymbol{x}(0) = \boldsymbol{x}_0$，ODE (3)在局部时间区间$[0, T]$上存在唯一解。</p>
<p><strong>意义</strong>：光滑目标函数保证梯度流轨迹的存在唯一性。</p>
<h4 id="13">1.3 函数值的单调递减性质<a class="toc-link" href="#13" title="Permanent link">&para;</a></h4>
<p>沿梯度流轨迹，函数值的变化率：
\begin{equation}\frac{df(\boldsymbol{x}(t))}{dt} = \nabla f(\boldsymbol{x}(t))^{\top} \frac{d\boldsymbol{x}(t)}{dt} = -|\nabla f(\boldsymbol{x}(t))|^2 \leq 0\tag{5}\end{equation}</p>
<p><strong>关键性质</strong>：
1. $f(\boldsymbol{x}(t))$非递增
2. $\frac{df}{dt} = 0 \Leftrightarrow \nabla f = \boldsymbol{0}$（驻点）
3. 严格递减除非已达驻点</p>
<h3 id="2-lyapunov">2. Lyapunov函数与收敛性分析<a class="toc-link" href="#2-lyapunov" title="Permanent link">&para;</a></h3>
<h4 id="21-lyapunov">2.1 Lyapunov稳定性理论<a class="toc-link" href="#21-lyapunov" title="Permanent link">&para;</a></h4>
<p><strong>定义</strong>：$V: \mathbb{R}^d \to \mathbb{R}$称为Lyapunov函数，若：
1. $V(\boldsymbol{x}^<em>) = 0$（平衡点函数值为零）
2. $V(\boldsymbol{x}) &gt; 0, \forall \boldsymbol{x} \neq \boldsymbol{x}^</em>$（正定）
3. $\frac{dV(\boldsymbol{x}(t))}{dt} \leq 0$（能量耗散）</p>
<p><strong>Lyapunov定理</strong>：若存在Lyapunov函数，则$\boldsymbol{x}^<em>$稳定。若进一步$\frac{dV}{dt} &lt; 0$（除非$\boldsymbol{x} = \boldsymbol{x}^</em>$），则渐近稳定。</p>
<h4 id="22">2.2 凸函数情况<a class="toc-link" href="#22" title="Permanent link">&para;</a></h4>
<p>对凸函数$f$，选择Lyapunov函数：
\begin{equation}V(\boldsymbol{x}) = f(\boldsymbol{x}) - f(\boldsymbol{x}^*)\tag{6}\end{equation}</p>
<p>其中$\boldsymbol{x}^* = \arg\min f$。</p>
<p>验证Lyapunov条件：
\begin{equation}\frac{dV}{dt} = \frac{df}{dt} = -|\nabla f|^2 \leq 0\tag{7}\end{equation}</p>
<p><strong>结论</strong>：梯度流全局收敛到最小值点（若存在）。</p>
<h4 id="23">2.3 强凸函数的指数收敛<a class="toc-link" href="#23" title="Permanent link">&para;</a></h4>
<p><strong>定义</strong>：$f$称为$\mu$-强凸，若：
\begin{equation}f(\boldsymbol{y}) \geq f(\boldsymbol{x}) + \nabla f(\boldsymbol{x})^{\top}(\boldsymbol{y} - \boldsymbol{x}) + \frac{\mu}{2}|\boldsymbol{y} - \boldsymbol{x}|^2\tag{8}\end{equation}</p>
<p><strong>定理2</strong>（强凸收敛率）：设$f$为$\mu$-强凸，$L$-光滑（即$|\nabla f(\boldsymbol{x}) - \nabla f(\boldsymbol{y})| \leq L|\boldsymbol{x} - \boldsymbol{y}|$）。则梯度流满足：
\begin{equation}|\boldsymbol{x}(t) - \boldsymbol{x}^<em>|^2 \leq e^{-2\mu t} |\boldsymbol{x}(0) - \boldsymbol{x}^</em>|^2\tag{9}\end{equation}</p>
<p><strong>证明</strong>：定义$V(t) = |\boldsymbol{x}(t) - \boldsymbol{x}^*|^2$。</p>
<p>计算导数：
\begin{equation}\begin{aligned}
\frac{dV}{dt} &amp;= 2(\boldsymbol{x}(t) - \boldsymbol{x}^<em>)^{\top} \frac{d\boldsymbol{x}}{dt}\
&amp;= -2(\boldsymbol{x}(t) - \boldsymbol{x}^</em>)^{\top} \nabla f(\boldsymbol{x}(t))
\end{aligned}\tag{10}\end{equation}</p>
<p>由强凸性（取$\boldsymbol{y} = \boldsymbol{x}^<em>, \boldsymbol{x} = \boldsymbol{x}(t)$）：
\begin{equation}\nabla f(\boldsymbol{x}(t))^{\top}(\boldsymbol{x}(t) - \boldsymbol{x}^</em>) \geq f(\boldsymbol{x}(t)) - f(\boldsymbol{x}^<em>) + \frac{\mu}{2}|\boldsymbol{x}(t) - \boldsymbol{x}^</em>|^2\tag{11}\end{equation}</p>
<p>又因$\nabla f(\boldsymbol{x}^<em>) = \boldsymbol{0}$，式(8)在$\boldsymbol{x} = \boldsymbol{x}^</em>$处给出：
\begin{equation}f(\boldsymbol{x}(t)) - f(\boldsymbol{x}^<em>) \geq \frac{\mu}{2}|\boldsymbol{x}(t) - \boldsymbol{x}^</em>|^2\tag{12}\end{equation}</p>
<p>综合(10)(11)(12)：
\begin{equation}\frac{dV}{dt} \leq -2\mu V\tag{13}\end{equation}</p>
<p>应用Grönwall不等式：
\begin{equation}V(t) \leq e^{-2\mu t} V(0)\tag{14}\end{equation}</p>
<p>即得式(9)。</p>
<p><strong>数学直觉</strong>：强凸性提供"弹性力"，保证指数速率回归最小值。</p>
<h3 id="3">3. 梯度流的轨迹几何<a class="toc-link" href="#3" title="Permanent link">&para;</a></h3>
<h4 id="31">3.1 等值面与梯度流<a class="toc-link" href="#31" title="Permanent link">&para;</a></h4>
<p>目标函数的等值面（level set）：
\begin{equation}\mathcal{S}_c = {\boldsymbol{x} : f(\boldsymbol{x}) = c}\tag{15}\end{equation}</p>
<p><strong>定理3</strong>：梯度流轨迹处处垂直于等值面。</p>
<p><strong>证明</strong>：设$\boldsymbol{x}(t) \in \mathcal{S}<em _boldsymbol_x="\boldsymbol{x">c$，切向量$\boldsymbol{v} \in T</em>_c$满足：
\begin{equation}\nabla f(\boldsymbol{x})^{\top} \boldsymbol{v} = 0\tag{16}\end{equation}}}\mathcal{S</p>
<p>而梯度流速度$\frac{d\boldsymbol{x}}{dt} = -\nabla f(\boldsymbol{x})$恰为法向量，故正交。</p>
<p><strong>几何意义</strong>：梯度流沿"最速下降方向"，与等值面垂直。</p>
<h4 id="32">3.2 轨迹长度与能量耗散<a class="toc-link" href="#32" title="Permanent link">&para;</a></h4>
<p>梯度流轨迹长度：
\begin{equation}L = \int_0^\infty \left|\frac{d\boldsymbol{x}(t)}{dt}\right| dt = \int_0^\infty |\nabla f(\boldsymbol{x}(t))| dt\tag{17}\end{equation}</p>
<p><strong>定理4</strong>（轨迹长度有限性）：若$f$下有界且$\nabla f$Lipschitz连续，则$L &lt; \infty$。</p>
<p><strong>证明</strong>：由式(5)：
\begin{equation}\int_0^\infty |\nabla f|^2 dt = f(\boldsymbol{x}(0)) - \lim_{t\to\infty} f(\boldsymbol{x}(t)) &lt; \infty\tag{18}\end{equation}</p>
<p>由Cauchy-Schwarz不等式：
\begin{equation}L^2 = \left(\int_0^\infty |\nabla f| dt\right)^2 \leq T \int_0^T |\nabla f|^2 dt\tag{19}\end{equation}</p>
<p>结合有界性可得$L &lt; \infty$。</p>
<h4 id="33">3.3 临界点的稳定性<a class="toc-link" href="#33" title="Permanent link">&para;</a></h4>
<p><strong>定义</strong>：$\boldsymbol{x}^<em>$称为临界点若$\nabla f(\boldsymbol{x}^</em>) = \boldsymbol{0}$。</p>
<p>Hessian矩阵$H = \nabla^2 f(\boldsymbol{x}^<em>)$的特征值决定稳定性：
- </em><em>最小值</em><em>：$H \succ 0$（正定），渐近稳定
- </em><em>鞍点</em><em>：$H$不定，不稳定
- </em><em>最大值</em>*：$H \prec 0$（负定），不稳定</p>
<p><strong>线性化分析</strong>：在$\boldsymbol{x}^<em>$附近展开：
\begin{equation}\frac{d\boldsymbol{\delta}}{dt} \approx -H \boldsymbol{\delta}, \quad \boldsymbol{\delta} = \boldsymbol{x} - \boldsymbol{x}^</em>\tag{20}\end{equation}</p>
<p>解为：
\begin{equation}\boldsymbol{\delta}(t) = \exp(-Ht) \boldsymbol{\delta}(0) = \sum_i c_i e^{-\lambda_i t} \boldsymbol{v}_i\tag{21}\end{equation}</p>
<p>其中$\lambda_i, \boldsymbol{v}_i$是$H$的特征值特征向量。</p>
<p><strong>结论</strong>：所有$\lambda_i &gt; 0$时指数收敛；存在$\lambda_i &lt; 0$时发散。</p>
<h3 id="4">4. 带动量的梯度流<a class="toc-link" href="#4" title="Permanent link">&para;</a></h3>
<h4 id="41-heavy-ball">4.1 重球方法（Heavy Ball）<a class="toc-link" href="#41-heavy-ball" title="Permanent link">&para;</a></h4>
<p>离散形式：
\begin{equation}\boldsymbol{x}<em t-1="t-1">{t+1} = \boldsymbol{x}_t - \alpha \nabla f(\boldsymbol{x}_t) + \beta(\boldsymbol{x}_t - \boldsymbol{x}</em>})\tag{22}\end{equation</p>
<p>连续化为二阶ODE：
\begin{equation}\ddot{\boldsymbol{x}}(t) + \gamma \dot{\boldsymbol{x}}(t) + \nabla f(\boldsymbol{x}(t)) = \boldsymbol{0}\tag{23}\end{equation}</p>
<p><strong>物理类比</strong>：质点在势场$f$中运动，受阻尼$\gamma$。</p>
<p>引入速度变量$\boldsymbol{v} = \dot{\boldsymbol{x}}$，改写为一阶系统：
\begin{equation}\begin{cases}
\dot{\boldsymbol{x}} = \boldsymbol{v}\
\dot{\boldsymbol{v}} = -\gamma \boldsymbol{v} - \nabla f(\boldsymbol{x})
\end{cases}\tag{24}\end{equation}</p>
<h4 id="42-nesterov">4.2 Nesterov加速的连续化<a class="toc-link" href="#42-nesterov" title="Permanent link">&para;</a></h4>
<p>Nesterov加速梯度（NAG）：
\begin{equation}\begin{aligned}
\boldsymbol{y}<em t-1="t-1">t &amp;= \boldsymbol{x}_t + \beta(\boldsymbol{x}_t - \boldsymbol{x}</em>)\
\boldsymbol{x}_{t+1} &amp;= \boldsymbol{y}_t - \alpha \nabla f(\boldsymbol{y}_t)
\end{aligned}\tag{25}\end{equation}</p>
<p>Su-Boyd-Candès的ODE近似：
\begin{equation}\ddot{\boldsymbol{x}}(t) + \frac{3}{t}\dot{\boldsymbol{x}}(t) + \nabla f(\boldsymbol{x}(t)) = \boldsymbol{0}\tag{26}\end{equation}</p>
<p><strong>关键差异</strong>：阻尼系数$\gamma = 3/t$随时间衰减。</p>
<p><strong>Lyapunov函数</strong>：
\begin{equation}E(t) = t^2(f(\boldsymbol{x}(t)) - f^<em>) + \frac{1}{2}|\boldsymbol{x}(t) + \frac{t}{3}\dot{\boldsymbol{x}}(t) - \boldsymbol{x}^</em>|^2\tag{27}\end{equation}</p>
<p>计算导数：
\begin{equation}\frac{dE}{dt} = -\frac{t^2}{3}|\dot{\boldsymbol{x}}(t)|^2 \leq 0\tag{28}\end{equation}</p>
<p><strong>收敛率</strong>：对强凸函数：
\begin{equation}f(\boldsymbol{x}(t)) - f^* = O\left(\frac{1}{t^2}\right)\tag{29}\end{equation}</p>
<p>对比标准梯度流的$O(e^{-\mu t})$，Nesterov在非强凸情况更优。</p>
<h3 id="5-wasserstein">5. Wasserstein空间中的梯度流<a class="toc-link" href="#5-wasserstein" title="Permanent link">&para;</a></h3>
<h4 id="51">5.1 概率测度空间<a class="toc-link" href="#51" title="Permanent link">&para;</a></h4>
<p>记$\mathcal{P}_2(\mathbb{R}^d)$为二阶矩有限的概率测度集合：
\begin{equation}\mathcal{P}_2(\mathbb{R}^d) = \left{\rho : \int |\boldsymbol{x}|^2 d\rho(\boldsymbol{x}) &lt; \infty, \int d\rho = 1\right}\tag{30}\end{equation}</p>
<h4 id="52-wasserstein-2">5.2 Wasserstein-2距离<a class="toc-link" href="#52-wasserstein-2" title="Permanent link">&para;</a></h4>
<p>对$\rho_0, \rho_1 \in \mathcal{P}<em _Pi_rho_0_="\Pi(\rho_0," _in="\in" _pi="\pi" _rho_1_="\rho_1)">2(\mathbb{R}^d)$，Wasserstein-2距离定义为：
\begin{equation}W_2^2(\rho_0, \rho_1) = \inf</em>} \int_{\mathbb{R}^d \times \mathbb{R}^d} |\boldsymbol{x} - \boldsymbol{y}|^2 d\pi(\boldsymbol{x}, \boldsymbol{y})\tag{31}\end{equation</p>
<p>其中$\Pi(\rho_0, \rho_1)$是边际分布为$\rho_0, \rho_1$的联合分布集合。</p>
<p><strong>Kantorovich对偶</strong>：
\begin{equation}W_2^2(\rho_0, \rho_1) = \sup_{\phi} \left{\int \phi d\rho_1 - \int \phi^c d\rho_0\right}\tag{32}\end{equation}</p>
<p>其中$\phi^c(\boldsymbol{x}) = \inf_{\boldsymbol{y}} {|\boldsymbol{x} - \boldsymbol{y}|^2 - \phi(\boldsymbol{y})}$是$c$-变换。</p>
<h4 id="53-otto">5.3 Otto微积分与切空间<a class="toc-link" href="#53-otto" title="Permanent link">&para;</a></h4>
<p>概率测度流形$\mathcal{P}<em>2$在$\rho$处的切空间：
\begin{equation}T</em>\rho \mathcal{P}_2 = {\nabla \phi : \phi \in C^\infty_c(\mathbb{R}^d)}\tag{33}\end{equation}</p>
<p><strong>黎曼度量</strong>：对$\boldsymbol{v}<em>1 = \nabla \phi_1, \boldsymbol{v}_2 = \nabla \phi_2 \in T</em>\rho \mathcal{P}<em>2$：
\begin{equation}\langle \boldsymbol{v}_1, \boldsymbol{v}_2 \rangle</em>\rho = \int \nabla \phi_1(\boldsymbol{x}) \cdot \nabla \phi_2(\boldsymbol{x}) d\rho(\boldsymbol{x})\tag{34}\end{equation}</p>
<h4 id="54">5.4 泛函的第一变分<a class="toc-link" href="#54" title="Permanent link">&para;</a></h4>
<p>设泛函$\mathcal{F}: \mathcal{P}<em 0="0" _epsilon="\epsilon" _to="\to">2 \to \mathbb{R}$。变分导数$\frac{\delta \mathcal{F}}{\delta \rho}$定义为：
\begin{equation}\lim</em>} \frac{\mathcal{F}[\rho + \epsilon \eta] - \mathcal{F}[\rho]}{\epsilon} = \int \frac{\delta \mathcal{F}}{\delta \rho}(\boldsymbol{x}) \eta(\boldsymbol{x}) d\boldsymbol{x}\tag{35}\end{equation</p>
<p><strong>例子</strong>：对$\mathcal{F}[\rho] = \int V(\boldsymbol{x}) \rho(\boldsymbol{x}) d\boldsymbol{x}$：
\begin{equation}\frac{\delta \mathcal{F}}{\delta \rho} = V(\boldsymbol{x})\tag{36}\end{equation}</p>
<h4 id="55-wasserstein">5.5 Wasserstein梯度流方程<a class="toc-link" href="#55-wasserstein" title="Permanent link">&para;</a></h4>
<p>泛函$\mathcal{F}$的Wasserstein梯度流：
\begin{equation}\frac{\partial \rho}{\partial t} = \nabla \cdot \left(\rho \nabla \frac{\delta \mathcal{F}}{\delta \rho}\right)\tag{37}\end{equation}</p>
<p>这是连续性方程形式：
\begin{equation}\frac{\partial \rho}{\partial t} + \nabla \cdot (\rho \boldsymbol{v}) = 0\tag{38}\end{equation}</p>
<p>其中速度场：
\begin{equation}\boldsymbol{v} = -\nabla \frac{\delta \mathcal{F}}{\delta \rho}\tag{39}\end{equation}</p>
<p><strong>物理意义</strong>：概率质量沿变分导数的负梯度方向输运。</p>
<h4 id="56">5.6 能量耗散结构<a class="toc-link" href="#56" title="Permanent link">&para;</a></h4>
<p>沿Wasserstein梯度流，泛函的时间导数：
\begin{equation}\frac{d\mathcal{F}[\rho_t]}{dt} = -\int \rho_t \left|\nabla \frac{\delta \mathcal{F}}{\delta \rho_t}\right|^2 d\boldsymbol{x} \leq 0\tag{40}\end{equation}</p>
<p><strong>证明</strong>：
\begin{equation}\begin{aligned}
\frac{d\mathcal{F}}{dt} &amp;= \int \frac{\delta \mathcal{F}}{\delta \rho} \frac{\partial \rho}{\partial t} d\boldsymbol{x}\
&amp;= \int \frac{\delta \mathcal{F}}{\delta \rho} \nabla \cdot \left(\rho \nabla \frac{\delta \mathcal{F}}{\delta \rho}\right) d\boldsymbol{x}\
&amp;= -\int \nabla \frac{\delta \mathcal{F}}{\delta \rho} \cdot \left(\rho \nabla \frac{\delta \mathcal{F}}{\delta \rho}\right) d\boldsymbol{x}\
&amp;= -\int \rho \left|\nabla \frac{\delta \mathcal{F}}{\delta \rho}\right|^2 d\boldsymbol{x}
\end{aligned}\tag{41}\end{equation}</p>
<h3 id="6-wasserstein">6. 经典泛函的Wasserstein梯度流<a class="toc-link" href="#6-wasserstein" title="Permanent link">&para;</a></h3>
<h4 id="61-boltzmann">6.1 Boltzmann熵<a class="toc-link" href="#61-boltzmann" title="Permanent link">&para;</a></h4>
<p>内能泛函：
\begin{equation}\mathcal{E}[\rho] = \int V(\boldsymbol{x}) \rho(\boldsymbol{x}) d\boldsymbol{x}\tag{42}\end{equation}</p>
<p>Boltzmann熵：
\begin{equation}\mathcal{H}[\rho] = \int \rho(\boldsymbol{x}) \log \rho(\boldsymbol{x}) d\boldsymbol{x}\tag{43}\end{equation}</p>
<p>自由能：
\begin{equation}\mathcal{F}[\rho] = \mathcal{E}[\rho] + \mathcal{H}[\rho]\tag{44}\end{equation}</p>
<p>变分导数：
\begin{equation}\frac{\delta \mathcal{F}}{\delta \rho} = V(\boldsymbol{x}) + \log \rho(\boldsymbol{x}) + 1\tag{45}\end{equation}</p>
<p>Wasserstein梯度流：
\begin{equation}\frac{\partial \rho}{\partial t} = \nabla \cdot (\rho \nabla V) + \Delta \rho\tag{46}\end{equation}</p>
<p><strong>识别</strong>：这正是Fokker-Planck方程！</p>
<p>平衡态$\frac{\partial \rho}{\partial t} = 0$：
\begin{equation}\rho_\infty(\boldsymbol{x}) \propto \exp(-V(\boldsymbol{x}))\tag{47}\end{equation}</p>
<p>即Gibbs分布。</p>
<h4 id="62-fisher">6.2 Fisher信息泛函<a class="toc-link" href="#62-fisher" title="Permanent link">&para;</a></h4>
<p>Fisher信息：
\begin{equation}\mathcal{I}[\rho] = \int \frac{|\nabla \rho|^2}{\rho} d\boldsymbol{x} = 4\int |\nabla \sqrt{\rho}|^2 d\boldsymbol{x}\tag{48}\end{equation}</p>
<p>变分导数：
\begin{equation}\frac{\delta \mathcal{I}}{\delta \rho} = -2 \frac{\Delta \rho}{\rho} + \frac{|\nabla \rho|^2}{\rho^2}\tag{49}\end{equation}</p>
<p>Wasserstein梯度流对应热方程：
\begin{equation}\frac{\partial \rho}{\partial t} = \Delta \rho\tag{50}\end{equation}</p>
<p><strong>收敛性</strong>：Fisher信息沿热方程单调递减：
\begin{equation}\frac{d\mathcal{I}[\rho_t]}{dt} = -\int \rho \left|\nabla \frac{\delta \mathcal{I}}{\delta \rho}\right|^2 d\boldsymbol{x} \leq 0\tag{51}\end{equation}</p>
<h4 id="63-kl">6.3 KL散度的梯度流<a class="toc-link" href="#63-kl" title="Permanent link">&para;</a></h4>
<p>设目标分布$\rho_<em>$，KL散度：
\begin{equation}\text{KL}(\rho | \rho_</em>) = \int \rho \log \frac{\rho}{\rho_*} d\boldsymbol{x}\tag{52}\end{equation}</p>
<p>变分导数：
\begin{equation}\frac{\delta \text{KL}}{\delta \rho} = \log \frac{\rho}{\rho_*} + 1\tag{53}\end{equation}</p>
<p>Wasserstein梯度流：
\begin{equation}\frac{\partial \rho}{\partial t} = \nabla \cdot \left(\rho \nabla \log \frac{\rho}{\rho_*}\right)\tag{54}\end{equation}</p>
<p>等价形式：
\begin{equation}\frac{\partial \rho}{\partial t} = \Delta \rho - \nabla \cdot (\rho \boldsymbol{v}<em><em>), \quad \boldsymbol{v}_</em> = -\nabla \log \rho</em>*\tag{55}\end{equation}</p>
<p><strong>应用</strong>：采样算法——从任意初始$\rho_0$出发，沿此流收敛到$\rho_*$。</p>
<h3 id="7-jko">7. JKO格式与时间离散化<a class="toc-link" href="#7-jko" title="Permanent link">&para;</a></h3>
<h4 id="71-jordan-kinderlehrer-ottojko">7.1 Jordan-Kinderlehrer-Otto（JKO）格式<a class="toc-link" href="#71-jordan-kinderlehrer-ottojko" title="Permanent link">&para;</a></h4>
<p>将Wasserstein梯度流离散为优化序列：
\begin{equation}\rho_{k+1} = \arg\min_\rho \left{\mathcal{F}[\rho] + \frac{1}{2\tau} W_2^2(\rho, \rho_k)\right}\tag{56}\end{equation}</p>
<p><strong>解释</strong>：每步最小化泛函与"运输成本"的折中。</p>
<p><strong>定理5</strong>（JKO收敛性）：当$\tau \to 0$，$\rho_{k}$的插值收敛到连续梯度流解。</p>
<h4 id="72">7.2 计算实例：热方程<a class="toc-link" href="#72" title="Permanent link">&para;</a></h4>
<p>对Fisher信息$\mathcal{I}[\rho]$，JKO格式：
\begin{equation}\rho_{k+1} = \arg\min_\rho \left{\mathcal{I}[\rho] + \frac{1}{2\tau} W_2^2(\rho, \rho_k)\right}\tag{57}\end{equation}</p>
<p>Euler-Lagrange方程导出：
\begin{equation}\rho_{k+1} = \rho_k + \tau \Delta \rho_{k+1}\tag{58}\end{equation}</p>
<p>这是热方程的隐式Euler格式！</p>
<h3 id="8">8. 粒子系统与均场极限<a class="toc-link" href="#8" title="Permanent link">&para;</a></h3>
<h4 id="81">8.1 有限粒子近似<a class="toc-link" href="#81" title="Permanent link">&para;</a></h4>
<p>用经验测度近似概率密度：
\begin{equation}\rho_N = \frac{1}{N}\sum_{i=1}^N \delta_{\boldsymbol{x}_i(t)}\tag{59}\end{equation}</p>
<p>代入Wasserstein梯度流式(37)，得粒子系统：
\begin{equation}\frac{d\boldsymbol{x}<em _boldsymbol_x="\boldsymbol{x">i}{dt} = -\nabla \frac{\delta \mathcal{F}}{\delta \rho}\bigg|</em>}=\boldsymbol{x}_i}\tag{60}\end{equation</p>
<h4 id="82">8.2 例子：势能泛函<a class="toc-link" href="#82" title="Permanent link">&para;</a></h4>
<p>对$\mathcal{F}[\rho] = \int V(\boldsymbol{x}) \rho d\boldsymbol{x}$：
\begin{equation}\frac{d\boldsymbol{x}_i}{dt} = -\nabla V(\boldsymbol{x}_i)\tag{61}\end{equation}</p>
<p>每个粒子独立梯度下降。</p>
<h4 id="83">8.3 交互势能<a class="toc-link" href="#83" title="Permanent link">&para;</a></h4>
<p>含交互的泛函：
\begin{equation}\mathcal{F}[\rho] = \int V(\boldsymbol{x}) \rho d\boldsymbol{x} + \frac{1}{2}\iint K(\boldsymbol{x}, \boldsymbol{y}) \rho(\boldsymbol{x}) \rho(\boldsymbol{y}) d\boldsymbol{x}d\boldsymbol{y}\tag{62}\end{equation}</p>
<p>变分导数：
\begin{equation}\frac{\delta \mathcal{F}}{\delta \rho}(\boldsymbol{x}) = V(\boldsymbol{x}) + \int K(\boldsymbol{x}, \boldsymbol{y}) \rho(\boldsymbol{y}) d\boldsymbol{y}\tag{63}\end{equation}</p>
<p>粒子系统：
\begin{equation}\frac{d\boldsymbol{x}<em j="1">i}{dt} = -\nabla V(\boldsymbol{x}_i) - \frac{1}{N}\sum</em>}^N \nabla_{\boldsymbol{x}} K(\boldsymbol{x}_i, \boldsymbol{x}_j)\tag{64}\end{equation</p>
<p><strong>应用</strong>：Coulomb气体、粒子群优化。</p>
<h3 id="9">9. 数值方法与实现<a class="toc-link" href="#9" title="Permanent link">&para;</a></h3>
<h4 id="91-euler">9.1 梯度流的Euler方法<a class="toc-link" href="#91-euler" title="Permanent link">&para;</a></h4>
<p>显式Euler：
\begin{equation}\boldsymbol{x}_{k+1} = \boldsymbol{x}_k - h \nabla f(\boldsymbol{x}_k)\tag{65}\end{equation}</p>
<p>隐式Euler：
\begin{equation}\boldsymbol{x}<em k_1="k+1">{k+1} = \boldsymbol{x}_k - h \nabla f(\boldsymbol{x}</em>})\tag{66}\end{equation</p>
<p><strong>稳定性</strong>：隐式Euler无条件稳定，显式需$h &lt; 2/L$（$L$为Lipschitz常数）。</p>
<h4 id="92-runge-kutta">9.2 Runge-Kutta方法<a class="toc-link" href="#92-runge-kutta" title="Permanent link">&para;</a></h4>
<p>四阶RK（RK4）：
\begin{equation}\begin{aligned}
\boldsymbol{k}<em n_1="n+1">1 &amp;= -\nabla f(\boldsymbol{x}_n)\
\boldsymbol{k}_2 &amp;= -\nabla f(\boldsymbol{x}_n + \frac{h}{2}\boldsymbol{k}_1)\
\boldsymbol{k}_3 &amp;= -\nabla f(\boldsymbol{x}_n + \frac{h}{2}\boldsymbol{k}_2)\
\boldsymbol{k}_4 &amp;= -\nabla f(\boldsymbol{x}_n + h\boldsymbol{k}_3)\
\boldsymbol{x}</em>_4)
\end{aligned}\tag{67}\end{equation}} &amp;= \boldsymbol{x}_n + \frac{h}{6}(\boldsymbol{k}_1 + 2\boldsymbol{k}_2 + 2\boldsymbol{k}_3 + \boldsymbol{k</p>
<p><strong>优势</strong>：高阶精度$O(h^4)$。</p>
<h4 id="93-wasserstein">9.3 Wasserstein梯度流的粒子实现<a class="toc-link" href="#93-wasserstein" title="Permanent link">&para;</a></h4>
<p>伪代码：</p>
<div class="highlight"><pre><span></span><code>输入：初始粒子位置 {x_i(0)}_{i=1}^N，步长 h，迭代数 T
      泛函 F[ρ]

for t = 1 to T do
    ρ_t = (1/N) Σ_i δ_{x_i(t)}

    for i = 1 to N do
        # 计算变分导数在 x_i 处的值
        v_i = ∇ (δF/δρ)|_{x=x_i}

        # 粒子更新
        x_i(t+1) = x_i(t) - h · v_i
    end for
end for

返回：{x_i(T)}
</code></pre></div>

<h3 id="10">10. 应用实例与计算示例<a class="toc-link" href="#10" title="Permanent link">&para;</a></h3>
<h4 id="101-rosenbrock">10.1 Rosenbrock函数<a class="toc-link" href="#101-rosenbrock" title="Permanent link">&para;</a></h4>
<p>目标函数：
\begin{equation}f(x_1, x_2) = (1 - x_1)^2 + 100(x_2 - x_1^2)^2\tag{68}\end{equation}</p>
<p>梯度：
\begin{equation}\nabla f = \begin{pmatrix} -2(1-x_1) - 400x_1(x_2 - x_1^2)\ 200(x_2 - x_1^2) \end{pmatrix}\tag{69}\end{equation}</p>
<p>梯度流ODE：
\begin{equation}\begin{cases}
\dot{x}_1 = 2(1-x_1) + 400x_1(x_2 - x_1^2)\
\dot{x}_2 = -200(x_2 - x_1^2)
\end{cases}\tag{70}\end{equation}</p>
<p>数值求解从$\boldsymbol{x}(0) = (-1, 1)$出发，步长$h = 0.001$，收敛到最小值$(1, 1)$。</p>
<h4 id="102-fokker-planck">10.2 Fokker-Planck方程采样<a class="toc-link" href="#102-fokker-planck" title="Permanent link">&para;</a></h4>
<p>目标分布$\rho_*(\boldsymbol{x}) \propto \exp(-V(\boldsymbol{x}))$，例如$V(\boldsymbol{x}) = \frac{1}{2}|\boldsymbol{x}|^2$（高斯分布）。</p>
<p>Wasserstein梯度流（式46）：
\begin{equation}\frac{\partial \rho}{\partial t} = \nabla \cdot (\rho \nabla V) + \Delta \rho\tag{71}\end{equation}</p>
<p>粒子系统：
\begin{equation}\frac{d\boldsymbol{x}_i}{dt} = -\nabla V(\boldsymbol{x}_i) + \sqrt{2} \boldsymbol{\xi}_i(t)\tag{72}\end{equation}</p>
<p>其中$\boldsymbol{\xi}_i$是标准布朗运动。</p>
<p><strong>实现</strong>：Langevin动力学Monte Carlo。</p>
<h3 id="11_1">11. 深度学习中的连接<a class="toc-link" href="#11_1" title="Permanent link">&para;</a></h3>
<h4 id="111">11.1 训练动力学<a class="toc-link" href="#111" title="Permanent link">&para;</a></h4>
<p>神经网络训练损失$\mathcal{L}(\boldsymbol{\theta})$关于参数$\boldsymbol{\theta}$的梯度流：
\begin{equation}\frac{d\boldsymbol{\theta}}{dt} = -\nabla_{\boldsymbol{\theta}} \mathcal{L}\tag{73}\end{equation}</p>
<p><strong>Neural Tangent Kernel（NTK）</strong>：线性化分析下，无限宽网络的训练动力学可解析求解。</p>
<h4 id="112-score-matching">11.2 扩散模型的score matching<a class="toc-link" href="#112-score-matching" title="Permanent link">&para;</a></h4>
<p>生成模型通过逆时扩散采样：
\begin{equation}d\boldsymbol{x} = -\nabla \log \rho_t(\boldsymbol{x}) dt + \sqrt{2} d\boldsymbol{W}\tag{74}\end{equation}</p>
<p>其中$\nabla \log \rho_t$（score function）通过神经网络学习。</p>
<p><strong>连接</strong>：式(74)是Boltzmann熵Wasserstein梯度流的Langevin版本。</p>
<h3 id="_10">总结<a class="toc-link" href="#_10" title="Permanent link">&para;</a></h3>
<p>本文系统推导了梯度流的理论框架：</p>
<ol>
<li><strong>ODE视角</strong>：梯度下降的连续极限，Lyapunov稳定性分析</li>
<li><strong>几何视角</strong>：轨迹与等值面的正交性，能量耗散结构</li>
<li><strong>加速方法</strong>：重球与Nesterov的动力系统解释</li>
<li><strong>Wasserstein流形</strong>：概率空间上的黎曼几何，变分导数</li>
<li><strong>经典泛函</strong>：Fokker-Planck、热方程、KL散度的统一视角</li>
<li><strong>数值方法</strong>：Euler、RK、JKO格式的实现</li>
<li><strong>应用拓展</strong>：粒子系统、采样算法、深度学习动力学</li>
</ol>
<p>核心洞察：优化、采样、偏微分方程通过梯度流概念紧密相连，为算法设计提供统一理论语言。</p>
                </div>

                <!-- Previous/Next Navigation -->
                <nav class="post-navigation" aria-label="文章导航">
                    <div class="row g-3">
                        <div class="col-6">
                            
                            <a href="naive-bayes-is-all-you-need.html" class="nav-link-prev">
                                <div class="nav-direction"><i class="fas fa-chevron-left"></i> 上一篇</div>
                                <div class="nav-title">#235 Naive Bayes is all you need ?</div>
                            </a>
                            
                        </div>
                        <div class="col-6">
                            
                            <a href="生成扩散模型漫谈十九作为扩散ode的gan.html" class="nav-link-next">
                                <div class="nav-direction">下一篇 <i class="fas fa-chevron-right"></i></div>
                                <div class="nav-title">#237 生成扩散模型漫谈（十九）：作为扩散ODE的GAN</div>
                            </a>
                            
                        </div>
                    </div>
                </nav>

                <!-- Back to Home -->
                <div class="text-center mt-4 mb-4">
                    <a href="../index.html" class="btn btn-outline-primary">
                        <i class="fas fa-arrow-left"></i> 返回首页
                    </a>
                </div>
            </div>

            <!-- Sidebar (TOC) -->
            <div class="col-lg-3">
                <aside class="sidebar">
                    
                    <div class="toc-sidebar">
                        <h5 class="toc-title"><i class="fas fa-list"></i> 目录</h5>
                        <div class="toc-content">
                            <div class="toc">
<ul>
<li><a href="#_1">梯度流：探索通向最小值之路</a><ul>
<li><a href="#_2">梯度下降</a></li>
<li><a href="#_3">最速方向</a></li>
<li><a href="#_4">优化视角</a></li>
<li><a href="#_5">泛函入门</a></li>
<li><a href="#_6">概率之流</a></li>
<li><a href="#_7">一些例子</a></li>
<li><a href="#_8">文章小结</a></li>
<li><a href="#_9">公式推导与注释</a><ul>
<li><a href="#1-ode">1. 梯度下降的ODE视角</a></li>
<li><a href="#2-lyapunov">2. Lyapunov函数与收敛性分析</a></li>
<li><a href="#3">3. 梯度流的轨迹几何</a></li>
<li><a href="#4">4. 带动量的梯度流</a></li>
<li><a href="#5-wasserstein">5. Wasserstein空间中的梯度流</a></li>
<li><a href="#6-wasserstein">6. 经典泛函的Wasserstein梯度流</a></li>
<li><a href="#7-jko">7. JKO格式与时间离散化</a></li>
<li><a href="#8">8. 粒子系统与均场极限</a></li>
<li><a href="#9">9. 数值方法与实现</a></li>
<li><a href="#10">10. 应用实例与计算示例</a></li>
<li><a href="#11_1">11. 深度学习中的连接</a></li>
<li><a href="#_10">总结</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>

                        </div>
                        <div class="toc-actions">
                            <button class="btn btn-sm btn-outline-secondary" onclick="expandAll()">
                                <i class="fas fa-expand"></i> 全部展开
                            </button>
                            <button class="btn btn-sm btn-outline-secondary" onclick="collapseAll()">
                                <i class="fas fa-compress"></i> 全部折叠
                            </button>
                        </div>
                    </div>
                    

                    <!-- Back to Top Button -->
                    <button id="backToTop" class="back-to-top" title="回到顶部">
                        <i class="fas fa-arrow-up"></i>
                    </button>
                </aside>
            </div>
        </div>
    </article>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>
                博客来源: <a href="https://spaces.ac.cn" target="_blank">科学空间</a> |
                内容经过整理并添加详细数学推导
            </p>
            <p>
                Powered by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>
            </p>
        </div>
    </footer>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>

    <!-- Syntax highlighting -->
    <script>hljs.highlightAll();</script>

    <!-- Back to top functionality -->
    <script>
        // Show/hide back to top button based on scroll position
        window.addEventListener('scroll', function() {
            const backToTop = document.getElementById('backToTop');
            if (window.pageYOffset > 300) {
                backToTop.classList.add('show');
            } else {
                backToTop.classList.remove('show');
            }
        });

        // Smooth scroll to top
        document.getElementById('backToTop').addEventListener('click', function() {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        });

        // Sticky TOC sidebar
        window.addEventListener('scroll', function() {
            const sidebar = document.querySelector('.sidebar');
            if (!sidebar) return;

            const sidebarTop = sidebar.offsetTop;
            const scrollTop = window.pageYOffset;

            if (scrollTop > sidebarTop - 20) {
                sidebar.classList.add('sticky');
            } else {
                sidebar.classList.remove('sticky');
            }
        });
    </script>
</body>
</html>