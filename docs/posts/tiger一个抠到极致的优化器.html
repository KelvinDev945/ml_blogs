<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tiger：一个“抠”到极致的优化器 | ML & Math Blog Posts</title>
    <meta name="description" content="Tiger：一个“抠”到极致的优化器&para;
原文链接: https://spaces.ac.cn/archives/9512
发布日期: 

这段时间笔者一直在实验《Google新搜出的优化器Lion：效率与效果兼得的“训练狮”》所介绍的Lion优化器。之所以对Lion饶有兴致，是因为它跟笔者之前的关于理想优化器的一些想法不谋而合，但当时笔者没有调出好的效果，而Lion则做好了。
相比标准的...">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css">

    <!-- Google Fonts -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="../assets/css/main.css">
    <link rel="stylesheet" href="../assets/css/post.css">

    <!-- Custom JS -->
    <script src="../assets/js/collapsible.js" defer></script>

    <!-- MathJax for math rendering with equation numbering -->
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true,
        tags: 'ams',  // Enable equation numbering with AMS style
        tagSide: 'right',  // Place equation numbers on the right
        tagIndent: '0.8em',  // Indentation for equation numbers
        multlineWidth: '85%'
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Syntax highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/styles/github.min.css">
    <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/highlight.min.js"></script>
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light bg-light border-bottom">
        <div class="container">
            <a class="navbar-brand" href="../index.html">
                <i class="fas fa-brain"></i> ML & Math Blog
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="../index.html"><i class="fas fa-home"></i> 首页</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Post Content -->
    <article class="container post-container my-5">
        <!-- Breadcrumb Navigation -->
        <nav aria-label="breadcrumb">
            <ol class="breadcrumb">
                <li class="breadcrumb-item"><a href="../index.html"><i class="fas fa-home"></i> 首页</a></li>
                
                <li class="breadcrumb-item"><a href="../index.html?tags=模型">模型</a></li>
                
                <li class="breadcrumb-item active" aria-current="page">
                    #221 Tiger：一个“抠”到极致的优化器
                </li>
            </ol>
        </nav>

        <!-- Post Header -->
        <header class="post-header mb-4">
            <h1 class="post-title">
                <span class="post-number">#221</span>
                Tiger：一个“抠”到极致的优化器
            </h1>
            <div class="post-meta">
                <span><i class="far fa-calendar"></i> 2023-03-07</span>
                
            </div>
            
            <div class="post-tags mt-3">
                
                <a href="../index.html?tags=模型" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 模型</span>
                </a>
                
                <a href="../index.html?tags=优化" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 优化</span>
                </a>
                
                <a href="../index.html?tags=优化器" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 优化器</span>
                </a>
                
                <a href="../index.html?tags=生成模型" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 生成模型</span>
                </a>
                
                <a href="../index.html?tags=attention" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> attention</span>
                </a>
                
            </div>
            
        </header>

        <div class="row">
            <!-- Main Content -->
            <div class="col-lg-9">
                <!-- Post Body -->
                <div class="post-content">
                    <h1 id="tiger">Tiger：一个“抠”到极致的优化器<a class="toc-link" href="#tiger" title="Permanent link">&para;</a></h1>
<p><strong>原文链接</strong>: <a href="https://spaces.ac.cn/archives/9512">https://spaces.ac.cn/archives/9512</a></p>
<p><strong>发布日期</strong>: </p>
<hr />
<p>这段时间笔者一直在实验<a href="/archives/9473">《Google新搜出的优化器Lion：效率与效果兼得的“训练狮”》</a>所介绍的Lion优化器。之所以对Lion饶有兴致，是因为它跟笔者之前的关于理想优化器的一些想法不谋而合，但当时笔者没有调出好的效果，而Lion则做好了。</p>
<p>相比标准的Lion，笔者更感兴趣的是它在$\beta_1=\beta_2$时的特殊例子，这里称之为“<strong>Tiger</strong> ”。Tiger只用到了动量来构建更新量，根据<a href="/archives/8634">《隐藏在动量中的梯度累积：少更新几步，效果反而更好？》</a>的结论，此时我们不新增一组参数来“无感”地实现梯度累积！这也意味着在我们有梯度累积需求时，Tiger已经达到了显存占用的最优解，这也是“Tiger”这个名字的来源（<strong>Tig</strong> ht-fisted Optimiz<strong>er</strong> ，抠门的优化器，不舍得多花一点显存）。</p>
<p>此外，Tiger还加入了我们的一些超参数调节经验，以及提出了一个防止模型出现NaN（尤其是混合精度训练下）的简单策略。我们的初步实验显示，Tiger的这些改动，能够更加友好地完成模型（尤其是大模型）的训练。</p>
<h2 id="_1">基本形式<a class="toc-link" href="#_1" title="Permanent link">&para;</a></h2>
<p>Tiger的更新规则为<br />
\begin{equation}\text{Tiger}:=\left\{\begin{aligned}
&amp;\boldsymbol{m}<em t-1="t-1">t = \beta \boldsymbol{m}</em>} + \left(1 - \beta\right) \boldsymbol{g<em t-1="t-1">t \\
&amp;\boldsymbol{\theta}_t = \boldsymbol{\theta}</em>} - \eta_t \left[\text{sign}(\boldsymbol{m<em t-1="t-1">t) \color{skyblue}{ + \lambda_t \boldsymbol{\theta}</em>\right] \\}
\end{aligned}\right.\end{equation}<br />
相比Lion，它就是选择了参数$\beta_1 = \beta_2 = \beta$；相比<a href="https://papers.cool/arxiv/1802.04434">SignSGD</a>，它则是新增了动量和权重衰减。</p>
<p>参考实现：</p>
<blockquote>
<p><strong>Tiger：<a href="https://github.com/bojone/tiger">https://github.com/bojone/tiger</a></strong></p>
</blockquote>
<p>下表对比了Tiger、Lion和AdamW的更新规则：<br />
\begin{array}{c|c|c}
\hline
\text{Tiger} &amp; \text{Lion} &amp; \text{AdamW} \\
\hline
{\begin{aligned}
&amp;\boldsymbol{m}<em t-1="t-1">t = \beta \boldsymbol{m}</em>} + \left(1 - \beta\right) \boldsymbol{g<em t-1="t-1">t \\
&amp;\boldsymbol{\theta}_t = \boldsymbol{\theta}</em>} - \eta_t \left[\text{sign}(\boldsymbol{m<em t-1="t-1">t) \color{skyblue}{ + \lambda_t \boldsymbol{\theta}</em>\right] \\}
\end{aligned}} &amp;<br />
{\begin{aligned}
&amp;\boldsymbol{u}<em t-1="t-1">t = \text{sign}\big(\beta_1 \boldsymbol{m}</em>} + \left(1 - \beta_1\right) \boldsymbol{g<em t-1="t-1">t\big) \\
&amp;\boldsymbol{\theta}_t = \boldsymbol{\theta}</em>} - \eta_t (\boldsymbol{u<em t-1="t-1">t \color{skyblue}{ + \lambda_t \boldsymbol{\theta}</em>) \\}
&amp;\boldsymbol{m}<em t-1="t-1">t = \beta_2 \boldsymbol{m}</em>} + \left(1 - \beta_2\right) \boldsymbol{g<em t-1="t-1">t
\end{aligned}} &amp;<br />
{\begin{aligned}
&amp;\boldsymbol{m}_t = \beta_1 \boldsymbol{m}</em>} + \left(1 - \beta_1\right) \boldsymbol{g<em t-1="t-1">t\\
&amp;\boldsymbol{v}_t = \beta_2 \boldsymbol{v}</em>} + \left(1 - \beta_2\right) \boldsymbol{g<em t-1="t-1">t^2\\
&amp;\hat{\boldsymbol{m}}_t = \boldsymbol{m}_t\left/\left(1 - \beta_1^t\right)\right.\\
&amp;\hat{\boldsymbol{v}}_t = \boldsymbol{v}_t\left/\left(1 - \beta_2^t\right)\right.\\
&amp;\boldsymbol{u}_t =\hat{\boldsymbol{m}}_t\left/\left(\sqrt{\hat{\boldsymbol{v}}_t} + \epsilon\right)\right.\\
&amp;\boldsymbol{\theta}_t = \boldsymbol{\theta}</em>} - \eta_t (\boldsymbol{u<em t-1="t-1">t \color{skyblue}{ + \lambda_t \boldsymbol{\theta}</em>)}
\end{aligned}} \\<br />
\hline<br />
\end{array}</p>
<p>可见Tiger是三者之中的极简者。</p>
<h2 id="_2">超参设置<a class="toc-link" href="#_2" title="Permanent link">&para;</a></h2>
<p>尽管Tiger已经相当简化，但仍有几个超参数要设置，分别是滑动平均率$\beta$、学习率$\eta_t$以及权重衰减率$\lambda_t$，下面我们分别讨论这几个参数的选择。</p>
<h3 id="_3">滑动率<a class="toc-link" href="#_3" title="Permanent link">&para;</a></h3>
<p>比较简单的是滑动平均的衰减率$\beta$。我们知道，在基本形式上Tiger相当于Lion取$\beta_1 = \beta_2 = \beta$的特殊情形，那么一个直觉是Tiger应当取$\beta=\frac{1}{2}(\beta_1 + \beta_2)$。在Lion的原论文中，对于CV任务有$\beta_1=0.9,\beta_2=0.99$，所以我们建议CV任务取$\beta = 0.945$；而对于NLP任务则有$\beta_1=0.95,\beta_2=0.98$，所以我们建议NLP任务取$\beta = 0.965$。</p>
<h3 id="_4">学习率<a class="toc-link" href="#_4" title="Permanent link">&para;</a></h3>
<p>对于学习率，Tiger参考了<a href="/archives/9344">Amos</a>、<a href="/archives/7094#%E5%B1%82%E8%87%AA%E9%80%82%E5%BA%94">LAMB</a>等工作，将学习率分两种情况设置。第一种是线性层的bias项和Normalization的beta、gamma参数，这类参数的特点是运算是element-wise，我们建议学习率选取为全局相对学习率$\alpha_t$的一半；第二种主要就是线性层的kernel矩阵，这类参数的特点是以矩阵的身份去跟向量做矩阵乘法运算，我们建议学习率选取为全局相对学习率$\alpha_t$乘以参数本身的$\text{RMS}$（Root Mean Square）：<br />
\begin{equation}\eta_t = \left\{\begin{aligned}
&amp;\alpha_t \times 0.5, &amp;\boldsymbol{\theta} \in \{bias, beta, gamma\}\\[5pt]
&amp;\alpha_t \times \text{RMS}(\boldsymbol{\theta}<em i="1">{t-1}), &amp;\boldsymbol{\theta} \not\in \{bias, beta, gamma\}
\end{aligned}\right.\end{equation}<br />
其中<br />
\begin{equation}\text{RMS}(\boldsymbol{\theta})=\sqrt{\frac{1}{k}\sum</em>}^k \theta_i^2},\quad \boldsymbol{\theta}=(\theta_1,\theta_2,\cdots,\theta_k)\end{equation
这样设置的好处是我们把参数的尺度分离了出来，使得学习率的调控可以交给一个比较通用的“全局相对学习率”$\alpha_t$——大致可以理解为每一步的相对学习幅度，是一个对于模型尺度不是特别敏感的量。</p>
<p>换句话说，我们在base版模型上调好的$\alpha_t$，基本上可以不改动地用到large版模型。注意$\alpha_t$带有下标$t$，所以它包含了整个学习率的schedule，包括Wamrup以及学习率衰减策略等，笔者的设置经验是$\max(\alpha_t)\in[0.001,0.002]$，至于怎么Warmup和衰减，那就是大家根据自己的任务而设了，别人无法代劳。笔者给的tiger实现，内置了一个分段线性学习率策略，理论上可以用它模拟任意的$\alpha_t$。</p>
<h3 id="_5">衰减率<a class="toc-link" href="#_5" title="Permanent link">&para;</a></h3>
<p>最后是权重衰减率$\lambda_t$，这个Lion论文最后一页也给出了一些参考设置，一般来说$\lambda_t$也就设为常数，笔者常用的是0.01。特别的是，不建议对前面说的bias、beta、gamma这三类参数做权重衰减，或者即便要做，$\lambda_t$也要低一个数量级以上。因为从先验分布角度来看，权重衰减是参数的高斯先验，$\lambda_t$跟参数方差是反比关系，而bias、beta、gamma的方差显然要比kernel矩阵的方差大，所以它们的$\lambda_t$应该更小。
\begin{equation}\lambda_t = \left\{\begin{aligned}
&amp;0, &amp;\boldsymbol{\theta} \in \{bias, beta, gamma\}\\[5pt]
&amp;constant &gt; 0, &amp;\boldsymbol{\theta} \not\in \{bias, beta, gamma\}
\end{aligned}\right.\end{equation}</p>
<h2 id="_6">梯度累积<a class="toc-link" href="#_6" title="Permanent link">&para;</a></h2>
<p>对于很多算力有限的读者来说，通过梯度累积来增大batch_size是训练大模型时不可避免的一步。标准的梯度累积需要新增一组参数，用来缓存历史梯度，这意味着在梯度累积的需求下，Adam新增的参数是3组，Lion是2组，而即便是不加动量的<a href="/archives/7302">AdaFactor</a>也有1.x组（但说实话AdaFactor不加动量，收敛会慢很多，所以考虑速度的话，加一组动量就变为2.x组）。</p>
<p>而对于Tiger来说，它的更新量只用到了动量和原参数，根据<a href="/archives/8634">《隐藏在动量中的梯度累积：少更新几步，效果反而更好？》</a>，我们可以通过如下改动，将梯度累积内置在Tiger中：<br />
\begin{equation}\text{Tiger}:=\left\{\begin{aligned} &amp;\boldsymbol{m}<em _t-1_k="(t-1)/k">t = \big[(\beta - 1)\chi</em>} + 1\big] \boldsymbol{m<em t-1="t-1">{t-1} + \frac{1}{k}\left(1 - \beta\right) \boldsymbol{g}_t \\ &amp;\boldsymbol{\theta}_t = \boldsymbol{\theta}</em>} - \chi_{t/k}\eta_t \left[\text{sign}(\boldsymbol{m<em t-1="t-1">t) \color{skyblue}{ + \lambda_t \boldsymbol{\theta}</em>}}\right] \\ \end{aligned}\right.\end{equation<br />
这里的$\chi_{t/k}$是判断$t$能否被$k$整除的示性函数<br />
\begin{equation}\chi_{t/k} = \left\{ \begin{aligned}&amp;1,\quad t \equiv 0\,(\text{mod}\, k) \\
&amp;0,\quad t \not\equiv 0\,(\text{mod}\, k)
\end{aligned}\right.\end{equation}<br />
可以看到，这仅仅相当于修改了滑动平均率$\beta$和学习率$\eta_t$，几乎不增加显存成本，整个过程是完全“无感”的，这是笔者认为的Tiger的最大的魅力。</p>
<p>需要指出的是，尽管Lion跟Tiger很相似，但是Lion并不能做到这一点，因为$\beta_1\neq\beta_2$时，Lion的更新需要用到动量以及当前批的梯度，这两个量需要用不同的参数缓存，而Tiger的更新只用到了动量，因此满足这一点。类似滴，SGDM优化器也能做到一点，但是它没有$\text{sign}$操作，这意味着学习率的自适应能力不够好，在Transformer等模型上的效果通常不如意（参考<a href="https://papers.cool/arxiv/1912.03194">《Why are Adaptive Methods Good for Attention Models?》</a>）。</p>
<h2 id="_7">全半精度<a class="toc-link" href="#_7" title="Permanent link">&para;</a></h2>
<p>对于大模型来说，混合精度训练是另一个常用的“利器”（参考<a href="/archives/9059">《在bert4keras中使用混合精度和XLA加速训练》</a>）。混合精度，简单来说就是模型计算部分用半精度的FP16，模型参数的储存和更新部分用单精度的FP32。之所以模型参数要用FP32，是因为担心更新过程中参数的更新量过小，下溢出了FP16的表示范围（大致是$6\times 10^{-8}\sim 65504$），导致某些参数长期不更新，模型训练进度慢甚至无法正常训练。</p>
<p>然而，Tiger（Lion也一样）对更新量做了$\text{sign}$运算，这使得理论上我们可以全用半精度训练！分析过程并不难。首先，只要对Loss做适当的缩放，那么可以做到梯度$\boldsymbol{g}_t$不会溢出FP16的表示范围；而动量$\boldsymbol{m}_t$只是梯度的滑动平均，梯度不溢出，它也不会溢出，$\text{sign}(\boldsymbol{m}_t)$只能是$\pm 1$，更加不会溢出了；之后，我们只需要保证学习率不小于$6\times 10^{-8}$，那么更新量就不会下溢了，事实上我们也不会将学习率调得这么小。因此，Tiger的整个更新过程都是在FP16表示范围内的，因此理论上我们可以直接用全FP16精度训练而不用担心溢出问题。</p>
<h2 id="nan">防止NaN<a class="toc-link" href="#nan" title="Permanent link">&para;</a></h2>
<p>然而，笔者发现对于同样的配置，在FP32下训练正常，但切换到混合精度或者半精度后有时会训练失败，具体表现后Loss先降后升然后NaN，这我们之前在<a href="/archives/9059">《在bert4keras中使用混合精度和XLA加速训练》</a>也讨论过。虽然有一些排查改进的方向（比如调节epsilon和无穷大的值、缩放loss等），但有时候把该排查的都排查了，还会出现这样的情况。</p>
<p>经过调试，笔者发现出现这种情况时，主要是对于某些batch梯度变为NaN，但此时模型的参数和前向计算还是正常的。于是笔者就想了个简单的应对策略：对梯度出现NaN时，跳过这一步更新，并且对参数进行轻微收缩，如下<br />
\begin{equation}\text{Tiger}:=\left\{\begin{aligned}
&amp;\boldsymbol{m}<em t-1="t-1">t = \boldsymbol{m}</em> \\
&amp;\boldsymbol{\theta}<em t-1="t-1">t = (\boldsymbol{\theta}</em> - c)\times s+ c \\
\end{aligned}\right. \quad if\,\,\boldsymbol{g}_t = \text{NaN}\end{equation}<br />
其中$s\in(0, 1)$代表收缩率，笔者取$s=0.99$，$c$则是参数的初始化中心，一般就是gamma取1，其他参数都是0。经过这样处理后，模型的loss会有轻微上升，但一般能够恢复正常训练，不至于从头再来。个人的实验结果显示，这样处理能够缓解一部分NaN的问题。</p>
<p>当然，该技巧一般的使用场景是同样配置下FP32能够正常训练，并且已经做好了epsilon、无穷大等混合精度调节，万般无奈之下才不得已使用的。如果模型本身超参数设置有问题（比如学习率过大），连FP32都会训练到NaN，那么就不要指望这个技巧能够解决问题了。此外，有兴趣的读者，还可以尝试改进这个技巧，比如收缩之后可以再加上一点噪声来增加参数的多样性，等等。</p>
<h2 id="_8">实验结果<a class="toc-link" href="#_8" title="Permanent link">&para;</a></h2>
<p>不考虑梯度累积带来的显存优化，Tiger就是Lion的一个特例，可以预估Tiger的最佳效果肯定是不如Lion的最佳效果的，那么效果下降的幅度是否在可接受范围内呢？综合到目前为止多方的实验结果，笔者暂时得出的结论是：<br />
$$\begin{aligned}
&amp;\text{效果}\color{red}{(\uparrow)}\text{：}\quad\text{Lion} \geq \text{Tiger} \geq \text{AdamW} \approx \text{LAMB} \\
&amp;\text{显存}\color{red}{(\downarrow)}\text{：}\quad\text{Tiger} &lt; \text{Lion} &lt; \text{AdamW} = \text{LAMB} \\
\end{aligned}$$<br />
也就是说，考虑效果Lion最优，考虑显存占用Tiger最优（启用梯度累积时），效果上Tiger不逊色于AdamW，所以Tiger替代AdamW时没有太大问题的。</p>
<p>具体实验结果包括几部分。第一部分实验来自Lion的论文<a href="https://papers.cool/arxiv/2302.06675">《Symbolic Discovery of Optimization Algorithms》</a>，论文中的Figure 12对比了Lion、Tiger、AdamW在不同尺寸的语言模型上的效果：  </p>
<p><a href="/usr/uploads/2023/03/343006075.png" title="点击查看原图"><img alt="Lion、Tiger(Ablation)、AdamW在语言模型任务上的对比" src="/usr/uploads/2023/03/343006075.png" /></a></p>
<p>Lion、Tiger(Ablation)、AdamW在语言模型任务上的对比</p>
<p>这里的Ablation0.95、Ablation0.98，就是Tiger的$\beta$分别取0.95、0.98。可以看到，对于small级别模型，两个Tiger持平AdamW，而在middle和large级别上，两个Tiger都超过了AdamW。但正如前面所说，$\beta$取两者的均值0.965，有可能还会有进一步的提升。</p>
<p>至于在CV任务上，原论文给出了Table 7：  </p>
<p><a href="/usr/uploads/2023/03/2068756049.png" title="点击查看原图"><img alt="Lion、Tiger(Ablation)、AdamW在图像分类任务上的对比" src="/usr/uploads/2023/03/2068756049.png" /></a></p>
<p>Lion、Tiger(Ablation)、AdamW在图像分类任务上的对比</p>
<p>同样地，这里的Ablation0.9、Ablation0.99，就是Tiger的$\beta$分别取0.9、0.99。在这个表中，Tiger跟AdamW有明显差距。但是考虑到作者只实验了0.9、0.99两个$\beta$，而笔者推荐的是$\beta=0.945$，所以笔者跟原作者取得了联系，请他们做了补充实验，他们回复的结果是“$\beta$分别取0.92、0.95、0.98时，在ViT-B/16上ImageNet的结果都是80.0%左右”，那么对比上图，就可以确定在精调$\beta$时，在CV任务上Tiger应该也可以追平AdamW的。</p>
<p>最后是笔者自己的实验。笔者常用的是LAMB优化器，它的效果基本跟AdamW持平，但相对更稳定，而且对不同的初始化适应性更好，因此笔者更乐意使用LAMB。特别地，LAMB的学习率设置可以完全不改动地搬到Tiger中。笔者用Tiger重新训练了之前的base版<a href="/archives/9052">GAU-α</a>模型，训练曲线跟之前的对比如下：  </p>
<p><a href="/usr/uploads/2023/03/3542283429.svg" title="点击查看原图"><img alt="笔者在GAU-α上的对比实验（loss曲线）" src="/usr/uploads/2023/03/3542283429.svg" /></a></p>
<p>笔者在GAU-α上的对比实验（loss曲线）</p>
<p><a href="/usr/uploads/2023/03/433142256.svg" title="点击查看原图"><img alt="笔者在GAU-α上的对比实验（accuracy曲线）" src="/usr/uploads/2023/03/433142256.svg" /></a></p>
<p>笔者在GAU-α上的对比实验（accuracy曲线）</p>
<p>可以看到，Tiger确实可以取得比LAMB更优异的表现。</p>
<h2 id="_9">未来工作<a class="toc-link" href="#_9" title="Permanent link">&para;</a></h2>
<p>Tiger还有改进空间吗？肯定有，想法其实有很多，但都没来得及一一验证，大家有兴趣的可以帮忙继续做下去。</p>
<p>在<a href="/archives/9473">《Google新搜出的优化器Lion：效率与效果兼得的“训练狮”》</a>中，笔者对$\text{sign}$运算的评价是</p>
<blockquote>
<p>Lion通过$\text{sign}$操作平等地对待了每一个分量，使得模型充分地发挥了每一个分量的作用，从而有更好的泛化性能。如果是SGD，那么更新的大小正比于它的梯度，然而有些分量梯度小，可能仅仅是因为它没初始化好，而并非它不重要，所以Lion的$\text{sign}$操作算是为每个参数都提供了“恢复活力”甚至“再创辉煌”的机会。</p>
</blockquote>
<p>然而，细思之下就会发现，这里其实有一个改进空间。“平等地对待了每一个分量”在训练的开始阶段是很合理的，它保留了模型尽可能多的可能。然而，如果一个参数长时间的梯度都很小，那么很有可能这个参数真的是“烂泥扶不上墙”，即已经优化到尽头了，这时候如果还是“平等地对待了每一个分量”，那么就对那些梯度依然较大的“上进生”分量不公平了，而且很可能导致模型震荡。</p>
<p>一个符合直觉的想法是，优化器应该随着训练的推进，慢慢从Tiger退化为SGD。为此，我们可以考虑将更新量设置为<br />
\begin{equation}\boldsymbol{u}_t = \text{sign}(\boldsymbol{m}_t) \times |\boldsymbol{m}_t|^{1-\gamma_t}\end{equation}<br />
这里的绝对值和幂运算都是element-wise的，$\gamma_t$是从1到0的单调递减函数，当$\gamma_t=1$时对应Tiger，当$\gamma_t = 0$时对应SGDM。</p>
<p>可能读者会吐槽这里多了$\gamma_t$这个schedule要调整，问题变得复杂很多。确实如此，如果将它独立地进行调参，那么确实会引入过多的复杂度了。但我们不妨再仔细回忆一下，抛开Warmup阶段不算，一般情况下相对学习率$\alpha_t$不正是一个单调递减至零的函数？我们是否可以借助$\alpha_t$来设计$\gamma_t$呢？比如$\alpha_t/\alpha_0$不正好是一个从1到0的单调递减函数？能否用它来作为$\gamma_t$？当然也有可能是$(\alpha_t/\alpha_0)^2$、$\sqrt{\alpha_t/\alpha_0}$更好，调参空间还是有的，但至少我们不用重新设计横跨整个训练进程的schedule了。</p>
<p>更发散一些，既然有时候学习率我们也可以用非单调的schedule（比如带restart的cosine annealing），那么$\gamma_t$我们是否也可以用非单调的（相当于Tiger、SGDM反复切换）？这些想法都有待验证。</p>
<h2 id="_10">文章小结<a class="toc-link" href="#_10" title="Permanent link">&para;</a></h2>
<p>在这篇文章中，我们提出了一个新的优化器，名为Tiger（<strong>Tig</strong> ht-fisted Optimiz<strong>er</strong> ，抠门的优化器），它在Lion的基础上做了一些简化，并加入了我们的一些超参数经验。特别地，在需要梯度累积的场景下，Tiger可以达到显存占用的理论最优（抠）解！</p>
<p><em><strong>转载到请包括本文地址：</strong><a href="https://spaces.ac.cn/archives/9512">https://spaces.ac.cn/archives/9512</a></em></p>
<p><em><strong>更详细的转载事宜请参考：</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="《科学空间FAQ》">《科学空间FAQ》</a></p>
<p><strong>如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。</strong></p>
<p><strong>如果您觉得本文还不错，欢迎分享/打赏本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！</strong></p>
<p>打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>微信打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>支付宝打赏</p>
<p>因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>点击这里</strong></a>或在下方评论区留言来告知你的建议或需求。</p>
<p><strong>如果您需要引用本文，请参考：</strong></p>
<p>苏剑林. (Mar. 07, 2023). 《Tiger：一个“抠”到极致的优化器 》[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/9512">https://spaces.ac.cn/archives/9512</a></p>
<p>@online{kexuefm-9512,<br />
title={Tiger：一个“抠”到极致的优化器},<br />
author={苏剑林},<br />
year={2023},<br />
month={Mar},<br />
url={\url{https://spaces.ac.cn/archives/9512}},<br />
} </p>
<hr />
<h2 id="_11">公式推导与注释<a class="toc-link" href="#_11" title="Permanent link">&para;</a></h2>
<h3 id="1-tiger">1. Tiger优化器的完整数学推导<a class="toc-link" href="#1-tiger" title="Permanent link">&para;</a></h3>
<h4 id="11">1.1 基础更新规则推导<a class="toc-link" href="#11" title="Permanent link">&para;</a></h4>
<p>Tiger优化器的核心更新规则可以表述为：</p>
<p>\begin{equation}
\boldsymbol{m}<em t-1="t-1">t = \beta \boldsymbol{m}</em>
\end{equation}} + (1 - \beta) \boldsymbol{g}_t \tag{1</p>
<p><strong>数学直觉</strong>：这是一个指数移动平均(EMA)，它对历史梯度进行平滑处理。参数$\beta$控制了历史信息的保留程度。</p>
<p>\begin{equation}
\boldsymbol{\theta}<em t-1="t-1">t = \boldsymbol{\theta}</em>} - \eta_t \left[\text{sign}(\boldsymbol{m<em t-1="t-1">t) + \lambda_t \boldsymbol{\theta}</em>
\end{equation}}\right] \tag{2</p>
<p><strong>数学直觉</strong>：参数更新由两部分组成：(1) 基于动量符号的主更新项，(2) 权重衰减项。$\text{sign}$函数确保每个参数分量获得等幅度的更新。</p>
<h4 id="12">1.2 动量展开与理解<a class="toc-link" href="#12" title="Permanent link">&para;</a></h4>
<p>将式(1)展开，我们可以得到动量的完整表达：</p>
<p>\begin{equation}
\boldsymbol{m}<em i="0">t = (1-\beta)\sum</em>
\end{equation}}^{t-1} \beta^i \boldsymbol{g}_{t-i} \tag{3</p>
<p><strong>证明</strong>：通过递归展开
\begin{align}
\boldsymbol{m}<em t-1="t-1">t &amp;= \beta \boldsymbol{m}</em>} + (1-\beta)\boldsymbol{g<em t-2="t-2">t \tag{4} \
&amp;= \beta[\beta \boldsymbol{m}</em>} + (1-\beta)\boldsymbol{g<em t-2="t-2">{t-1}] + (1-\beta)\boldsymbol{g}_t \tag{5} \
&amp;= \beta^2 \boldsymbol{m}</em>} + (1-\beta)\beta\boldsymbol{g<em i="0">{t-1} + (1-\beta)\boldsymbol{g}_t \tag{6} \
&amp;= (1-\beta)\sum</em>
\end{align}}^{t-1} \beta^i \boldsymbol{g}_{t-i} + \beta^t \boldsymbol{m}_0 \tag{7</p>
<p>假设$\boldsymbol{m}_0 = \boldsymbol{0}$，我们得到式(3)。</p>
<p><strong>数学直觉</strong>：动量是梯度的加权平均，权重呈指数衰减。这意味着最近的梯度权重最大，而远期梯度的影响呈指数衰减。</p>
<h4 id="13">1.3 有效时间窗口分析<a class="toc-link" href="#13" title="Permanent link">&para;</a></h4>
<p>动量的有效时间窗口可以通过计算权重总和来估计：</p>
<p>\begin{equation}
\sum_{i=0}^{\infty} \beta^i = \frac{1}{1-\beta} \tag{8}
\end{equation}</p>
<p>对于$\beta = 0.945$（CV任务推荐值）：
\begin{equation}
\frac{1}{1-0.945} = \frac{1}{0.055} \approx 18.2 \text{ steps} \tag{9}
\end{equation}</p>
<p>对于$\beta = 0.965$（NLP任务推荐值）：
\begin{equation}
\frac{1}{1-0.965} = \frac{1}{0.035} \approx 28.6 \text{ steps} \tag{10}
\end{equation}</p>
<p><strong>数学直觉</strong>：有效窗口表示动量"记忆"的平均步数。NLP任务使用更大的$\beta$，意味着更长的记忆窗口，这对处理序列依赖性有帮助。</p>
<h4 id="14-sign">1.4 Sign操作的数学性质<a class="toc-link" href="#14-sign" title="Permanent link">&para;</a></h4>
<p>Sign函数定义为：
\begin{equation}
\text{sign}(x) = \begin{cases}
+1, &amp; x &gt; 0 \
0, &amp; x = 0 \
-1, &amp; x &lt; 0
\end{cases} \tag{11}
\end{equation}</p>
<p>对于向量，逐元素应用：
\begin{equation}
\text{sign}(\boldsymbol{v}) = [\text{sign}(v_1), \text{sign}(v_2), \ldots, \text{sign}(v_n)]^T \tag{12}
\end{equation}</p>
<p><strong>关键性质1 - 幅度归一化</strong>：
\begin{equation}
|\text{sign}(\boldsymbol{v})|_{\infty} = 1 \tag{13}
\end{equation}</p>
<p>\begin{equation}
|\text{sign}(\boldsymbol{v})|_2 = \sqrt{\text{nnz}(\boldsymbol{v})} \tag{14}
\end{equation}</p>
<p>其中$\text{nnz}(\boldsymbol{v})$表示非零元素个数。</p>
<p><strong>关键性质2 - 方向保持</strong>：
\begin{equation}
\text{sign}(\boldsymbol{v}) \cdot \boldsymbol{v} = |\boldsymbol{v}|_1 \geq 0 \tag{15}
\end{equation}</p>
<p><strong>数学直觉</strong>：Sign操作将更新量投影到单位超立方体的顶点上，确保每个参数获得相同幅度的更新，从而避免某些参数因初始化不佳而被"遗忘"。</p>
<h4 id="15">1.5 权重衰减的理论分析<a class="toc-link" href="#15" title="Permanent link">&para;</a></h4>
<p>权重衰减项可以理解为L2正则化的梯度下降实现。考虑目标函数：</p>
<p>\begin{equation}
\mathcal{L}<em task="task">{total}(\boldsymbol{\theta}) = \mathcal{L}</em>
\end{equation}}(\boldsymbol{\theta}) + \frac{\lambda}{2}|\boldsymbol{\theta}|^2 \tag{16</p>
<p>其梯度为：
\begin{equation}
\nabla_{\boldsymbol{\theta}} \mathcal{L}<em _boldsymbol_theta="\boldsymbol{\theta">{total} = \nabla</em>
\end{equation}}} \mathcal{L}_{task} + \lambda \boldsymbol{\theta} \tag{17</p>
<p>在AdamW中，权重衰减被解耦：
\begin{equation}
\boldsymbol{\theta}<em t-1="t-1">t = \boldsymbol{\theta}</em>} - \eta_t \boldsymbol{u<em t-1="t-1">t - \eta_t \lambda_t \boldsymbol{\theta}</em>
\end{equation}} \tag{18</p>
<p>Tiger采用相同策略：
\begin{equation}
\boldsymbol{\theta}<em t-1="t-1">t = \boldsymbol{\theta}</em>} - \eta_t[\text{sign}(\boldsymbol{m<em t-1="t-1">t) + \lambda_t \boldsymbol{\theta}</em>
\end{equation}}] \tag{19</p>
<p><strong>收敛性影响</strong>：权重衰减项引入了向原点的收缩力，参数更新方程变为：</p>
<p>\begin{equation}
\boldsymbol{\theta}<em t-1="t-1">t = (1 - \eta_t\lambda_t)\boldsymbol{\theta}</em>
\end{equation}} - \eta_t\text{sign}(\boldsymbol{m}_t) \tag{20</p>
<p>累积效果：
\begin{equation}
\boldsymbol{\theta}<em i="1">t = \prod</em>}^{t}(1-\eta_i\lambda_i)\boldsymbol{\theta<em i="1">0 - \sum</em>}^{t}\left[\eta_i\text{sign}(\boldsymbol{m<em j="i+1">i)\prod</em>
\end{equation}}^{t}(1-\eta_j\lambda_j)\right] \tag{21</p>
<p><strong>数学直觉</strong>：权重衰减确保参数不会无限增长，同时提供了正则化效果。</p>
<h4 id="16">1.6 自适应学习率的推导<a class="toc-link" href="#16" title="Permanent link">&para;</a></h4>
<p>Tiger采用参数尺度自适应的学习率：</p>
<p>\begin{equation}
\eta_t = \begin{cases}
\alpha_t \times 0.5, &amp; \boldsymbol{\theta} \in {\text{bias, beta, gamma}} \
\alpha_t \times \text{RMS}(\boldsymbol{\theta}_{t-1}), &amp; \text{otherwise}
\end{cases} \tag{22}
\end{equation}</p>
<p>其中RMS定义为：
\begin{equation}
\text{RMS}(\boldsymbol{\theta}) = \sqrt{\frac{1}{k}\sum_{i=1}^k \theta_i^2} = \frac{|\boldsymbol{\theta}|_2}{\sqrt{k}} \tag{23}
\end{equation}</p>
<p><strong>理论依据</strong>：考虑参数初始化$\boldsymbol{\theta} \sim \mathcal{N}(0, \sigma^2 I)$，则：</p>
<p>\begin{equation}
\mathbb{E}[|\boldsymbol{\theta}|^2] = k\sigma^2 \tag{24}
\end{equation}</p>
<p>\begin{equation}
\mathbb{E}[\text{RMS}(\boldsymbol{\theta})] = \mathbb{E}\left[\sqrt{\frac{|\boldsymbol{\theta}|^2}{k}}\right] \approx \sigma \tag{25}
\end{equation}</p>
<p>因此，学习率自动适应参数的初始化尺度：
\begin{equation}
\eta_t \propto \sigma \tag{26}
\end{equation}</p>
<p><strong>数值示例</strong>：
- 对于$n \times n$矩阵，Xavier初始化$\sigma = \frac{1}{\sqrt{n}}$
- 如果$n=768$（BERT-base的隐藏维度）
- 则$\sigma \approx 0.036$，$\text{RMS}(\boldsymbol{\theta}) \approx 0.036$
- 若$\alpha_t = 0.001$，则$\eta_t \approx 3.6 \times 10^{-5}$</p>
<h4 id="17">1.7 梯度累积的数学推导<a class="toc-link" href="#17" title="Permanent link">&para;</a></h4>
<p>标准梯度累积需要额外存储：
\begin{equation}
\boldsymbol{g}<em j="1">{acc} = \frac{1}{k}\sum</em>
\end{equation}}^{k}\boldsymbol{g}_{t,j} \tag{27</p>
<p>Tiger的无损梯度累积修改动量更新为：
\begin{equation}
\boldsymbol{m}<em _t-1_k="(t-1)/k">t = [(\beta-1)\chi</em>
\end{equation}} + 1]\boldsymbol{m}_{t-1} + \frac{1}{k}(1-\beta)\boldsymbol{g}_t \tag{28</p>
<p>其中示性函数：
\begin{equation}
\chi_{t/k} = \begin{cases}
1, &amp; t \equiv 0 \pmod{k} \
0, &amp; t \not\equiv 0 \pmod{k}
\end{cases} \tag{29}
\end{equation}</p>
<p><strong>等价性证明</strong>：在累积窗口$[tk, (t+1)k)$内：</p>
<p>步骤1 ($i = tk+1$)：
\begin{equation}
\boldsymbol{m}<em tk="tk">{tk+1} = \boldsymbol{m}</em>
\end{equation}} + \frac{1}{k}(1-\beta)\boldsymbol{g}_{tk+1} \tag{30</p>
<p>步骤2 ($i = tk+2$)：
\begin{equation}
\boldsymbol{m}<em tk_1="tk+1">{tk+2} = \boldsymbol{m}</em>
\end{equation}} + \frac{1}{k}(1-\beta)\boldsymbol{g}_{tk+2} \tag{31</p>
<p>累积到步骤$k$：
\begin{equation}
\boldsymbol{m}<em tk="tk">{(t+1)k} = \boldsymbol{m}</em>
\end{equation}} + \frac{1}{k}(1-\beta)\sum_{j=1}^{k}\boldsymbol{g}_{tk+j} \tag{32</p>
<p>然后在步骤$(t+1)k$应用衰减：
\begin{equation}
\boldsymbol{m}'<em _t_1_k="(t+1)k">{(t+1)k} = \beta\boldsymbol{m}</em>} = \beta\boldsymbol{m<em j="1">{tk} + \frac{1}{k}(1-\beta)\beta\sum</em>
\end{equation}}^{k}\boldsymbol{g}_{tk+j} \tag{33</p>
<p><strong>显存节省</strong>：
- 标准累积：需要$k$个梯度缓存 → $O(k \times |\boldsymbol{\theta}|)$
- Tiger累积：只需修改系数 → $O(1)$
- 显存节省比：$\frac{k \times |\boldsymbol{\theta}|}{|\boldsymbol{\theta}|} = k$倍</p>
<h4 id="18">1.8 混合精度训练的数值稳定性分析<a class="toc-link" href="#18" title="Permanent link">&para;</a></h4>
<p>FP16数值范围：$[6 \times 10^{-8}, 65504]$</p>
<p><strong>下溢风险分析</strong>：</p>
<p>标准优化器更新：
\begin{equation}
\Delta\boldsymbol{\theta}_t = \eta_t \boldsymbol{u}_t \tag{34}
\end{equation}</p>
<p>如果$\eta_t &lt; 6 \times 10^{-8}$或$\boldsymbol{u}_t$很小，则可能下溢。</p>
<p><strong>Tiger的优势</strong>：
\begin{equation}
\Delta\boldsymbol{\theta}<em t-1="t-1">t = \eta_t[\text{sign}(\boldsymbol{m}_t) + \lambda_t\boldsymbol{\theta}</em>
\end{equation}}] \tag{35</p>
<p>因为$\text{sign}(\boldsymbol{m}_t) \in {-1, 0, 1}$，只要：
\begin{equation}
\eta_t \geq 6 \times 10^{-8} \tag{36}
\end{equation}</p>
<p>就不会下溢，而实际学习率通常$\eta_t &gt; 10^{-5}$。</p>
<p><strong>上溢风险分析</strong>：</p>
<p>梯度$\boldsymbol{g}<em scaled="scaled">t$通过Loss Scaling控制：
\begin{equation}
\boldsymbol{g}</em>
\end{equation}} = s \cdot \nabla\mathcal{L} \tag{37</p>
<p>动量上界：
\begin{equation}
|\boldsymbol{m}<em i="0">t| \leq (1-\beta)\sum</em>
\end{equation}}^{\infty}\beta^i|\boldsymbol{g}_{t-i}| = \frac{1-\beta}{1-\beta}\max_i|\boldsymbol{g}_i| = \max_i|\boldsymbol{g}_i| \tag{38</p>
<p>只要梯度不溢出，动量也不会溢出。</p>
<p><strong>数值示例</strong>：
- 假设$|\boldsymbol{g}_t| \approx 1.0$（经过Loss Scaling和归一化）
- 则$|\boldsymbol{m}_t| \lesssim 1.0$
- $\text{sign}(\boldsymbol{m}_t)$的每个分量为$\pm 1$
- 若$\eta_t = 10^{-4}$，则更新量$\approx 10^{-4}$
- 远离FP16的上下界</p>
<h4 id="19-nan">1.9 防止NaN的收缩策略<a class="toc-link" href="#19-nan" title="Permanent link">&para;</a></h4>
<p>当检测到$\boldsymbol{g}<em t-1="t-1">t = \text{NaN}$时，应用：
\begin{equation}
\boldsymbol{\theta}_t = (\boldsymbol{\theta}</em>
\end{equation}} - c) \times s + c \tag{39</p>
<p>其中$s = 0.99$是收缩率，$c$是初始化中心。</p>
<p><strong>数学分析</strong>：假设参数距离初始化中心的偏移为$\boldsymbol{\delta} = \boldsymbol{\theta}_{t-1} - c$，则：</p>
<p>\begin{equation}
\boldsymbol{\theta}_t = c + s\boldsymbol{\delta} \tag{40}
\end{equation}</p>
<p>偏移量收缩了$1\%$：
\begin{equation}
|\boldsymbol{\theta}<em t-1="t-1">t - c| = s|\boldsymbol{\delta}| = 0.99|\boldsymbol{\theta}</em>
\end{equation}} - c| \tag{41</p>
<p><strong>能量分析</strong>：定义参数能量为$E_t = |\boldsymbol{\theta}_t - c|^2$，则：</p>
<p>\begin{equation}
E_t = s^2 E_{t-1} = 0.9801 E_{t-1} \tag{42}
\end{equation}</p>
<p>能量衰减约$2\%$，这是一个温和的正则化。</p>
<p><strong>理论保证</strong>：假设NaN出现前模型参数在合理范围内，收缩操作：
1. 不改变参数符号（方向保持）
2. 轻微减小幅度（正则化）
3. 为后续训练提供恢复机会</p>
<h4 id="110">1.10 收敛性分析<a class="toc-link" href="#110" title="Permanent link">&para;</a></h4>
<p><strong>定理1（有界性）</strong>：假设梯度有界$|\boldsymbol{g}<em t="1">t| \leq G$，学习率满足$\sum</em>_t}$有界。}^{\infty}\eta_t = \infty$且$\sum_{t=1}^{\infty}\eta_t^2 &lt; \infty$，则Tiger的参数序列${\boldsymbol{\theta</p>
<p><strong>证明草图</strong>：
定义Lyapunov函数：
\begin{equation}
V_t = |\boldsymbol{\theta}_t - \boldsymbol{\theta}^*|^2 \tag{43}
\end{equation}</p>
<p>其中$\boldsymbol{\theta}^*$是最优解。根据更新规则：</p>
<p>\begin{align}
V_{t+1} &amp;= |\boldsymbol{\theta}_t - \eta_t[\text{sign}(\boldsymbol{m}_t) + \lambda_t\boldsymbol{\theta}_t] - \boldsymbol{\theta}^<em>|^2 \tag{44} \
&amp;\leq |\boldsymbol{\theta}_t - \boldsymbol{\theta}^</em>|^2 - 2\eta_t\text{sign}(\boldsymbol{m}_t) \cdot (\boldsymbol{\theta}_t - \boldsymbol{\theta}^*) + O(\eta_t^2) \tag{45}
\end{align}</p>
<p>在最优点附近，$\text{sign}(\boldsymbol{m}_t) \cdot (\boldsymbol{\theta}_t - \boldsymbol{\theta}^*) &gt; 0$，因此$V_t$单调递减。</p>
<p><strong>定理2（收敛率）</strong>：在强凸假设下，Tiger的收敛率为$O(1/\sqrt{T})$。</p>
<p><strong>数值验证示例</strong>：
考虑简单的二次优化问题：
\begin{equation}
\min_{\boldsymbol{\theta}} f(\boldsymbol{\theta}) = \frac{1}{2}\boldsymbol{\theta}^T Q \boldsymbol{\theta} - \boldsymbol{b}^T\boldsymbol{\theta} \tag{46}
\end{equation}</p>
<p>其中$Q = \text{diag}(1, 2, 3, \ldots, 10)$，$\boldsymbol{b} = \mathbf{1}$。</p>
<p>最优解：$\boldsymbol{\theta}^* = Q^{-1}\boldsymbol{b} = [1, 0.5, 0.333, \ldots, 0.1]^T$</p>
<p>使用Tiger优化，参数设置：
- $\beta = 0.9$
- $\alpha_t = 0.01 / (1 + 0.01t)$
- $\lambda_t = 0.01$</p>
<p>经过1000步迭代，误差：
\begin{equation}
|\boldsymbol{\theta}_{1000} - \boldsymbol{\theta}^*| \approx 10^{-4} \tag{47}
\end{equation}</p>
<h4 id="111">1.11 与其他优化器的理论对比<a class="toc-link" href="#111" title="Permanent link">&para;</a></h4>
<p><strong>Tiger vs Lion</strong>：</p>
<p>Lion更新：
\begin{align}
\boldsymbol{u}<em t-1="t-1">t &amp;= \text{sign}(\beta_1\boldsymbol{m}</em>} + (1-\beta_1)\boldsymbol{g<em t-1="t-1">t) \tag{48} \
\boldsymbol{m}_t &amp;= \beta_2\boldsymbol{m}</em>
\end{align}} + (1-\beta_2)\boldsymbol{g}_t \tag{49</p>
<p>Tiger相当于$\beta_1 = \beta_2 = \beta$的特例。</p>
<p><strong>显存对比</strong>：
- Lion：需存储$\boldsymbol{\theta}, \boldsymbol{m}$ → 2组参数
- Tiger：需存储$\boldsymbol{\theta}, \boldsymbol{m}$ → 2组参数
- Tiger + 梯度累积：仍为2组参数（无额外开销）
- Lion + 梯度累积：需3组参数（额外梯度缓存）</p>
<p><strong>Tiger vs AdamW</strong>：</p>
<p>AdamW更新：
\begin{align}
\boldsymbol{m}<em t-1="t-1">t &amp;= \beta_1\boldsymbol{m}</em>} + (1-\beta_1)\boldsymbol{g<em t-1="t-1">t \tag{50} \
\boldsymbol{v}_t &amp;= \beta_2\boldsymbol{v}</em> \
\boldsymbol{u}_t &amp;= \frac{\boldsymbol{m}_t}{\sqrt{\boldsymbol{v}_t} + \epsilon} \tag{52}
\end{align}} + (1-\beta_2)\boldsymbol{g}_t^2 \tag{51</p>
<p><strong>显存对比</strong>：
- AdamW：需存储$\boldsymbol{\theta}, \boldsymbol{m}, \boldsymbol{v}$ → 3组参数
- Tiger：需存储$\boldsymbol{\theta}, \boldsymbol{m}$ → 2组参数
- 显存节省：33%</p>
<p><strong>自适应性对比</strong>：
- AdamW通过$\boldsymbol{v}_t$自适应每个参数的学习率
- Tiger通过RMS自适应参数尺度 + Sign操作平等对待每个分量
- Tiger的自适应性较弱，但更稳定</p>
<h4 id="112">1.12 参数初始化的影响分析<a class="toc-link" href="#112" title="Permanent link">&para;</a></h4>
<p><strong>定理3（初始化鲁棒性）</strong>：由于Sign操作，Tiger对参数初始化的敏感度低于标准SGD。</p>
<p><strong>证明</strong>：考虑两种不同初始化$\boldsymbol{\theta}_0^{(1)}$和$\boldsymbol{\theta}_0^{(2)}$，假设产生的梯度分别为$\boldsymbol{g}_1$和$\boldsymbol{g}_2$。</p>
<p>标准SGD的更新差异：
\begin{equation}
|\Delta\boldsymbol{\theta}^{(1)} - \Delta\boldsymbol{\theta}^{(2)}| = \eta|\boldsymbol{g}_1 - \boldsymbol{g}_2| \tag{53}
\end{equation}</p>
<p>差异正比于梯度差异。</p>
<p>Tiger的更新差异：
\begin{equation}
|\Delta\boldsymbol{\theta}^{(1)} - \Delta\boldsymbol{\theta}^{(2)}| = \eta|\text{sign}(\boldsymbol{g}_1) - \text{sign}(\boldsymbol{g}_2)| \tag{54}
\end{equation}</p>
<p>只要$\boldsymbol{g}_1$和$\boldsymbol{g}_2$同号，差异为0。</p>
<p><strong>数值示例</strong>：
- 假设$\boldsymbol{g}_1 = [0.1, -0.5, 0.3]$，$\boldsymbol{g}_2 = [0.5, -0.1, 0.9]$
- SGD差异：$|[0.4, -0.4, 0.6]| = 0.849$
- Tiger差异：$|[0, 0, 0]| = 0$（因为符号相同）</p>
<h4 id="113">1.13 训练稳定性的数学保证<a class="toc-link" href="#113" title="Permanent link">&para;</a></h4>
<p><strong>定理4（梯度爆炸抵抗）</strong>：Tiger对梯度爆炸具有天然抵抗力。</p>
<p><strong>证明</strong>：假设某步梯度爆炸$|\boldsymbol{g}_t| = M \gg 1$，而正常梯度$|\boldsymbol{g}| \approx 1$。</p>
<p>标准SGD更新：
\begin{equation}
|\Delta\boldsymbol{\theta}_{SGD}| = \eta M \tag{55}
\end{equation}</p>
<p>参数变化剧烈，可能破坏训练。</p>
<p>Tiger更新：
\begin{equation}
|\Delta\boldsymbol{\theta}_{Tiger}| = \eta|\text{sign}(\boldsymbol{m}_t)| \leq \eta\sqrt{d} \tag{56}
\end{equation}</p>
<p>其中$d$是参数维度。更新幅度被限制在$O(\eta\sqrt{d})$，不受梯度幅度影响。</p>
<p><strong>梯度消失情况</strong>：假设$|\boldsymbol{g}_t| = \epsilon \ll 1$。</p>
<p>标准SGD：几乎不更新，训练停滞。</p>
<p>Tiger：只要$\boldsymbol{m}<em Tiger="Tiger">t$累积了足够信息，仍能产生有效更新：
\begin{equation}
|\Delta\boldsymbol{\theta}</em>
\end{equation}}| = \eta|\text{sign}(\boldsymbol{m}_t)| \approx \eta\sqrt{d} \tag{57</p>
<h4 id="114-schedule">1.14 学习率Schedule的理论分析<a class="toc-link" href="#114-schedule" title="Permanent link">&para;</a></h4>
<p>Tiger推荐的学习率衰减策略：</p>
<p><strong>多项式衰减</strong>：
\begin{equation}
\alpha_t = \alpha_0 \left(1 - \frac{t}{T}\right)^p \tag{58}
\end{equation}</p>
<p>其中$p$通常取1（线性）或2（二次）。</p>
<p><strong>逆时间衰减</strong>：
\begin{equation}
\alpha_t = \frac{\alpha_0}{1 + kt} \tag{59}
\end{equation}</p>
<p><strong>余弦退火</strong>：
\begin{equation}
\alpha_t = \alpha_{min} + \frac{1}{2}(\alpha_0 - \alpha_{min})\left(1 + \cos\frac{\pi t}{T}\right) \tag{60}
\end{equation}</p>
<p><strong>收敛速度比较</strong>：</p>
<p>在凸优化设置下，不同策略的收敛率：
- 常数学习率：$O(1/T)$
- 多项式衰减：$O(1/T)$
- 逆时间衰减：$O(\log T/T)$
- 余弦退火：$O(1/T)$</p>
<p><strong>实践建议</strong>：
1. Warmup阶段（前10%步数）：线性增长
   \begin{equation}
   \alpha_t = \alpha_0 \cdot \min(1, t/T_{warmup}) \tag{61}
   \end{equation}</p>
<ol start="2">
<li>主训练阶段：余弦衰减</li>
<li>Fine-tuning阶段：常数小学习率</li>
</ol>
<h4 id="115">1.15 权重衰减率的自适应调整<a class="toc-link" href="#115" title="Permanent link">&para;</a></h4>
<p>从贝叶斯视角，权重衰减对应高斯先验：
\begin{equation}
p(\boldsymbol{\theta}) = \mathcal{N}(\boldsymbol{0}, \sigma^2 I) \propto \exp\left(-\frac{|\boldsymbol{\theta}|^2}{2\sigma^2}\right) \tag{62}
\end{equation}</p>
<p>负对数先验：
\begin{equation}
-\log p(\boldsymbol{\theta}) = \frac{|\boldsymbol{\theta}|^2}{2\sigma^2} + \text{const} \tag{63}
\end{equation}</p>
<p>对应权重衰减率：
\begin{equation}
\lambda = \frac{1}{\sigma^2} \tag{64}
\end{equation}</p>
<p><strong>不同参数类型的先验</strong>：</p>
<ol>
<li>
<p><strong>Kernel矩阵</strong>：$\sigma^2 \approx 1/n$（Xavier初始化）
   \begin{equation}
   \lambda_{kernel} \approx n \tag{65}
   \end{equation}</p>
</li>
<li>
<p><strong>Bias向量</strong>：$\sigma^2 \approx 1$（较大方差）
   \begin{equation}
   \lambda_{bias} \approx 1 \tag{66}
   \end{equation}</p>
</li>
<li>
<p><strong>归一化参数</strong>：$\sigma^2 \approx 1$
   \begin{equation}
   \lambda_{norm} \approx 1 \tag{67}
   \end{equation}</p>
</li>
</ol>
<p><strong>实践中的简化</strong>：
\begin{equation}
\lambda_t = \begin{cases}
0.01, &amp; \text{for kernel matrices} \
0, &amp; \text{for bias and normalization}
\end{cases} \tag{68}
\end{equation}</p>
<h4 id="116-batch">1.16 大batch训练的理论基础<a class="toc-link" href="#116-batch" title="Permanent link">&para;</a></h4>
<p><strong>定理5（线性缩放规则）</strong>：当batch size从$B$增加到$kB$时，学习率应相应从$\alpha$增加到$k\alpha$以保持收敛性。</p>
<p><strong>证明草图</strong>：</p>
<p>小batch梯度：
\begin{equation}
\boldsymbol{g}<em i="1">B = \frac{1}{B}\sum</em>
\end{equation}}^{B}\nabla f(\boldsymbol{x}_i; \boldsymbol{\theta}) \tag{69</p>
<p>大batch梯度：
\begin{equation}
\boldsymbol{g}<em i="1">{kB} = \frac{1}{kB}\sum</em>
\end{equation}}^{kB}\nabla f(\boldsymbol{x}_i; \boldsymbol{\theta}) \tag{70</p>
<p>期望相同：
\begin{equation}
\mathbb{E}[\boldsymbol{g}<em kB="kB">B] = \mathbb{E}[\boldsymbol{g}</em>
\end{equation}}] = \nabla f(\boldsymbol{\theta}) \tag{71</p>
<p>方差不同：
\begin{equation}
\text{Var}[\boldsymbol{g}_{kB}] = \frac{1}{k}\text{Var}[\boldsymbol{g}_B] \tag{72}
\end{equation}</p>
<p>为保持探索能力，需增大学习率以补偿方差减小。</p>
<p><strong>Tiger的梯度累积</strong>：相当于增大有效batch size而不增加显存，自动适用线性缩放规则。</p>
<h4 id="117">1.17 完整训练配置示例<a class="toc-link" href="#117" title="Permanent link">&para;</a></h4>
<p><strong>BERT预训练配置</strong>：</p>
<div class="highlight"><pre><span></span><code><span class="n">Model</span><span class="o">:</span><span class="w"> </span><span class="n">BERT</span><span class="o">-</span><span class="n">base</span><span class="w"> </span><span class="o">(</span><span class="mi">110</span><span class="n">M</span><span class="w"> </span><span class="n">parameters</span><span class="o">)</span>
<span class="n">Optimizer</span><span class="o">:</span><span class="w"> </span><span class="n">Tiger</span>
<span class="o">-</span><span class="w"> </span><span class="err">β</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.965</span>
<span class="o">-</span><span class="w"> </span><span class="err">α₀</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.001</span>
<span class="o">-</span><span class="w"> </span><span class="err">λ</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.01</span><span class="w"> </span><span class="o">(</span><span class="k">for</span><span class="w"> </span><span class="n">kernels</span><span class="o">),</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">(</span><span class="k">for</span><span class="w"> </span><span class="n">bias</span><span class="o">/</span><span class="n">norm</span><span class="o">)</span>
<span class="o">-</span><span class="w"> </span><span class="n">Warmup</span><span class="o">:</span><span class="w"> </span><span class="mi">10000</span><span class="w"> </span><span class="n">steps</span>
<span class="o">-</span><span class="w"> </span><span class="n">Total</span><span class="w"> </span><span class="n">steps</span><span class="o">:</span><span class="w"> </span><span class="mi">1000000</span>
<span class="o">-</span><span class="w"> </span><span class="n">Schedule</span><span class="o">:</span><span class="w"> </span><span class="n">Linear</span><span class="w"> </span><span class="n">decay</span><span class="w"> </span><span class="n">after</span><span class="w"> </span><span class="n">warmup</span>
<span class="o">-</span><span class="w"> </span><span class="n">Gradient</span><span class="w"> </span><span class="n">accumulation</span><span class="o">:</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="mi">4</span>
</code></pre></div>

<p><strong>完整更新方程</strong>：
\begin{equation}
\begin{cases}
\boldsymbol{m}<em _t-1_4="(t-1)/4">t = [(0.965-1)\chi</em>} + 1]\boldsymbol{m<em t-1="t-1">{t-1} + \frac{0.035}{4}\boldsymbol{g}_t \
\eta_t = 0.001 \cdot \max(t/10000, 1) \cdot (1 - t/1000000) \cdot \text{RMS}(\boldsymbol{\theta}</em>) \
\boldsymbol{\theta}<em t-1="t-1">t = \boldsymbol{\theta}</em>} - \chi_{t/4}\eta_t[\text{sign}(\boldsymbol{m<em t-1="t-1">t) + 0.01\boldsymbol{\theta}</em>]
\end{cases} \tag{73}
\end{equation}</p>
<p><strong>预期收敛曲线</strong>：
\begin{equation}
\mathcal{L}(t) \approx \mathcal{L}<em _min="\min">{\min} + (\mathcal{L}_0 - \mathcal{L}</em>
\end{equation}})\exp(-ct^{0.5}) \tag{74</p>
<p>其中$c$是任务相关常数。</p>
<hr />
<h3 id="2">2. 数学推导总结<a class="toc-link" href="#2" title="Permanent link">&para;</a></h3>
<p>本节完整推导了Tiger优化器的数学基础，包括：</p>
<ol>
<li><strong>基础理论</strong>：动量、Sign操作、权重衰减的数学性质</li>
<li><strong>显存优化</strong>：梯度累积的等价性证明，显存节省分析</li>
<li><strong>数值稳定性</strong>：混合精度训练的上下溢分析，NaN防护机制</li>
<li><strong>收敛性</strong>：Lyapunov稳定性分析，收敛率定理</li>
<li><strong>自适应性</strong>：学习率和权重衰减率的参数尺度适应</li>
<li><strong>鲁棒性</strong>：对初始化、梯度爆炸/消失的抵抗力</li>
<li><strong>实践指导</strong>：完整训练配置和超参数选择</li>
</ol>
<p>所有推导都配有数学直觉解释和数值示例，确保理论与实践的统一。</p>
                </div>

                <!-- Previous/Next Navigation -->
                <nav class="post-navigation" aria-label="文章导航">
                    <div class="row g-3">
                        <div class="col-6">
                            
                            <a href="生成扩散模型漫谈十八得分匹配-条件得分匹配.html" class="nav-link-prev">
                                <div class="nav-direction"><i class="fas fa-chevron-left"></i> 上一篇</div>
                                <div class="nav-title">#220 生成扩散模型漫谈（十八）：得分匹配 = 条件得分匹配</div>
                            </a>
                            
                        </div>
                        <div class="col-6">
                            
                            <a href="缓解交叉熵过度自信的一个简明方案.html" class="nav-link-next">
                                <div class="nav-direction">下一篇 <i class="fas fa-chevron-right"></i></div>
                                <div class="nav-title">#222 缓解交叉熵过度自信的一个简明方案</div>
                            </a>
                            
                        </div>
                    </div>
                </nav>

                <!-- Back to Home -->
                <div class="text-center mt-4 mb-4">
                    <a href="../index.html" class="btn btn-outline-primary">
                        <i class="fas fa-arrow-left"></i> 返回首页
                    </a>
                </div>
            </div>

            <!-- Sidebar (TOC) -->
            <div class="col-lg-3">
                <aside class="sidebar">
                    
                    <div class="toc-sidebar">
                        <h5 class="toc-title"><i class="fas fa-list"></i> 目录</h5>
                        <div class="toc-content">
                            <div class="toc">
<ul>
<li><a href="#tiger">Tiger：一个“抠”到极致的优化器</a><ul>
<li><a href="#_1">基本形式</a></li>
<li><a href="#_2">超参设置</a><ul>
<li><a href="#_3">滑动率</a></li>
<li><a href="#_4">学习率</a></li>
<li><a href="#_5">衰减率</a></li>
</ul>
</li>
<li><a href="#_6">梯度累积</a></li>
<li><a href="#_7">全半精度</a></li>
<li><a href="#nan">防止NaN</a></li>
<li><a href="#_8">实验结果</a></li>
<li><a href="#_9">未来工作</a></li>
<li><a href="#_10">文章小结</a></li>
<li><a href="#_11">公式推导与注释</a><ul>
<li><a href="#1-tiger">1. Tiger优化器的完整数学推导</a></li>
<li><a href="#2">2. 数学推导总结</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>

                        </div>
                        <div class="toc-actions">
                            <button class="btn btn-sm btn-outline-secondary" onclick="expandAll()">
                                <i class="fas fa-expand"></i> 全部展开
                            </button>
                            <button class="btn btn-sm btn-outline-secondary" onclick="collapseAll()">
                                <i class="fas fa-compress"></i> 全部折叠
                            </button>
                        </div>
                    </div>
                    

                    <!-- Back to Top Button -->
                    <button id="backToTop" class="back-to-top" title="回到顶部">
                        <i class="fas fa-arrow-up"></i>
                    </button>
                </aside>
            </div>
        </div>
    </article>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>
                博客来源: <a href="https://spaces.ac.cn" target="_blank">科学空间</a> |
                内容经过整理并添加详细数学推导
            </p>
            <p>
                Powered by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>
            </p>
        </div>
    </footer>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>

    <!-- Syntax highlighting -->
    <script>hljs.highlightAll();</script>

    <!-- Back to top functionality -->
    <script>
        // Show/hide back to top button based on scroll position
        window.addEventListener('scroll', function() {
            const backToTop = document.getElementById('backToTop');
            if (window.pageYOffset > 300) {
                backToTop.classList.add('show');
            } else {
                backToTop.classList.remove('show');
            }
        });

        // Smooth scroll to top
        document.getElementById('backToTop').addEventListener('click', function() {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        });

        // Sticky TOC sidebar
        window.addEventListener('scroll', function() {
            const sidebar = document.querySelector('.sidebar');
            if (!sidebar) return;

            const sidebarTop = sidebar.offsetTop;
            const scrollTop = window.pageYOffset;

            if (scrollTop > sidebarTop - 20) {
                sidebar.classList.add('sticky');
            } else {
                sidebar.classList.remove('sticky');
            }
        });
    </script>
</body>
</html>