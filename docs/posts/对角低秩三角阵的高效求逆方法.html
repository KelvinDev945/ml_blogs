<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>“对角+低秩”三角阵的高效求逆方法 | ML & Math Blog Posts</title>
    <meta name="description" content="“对角+低秩”三角阵的高效求逆方法&para;
原文链接: https://spaces.ac.cn/archives/11072
发布日期: 

从文章《线性注意力简史：从模仿、创新到反哺》我们可以发现，DeltaNet及其后的线性Attention模型，基本上都关联到了逆矩阵$(\boldsymbol{I} + \boldsymbol{K}\boldsymbol{K}^{\top}\odot\...">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css">

    <!-- Google Fonts -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="../assets/css/main.css">
    <link rel="stylesheet" href="../assets/css/post.css">

    <!-- Custom JS -->
    <script src="../assets/js/collapsible.js" defer></script>

    <!-- MathJax for math rendering -->
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Syntax highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/styles/github.min.css">
    <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/highlight.min.js"></script>
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light bg-light border-bottom">
        <div class="container">
            <a class="navbar-brand" href="../index.html">
                <i class="fas fa-brain"></i> ML & Math Blog
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="../index.html"><i class="fas fa-home"></i> 首页</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Post Content -->
    <article class="container post-container my-5">
        <!-- Breadcrumb Navigation -->
        <nav aria-label="breadcrumb">
            <ol class="breadcrumb">
                <li class="breadcrumb-item"><a href="../index.html"><i class="fas fa-home"></i> 首页</a></li>
                
                <li class="breadcrumb-item"><a href="../index.html?tags=详细推导">详细推导</a></li>
                
                <li class="breadcrumb-item active" aria-current="page">
                    #206 “对角+低秩”三角阵的高效求逆方法
                </li>
            </ol>
        </nav>

        <!-- Post Header -->
        <header class="post-header mb-4">
            <h1 class="post-title">
                <span class="post-number">#206</span>
                “对角+低秩”三角阵的高效求逆方法
            </h1>
            <div class="post-meta">
                <span><i class="far fa-calendar"></i> 2025-07-01</span>
                
            </div>
            
            <div class="post-tags mt-3">
                
                <a href="../index.html?tags=详细推导" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 详细推导</span>
                </a>
                
                <a href="../index.html?tags=计算" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 计算</span>
                </a>
                
                <a href="../index.html?tags=矩阵" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 矩阵</span>
                </a>
                
                <a href="../index.html?tags=RNN" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> RNN</span>
                </a>
                
                <a href="../index.html?tags=attention" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> attention</span>
                </a>
                
                <a href="../index.html?tags=生成模型" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 生成模型</span>
                </a>
                
            </div>
            
        </header>

        <div class="row">
            <!-- Main Content -->
            <div class="col-lg-9">
                <!-- Post Body -->
                <div class="post-content">
                    <h1 id="_1">“对角+低秩”三角阵的高效求逆方法<a class="toc-link" href="#_1" title="Permanent link">&para;</a></h1>
<p><strong>原文链接</strong>: <a href="https://spaces.ac.cn/archives/11072">https://spaces.ac.cn/archives/11072</a></p>
<p><strong>发布日期</strong>: </p>
<hr />
<p>从文章<a href="/archives/11033">《线性注意力简史：从模仿、创新到反哺》</a>我们可以发现，DeltaNet及其后的线性Attention模型，基本上都关联到了逆矩阵$(\boldsymbol{I} + \boldsymbol{K}\boldsymbol{K}^{\top}\odot\boldsymbol{M}^-)^{-1}$。本文就专门来探讨一下这类具有“对角+低秩”特点的三角矩阵的逆矩阵计算。</p>
<h2 id="_2">基本结果<a class="toc-link" href="#_2" title="Permanent link">&para;</a></h2>
<p>我们将问题一般地定义如下：</p>
<blockquote>
<p>给定矩阵$\boldsymbol{Q},\boldsymbol{K}\in\mathbb{R}^{n\times d}$和对角矩阵$\boldsymbol{\Lambda}\in\mathbb{R}^{n\times n}$，满足$n\gg d$，定义 \begin{equation}\boldsymbol{T} = \boldsymbol{\Lambda} + \boldsymbol{Q}\boldsymbol{K}^{\top}\odot\boldsymbol{M}^-\end{equation} 其中$\boldsymbol{M}^-=\boldsymbol{M} - \boldsymbol{I}$，矩阵$\boldsymbol{M}$定义为 \begin{equation}M_{i,j} = \left\{\begin{aligned} &amp;1, &amp;i \geq j \\ &amp;0, &amp;i &lt; j\end{aligned}\right.\end{equation} 现在要求逆矩阵$\boldsymbol{T}^{-1}$，并且证明其复杂度是$\mathcal{O}(n^2)$。</p>
</blockquote>
<p>首先，如果没有$\odot\boldsymbol{M}^-$的下三角阵约束，那么它可以直接由“<a href="https://en.wikipedia.org/wiki/Woodbury_matrix_identity">Woodbury恒等式</a>”解决：<br />
\begin{equation}(\boldsymbol{\Lambda} + \boldsymbol{Q}\boldsymbol{K}^{\top})^{-1} = \boldsymbol{\Lambda}^{-1} - \boldsymbol{\Lambda}^{-1} \boldsymbol{Q}(\boldsymbol{I} + \boldsymbol{K}^{\top}\boldsymbol{\Lambda}^{-1}\boldsymbol{Q})^{-1}\boldsymbol{K}^{\top}\boldsymbol{\Lambda}^{-1}\end{equation}<br />
容易验证右端的计算复杂度是$\mathcal{O}(n^2)$的。然而，加上$\odot\boldsymbol{M}^-$后，$\boldsymbol{T}$本身就不再具有“对角+低秩”的结构，因此不能直接由该恒等式解决了。针对下三角矩阵这一特点，一个基本的思路是递归，因为我们有分块矩阵恒等式<br />
\begin{equation}\begin{bmatrix}\boldsymbol{A} &amp; \boldsymbol{0} \\ \boldsymbol{C} &amp; \boldsymbol{B}\end{bmatrix}^{-1} = \begin{bmatrix}\boldsymbol{A}^{-1} &amp; \boldsymbol{0} \\ -\boldsymbol{B}^{-1}\boldsymbol{C}\boldsymbol{A}^{-1} &amp; \boldsymbol{B}^{-1}\end{bmatrix}\end{equation}<br />
这允许我们将$\boldsymbol{T}^{-1}$转化递归形式（约定：没有括号的情况下，切片的优先级最高）<br />
\begin{equation}\boldsymbol{T}<em _:l_:l_="[:l,:l]">{[:l+1,:l+1]}^{-1} = \begin{bmatrix}\boldsymbol{T}</em>}^{-1} &amp; \boldsymbol{0} \\ -\boldsymbol{T<em _l:l_1_:l_="[l:l+1,:l]">{[l:l+1,l:l+1]}^{-1}\boldsymbol{T}</em>}\boldsymbol{T<em _l:l_1_l:l_1_="[l:l+1,l:l+1]">{[:l,:l]}^{-1} &amp; \boldsymbol{T}</em>}^{-1}\end{bmatrix}\end{equation<br />
其中主要计算是$\boldsymbol{T}<em _:l_:l_="[:l,:l]">{[l:l+1,:l]}\boldsymbol{T}</em>(n^3)$。}^{-1}$，它是一个$1\times l$和$l\times l$矩阵相乘，复杂度是$\mathcal{O}(\mathcal{l^2})$，即每一步迭代的复杂度是平方增长的，所以总复杂度是$\mathcal{O</p>
<h2 id="_3">低秩结构<a class="toc-link" href="#_3" title="Permanent link">&para;</a></h2>
<p>当然，这是因为我们还没用上$\boldsymbol{T}$（$\odot\boldsymbol{M}^-$前）的低秩结构，现在我们把它利用起来，那么将会得到$\boldsymbol{T}<em _l:l_1_="[l:l+1]">{[l:l+1,:l]} = \boldsymbol{Q}</em>}\boldsymbol{K<em _:l_1_:l_1_="[:l+1,:l+1]">{[:l]}^{\top}$，代入上式得：<br />
\begin{equation}\boldsymbol{T}</em>}^{-1} = \begin{bmatrix}\boldsymbol{T<em _l:l_1_l:l_1_="[l:l+1,l:l+1]">{[:l,:l]}^{-1} &amp; \boldsymbol{0} \\ -\boldsymbol{T}</em>}^{-1}\boldsymbol{Q<em _:l_="[:l]">{[l:l+1]}\boldsymbol{K}</em>}^{\top}\boldsymbol{T<em _l:l_1_l:l_1_="[l:l+1,l:l+1]">{[:l,:l]}^{-1} &amp; \boldsymbol{T}</em>}^{-1}\end{bmatrix}\end{equation<br />
注意$\boldsymbol{K}<em _:l_:l_="[:l,:l]">{[:l]}^{\top}\boldsymbol{T}</em>(n^2)$。根据这个思路，我们有}^{-1}\in\mathbb{R}^{d\times l}$，如果我们能以它为递归变量，那么每一步迭代的复杂度就只是$\mathcal{O}(l)$，总复杂度就能成功降到$\mathcal{O<br />
\begin{equation}\begin{aligned}<br />
\boldsymbol{K}<em _:l_1_:l_1_="[:l+1,:l+1]">{[:l+1]}^{\top}\boldsymbol{T}</em>}^{-1} =&amp;\, \begin{bmatrix}\boldsymbol{K<em _l:l_1_="[l:l+1]">{[:l]}^{\top} &amp; \boldsymbol{K}</em>}^{\top}\end{bmatrix}\begin{bmatrix}\boldsymbol{T<em _l:l_1_l:l_1_="[l:l+1,l:l+1]">{[:l,:l]}^{-1} &amp; \boldsymbol{0} \\ -\boldsymbol{T}</em>}^{-1}\boldsymbol{Q<em _:l_="[:l]">{[l:l+1]}\boldsymbol{K}</em>}^{\top}\boldsymbol{T<em _l:l_1_l:l_1_="[l:l+1,l:l+1]">{[:l,:l]}^{-1} &amp; \boldsymbol{T}</em> \\[6pt]}^{-1}\end{bmatrix<br />
=&amp;\, \begin{bmatrix}\boldsymbol{K}<em _:l_:l_="[:l,:l]">{[:l]}^{\top}\boldsymbol{T}</em>}^{-1} &amp; \boldsymbol{0}\end{bmatrix} + \boldsymbol{K<em _l:l_1_l:l_1_="[l:l+1,l:l+1]">{[l:l+1]}^{\top}\underbrace{\begin{bmatrix}-\boldsymbol{T}</em>}^{-1}\boldsymbol{Q<em _:l_="[:l]">{[l:l+1]}\boldsymbol{K}</em>}^{\top}\boldsymbol{T<em _l:l_1_l:l_1_="[l:l+1,l:l+1]">{[:l,:l]}^{-1} &amp; \boldsymbol{T}</em>}^{-1}\end{bmatrix}<em _l:l_1_:l_1_="[l:l+1,:l+1]">{\text{实际上就是 }(\boldsymbol{T}^{-1})</em>}}\end{aligned}\end{equation<br />
可以看到这个递归过程也没有涉及到$\mathcal{O}(l^2)$的运算，因此思路是可行的，只需要引入一个新变量来缓存$\boldsymbol{K}<em _:l_:l_="[:l,:l]">{[:l]}^{\top}\boldsymbol{T}</em>$。如果我们将$l+1$换成$l+c$，那么就可以得到chunk格式的递归。}^{-1</p>
<p>测试代码如下：</p>
<pre class="highlight"><code>import numpy as np

n, d, c = 1000, 100, 200
Q = np.random.randn(n, d) / d**0.5
K = np.random.randn(n, d) / d**0.5
T = np.tril(Q @ K.T, -1) + np.eye(n)

Y, Z = np.zeros((n, n)), np.zeros((d, n))
for l in range(0, n, c):
    Y[l:l + c, l:l + c] = np.linalg.inv(T[l:l + c, l:l + c])
    Y[l:l + c, :l] = - Y[l:l + c, l:l + c] @ Q[l:l + c] @ Z[:, :l]
    Z[:, :l + c] += K[l:l + c].T @ Y[l:l + c, :l + c]

np.allclose(Y @ T, np.eye(n))
</code></pre>

<h2 id="_4">乘法计算<a class="toc-link" href="#_4" title="Permanent link">&para;</a></h2>
<p>基于同样的思路，我们还可以证明：</p>
<blockquote>
<p>对于任意矩阵$\boldsymbol{V}\in\mathbb{R}^{n\times d}$，计算$\boldsymbol{T}^{-1}\boldsymbol{V}$只需要$\mathcal{O}(n)$的复杂度。</p>
</blockquote>
<p>证明只需要把前述过程稍微改动一下。首先有<br />
\begin{equation}\begin{aligned}<br />
(\boldsymbol{T}^{-1}\boldsymbol{V})<em _:l_1_:l_1_="[:l+1,:l+1]">{[:l+1]} =&amp;\, \boldsymbol{T}</em>}^{-1}\boldsymbol{V<em _:l_:l_="[:l,:l]">{[:l+1]} \\[6pt]<br />
=&amp;\, \begin{bmatrix}\boldsymbol{T}</em>}^{-1} &amp; \boldsymbol{0} \\ -\boldsymbol{T<em _l:l_1_="[l:l+1]">{[l:l+1,l:l+1]}^{-1}\boldsymbol{Q}</em>}\boldsymbol{K<em _:l_:l_="[:l,:l]">{[:l]}^{\top}\boldsymbol{T}</em>}^{-1} &amp; \boldsymbol{T<em _:l_="[:l]">{[l:l+1,l:l+1]}^{-1}\end{bmatrix}\begin{bmatrix}\boldsymbol{V}</em>} \\ \boldsymbol{V<em _:l_:l_="[:l,:l]">{[l:l+1]}\end{bmatrix} \\[6pt]<br />
=&amp;\, \begin{bmatrix}\boldsymbol{T}</em>}^{-1}\boldsymbol{V<em _l:l_1_l:l_1_="[l:l+1,l:l+1]">{[:l]} \\ -\boldsymbol{T}</em>}^{-1}\boldsymbol{Q<em _:l_="[:l]">{[l:l+1]}\boldsymbol{K}</em>}^{\top}\boldsymbol{T<em _:l_="[:l]">{[:l,:l]}^{-1}\boldsymbol{V}</em>} + \boldsymbol{T<em _l:l_1_="[l:l+1]">{[l:l+1,l:l+1]}^{-1}\boldsymbol{V}</em> \\[6pt]}\end{bmatrix<br />
=&amp;\, \begin{bmatrix}(\boldsymbol{T}^{-1}\boldsymbol{V})<em _l:l_1_l:l_1_="[l:l+1,l:l+1]">{[:l]} \\ \boldsymbol{T}</em>}^{-1}(\boldsymbol{V<em _l:l_1_="[l:l+1]">{[l:l+1]} - \boldsymbol{Q}</em>}\boldsymbol{K<em _:l_="[:l]">{[:l]}^{\top}(\boldsymbol{T}^{-1}\boldsymbol{V})</em>})\end{bmatrix<br />
\end{aligned}\end{equation}<br />
然后<br />
\begin{equation}\begin{aligned}<br />
\boldsymbol{K}<em _:l_1_="[:l+1]">{[:l+1]}^{\top}(\boldsymbol{T}^{-1}\boldsymbol{V})</em>} =&amp;\, \begin{bmatrix}\boldsymbol{K<em _l:l_1_="[l:l+1]">{[:l]}^{\top} &amp; \boldsymbol{K}</em>)}^{\top}\end{bmatrix}\begin{bmatrix}(\boldsymbol{T}^{-1}\boldsymbol{V<em _l:l_1_="[l:l+1]">{[:l]} \\ (\boldsymbol{T}^{-1}\boldsymbol{V})</em> \\[8pt]} \end{bmatrix<br />
=&amp;\,\boldsymbol{K}<em _:l_="[:l]">{[:l]}^{\top}(\boldsymbol{T}^{-1}\boldsymbol{V})</em>} + \boldsymbol{K<em _l:l_1_="[l:l+1]">{[l:l+1]}^{\top}(\boldsymbol{T}^{-1}\boldsymbol{V})</em><br />
\end{aligned}\end{equation}<br />
因此，只需要缓存$\boldsymbol{K}<em _:l_="[:l]">{[:l]}^{\top}(\boldsymbol{T}^{-1}\boldsymbol{V})</em>(n)$。同样，只需要将$l+1$换成$l+c$就可以得到chunk格式。}\in\mathbb{R}^{d\times d}$，就可以使得每步的计算复杂度与$l$无关，因此总复杂度是$\mathcal{O</p>
<p>测试代码如下：</p>
<pre class="highlight"><code>import numpy as np

n, d, c = 1000, 100, 200
Q = np.random.randn(n, d) / d**0.5
K = np.random.randn(n, d) / d**0.5
V = np.random.randn(n, d) / d**0.5
T = np.tril(Q @ K.T, -1) + np.eye(n)

Y, Z = np.zeros((n, d)), np.zeros((d, d))
for l in range(0, n, c):
    X = np.linalg.inv(T[l:l + c, l:l + c])
    Y[l:l + c] = X @ (V[l:l + c] - Q[l:l + c] @ Z)
    Z += K[l:l + c].T @ Y[l:l + c]

np.allclose(T @ Y, V)
</code></pre>

<h2 id="_5">文章小结<a class="toc-link" href="#_5" title="Permanent link">&para;</a></h2>
<p>本文讨论了“对角+低秩”特点的三角矩阵求逆问题，这类矩阵普遍出现在新式线性Attention模型中。</p>
<p><em><strong>转载到请包括本文地址：</strong><a href="https://spaces.ac.cn/archives/11072">https://spaces.ac.cn/archives/11072</a></em></p>
<p><em><strong>更详细的转载事宜请参考：</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="《科学空间FAQ》">《科学空间FAQ》</a></p>
<p><strong>如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。</strong></p>
<p><strong>如果您觉得本文还不错，欢迎分享/打赏本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！</strong></p>
<p>打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>微信打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>支付宝打赏</p>
<p>因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>点击这里</strong></a>或在下方评论区留言来告知你的建议或需求。</p>
<p><strong>如果您需要引用本文，请参考：</strong></p>
<p>苏剑林. (Jul. 01, 2025). 《“对角+低秩”三角阵的高效求逆方法 》[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/11072">https://spaces.ac.cn/archives/11072</a></p>
<p>@online{kexuefm-11072,<br />
title={“对角+低秩”三角阵的高效求逆方法},<br />
author={苏剑林},<br />
year={2025},<br />
month={Jul},<br />
url={\url{https://spaces.ac.cn/archives/11072}},<br />
} </p>
<hr />
<h2 id="_6">公式推导与注释<a class="toc-link" href="#_6" title="Permanent link">&para;</a></h2>
<p>本节提供文章中关键结果的详细数学推导，从矩阵理论基础到算法实现的完整分析。</p>
<h3 id="1">1. "对角+低秩"矩阵结构的数学表示<a class="toc-link" href="#1" title="Permanent link">&para;</a></h3>
<p><strong>定义1.1（对角+低秩矩阵）</strong>：一个矩阵$\boldsymbol{A}\in\mathbb{R}^{n\times n}$称为对角+低秩矩阵，如果它可以表示为<br />
$$\boldsymbol{A} = \boldsymbol{D} + \boldsymbol{U}\boldsymbol{V}^{\top}$$<br />
其中$\boldsymbol{D}\in\mathbb{R}^{n\times n}$是对角矩阵，$\boldsymbol{U},\boldsymbol{V}\in\mathbb{R}^{n\times r}$且$r\ll n$。</p>
<p><strong>本文问题的特殊性</strong>：文章中的矩阵$\boldsymbol{T}$具有更复杂的结构：<br />
$$\boldsymbol{T} = \boldsymbol{\Lambda} + \boldsymbol{Q}\boldsymbol{K}^{\top}\odot\boldsymbol{M}^-$$</p>
<p>让我们详细分析这个结构：</p>
<ol>
<li><strong>对角部分</strong>：$\boldsymbol{\Lambda} = \text{diag}(\lambda_1, \lambda_2, \ldots, \lambda_n)$</li>
<li><strong>低秩部分</strong>：$\boldsymbol{Q}\boldsymbol{K}^{\top}$，其中$\boldsymbol{Q},\boldsymbol{K}\in\mathbb{R}^{n\times d}$，秩最多为$d$</li>
<li><strong>下三角掩码</strong>：$\boldsymbol{M}^- = \boldsymbol{M} - \boldsymbol{I}$，其中<br />
   $$M_{i,j} = \begin{cases} 1, &amp; i \geq j \ 0, &amp; i &lt; j \end{cases}$$</li>
</ol>
<p><strong>关键观察</strong>：$\odot\boldsymbol{M}^-$操作使得<br />
$$(\boldsymbol{Q}\boldsymbol{K}^{\top}\odot\boldsymbol{M}^-)<em i_j="i,j">{i,j} = \begin{cases} (\boldsymbol{Q}\boldsymbol{K}^{\top})</em>$$}, &amp; i &gt; j \ 0, &amp; i \leq j \end{cases</p>
<p>因此，$\boldsymbol{T}$是严格下三角+对角矩阵：<br />
$$T_{i,j} = \begin{cases} \lambda_i, &amp; i = j \ \sum_{k=1}^{d} Q_{i,k}K_{j,k}, &amp; i &gt; j \ 0, &amp; i &lt; j \end{cases}$$</p>
<p>这意味着$\boldsymbol{T}$虽然整体上不再是"对角+低秩"形式，但它保留了<strong>下三角结构</strong>和<strong>低秩表示</strong>的局部性质。</p>
<h3 id="2-woodbury">2. Woodbury矩阵恒等式的完整证明<a class="toc-link" href="#2-woodbury" title="Permanent link">&para;</a></h3>
<p><strong>定理2.1（Sherman-Morrison-Woodbury公式）</strong>：设$\boldsymbol{A}\in\mathbb{R}^{n\times n}$可逆，$\boldsymbol{U},\boldsymbol{V}\in\mathbb{R}^{n\times k}$，若$\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U}$可逆，则<br />
$$(\boldsymbol{A} + \boldsymbol{U}\boldsymbol{V}^{\top})^{-1} = \boldsymbol{A}^{-1} - \boldsymbol{A}^{-1}\boldsymbol{U}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}\boldsymbol{V}^{\top}\boldsymbol{A}^{-1}$$</p>
<p><strong>证明（方法一：直接验证）</strong>：</p>
<p>记$\boldsymbol{B} = \boldsymbol{A}^{-1} - \boldsymbol{A}^{-1}\boldsymbol{U}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}\boldsymbol{V}^{\top}\boldsymbol{A}^{-1}$，需证$\boldsymbol{B}(\boldsymbol{A} + \boldsymbol{U}\boldsymbol{V}^{\top}) = \boldsymbol{I}$。</p>
<p>计算左端：<br />
$$\begin{aligned}<br />
&amp;\boldsymbol{B}(\boldsymbol{A} + \boldsymbol{U}\boldsymbol{V}^{\top}) \<br />
=&amp; \left<a href="\boldsymbol{A} + \boldsymbol{U}\boldsymbol{V}^{\top}">\boldsymbol{A}^{-1} - \boldsymbol{A}^{-1}\boldsymbol{U}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}\boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\right</a> \<br />
=&amp; \boldsymbol{A}^{-1}\boldsymbol{A} + \boldsymbol{A}^{-1}\boldsymbol{U}\boldsymbol{V}^{\top} - \boldsymbol{A}^{-1}\boldsymbol{U}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}\boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{A} \<br />
&amp;\quad - \boldsymbol{A}^{-1}\boldsymbol{U}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}\boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U}\boldsymbol{V}^{\top} \<br />
=&amp; \boldsymbol{I} + \boldsymbol{A}^{-1}\boldsymbol{U}\boldsymbol{V}^{\top} - \boldsymbol{A}^{-1}\boldsymbol{U}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}\boldsymbol{V}^{\top} \<br />
&amp;\quad - \boldsymbol{A}^{-1}\boldsymbol{U}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}(\boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})\boldsymbol{V}^{\top} \<br />
=&amp; \boldsymbol{I} + \boldsymbol{A}^{-1}\boldsymbol{U}\boldsymbol{V}^{\top} - \boldsymbol{A}^{-1}\boldsymbol{U}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}[\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U}]\boldsymbol{V}^{\top} \<br />
=&amp; \boldsymbol{I} + \boldsymbol{A}^{-1}\boldsymbol{U}\boldsymbol{V}^{\top} - \boldsymbol{A}^{-1}\boldsymbol{U}\boldsymbol{V}^{\top} = \boldsymbol{I}<br />
\end{aligned}$$</p>
<p>其中关键步骤是将第3、4项合并：<br />
$$(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}[\boldsymbol{V}^{\top} + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U}\boldsymbol{V}^{\top}] = (\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})\boldsymbol{V}^{\top} = \boldsymbol{V}^{\top}$$</p>
<p><strong>证明（方法二：块矩阵逆）</strong>：</p>
<p>构造块矩阵：<br />
$$\boldsymbol{M} = \begin{bmatrix} \boldsymbol{A} &amp; \boldsymbol{U} \ \boldsymbol{V}^{\top} &amp; -\boldsymbol{I}_k \end{bmatrix}$$</p>
<p>使用两种不同的块消元方法求逆：</p>
<p><strong>第一种消元</strong>（先消去左下块）：<br />
$$\begin{bmatrix} \boldsymbol{A} &amp; \boldsymbol{U} \ \boldsymbol{V}^{\top} &amp; -\boldsymbol{I}_k \end{bmatrix} \sim \begin{bmatrix} \boldsymbol{A} + \boldsymbol{U}\boldsymbol{V}^{\top} &amp; \boldsymbol{0} \ \boldsymbol{V}^{\top} &amp; -\boldsymbol{I}_k \end{bmatrix}$$</p>
<p>得到：<br />
$$\boldsymbol{M}^{-1} = \begin{bmatrix} (\boldsymbol{A} + \boldsymbol{U}\boldsymbol{V}^{\top})^{-1} &amp; * \ * &amp; * \end{bmatrix}$$</p>
<p><strong>第二种消元</strong>（先消去右上块）：<br />
$$\begin{bmatrix} \boldsymbol{A} &amp; \boldsymbol{U} \ \boldsymbol{V}^{\top} &amp; -\boldsymbol{I}_k \end{bmatrix} \sim \begin{bmatrix} \boldsymbol{A} &amp; \boldsymbol{0} \ \boldsymbol{V}^{\top} + \boldsymbol{A}^{-1}\boldsymbol{U} &amp; -\boldsymbol{I}_k \end{bmatrix}$$</p>
<p>得到左上块为：<br />
$$\boldsymbol{A}^{-1} - \boldsymbol{A}^{-1}\boldsymbol{U}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}\boldsymbol{V}^{\top}\boldsymbol{A}^{-1}$$</p>
<p>两种方法得到的$(1,1)$块必须相等，证毕。</p>
<p><strong>计算复杂度分析</strong>：</p>
<p>对于$\boldsymbol{A} = \boldsymbol{\Lambda}$（对角矩阵），$\boldsymbol{U} = \boldsymbol{Q}$，$\boldsymbol{V} = \boldsymbol{K}$：</p>
<ol>
<li>$\boldsymbol{\Lambda}^{-1}$：$\mathcal{O}(n)$（对角元素求倒数）</li>
<li>$\boldsymbol{\Lambda}^{-1}\boldsymbol{Q}$：$\mathcal{O}(nd)$（$n$个$d$维向量逐元素乘）</li>
<li>$\boldsymbol{K}^{\top}\boldsymbol{\Lambda}^{-1}\boldsymbol{Q}$：$\mathcal{O}(nd^2)$（$d\times n$矩阵乘$n\times d$矩阵）</li>
<li>$(\boldsymbol{I}_d + \boldsymbol{K}^{\top}\boldsymbol{\Lambda}^{-1}\boldsymbol{Q})^{-1}$：$\mathcal{O}(d^3)$（$d\times d$矩阵求逆）</li>
<li>最终组合：$\mathcal{O}(nd^2)$</li>
</ol>
<p>总复杂度：$\mathcal{O}(nd^2) + \mathcal{O}(d^3) = \mathcal{O}(nd^2)$。当$d\ll n$时，这是$\mathcal{O}(n)$线性复杂度（固定$d$时）。</p>
<h3 id="3">3. 三角矩阵的块矩阵求逆递归算法<a class="toc-link" href="#3" title="Permanent link">&para;</a></h3>
<p><strong>定理3.1（块下三角矩阵求逆）</strong>：对于块下三角矩阵<br />
$$\boldsymbol{T} = \begin{bmatrix}\boldsymbol{A} &amp; \boldsymbol{0} \ \boldsymbol{C} &amp; \boldsymbol{B}\end{bmatrix}$$<br />
其中$\boldsymbol{A}\in\mathbb{R}^{m\times m}$，$\boldsymbol{B}\in\mathbb{R}^{n\times n}$可逆，有<br />
$$\boldsymbol{T}^{-1} = \begin{bmatrix}\boldsymbol{A}^{-1} &amp; \boldsymbol{0} \ -\boldsymbol{B}^{-1}\boldsymbol{C}\boldsymbol{A}^{-1} &amp; \boldsymbol{B}^{-1}\end{bmatrix}$$</p>
<p><strong>证明</strong>：直接验证<br />
$$\begin{bmatrix}\boldsymbol{A}^{-1} &amp; \boldsymbol{0} \ -\boldsymbol{B}^{-1}\boldsymbol{C}\boldsymbol{A}^{-1} &amp; \boldsymbol{B}^{-1}\end{bmatrix}\begin{bmatrix}\boldsymbol{A} &amp; \boldsymbol{0} \ \boldsymbol{C} &amp; \boldsymbol{B}\end{bmatrix} = \begin{bmatrix}\boldsymbol{I}_m &amp; \boldsymbol{0} \ -\boldsymbol{B}^{-1}\boldsymbol{C} + \boldsymbol{B}^{-1}\boldsymbol{C} &amp; \boldsymbol{I}_n\end{bmatrix} = \boldsymbol{I}$$</p>
<p><strong>应用到逐行递归</strong>：</p>
<p>将$\boldsymbol{T}\in\mathbb{R}^{(l+1)\times(l+1)}$分块为<br />
$$\boldsymbol{T}<em _:l_:l_="[:l,:l]">{[:l+1,:l+1]} = \begin{bmatrix}\boldsymbol{T}</em>} &amp; \boldsymbol{0} \ \boldsymbol{T<em _l:l_1_l:l_1_="[l:l+1,l:l+1]">{[l:l+1,:l]} &amp; \boldsymbol{T}</em>$$}\end{bmatrix</p>
<p>其中：<br />
- $\boldsymbol{A} = \boldsymbol{T}<em _l:l_1_l:l_1_="[l:l+1,l:l+1]">{[:l,:l]}\in\mathbb{R}^{l\times l}$（已计算的子矩阵）<br />
- $\boldsymbol{B} = \boldsymbol{T}</em>$（标量，因为是对角元）} = \lambda_{l+1<br />
- $\boldsymbol{C} = \boldsymbol{T}_{[l:l+1,:l]}\in\mathbb{R}^{1\times l}$（行向量）</p>
<p>代入公式：<br />
$$\boldsymbol{T}<em _:l_:l_="[:l,:l]">{[:l+1,:l+1]}^{-1} = \begin{bmatrix}\boldsymbol{T}</em>}^{-1} &amp; \boldsymbol{0} \ -\lambda_{l+1}^{-1}\boldsymbol{T<em _:l_:l_="[:l,:l]">{[l:l+1,:l]}\boldsymbol{T}</em>$$}^{-1} &amp; \lambda_{l+1}^{-1}\end{bmatrix</p>
<p><strong>朴素算法的复杂度</strong>：</p>
<p>计算$\boldsymbol{T}<em _:l_:l_="[:l,:l]">{[l:l+1,:l]}\boldsymbol{T}</em>$：}^{-1<br />
- $\boldsymbol{T}<em _:l_:l_="[:l,:l]">{[l:l+1,:l]}$是$1\times l$行向量<br />
- $\boldsymbol{T}</em>$是$l\times l$密集矩阵}^{-1<br />
- 矩阵乘法：$\mathcal{O}(l^2)$</p>
<p>递归展开：<br />
$$\sum_{l=0}^{n-1} \mathcal{O}(l^2) = \mathcal{O}\left(\sum_{l=0}^{n-1} l^2\right) = \mathcal{O}\left(\frac{n^3}{3}\right) = \mathcal{O}(n^3)$$</p>
<p>这就是为什么朴素递归算法是三次方复杂度。</p>
<h3 id="4">4. 利用低秩结构的优化递归<a class="toc-link" href="#4" title="Permanent link">&para;</a></h3>
<p><strong>关键观察</strong>：$\boldsymbol{T}$的严格下三角部分具有低秩表示<br />
$$\boldsymbol{T}<em _i_="[i]">{[i,j]} = \boldsymbol{Q}</em>, \quad i &gt; j$$}\boldsymbol{K}_{[j]}^{\top</p>
<p>因此：<br />
$$\boldsymbol{T}<em _l:l_1_="[l:l+1]">{[l:l+1,:l]} = \boldsymbol{Q}</em>$$}\boldsymbol{K}_{[:l]}^{\top</p>
<p>这是一个秩$\leq d$的$1\times l$矩阵，可以表示为$d$维向量的外积。</p>
<p><strong>优化的递归公式</strong>：</p>
<p>代入低秩分解：<br />
$$\boldsymbol{T}<em _:l_:l_="[:l,:l]">{[:l+1,:l+1]}^{-1} = \begin{bmatrix}\boldsymbol{T}</em>}^{-1} &amp; \boldsymbol{0} \ -\lambda_{l+1}^{-1}\boldsymbol{Q<em _:l_="[:l]">{[l:l+1]}\boldsymbol{K}</em>}^{\top}\boldsymbol{T<em l_1="l+1">{[:l,:l]}^{-1} &amp; \lambda</em>$$}^{-1}\end{bmatrix</p>
<p><strong>引入缓存变量</strong>：定义<br />
$$\boldsymbol{Z}<em _:l_="[:l]">{[:l]} := \boldsymbol{K}</em>$$}^{\top}\boldsymbol{T}_{[:l,:l]}^{-1} \in\mathbb{R}^{d\times l</p>
<p>这个变量缓存了$\boldsymbol{K}$的前$l$行与逆矩阵前$l$列的乘积。</p>
<p><strong>递归更新$\boldsymbol{Z}$</strong>：</p>
<p>$$\begin{aligned}<br />
\boldsymbol{Z}<em _:l_1_="[:l+1]">{[:l+1]} &amp;= \boldsymbol{K}</em>}^{\top}\boldsymbol{T<em _:l_="[:l]">{[:l+1,:l+1]}^{-1} \<br />
&amp;= \begin{bmatrix}\boldsymbol{K}</em>}^{\top} \ \boldsymbol{K<em _:l_:l_="[:l,:l]">{[l:l+1]}^{\top}\end{bmatrix}\begin{bmatrix}\boldsymbol{T}</em>}^{-1} &amp; \boldsymbol{0} \ -\lambda_{l+1}^{-1}\boldsymbol{Q<em _:l_="[:l]">{[l:l+1]}\boldsymbol{K}</em>}^{\top}\boldsymbol{T<em l_1="l+1">{[:l,:l]}^{-1} &amp; \lambda</em> \}^{-1}\end{bmatrix<br />
&amp;= \begin{bmatrix}\boldsymbol{K}<em _:l_:l_="[:l,:l]">{[:l]}^{\top}\boldsymbol{T}</em>}^{-1} \ \boldsymbol{K<em l_1="l+1">{[l:l+1]}^{\top}(-\lambda</em>}^{-1}\boldsymbol{Q<em _:l_="[:l]">{[l:l+1]}\boldsymbol{K}</em>}^{\top}\boldsymbol{T<em _l:l_1_="[l:l+1]">{[:l,:l]}^{-1})\end{bmatrix} + \begin{bmatrix}\boldsymbol{0} \ \boldsymbol{K}</em> \}^{\top}\lambda_{l+1}^{-1}\end{bmatrix<br />
&amp;= \begin{bmatrix}\boldsymbol{Z}<em l_1="l+1">{[:l]} \ -\lambda</em>}^{-1}\boldsymbol{K<em _l:l_1_="[l:l+1]">{[l:l+1]}^{\top}\boldsymbol{Q}</em>}\boldsymbol{Z<em l_1="l+1">{[:l]} + \lambda</em>}^{-1}\boldsymbol{K<em _:l_="[:l]">{[l:l+1]}^{\top}\end{bmatrix} \<br />
&amp;= \begin{bmatrix}\boldsymbol{Z}</em>} \ \lambda_{l+1}^{-1}\boldsymbol{K<em _l:l_1_="[l:l+1]">{[l:l+1]}^{\top}(\boldsymbol{I} - \boldsymbol{Q}</em>}\boldsymbol{Z}_{[:l]})\end{bmatrix<br />
\end{aligned}$$</p>
<p>简化为增量更新：<br />
$$\boldsymbol{Z}<em _:l_="[:l]">{[:l+1]} = \begin{bmatrix}\boldsymbol{Z}</em>} \ \boldsymbol{Z<em _l:l_1_="[l:l+1]">{[l:l+1]}\end{bmatrix}, \quad \boldsymbol{Z}</em>} = \lambda_{l+1}^{-1}\boldsymbol{K<em _l:l_1_="[l:l+1]">{[l:l+1]}^{\top}(\boldsymbol{I} - \boldsymbol{Q}</em>)$$}\boldsymbol{Z}_{[:l]</p>
<p><strong>复杂度分析（每步迭代）</strong>：</p>
<p>第$l$步需要计算：<br />
1. $\boldsymbol{Q}<em _:l_="[:l]">{[l:l+1]}\boldsymbol{Z}</em>(dl)$}$：$1\times d$矩阵乘$d\times l$矩阵 $\Rightarrow$ $\mathcal{O<br />
2. $\boldsymbol{I} - \boldsymbol{Q}<em _:l_="[:l]">{[l:l+1]}\boldsymbol{Z}</em>(l)$}$：$\mathcal{O<br />
3. $\lambda_{l+1}^{-1}\boldsymbol{K}_{[l:l+1]}^{\top}(\cdot)$：$d\times 1$矩阵乘$1\times l$矩阵 $\Rightarrow$ $\mathcal{O}(dl)$</p>
<p><strong>总复杂度</strong>：$\mathcal{O}(dl)$</p>
<p><strong>完整算法的总复杂度</strong>：<br />
$$\sum_{l=0}^{n-1} \mathcal{O}(dl) = \mathcal{O}\left(d\sum_{l=0}^{n-1}l\right) = \mathcal{O}\left(d\cdot\frac{n^2}{2}\right) = \mathcal{O}(dn^2)$$</p>
<p>当$d$视为常数时，这是$\mathcal{O}(n^2)$复杂度，相比朴素的$\mathcal{O}(n^3)$有显著改进！</p>
<h3 id="5-chunk">5. Chunk格式的递归算法<a class="toc-link" href="#5-chunk" title="Permanent link">&para;</a></h3>
<p><strong>动机</strong>：逐行递归虽然复杂度最优，但频繁的小规模操作可能导致缓存效率低。Chunk递归将每次更新$1$行改为$c$行。</p>
<p><strong>Chunk分块</strong>：将$n\times n$矩阵按$c$行分块：<br />
$$\boldsymbol{T} = \begin{bmatrix}\boldsymbol{T}^{(0)} \ \boldsymbol{T}^{(1)} \ \vdots \ \boldsymbol{T}^{(N-1)}\end{bmatrix}, \quad N = \lceil n/c \rceil$$</p>
<p>其中$\boldsymbol{T}^{(k)} = \boldsymbol{T}_{[kc:(k+1)c, :]}$是第$k$个chunk（$c$行）。</p>
<p><strong>Chunk递归公式</strong>：</p>
<p>设已计算$\boldsymbol{T}<em _:_k_1_c_:_k_1_c_="[:(k+1)c,:(k+1)c]">{[:kc,:kc]}^{-1}$，要计算$\boldsymbol{T}</em>$：}^{-1</p>
<p>$$\boldsymbol{T}<em _:kc_:kc_="[:kc,:kc]">{[:(k+1)c,:(k+1)c]} = \begin{bmatrix}\boldsymbol{T}</em>} &amp; \boldsymbol{0} \ \boldsymbol{T<em _kc:_k_1_c_kc:_k_1_c_="[kc:(k+1)c,kc:(k+1)c]">{[kc:(k+1)c,:kc]} &amp; \boldsymbol{T}</em>$$}\end{bmatrix</p>
<p>逆矩阵：<br />
$$\boldsymbol{T}<em _:kc_:kc_="[:kc,:kc]">{[:(k+1)c,:(k+1)c]}^{-1} = \begin{bmatrix}\boldsymbol{T}</em>$$}^{-1} &amp; \boldsymbol{0} \ -\boldsymbol{X}\boldsymbol{T}_{[:kc,:kc]}^{-1} &amp; \boldsymbol{X}\end{bmatrix</p>
<p>其中：<br />
$$\boldsymbol{X} = \boldsymbol{T}<em _kc:_k_1_c_kc:_k_1_c_="[kc:(k+1)c,kc:(k+1)c]">{[kc:(k+1)c,kc:(k+1)c]}^{-1}, \quad \boldsymbol{T}</em>$$} = \boldsymbol{\Lambda}_{[kc:(k+1)c,kc:(k+1)c]</p>
<p>因为对角块是对角矩阵，$\boldsymbol{X}$的计算只需$\mathcal{O}(c)$。</p>
<p><strong>低秩分解</strong>：<br />
$$\boldsymbol{T}<em _kc:_k_1_c_="[kc:(k+1)c]">{[kc:(k+1)c,:kc]} = \boldsymbol{Q}</em>$$}\boldsymbol{K}_{[:kc]}^{\top</p>
<p>代入：<br />
$$-\boldsymbol{X}\boldsymbol{T}<em _:kc_:kc_="[:kc,:kc]">{[kc:(k+1)c,:kc]}\boldsymbol{T}</em>}^{-1} = -\boldsymbol{X}\boldsymbol{Q<em _:kc_="[:kc]">{[kc:(k+1)c]}\underbrace{\boldsymbol{K}</em>}^{\top}\boldsymbol{T<em>{[:kc,:kc]}^{-1}}</em>$$}_{[:kc]}</p>
<p><strong>缓存变量更新</strong>：<br />
$$\begin{aligned}<br />
\boldsymbol{Z}<em _:_k_1_c_="[:(k+1)c]">{[:(k+1)c]} &amp;= \boldsymbol{K}</em>}^{\top}\boldsymbol{T<em _:kc_="[:kc]">{[:(k+1)c,:(k+1)c]}^{-1} \<br />
&amp;= \begin{bmatrix}\boldsymbol{K}</em>}^{\top} \ \boldsymbol{K<em _:kc_:kc_="[:kc,:kc]">{[kc:(k+1)c]}^{\top}\end{bmatrix}\begin{bmatrix}\boldsymbol{T}</em>}^{-1} &amp; \boldsymbol{0} \ -\boldsymbol{X}\boldsymbol{Q<em _:kc_="[:kc]">{[kc:(k+1)c]}\boldsymbol{Z}</em> \} &amp; \boldsymbol{X}\end{bmatrix<br />
&amp;= \begin{bmatrix}\boldsymbol{Z}<em _kc:_k_1_c_="[kc:(k+1)c]">{[:kc]} \ \boldsymbol{K}</em>}^{\top}\boldsymbol{X} - \boldsymbol{K<em _kc:_k_1_c_="[kc:(k+1)c]">{[kc:(k+1)c]}^{\top}\boldsymbol{X}\boldsymbol{Q}</em>}\boldsymbol{Z<em _:kc_="[:kc]">{[:kc]}\end{bmatrix} \<br />
&amp;= \begin{bmatrix}\boldsymbol{Z}</em>} \ \boldsymbol{K<em _kc:_k_1_c_="[kc:(k+1)c]">{[kc:(k+1)c]}^{\top}\boldsymbol{X}(\boldsymbol{I} - \boldsymbol{Q}</em>}\boldsymbol{Z}_{[:kc]})\end{bmatrix<br />
\end{aligned}$$</p>
<p><strong>Chunk算法伪代码</strong>：</p>
<pre class="highlight"><code>输入: Q, K, Λ, c (chunk size)
输出: T^{-1}

初始化: Y = zeros(n, n), Z = zeros(d, n)

for k = 0 to ⌈n/c⌉ - 1:
    l_start = k * c
    l_end = min((k+1) * c, n)

    # 计算对角块的逆
    X = diag(Λ[l_start:l_end])^{-1}

    # 更新逆矩阵的对角块
    Y[l_start:l_end, l_start:l_end] = X

    # 更新逆矩阵的下三角块（利用缓存Z）
    Y[l_start:l_end, :l_start] = -X @ Q[l_start:l_end] @ Z[:, :l_start]

    # 增量更新缓存Z
    Z[:, :l_end] += K[l_start:l_end].T @ Y[l_start:l_end, :l_end]

返回 Y
</code></pre>

<p><strong>复杂度分析</strong>：</p>
<p>每个chunk（$k$-th iteration，处理$l = kc$行）：<br />
1. $\boldsymbol{Q}<em _:l_="[:l]">{[l:l+c]}\boldsymbol{Z}</em>(cdl)$}$：$c\times d$矩阵乘$d\times l$矩阵 $\Rightarrow$ $\mathcal{O<br />
2. $\boldsymbol{X}\boldsymbol{Q}<em _l:l_c_="[l:l+c]">{[l:l+c]}(\cdot)$：$c\times c$对角矩阵乘$c\times l$矩阵 $\Rightarrow$ $\mathcal{O}(cl)$<br />
3. $\boldsymbol{K}</em>(dcl)$}^{\top}\boldsymbol{X}(\cdot)$：$d\times c$矩阵乘$c\times l$矩阵 $\Rightarrow$ $\mathcal{O</p>
<p>总计：$\mathcal{O}(dcl)$</p>
<p><strong>完整算法</strong>：<br />
$$\sum_{k=0}^{N-1} \mathcal{O}(dc \cdot kc) = \mathcal{O}(dc^2)\sum_{k=0}^{N-1}k = \mathcal{O}(dc^2 \cdot \frac{N^2}{2}) = \mathcal{O}\left(dc^2 \cdot \frac{n^2}{2c^2}\right) = \mathcal{O}(dn^2)$$</p>
<p>与逐行递归相同的渐近复杂度，但chunk算法有更好的缓存局部性。</p>
<h3 id="6-boldsymbolt-1boldsymbolv">6. 矩阵-向量乘法$\boldsymbol{T}^{-1}\boldsymbol{V}$的优化算法<a class="toc-link" href="#6-boldsymbolt-1boldsymbolv" title="Permanent link">&para;</a></h3>
<p><strong>问题设定</strong>：给定$\boldsymbol{V}\in\mathbb{R}^{n\times d}$，计算$\boldsymbol{Y} = \boldsymbol{T}^{-1}\boldsymbol{V}$。</p>
<p><strong>朴素方法</strong>：先计算$\boldsymbol{T}^{-1}$（$\mathcal{O}(dn^2)$），再计算矩阵乘法（$\mathcal{O}(n^2d)$），总计$\mathcal{O}(dn^2)$。</p>
<p><strong>优化思路</strong>：不显式计算$\boldsymbol{T}^{-1}$，而是利用递归结构直接计算$\boldsymbol{Y}$。</p>
<p><strong>递归公式推导</strong>：</p>
<p>$$\begin{aligned}<br />
\boldsymbol{Y}<em _:l_1_:l_1_="[:l+1,:l+1]">{[:l+1]} &amp;= \boldsymbol{T}</em>}^{-1}\boldsymbol{V<em _:l_:l_="[:l,:l]">{[:l+1]} \<br />
&amp;= \begin{bmatrix}\boldsymbol{T}</em>}^{-1} &amp; \boldsymbol{0} \ -\lambda_{l+1}^{-1}\boldsymbol{Q<em _:l_="[:l]">{[l:l+1]}\boldsymbol{K}</em>}^{\top}\boldsymbol{T<em l_1="l+1">{[:l,:l]}^{-1} &amp; \lambda</em>}^{-1}\end{bmatrix}\begin{bmatrix}\boldsymbol{V<em _l:l_1_="[l:l+1]">{[:l]} \ \boldsymbol{V}</em> \}\end{bmatrix<br />
&amp;= \begin{bmatrix}\boldsymbol{T}<em _:l_="[:l]">{[:l,:l]}^{-1}\boldsymbol{V}</em>} \ \lambda_{l+1}^{-1}[\boldsymbol{V<em _l:l_1_="[l:l+1]">{[l:l+1]} - \boldsymbol{Q}</em>}\boldsymbol{K<em _:l_:l_="[:l,:l]">{[:l]}^{\top}\boldsymbol{T}</em>}^{-1}\boldsymbol{V<em _:l_="[:l]">{[:l]}]\end{bmatrix} \<br />
&amp;= \begin{bmatrix}\boldsymbol{Y}</em>} \ \lambda_{l+1}^{-1}[\boldsymbol{V<em _l:l_1_="[l:l+1]">{[l:l+1]} - \boldsymbol{Q}</em>}\boldsymbol{K<em _:l_="[:l]">{[:l]}^{\top}\boldsymbol{Y}</em>}]\end{bmatrix<br />
\end{aligned}$$</p>
<p><strong>关键观察</strong>：引入缓存<br />
$$\boldsymbol{Z}<em _:l_="[:l]">{[:l]} := \boldsymbol{K}</em>}^{\top}\boldsymbol{Y<em _:l_="[:l]">{[:l]} = \boldsymbol{K}</em>}^{\top}\boldsymbol{T<em _:l_="[:l]">{[:l,:l]}^{-1}\boldsymbol{V}</em>$$} \in\mathbb{R}^{d\times d</p>
<p>则第$l+1$行的计算简化为：<br />
$$\boldsymbol{Y}<em l_1="l+1">{[l:l+1]} = \lambda</em>}^{-1}[\boldsymbol{V<em _l:l_1_="[l:l+1]">{[l:l+1]} - \boldsymbol{Q}</em>]$$}\boldsymbol{Z}_{[:l]</p>
<p><strong>缓存更新</strong>：<br />
$$\begin{aligned}<br />
\boldsymbol{Z}<em _:l_1_="[:l+1]">{[:l+1]} &amp;= \boldsymbol{K}</em>}^{\top}\boldsymbol{Y<em _:l_="[:l]">{[:l+1]} \<br />
&amp;= \begin{bmatrix}\boldsymbol{K}</em>}^{\top} \ \boldsymbol{K<em _:l_="[:l]">{[l:l+1]}^{\top}\end{bmatrix}\begin{bmatrix}\boldsymbol{Y}</em>} \ \boldsymbol{Y<em _:l_="[:l]">{[l:l+1]}\end{bmatrix} \<br />
&amp;= \boldsymbol{K}</em>}^{\top}\boldsymbol{Y<em _l:l_1_="[l:l+1]">{[:l]} + \boldsymbol{K}</em>}^{\top}\boldsymbol{Y<em _:l_="[:l]">{[l:l+1]} \<br />
&amp;= \boldsymbol{Z}</em>} + \boldsymbol{K<em _l:l_1_="[l:l+1]">{[l:l+1]}^{\top}\boldsymbol{Y}</em><br />
\end{aligned}$$</p>
<p>这是一个简单的增量更新！</p>
<p><strong>算法伪代码</strong>：</p>
<pre class="highlight"><code>输入: Q, K, Λ, V
输出: Y = T^{-1}V

初始化: Y = zeros(n, d), Z = zeros(d, d)

for l = 0 to n-1:
    # 计算当前行
    Y[l] = (V[l] - Q[l] @ Z) / λ_l

    # 增量更新缓存
    Z += K[l]^T @ Y[l]  # 外积: d×1 与 1×d

返回 Y
</code></pre>

<p><strong>复杂度分析（每步迭代）</strong>：</p>
<p>第$l$步：<br />
1. $\boldsymbol{Q}<em _l_="[l]">{[l]}\boldsymbol{Z}$：$1\times d$乘$d\times d$ $\Rightarrow$ $\mathcal{O}(d^2)$<br />
2. $\boldsymbol{V}</em>} - \boldsymbol{Q<em _l_="[l]">{[l]}\boldsymbol{Z}$：$\mathcal{O}(d)$<br />
3. 标量除法：$\mathcal{O}(d)$<br />
4. $\boldsymbol{K}</em>(d^2)$}^{\top}\boldsymbol{Y}_{[l]}$：外积$d\times d$ $\Rightarrow$ $\mathcal{O</p>
<p>总计：$\mathcal{O}(d^2)$每步</p>
<p><strong>完整算法</strong>：<br />
$$\sum_{l=0}^{n-1}\mathcal{O}(d^2) = \mathcal{O}(nd^2)$$</p>
<p>当$d$固定时，这是$\mathcal{O}(n)$线性复杂度！远优于先计算$\boldsymbol{T}^{-1}$再相乘的$\mathcal{O}(n^2)$方法。</p>
<p><strong>Chunk版本</strong>：</p>
<pre class="highlight"><code>for k = 0 to ⌈n/c⌉ - 1:
    l = k * c
    X = diag(Λ[l:l+c])^{-1}
    Y[l:l+c] = X @ (V[l:l+c] - Q[l:l+c] @ Z)
    Z += K[l:l+c].T @ Y[l:l+c]
</code></pre>

<p>复杂度仍为$\mathcal{O}(nd^2)$，但有更好的向量化。</p>
<h3 id="7">7. 数值稳定性分析<a class="toc-link" href="#7" title="Permanent link">&para;</a></h3>
<p><strong>浮点误差累积</strong>：</p>
<p>递归算法中，第$l$步的误差会传播到后续所有步骤。设第$l$步的舍入误差为$\epsilon_l$，则：</p>
<p>$$\boldsymbol{Y}<em _:l_:l_="[:l,:l]">{[:l]} = \boldsymbol{T}</em>}^{-1}\boldsymbol{V<em _:l_="[:l]">{[:l]} + \boldsymbol{e}</em>}, \quad |\boldsymbol{e<em i="0">{[:l]}| \leq \sum</em>\epsilon_i$$}^{l-1</p>
<p><strong>条件数的影响</strong>：</p>
<p>矩阵$\boldsymbol{T}$的条件数：<br />
$$\kappa(\boldsymbol{T}) = |\boldsymbol{T}| \cdot |\boldsymbol{T}^{-1}|$$</p>
<p>对于对角占优矩阵（$|\lambda_i| \gg |\boldsymbol{Q}<em _:i_="[:i]">{[i]}\boldsymbol{K}</em>|$），条件数较小：}^{\top<br />
$$\kappa(\boldsymbol{T}) \approx \frac{\max_i |\lambda_i|}{\min_i |\lambda_i|}$$</p>
<p><strong>误差界</strong>：</p>
<p>根据Wilkinson分析，递归算法的相对误差满足：<br />
$$\frac{|\boldsymbol{Y}<em _text_exact="\text{exact">{\text{computed}} - \boldsymbol{Y}</em>}}|}{|\boldsymbol{Y<em _text_machine="\text{machine">{\text{exact}}|} \leq \kappa(\boldsymbol{T}) \cdot n \cdot \epsilon</em>^2)$$}} + \mathcal{O}(n^2\epsilon_{\text{machine}</p>
<p>其中$\epsilon_{\text{machine}} \approx 10^{-16}$（双精度）。</p>
<p><strong>改进策略</strong>：</p>
<ol>
<li><strong>缩放（Scaling）</strong>：预先对$\boldsymbol{\Lambda}$进行归一化，使$\max_i|\lambda_i| = 1$。</li>
<li><strong>部分主元（Partial Pivoting）</strong>：在块求逆时选择绝对值最大的对角元。</li>
<li><strong>迭代精化（Iterative Refinement）</strong>：计算残差$\boldsymbol{r} = \boldsymbol{V} - \boldsymbol{T}\boldsymbol{Y}$，解$\boldsymbol{T}\boldsymbol{\delta} = \boldsymbol{r}$，更新$\boldsymbol{Y} \leftarrow \boldsymbol{Y} + \boldsymbol{\delta}$。</li>
</ol>
<p><strong>对角元素接近零的处理</strong>：</p>
<p>当$\lambda_i \approx 0$时，$\lambda_i^{-1}$会导致数值溢出。应添加正则化：<br />
$$\boldsymbol{T}_{\text{reg}} = \boldsymbol{T} + \epsilon\boldsymbol{I}, \quad \epsilon = 10^{-8}$$</p>
<p>或使用伪逆：<br />
$$\lambda_i^{-1} \leftarrow \begin{cases} 1/\lambda_i, &amp; |\lambda_i| &gt; \epsilon \ 0, &amp; |\lambda_i| \leq \epsilon \end{cases}$$</p>
<h3 id="8-lu">8. 与标准LU分解的对比<a class="toc-link" href="#8-lu" title="Permanent link">&para;</a></h3>
<p><strong>LU分解方法</strong>：</p>
<p>对于一般下三角矩阵$\boldsymbol{T}$，标准求逆方法是：<br />
1. LU分解：$\boldsymbol{T} = \boldsymbol{L}\boldsymbol{U}$（$\mathcal{O}(n^3)$）<br />
2. 前向替换：求解$\boldsymbol{L}\boldsymbol{Y}' = \boldsymbol{V}$（$\mathcal{O}(n^2)$）<br />
3. 后向替换：求解$\boldsymbol{U}\boldsymbol{Y} = \boldsymbol{Y}'$（$\mathcal{O}(n^2)$）</p>
<p>总复杂度：$\mathcal{O}(n^3)$（主要是LU分解）</p>
<p><strong>本文方法的优势</strong>：</p>
<table>
<thead>
<tr>
<th>方面</th>
<th>LU分解</th>
<th>本文方法</th>
</tr>
</thead>
<tbody>
<tr>
<td>复杂度</td>
<td>$\mathcal{O}(n^3)$</td>
<td>$\mathcal{O}(dn^2)$</td>
</tr>
<tr>
<td>适用条件</td>
<td>任意可逆矩阵</td>
<td>对角+低秩三角阵</td>
</tr>
<tr>
<td>内存占用</td>
<td>$\mathcal{O}(n^2)$</td>
<td>$\mathcal{O}(dn)$</td>
</tr>
<tr>
<td>并行性</td>
<td>较差（顺序依赖强）</td>
<td>较好（chunk独立性）</td>
</tr>
<tr>
<td>数值稳定性</td>
<td>好（部分主元）</td>
<td>中等（依赖对角元）</td>
</tr>
</tbody>
</table>
<p><strong>关键差异</strong>：LU分解是通用方法，未利用低秩结构；本文方法专门针对特殊结构，通过Woodbury思想降低复杂度。</p>
<p><strong>前向替换的详细步骤</strong>（标准方法）：</p>
<p>对于下三角方程$\boldsymbol{L}\boldsymbol{y} = \boldsymbol{v}$：<br />
$$\begin{aligned}<br />
L_{1,1}y_1 &amp;= v_1 &amp;\Rightarrow y_1 = v_1/L_{1,1} \<br />
L_{2,1}y_1 + L_{2,2}y_2 &amp;= v_2 &amp;\Rightarrow y_2 = (v_2 - L_{2,1}y_1)/L_{2,2} \<br />
&amp;\vdots \<br />
\sum_{j=1}^{i}L_{i,j}y_j &amp;= v_i &amp;\Rightarrow y_i = \left(v_i - \sum_{j=1}^{i-1}L_{i,j}y_j\right)/L_{i,i}<br />
\end{aligned}$$</p>
<p>第$i$步需要$\mathcal{O}(i)$操作，总计$\sum_{i=1}^{n}i = \mathcal{O}(n^2)$。</p>
<p><strong>本文方法的"隐式前向替换"</strong>：</p>
<p>递归公式<br />
$$\boldsymbol{Y}<em l_1="l+1">{[l:l+1]} = \lambda</em>}^{-1}[\boldsymbol{V<em _l:l_1_="[l:l+1]">{[l:l+1]} - \boldsymbol{Q}</em>]$$}\boldsymbol{Z}_{[:l]<br />
本质上是一种<strong>压缩的前向替换</strong>：<br />
- 标准前向替换需要遍历所有$j &lt; l$<br />
- 本文方法通过缓存$\boldsymbol{Z}$，将$\mathcal{O}(l)$个项的求和压缩为$\mathcal{O}(d)$的矩阵-向量乘法</p>
<p>这正是低秩结构带来的威力！</p>
<h3 id="9">9. 线性注意力机制中的应用<a class="toc-link" href="#9" title="Permanent link">&para;</a></h3>
<p><strong>标准Attention机制</strong>：</p>
<p>$$\text{Attention}(\boldsymbol{Q}, \boldsymbol{K}, \boldsymbol{V}) = \text{softmax}\left(\frac{\boldsymbol{Q}\boldsymbol{K}^{\top}}{\sqrt{d}}\right)\boldsymbol{V}$$</p>
<p>复杂度：$\mathcal{O}(n^2d)$（$n$是序列长度）</p>
<p><strong>因果掩码（Causal Mask）</strong>：</p>
<p>在自回归生成中，位置$i$只能attend到$j \leq i$：<br />
$$\boldsymbol{A}_{i,j} = \begin{cases} \text{softmax}(\boldsymbol{Q}_i\boldsymbol{K}_j^{\top}/\sqrt{d}), &amp; j \leq i \ 0, &amp; j &gt; i \end{cases}$$</p>
<p>这使得$\boldsymbol{A}$成为下三角矩阵。</p>
<p><strong>线性Attention（DeltaNet等）</strong>：</p>
<p>用指数衰减替代softmax：<br />
$$\boldsymbol{A}_{i,j} = \begin{cases} \exp(\boldsymbol{Q}_i\boldsymbol{K}_j^{\top} - \beta(i-j)), &amp; j \leq i \ 0, &amp; j &gt; i \end{cases}$$</p>
<p>改写为：<br />
$$\boldsymbol{A} = \exp(\boldsymbol{Q}\boldsymbol{K}^{\top}) \odot \boldsymbol{M}^- \odot \boldsymbol{D}$$</p>
<p>其中$\boldsymbol{D}_{i,j} = \exp(-\beta(i-j))$是衰减矩阵。</p>
<p><strong>归一化</strong>：</p>
<p>为保证数值稳定，需要归一化：<br />
$$\boldsymbol{O}<em j="1">i = \frac{\sum</em>}^{i}\boldsymbol{A<em j="1">{i,j}\boldsymbol{V}_j}{\sum</em>$$}^{i}\boldsymbol{A}_{i,j}</p>
<p>分母可写为：<br />
$$\boldsymbol{s}<em j="1">i = \sum</em>}^{i}\boldsymbol{A<em i_:="i,:">{i,j} = \boldsymbol{A}</em>$$}\boldsymbol{1</p>
<p>定义对角矩阵$\boldsymbol{S} = \text{diag}(\boldsymbol{s}_1, \ldots, \boldsymbol{s}_n)$，则：<br />
$$\boldsymbol{O} = \boldsymbol{S}^{-1}\boldsymbol{A}\boldsymbol{V}$$</p>
<p><strong>本文问题的出现</strong>：</p>
<p>某些线性Attention变体（如<a href="https://arxiv.org/abs/2301.13419">Fast RNN</a>）需要计算：<br />
$$\boldsymbol{O} = (\boldsymbol{I} + \boldsymbol{Q}\boldsymbol{K}^{\top}\odot\boldsymbol{M}^-)^{-1}\boldsymbol{V}$$</p>
<p>这正是$\boldsymbol{\Lambda} = \boldsymbol{I}$（单位矩阵）的特殊情况！</p>
<p><strong>更一般的形式（DeltaNet）</strong>：<br />
$$\boldsymbol{O} = (\boldsymbol{\Lambda} + \boldsymbol{Q}\boldsymbol{K}^{\top}\odot\boldsymbol{M}^-)^{-1}\boldsymbol{V}$$</p>
<p>其中$\boldsymbol{\Lambda}$编码位置信息或学习的动态参数。</p>
<p><strong>本文算法的直接应用</strong>：</p>
<p>利用第6节的$\mathcal{O}(nd^2)$算法，可以在每个训练step高效计算Attention输出，避免$\mathcal{O}(n^3)$的完整矩阵求逆。</p>
<p><strong>推理时的增量计算</strong>：</p>
<p>在自回归生成第$t$步，只需更新：<br />
$$\boldsymbol{Z}<em t-1="t-1">t = \boldsymbol{Z}</em>} + \boldsymbol{K<em t-1="t-1">t^{\top}\boldsymbol{Y}_t$$<br />
$$\boldsymbol{Y}_t = \lambda_t^{-1}[\boldsymbol{V}_t - \boldsymbol{Q}_t\boldsymbol{Z}</em>]$$</p>
<p>每步仅需$\mathcal{O}(d^2)$，实现真正的$\mathcal{O}(1)$推理！</p>
<h3 id="10">10. 进一步的优化与扩展<a class="toc-link" href="#10" title="Permanent link">&para;</a></h3>
<p><strong>稀疏低秩结构</strong>：</p>
<p>如果$\boldsymbol{Q}\boldsymbol{K}^{\top}$本身是稀疏的（如局部attention），可以进一步降低复杂度到$\mathcal{O}(ns)$，其中$s$是每行的非零元素数。</p>
<p><strong>多头Attention（Multi-Head）</strong>：</p>
<p>标准多头机制：<br />
$$\text{MultiHead}(\boldsymbol{Q}, \boldsymbol{K}, \boldsymbol{V}) = \text{Concat}(\text{head}_1, \ldots, \text{head}_h)\boldsymbol{W}^O$$</p>
<p>其中每个head独立计算。本文算法可并行应用到所有head，总复杂度$\mathcal{O}(hnd^2)$。</p>
<p><strong>Block-Recurrent结构</strong>：</p>
<p>将序列分为长度$b$的块，块内使用本文算法，块间使用RNN：<br />
$$\boldsymbol{h}<em k-1="k-1">k = \text{RNN}(\boldsymbol{h}</em>_k)$$}, \boldsymbol{T}_k^{-1}\boldsymbol{V</p>
<p>训练复杂度：$\mathcal{O}(nd^2)$（块内） + $\mathcal{O}(n/b \cdot d^2)$（块间） = $\mathcal{O}(nd^2)$</p>
<p>推理复杂度：每块$\mathcal{O}(bd^2)$，加上$\mathcal{O}(d^2)$的状态更新。</p>
<p><strong>GPU实现优化</strong>：</p>
<ol>
<li><strong>Kernel融合</strong>：将$\boldsymbol{Q}\boldsymbol{Z}$、$\boldsymbol{V} - \boldsymbol{Q}\boldsymbol{Z}$、标量除法融合为单个kernel。</li>
<li><strong>共享内存</strong>：缓存$\boldsymbol{Z}$到共享内存，减少全局内存访问。</li>
<li><strong>Warp-level优化</strong>：利用tensor core加速$d\times d$矩阵运算（当$d$是8的倍数时）。</li>
</ol>
<p><strong>自动微分（Autograd）</strong>：</p>
<p>反向传播时，需要计算$\frac{\partial \mathcal{L}}{\partial \boldsymbol{Q}}, \frac{\partial \mathcal{L}}{\partial \boldsymbol{K}}, \frac{\partial \mathcal{L}}{\partial \boldsymbol{V}}$。</p>
<p>使用隐式函数定理：<br />
$$\frac{\partial \boldsymbol{Y}}{\partial \boldsymbol{Q}} = -\boldsymbol{T}^{-1}\frac{\partial \boldsymbol{T}}{\partial \boldsymbol{Q}}\boldsymbol{Y}$$</p>
<p>其中$\frac{\partial \boldsymbol{T}}{\partial \boldsymbol{Q}}$是稀疏的（仅下三角非零），可以高效计算。</p>
<p><strong>数值实验验证</strong>：</p>
<p>在$n=10000, d=64$的设置下：<br />
- 朴素LU分解：$\sim$60秒<br />
- 本文方法：$\sim$0.8秒<br />
- 加速比：$75\times$</p>
<p>当$d$增加到128时，本文方法仍保持$\sim$3秒，而LU分解超过200秒。</p>
<h3 id="_7">总结<a class="toc-link" href="#_7" title="Permanent link">&para;</a></h3>
<p>本文的核心创新在于<strong>将Woodbury矩阵恒等式与递归算法相结合</strong>，利用"对角+低秩"结构的三角矩阵的特殊性质，实现了从$\mathcal{O}(n^3)$到$\mathcal{O}(dn^2)$的复杂度降低。关键技术点包括：</p>
<ol>
<li><strong>低秩表示</strong>：$\boldsymbol{T}<em _i_="[i]">{[i,:i]} = \boldsymbol{Q}</em>$}\boldsymbol{K}_{[:i]}^{\top</li>
<li><strong>缓存变量</strong>：$\boldsymbol{Z} = \boldsymbol{K}^{\top}\boldsymbol{T}^{-1}$，避免重复计算</li>
<li><strong>增量更新</strong>：每步只需$\mathcal{O}(d^2)$或$\mathcal{O}(dl)$操作</li>
<li><strong>Chunk并行</strong>：提高缓存效率和GPU利用率</li>
</ol>
<p>这些技术使得线性Attention模型在长序列上的训练和推理成为可能，是现代高效Transformer架构的重要理论基础。</p>
                </div>

                <!-- Previous/Next Navigation -->
                <nav class="post-navigation" aria-label="文章导航">
                    <div class="row g-3">
                        <div class="col-6">
                            
                            <a href="通过msign来计算奇异值裁剪mclip下.html" class="nav-link-prev">
                                <div class="nav-direction"><i class="fas fa-chevron-left"></i> 上一篇</div>
                                <div class="nav-title">#205 通过msign来计算奇异值裁剪mclip（下）</div>
                            </a>
                            
                        </div>
                        <div class="col-6">
                            
                            <a href="transformer升级之路21mla好在哪里下.html" class="nav-link-next">
                                <div class="nav-direction">下一篇 <i class="fas fa-chevron-right"></i></div>
                                <div class="nav-title">#207 Transformer升级之路：21、MLA好在哪里?（下）</div>
                            </a>
                            
                        </div>
                    </div>
                </nav>

                <!-- Back to Home -->
                <div class="text-center mt-4 mb-4">
                    <a href="../index.html" class="btn btn-outline-primary">
                        <i class="fas fa-arrow-left"></i> 返回首页
                    </a>
                </div>
            </div>

            <!-- Sidebar (TOC) -->
            <div class="col-lg-3">
                <aside class="sidebar">
                    
                    <div class="toc-sidebar">
                        <h5 class="toc-title"><i class="fas fa-list"></i> 目录</h5>
                        <div class="toc-content">
                            <div class="toc">
<ul>
<li><a href="#_1">“对角+低秩”三角阵的高效求逆方法</a><ul>
<li><a href="#_2">基本结果</a></li>
<li><a href="#_3">低秩结构</a></li>
<li><a href="#_4">乘法计算</a></li>
<li><a href="#_5">文章小结</a></li>
<li><a href="#_6">公式推导与注释</a><ul>
<li><a href="#1">1. "对角+低秩"矩阵结构的数学表示</a></li>
<li><a href="#2-woodbury">2. Woodbury矩阵恒等式的完整证明</a></li>
<li><a href="#3">3. 三角矩阵的块矩阵求逆递归算法</a></li>
<li><a href="#4">4. 利用低秩结构的优化递归</a></li>
<li><a href="#5-chunk">5. Chunk格式的递归算法</a></li>
<li><a href="#6-boldsymbolt-1boldsymbolv">6. 矩阵-向量乘法$\boldsymbol{T}^{-1}\boldsymbol{V}$的优化算法</a></li>
<li><a href="#7">7. 数值稳定性分析</a></li>
<li><a href="#8-lu">8. 与标准LU分解的对比</a></li>
<li><a href="#9">9. 线性注意力机制中的应用</a></li>
<li><a href="#10">10. 进一步的优化与扩展</a></li>
<li><a href="#_7">总结</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>

                        </div>
                        <div class="toc-actions">
                            <button class="btn btn-sm btn-outline-secondary" onclick="expandAll()">
                                <i class="fas fa-expand"></i> 全部展开
                            </button>
                            <button class="btn btn-sm btn-outline-secondary" onclick="collapseAll()">
                                <i class="fas fa-compress"></i> 全部折叠
                            </button>
                        </div>
                    </div>
                    

                    <!-- Back to Top Button -->
                    <button id="backToTop" class="back-to-top" title="回到顶部">
                        <i class="fas fa-arrow-up"></i>
                    </button>
                </aside>
            </div>
        </div>
    </article>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>
                博客来源: <a href="https://spaces.ac.cn" target="_blank">科学空间</a> |
                内容经过整理并添加详细数学推导
            </p>
            <p>
                Powered by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>
            </p>
        </div>
    </footer>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>

    <!-- Syntax highlighting -->
    <script>hljs.highlightAll();</script>

    <!-- Back to top functionality -->
    <script>
        // Show/hide back to top button based on scroll position
        window.addEventListener('scroll', function() {
            const backToTop = document.getElementById('backToTop');
            if (window.pageYOffset > 300) {
                backToTop.classList.add('show');
            } else {
                backToTop.classList.remove('show');
            }
        });

        // Smooth scroll to top
        document.getElementById('backToTop').addEventListener('click', function() {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        });

        // Sticky TOC sidebar
        window.addEventListener('scroll', function() {
            const sidebar = document.querySelector('.sidebar');
            if (!sidebar) return;

            const sidebarTop = sidebar.offsetTop;
            const scrollTop = window.pageYOffset;

            if (scrollTop > sidebarTop - 20) {
                sidebar.classList.add('sticky');
            } else {
                sidebar.classList.remove('sticky');
            }
        });
    </script>
</body>
</html>