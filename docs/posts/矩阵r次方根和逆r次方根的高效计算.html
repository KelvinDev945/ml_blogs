<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>矩阵r次方根和逆r次方根的高效计算 | ML & Math Blog Posts</title>
    <meta name="description" content="矩阵r次方根和逆r次方根的高效计算&para;
原文链接: https://spaces.ac.cn/archives/11175
发布日期: 

上一篇文章《矩阵平方根和逆平方根的高效计算》中，笔者从$\newcommand{mcsgn}{\mathop{\text{mcsgn}}}\mcsgn$算子出发，提出了一种很漂亮的矩阵平方根和逆平方根的计算方法。比较神奇的是，该方案经过化简之后，最终公...">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css">

    <!-- Google Fonts -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="../assets/css/main.css">
    <link rel="stylesheet" href="../assets/css/post.css">

    <!-- Custom JS -->
    <script src="../assets/js/collapsible.js" defer></script>

    <!-- MathJax for math rendering with equation numbering -->
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true,
        tags: 'ams',  // Enable equation numbering with AMS style
        tagSide: 'right',  // Place equation numbers on the right
        tagIndent: '0.8em',  // Indentation for equation numbers
        multlineWidth: '85%'
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Syntax highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/styles/github.min.css">
    <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/highlight.min.js"></script>
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light bg-light border-bottom">
        <div class="container">
            <a class="navbar-brand" href="../index.html">
                <i class="fas fa-brain"></i> ML & Math Blog
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="../index.html"><i class="fas fa-home"></i> 首页</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Post Content -->
    <article class="container post-container my-5">
        <!-- Breadcrumb Navigation -->
        <nav aria-label="breadcrumb">
            <ol class="breadcrumb">
                <li class="breadcrumb-item"><a href="../index.html"><i class="fas fa-home"></i> 首页</a></li>
                
                <li class="breadcrumb-item"><a href="../index.html?tags=详细推导">详细推导</a></li>
                
                <li class="breadcrumb-item active" aria-current="page">
                    #334 矩阵r次方根和逆r次方根的高效计算
                </li>
            </ol>
        </nav>

        <!-- Post Header -->
        <header class="post-header mb-4">
            <h1 class="post-title">
                <span class="post-number">#334</span>
                矩阵r次方根和逆r次方根的高效计算
            </h1>
            <div class="post-meta">
                <span><i class="far fa-calendar"></i> 2025-07-21</span>
                
            </div>
            
            <div class="post-tags mt-3">
                
                <a href="../index.html?tags=详细推导" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 详细推导</span>
                </a>
                
                <a href="../index.html?tags=代数" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 代数</span>
                </a>
                
                <a href="../index.html?tags=迭代" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 迭代</span>
                </a>
                
                <a href="../index.html?tags=矩阵" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 矩阵</span>
                </a>
                
                <a href="../index.html?tags=线性" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 线性</span>
                </a>
                
                <a href="../index.html?tags=生成模型" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 生成模型</span>
                </a>
                
            </div>
            
        </header>

        <div class="row">
            <!-- Main Content -->
            <div class="col-lg-9">
                <!-- Post Body -->
                <div class="post-content">
                    <h1 id="rr">矩阵r次方根和逆r次方根的高效计算<a class="toc-link" href="#rr" title="Permanent link">&para;</a></h1>
<p><strong>原文链接</strong>: <a href="https://spaces.ac.cn/archives/11175">https://spaces.ac.cn/archives/11175</a></p>
<p><strong>发布日期</strong>: </p>
<hr />
<p>上一篇文章<a href="/archives/11158">《矩阵平方根和逆平方根的高效计算》</a>中，笔者从$\newcommand{mcsgn}{\mathop{\text{mcsgn}}}\mcsgn$算子出发，提出了一种很漂亮的矩阵平方根和逆平方根的计算方法。比较神奇的是，该方案经过化简之后，最终公式已经看不到最初$\mcsgn$形式的样子。这不禁引发了更深层的思考：该方案更本质的工作原理是什么？是否有推广到任意$r$次方根的可能性？</p>
<p>沿着这个角度进行分析后，笔者惊喜地发现，我们可以从一个更简单的角度去理解之前的迭代算法，并且在新角度下可以很轻松推广到任意$r$次方根和逆$r$次方根的计算。接下来我们将分享这一过程。</p>
<h2 id="_1">前情回顾<a class="toc-link" href="#_1" title="Permanent link">&para;</a></h2>
<p>设$\boldsymbol{G}\in\mathbb{R}^{m\times n}$是任意矩阵，$\boldsymbol{P}\in\mathbb{R}^{n\times n}$是任意特征值都在$[0,1]$内的矩阵，上一篇文章给出：<br />
\begin{gather}
\boldsymbol{G}<em t_1="t+1">0 = \boldsymbol{G}, \quad \boldsymbol{P}_0 = \boldsymbol{P} \notag\\[6pt]
\boldsymbol{G}</em>} = \boldsymbol{G<em t_1="t+1">t(a</em>}\boldsymbol{I} + b_{t+1}\boldsymbol{P<em t_1="t+1">t + c</em>}\boldsymbol{P<em t_1="t+1">t^2) \label{eq:r2-rsqrt}\\[6pt]
\boldsymbol{P}</em>} = (a_{t+1}\boldsymbol{I} + b_{t+1}\boldsymbol{P<em t_1="t+1">t + c</em>}\boldsymbol{P<em t_to_infty="t\to\infty">t^2)^2\boldsymbol{P}_t \label{eq:r3-rsqrt}\\[6pt]
\lim</em>} \boldsymbol{G<em t="0">t = \boldsymbol{G}\boldsymbol{P}^{-1/2}\notag
\end{gather}<br />
代入$\boldsymbol{G}=\boldsymbol{P}$就可以求得$\boldsymbol{P}^{1/2}$，代入$\boldsymbol{G}=\boldsymbol{I}$就可以求得$\boldsymbol{P}^{-1/2}$。仔细观察我们就会发现，上述迭代实际上是如下极限的体现：<br />
\begin{equation} \prod</em>}^{\infty}(a_{t+1}\boldsymbol{I} + b_{t+1}\boldsymbol{P<em t_1="t+1">t + c</em>}\boldsymbol{P<em t="0">t^2) = \boldsymbol{P}^{-1/2}\label{eq:prod-rsqrt}\end{equation}<br />
有趣的是，直接证明这个极限并不复杂，直接对式$\eqref{eq:r3-rsqrt}$两边开方，然后代入上式可得<br />
\begin{equation} \prod</em>}^{\infty}(a_{t+1}\boldsymbol{I} + b_{t+1}\boldsymbol{P<em t_1="t+1">t + c</em>}\boldsymbol{P<em t="0">t^2) = \prod</em>}^{\infty} \boldsymbol{P<em t_to_infty="t\to\infty">{t+1}^{1/2}\boldsymbol{P}_t^{-1/2} = \lim</em>} \boldsymbol{P<em t_to_infty="t\to\infty">t^{1/2}\boldsymbol{P}_0^{-1/2} = \lim</em>} \boldsymbol{P}_t^{1/2}\boldsymbol{P}^{-1/2}\end{equation
由此可见，只要序列$\{\boldsymbol{P}_t\}$始终保持可逆，并且最终极限为$\boldsymbol{I}$，那么极限$\eqref{eq:prod-rsqrt}$自动成立。至于迭代$\eqref{eq:r3-rsqrt}$如何让$\{\boldsymbol{P}_t\}$保持这两个条件，我们等会再一起讨论。</p>
<h2 id="_2">一般形式<a class="toc-link" href="#_2" title="Permanent link">&para;</a></h2>
<p>我们不妨一般地考虑迭代<br />
\begin{gather}
\boldsymbol{G}<em t_1="t+1">0 = \boldsymbol{G}, \quad \boldsymbol{P}_0 = \boldsymbol{P} \notag\\[6pt]
\boldsymbol{G}</em>} = \boldsymbol{G<em t_1="t+1">t(a</em>}\boldsymbol{I} + b_{t+1}\boldsymbol{P<em t_1="t+1">t + c</em>}\boldsymbol{P<em t_1="t+1">t^2)^s\\[6pt]
\boldsymbol{P}</em>} = (a_{t+1}\boldsymbol{I} + b_{t+1}\boldsymbol{P<em t_1="t+1">t + c</em>}\boldsymbol{P<em t_to_infty="t\to\infty">t^2)^r\boldsymbol{P}_t
\end{gather}<br />
类似地，如果序列$\{\boldsymbol{P}_t\}$始终保持可逆，并且最终极限为$\boldsymbol{I}$，那么可以证明成立<br />
\begin{equation}\lim</em>} \boldsymbol{G}_t = \boldsymbol{G}\boldsymbol{P}^{-s/r}\end{equation
于是我们就得到了一种求矩阵的任意$-s/r$次幂的通用迭代形式。在这个结果之上，我们只需选择$\boldsymbol{G}=\boldsymbol{P}, s=r-1$，就可以得到$\boldsymbol{P}^{1/r}$了，所以只需要集中精力解决$0\sim 1$次幂的逆就可以了。</p>
<p>这样一来，问题变成了如何选择适当$\{a_t,b_t,c_t\}$，让序列$\{\boldsymbol{P}_t\}$能够尽可能快地收敛到$\boldsymbol{I}$，收敛速度越快，意味着我们可以用越少的迭代步数达到指定精度。</p>
<h2 id="_3">迭代系数<a class="toc-link" href="#_3" title="Permanent link">&para;</a></h2>
<p>根据假设，$\boldsymbol{P}_0 = \boldsymbol{P}$是一个特征值都在$[0,1]$内的矩阵，而目标矩阵$\boldsymbol{I}$则是特征值全为1的矩阵，所以序列$\{\boldsymbol{P}_t\}$实际上就是特征值从任意$[0,1]$内的数变成$1$的过程，这实际上就是$\mcsgn$所做的事情！</p>
<p>我们设$\boldsymbol{X}<em t_1="t+1">t = \boldsymbol{P}_t^{1/r}$，那么$\boldsymbol{X}_0 = \boldsymbol{P}^{1/r}$同样是一个特征值都在$[0,1]$内的矩阵，且迭代方程变为<br />
\begin{equation}\boldsymbol{X}</em>} = a_{t+1}\boldsymbol{X<em t_1="t+1">t + b</em>}\boldsymbol{X<em t_1="t+1">t^{r+1} + c</em>}\boldsymbol{X}_t^{2r+1}\end{equation
现在问题则变成了如何让$\boldsymbol{X}_0$尽可能快地变成$\boldsymbol{I}$，这跟我们在<a href="/archives/10922">《msign算子的Newton-Schulz迭代（上）》</a>和<a href="/archives/10996">《msign算子的Newton-Schulz迭代（下）》</a>所讨论的问题实质是一样的。其中，“<a href="/archives/10996">下篇</a>”给出了$r=2$的理论最优解，但它的求解过程和结论都可以推广到任意$r$的。</p>
<p>具体来说，我们先将问题转化为标量的迭代：<br />
\begin{equation}x_{t+1} = f_t(x_t) = a_{t+1}x_t + b_{t+1}x_t^{r+1} + c_{t+1}x_t^{2r+1}\end{equation}<br />
然后证明贪心解就是最优解，而求贪心解则变成了解方程<br />
\begin{equation}\begin{gathered}
f_t(l_t) = 1 - \mathcal{E}, \quad f_t(u_t) = 1 + \mathcal{E} \\
f_t(x_1) = 1 + \mathcal{E}, \quad f_t(x_2) = 1 - \mathcal{E} \\
f_t'(x_1) = 0, \quad f_t'(x_2) = 0
\end{gathered}\end{equation}<br />
简单起见，将$f_t$参数化为<br />
\begin{equation}f_t'(x) = k(x^r-x_1^r)(x^r-x_2^r)\end{equation}<br />
那么就可以像“<a href="/archives/10996">下篇</a>一样，用Mathematica求解了。</p>
<h2 id="_4">初始分析<a class="toc-link" href="#_4" title="Permanent link">&para;</a></h2>
<p>不过正式求解之前，我们还要分析一下初始化。在上一篇文章<a href="/archives/11158">《矩阵平方根和逆平方根的高效计算》</a>中我们提到，在$\boldsymbol{P}$的特征值均非负的假设下，我们可以通过除以$\newcommand{tr}{\mathop{\text{tr}}}\tr(\boldsymbol{P})$将特征值都压缩到$[0,1]$内。不过这个压缩比例往往过大了，本文我们改为<br />
\begin{equation}\boldsymbol{P}_0 = \frac{\boldsymbol{P}}{\sqrt{\tr(\boldsymbol{P}^2)}}\end{equation}<br />
我们知道，$\tr(\boldsymbol{P}^2)$等于全体特征值的平方和，$\tr(\boldsymbol{P})^2$则等于全体特征值的和平方，在特征值非负时恒成立$\tr(\boldsymbol{P}^2)\leq\tr(\boldsymbol{P})^2$，所以上式提供了一个更紧凑的初始值。特别地，算$\tr(\boldsymbol{P}^2)$并不需要把$\boldsymbol{P}^2$显式计算出来，因为我们有恒等式<br />
\begin{equation}\tr(\boldsymbol{P}^2) = \langle \boldsymbol{P}, \boldsymbol{P}^{\top}\rangle_F\end{equation}</p>
<p>接着，我们还要分析需要处理多小的特征值，这跟<a href="/archives/10922">《msign算子的Newton-Schulz迭代（上）》</a>的初始奇异值分析是一样的。除以$\sqrt{\tr(\boldsymbol{P}^2)}$后，$\boldsymbol{P}_0$的特征值组成一个单位向量，如果特征值全部相等，那么每个特征值是$1/\sqrt{n}$。由鸽笼原理可知一般情况下必然存在小于$1/\sqrt{n}$的特征值，保守起见我们兼容到$0.01/\sqrt{n}$。</p>
<p>考虑到足够大的LLM，$n$已经到了$100^2$这个级别，所以我们需要兼容到$0.0001$。注意这只是$\boldsymbol{P}_0$的特征值，而$\boldsymbol{X}_0 = \boldsymbol{P}_0^{1/r}$，所以$\boldsymbol{X}_0$我们只需要兼容到$0.0001^{1/r}$，这比$\mcsgn$、$\newcommand{msign}{\mathop{\text{msign}}}\msign$的情况要理想一些，因为$\mcsgn$、$\msign$的输入是$\boldsymbol{X}_0$，我们需要兼容$\boldsymbol{X}_0$的小特征值，但这里的输入是$\boldsymbol{P}_0$，我们只需要从$\boldsymbol{P}_0$出发考虑。</p>
<h2 id="_5">计算结果<a class="toc-link" href="#_5" title="Permanent link">&para;</a></h2>
<p>综合上述考虑，我们最终的求解代码如下</p>
<div class="highlight"><pre><span></span><code><span class="n">r</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span>
<span class="n">df</span><span class="o">[</span><span class="n">x_</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">k</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">^</span><span class="n">r</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">x1</span><span class="o">^</span><span class="n">r</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="o">^</span><span class="n">r</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">x2</span><span class="o">^</span><span class="n">r</span><span class="p">);</span>
<span class="n">f</span><span class="o">[</span><span class="n">x_</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Integrate</span><span class="o">[</span><span class="n">df[x</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="err">{</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="err">}]</span><span class="p">;</span>
<span class="n">sol</span><span class="o">[</span><span class="n">l_, u_</span><span class="o">]</span><span class="w"> </span><span class="err">:</span><span class="o">=</span><span class="w"> </span>
<span class="w"> </span><span class="n">NSolve</span><span class="o">[</span><span class="n">{f[l</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">e</span><span class="p">,</span><span class="w"> </span><span class="n">f</span><span class="o">[</span><span class="n">x1</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">e</span><span class="p">,</span><span class="w"> </span><span class="n">f</span><span class="o">[</span><span class="n">x2</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">e</span><span class="p">,</span><span class="w"> </span><span class="n">f</span><span class="o">[</span><span class="n">u</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">e</span><span class="p">,</span>
<span class="w">    </span><span class="n">l</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">x1</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">x2</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">u</span><span class="p">,</span><span class="w"> </span><span class="n">e</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="err">}</span><span class="p">,</span><span class="w"> </span><span class="err">{</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">x2</span><span class="p">,</span><span class="w"> </span><span class="n">e</span><span class="err">}]</span>
<span class="n">ff</span><span class="o">[</span><span class="n">x_, l_, u_</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f</span><span class="o">[</span><span class="n">x</span><span class="o">]*</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">f</span><span class="o">[</span><span class="n">l</span><span class="o">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">f</span><span class="o">[</span><span class="n">u</span><span class="o">]</span><span class="p">)</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">Expand</span><span class="p">;</span>
<span class="n">lt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0001</span><span class="o">^</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">r</span><span class="p">);</span><span class="w"> </span><span class="n">ut</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.1</span><span class="p">;</span>
<span class="k">While</span><span class="o">[</span><span class="n">1 - lt &gt; 0.0001,</span>
<span class="n"> fff[x_</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ff</span><span class="o">[</span><span class="n">x, lt, ut</span><span class="o">]</span><span class="w"> </span><span class="o">/</span><span class="p">.</span><span class="w"> </span><span class="n">sol</span><span class="o">[</span><span class="n">Max[lt, lambda*ut</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">ut</span><span class="err">]</span><span class="o">[</span><span class="n">[1</span><span class="o">]</span><span class="err">]</span><span class="p">;</span>
<span class="w"> </span><span class="k">Print</span><span class="o">[</span><span class="n">fff[x</span><span class="o">]</span><span class="err">]</span><span class="p">;</span>
<span class="w"> </span><span class="n">lt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fff</span><span class="o">[</span><span class="n">lt</span><span class="o">]</span><span class="p">;</span><span class="w"> </span><span class="n">ut</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">lt</span><span class="err">]</span>
<span class="n">f</span><span class="o">[</span><span class="n">x</span><span class="o">]</span><span class="w"> </span><span class="o">/</span><span class="p">.</span><span class="w"> </span><span class="n">Solve</span><span class="o">[</span><span class="n">f[1</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="err">]</span><span class="o">[</span><span class="n">[1</span><span class="o">]</span><span class="err">]</span><span class="w"> </span><span class="o">/</span><span class="p">.</span><span class="w"> </span><span class="err">{</span><span class="n">x1</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">x2</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="mi">1</span><span class="err">}</span>
</code></pre></div>

<p>$r=1\sim 5$的计算结果如下：<br />
\begin{array}{c|ccc}
\hline
r &amp; t &amp; a &amp; b &amp; c \\
\hline
&amp; \quad 1\quad &amp; 14.2975 &amp; -31.2203 &amp; 18.9214 \\
&amp; 2 &amp; 7.12258 &amp; -7.78207 &amp; 2.35989 \\
\quad 1\quad &amp; 3 &amp; 6.9396 &amp; -7.61544 &amp; 2.3195 \\
&amp; 4 &amp; 5.98456 &amp; -6.77016 &amp; 2.12571 \\
&amp; 5 &amp; 3.79109 &amp; -4.18664 &amp; 1.39555 \\
&amp; \geq 6 &amp; 3 &amp; -3 &amp; 1 \\
\hline
&amp; 1 &amp; 7.42487 &amp; -18.3958 &amp; 12.8967 \\
&amp; 2 &amp; 3.48773 &amp; -2.33004 &amp; 0.440469 \\
2 &amp; 3 &amp; 2.77661 &amp; -2.07064 &amp; 0.463023 \\
&amp; 4 &amp; 1.99131 &amp; -1.37394 &amp; 0.387593 \\
&amp; \geq 5 &amp; 15/8 &amp; -5/4 &amp; 3/8 \\
\hline
&amp; 1 &amp; 5.05052 &amp; -13.5427 &amp; 10.2579 \\
&amp; 2 &amp; 2.31728 &amp; -1.06581 &amp; 0.144441 \\
3 &amp; 3 &amp; 1.79293 &amp; -0.913562 &amp; 0.186699 \\
&amp; 4 &amp; 1.56683 &amp; -0.786609 &amp; 0.220008 \\
&amp; \geq 5 &amp; 14/9 &amp; -7/9 &amp; 2/9 \\
\hline
&amp; 1 &amp; 3.85003 &amp; -10.8539 &amp; 8.61893 \\
4 &amp; 2 &amp; 1.80992 &amp; -0.587778 &amp; 0.0647852 \\
&amp; 3 &amp; 1.50394 &amp; -0.594516 &amp; 0.121161 \\
&amp; \geq 4 &amp; 45/32 &amp; -9/16 &amp; 5/32 \\
\hline
&amp; 1 &amp; 3.11194 &amp; -8.28217 &amp; 6.67716 \\
5 &amp; 2 &amp; 1.5752 &amp; -0.393327 &amp; 0.0380364 \\
&amp; 3 &amp; 1.3736 &amp; -0.44661 &amp; 0.0911259 \\
&amp; \geq 4 &amp; 33/25 &amp; -11/25 &amp; 3/25 \\
\hline
\end{array}</p>
<p>其中最后一步的收敛值，由$x_1=x_2=1$和$f(1)=1$得出。</p>
<h2 id="_6">测试一下<a class="toc-link" href="#_6" title="Permanent link">&para;</a></h2>
<p>一个简单的测试代码如下：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>

<span class="n">coefs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="kc">None</span><span class="p">,</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="mf">14.2975</span><span class="p">,</span> <span class="o">-</span><span class="mf">31.2203</span><span class="p">,</span> <span class="mf">18.9214</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">7.12258</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.78207</span><span class="p">,</span> <span class="mf">2.35989</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">6.9396</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.61544</span><span class="p">,</span> <span class="mf">2.3195</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">5.98456</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.77016</span><span class="p">,</span> <span class="mf">2.12571</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">3.79109</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.18664</span><span class="p">,</span> <span class="mf">1.39555</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="mf">7.42487</span><span class="p">,</span> <span class="o">-</span><span class="mf">18.3958</span><span class="p">,</span> <span class="mf">12.8967</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">3.48773</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.33004</span><span class="p">,</span> <span class="mf">0.440469</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">2.77661</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.07064</span><span class="p">,</span> <span class="mf">0.463023</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">1.99131</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.37394</span><span class="p">,</span> <span class="mf">0.387593</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">15</span> <span class="o">/</span> <span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span> <span class="o">/</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span> <span class="o">/</span> <span class="mi">8</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="mf">5.05052</span><span class="p">,</span> <span class="o">-</span><span class="mf">13.5427</span><span class="p">,</span> <span class="mf">10.2579</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">2.31728</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.06581</span><span class="p">,</span> <span class="mf">0.144441</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">1.79293</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.913562</span><span class="p">,</span> <span class="mf">0.186699</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">1.56683</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.786609</span><span class="p">,</span> <span class="mf">0.220008</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">14</span> <span class="o">/</span> <span class="mi">9</span><span class="p">,</span> <span class="o">-</span><span class="mi">7</span> <span class="o">/</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">9</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="mf">3.85003</span><span class="p">,</span> <span class="o">-</span><span class="mf">10.8539</span><span class="p">,</span> <span class="mf">8.61893</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">1.80992</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.587778</span><span class="p">,</span> <span class="mf">0.0647852</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">1.50394</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.594516</span><span class="p">,</span> <span class="mf">0.121161</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">45</span> <span class="o">/</span> <span class="mi">32</span><span class="p">,</span> <span class="o">-</span><span class="mi">9</span> <span class="o">/</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span> <span class="o">/</span> <span class="mi">32</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="mf">3.11194</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.28217</span><span class="p">,</span> <span class="mf">6.67716</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">1.5752</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.393327</span><span class="p">,</span> <span class="mf">0.0380364</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">1.3736</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.44661</span><span class="p">,</span> <span class="mf">0.0911259</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">33</span> <span class="o">/</span> <span class="mi">25</span><span class="p">,</span> <span class="o">-</span><span class="mi">11</span> <span class="o">/</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">3</span> <span class="o">/</span> <span class="mi">25</span><span class="p">),</span>
    <span class="p">],</span>
<span class="p">]</span>

<span class="k">def</span><span class="w"> </span><span class="nf">abc</span><span class="p">(</span><span class="n">r</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">w</span><span class="p">,</span> <span class="n">steps</span> <span class="o">=</span> <span class="n">coefs</span><span class="p">[</span><span class="n">r</span><span class="p">],</span> <span class="n">steps</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">coefs</span><span class="p">[</span><span class="n">r</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">w</span><span class="p">[:</span><span class="n">steps</span><span class="p">]</span> <span class="o">+</span> <span class="n">w</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:]</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="n">steps</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">),</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">yield</span> <span class="n">a</span> <span class="o">/</span> <span class="n">scale</span><span class="p">,</span> <span class="n">b</span> <span class="o">/</span> <span class="n">scale</span><span class="o">**</span><span class="p">(</span><span class="n">r</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">c</span> <span class="o">/</span> <span class="n">scale</span><span class="o">**</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">r</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">matmul_invroot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;return G @ P^(-s/r)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">I</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="kp">eye</span><span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="kp">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="kp">dtype</span><span class="o">=</span><span class="n">P</span><span class="o">.</span><span class="kp">dtype</span><span class="p">)</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">P</span> <span class="o">/</span> <span class="p">(</span><span class="n">t</span> <span class="o">:=</span> <span class="p">(</span><span class="n">P</span> <span class="o">*</span> <span class="n">P</span><span class="o">.</span><span class="n">mT</span><span class="p">)</span><span class="o">.</span><span class="kp">sum</span><span class="p">()</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">I</span>
    <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">abc</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="mf">1.001</span><span class="p">):</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">I</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="n">P</span> <span class="o">+</span> <span class="n">c</span> <span class="o">*</span> <span class="n">P</span> <span class="o">@</span> <span class="n">P</span>
        <span class="n">W1</span><span class="p">,</span> <span class="n">W2</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_power</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">s</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_power</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
        <span class="n">G</span><span class="p">,</span> <span class="n">P</span> <span class="o">=</span> <span class="n">G</span> <span class="o">@</span> <span class="n">W1</span><span class="p">,</span> <span class="n">P</span> <span class="o">@</span> <span class="n">W2</span>
    <span class="k">return</span> <span class="n">G</span> <span class="o">*</span> <span class="n">t</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="n">s</span> <span class="o">/</span> <span class="n">r</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">matmul_invroot_by_eigh</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;return G @ P^(-s/r)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">S</span><span class="p">,</span> <span class="n">Q</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">G</span> <span class="o">@</span> <span class="n">Q</span> <span class="o">@</span> <span class="n">jnp</span><span class="o">.</span><span class="kp">diag</span><span class="p">(</span><span class="n">S</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="n">s</span> <span class="o">/</span> <span class="n">r</span><span class="p">))</span> <span class="o">@</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="kp">inv</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>

<span class="n">d</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">s</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="o">/</span> <span class="n">d</span><span class="o">**</span><span class="mf">0.5</span>
<span class="n">P</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">:=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="o">/</span> <span class="n">d</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">@</span> <span class="n">x</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="mf">0.001</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="kp">eye</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

<span class="n">X1</span> <span class="o">=</span> <span class="n">matmul_invroot_by_eigh</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
<span class="n">X2</span> <span class="o">=</span> <span class="n">matmul_invroot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">jnp</span><span class="o">.</span><span class="kp">abs</span><span class="p">(</span><span class="n">X1</span> <span class="o">-</span> <span class="n">X2</span><span class="p">)</span><span class="o">.</span><span class="kp">mean</span><span class="p">()</span>  <span class="c1"># ~= 1e-3</span>

<span class="n">X2</span> <span class="o">=</span> <span class="n">matmul_invroot</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="kp">array</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="kp">dtype</span><span class="o">=</span><span class="s1">&#39;bfloat16&#39;</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="kp">array</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="kp">dtype</span><span class="o">=</span><span class="s1">&#39;bfloat16&#39;</span><span class="p">),</span> <span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">jnp</span><span class="o">.</span><span class="kp">abs</span><span class="p">(</span><span class="n">X1</span> <span class="o">-</span> <span class="n">X2</span><span class="p">)</span><span class="o">.</span><span class="kp">mean</span><span class="p">()</span>  <span class="c1"># ~= 2e-3</span>
</code></pre></div>

<p>这里有几点注意事项。首先输入$\boldsymbol{P}$的最小特征值不能太小，否则迭代过程极其容易爆炸，哪怕我们只想要求正数次幂如$\boldsymbol{P}^{1/2}$也是如此。这个其实不难理解，因为$\sqrt{x}$在$x=0$处也是比较病态的，一旦由于误差问题“不小心”到了负半轴，那直接就不存在（实数解）了，这时候迭代的表现就无法预估。</p>
<p>多小才不算“太小”呢？大概是$\boldsymbol{P}/\sqrt{\tr(\boldsymbol{P}^2)}$的最小特征值明显不能小于我们考虑的最小特征值，即$0.0001$。如果没法保证这一点，那么建议直接设置<br />
\begin{equation}\boldsymbol{P}_0 = \frac{\boldsymbol{P}}{\sqrt{\tr(\boldsymbol{P}^2)}} + \epsilon \cdot\boldsymbol{I} \end{equation}<br />
其中$\epsilon\sim 0.0001$。这样会损失一点精度，但能够明显增加数值稳定性。</p>
<p>此外，迭代步数在大多数情况下不需要超过推荐值<code>len(coefs[r])</code>，尤其是低精度计算场景，因为迭代步数越多，越容易由于累积误差而爆炸。实际上只要特征值在考虑范围内，推荐步数已经足够达到理想精度了，除非我们用fp32甚至更高精度迭代，那么可以考虑设置$\epsilon=0$、<code>scale=1</code>以及使用更多的迭代步数。</p>
<h2 id="_7">文章小结<a class="toc-link" href="#_7" title="Permanent link">&para;</a></h2>
<p>本文将上一篇文章的结果，推广到任意的$r$次方根和逆$r$次方根的计算，得到了一种矩阵的任意$-1/r$次方的通用迭代格式。</p>
<p><em><strong>转载到请包括本文地址：</strong><a href="https://spaces.ac.cn/archives/11175">https://spaces.ac.cn/archives/11175</a></em></p>
<p><em><strong>更详细的转载事宜请参考：</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="《科学空间FAQ》">《科学空间FAQ》</a></p>
<p><strong>如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。</strong></p>
<p><strong>如果您觉得本文还不错，欢迎分享/打赏本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！</strong></p>
<p>打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>微信打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>支付宝打赏</p>
<p>因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>点击这里</strong></a>或在下方评论区留言来告知你的建议或需求。</p>
<p><strong>如果您需要引用本文，请参考：</strong></p>
<p>苏剑林. (Jul. 21, 2025). 《矩阵r次方根和逆r次方根的高效计算 》[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/11175">https://spaces.ac.cn/archives/11175</a></p>
<p>@online{kexuefm-11175,<br />
title={矩阵r次方根和逆r次方根的高效计算},<br />
author={苏剑林},<br />
year={2025},<br />
month={Jul},<br />
url={\url{https://spaces.ac.cn/archives/11175}},<br />
} </p>
<hr />
<h2 id="_8">公式推导与注释<a class="toc-link" href="#_8" title="Permanent link">&para;</a></h2>
<p>本节对文中的关键算法和理论进行详细的数学推导，包括矩阵r次方根的理论基础、多种迭代算法的推导与收敛性分析、数值稳定性讨论等内容。</p>
<h3 id="1-r">1. 矩阵r次方根的精确定义与理论基础<a class="toc-link" href="#1-r" title="Permanent link">&para;</a></h3>
<h4 id="11">1.1 基于谱分解的定义<a class="toc-link" href="#11" title="Permanent link">&para;</a></h4>
<p>对于对称正定矩阵$\boldsymbol{P}\in\mathbb{R}^{n\times n}$，存在谱分解：
$$\boldsymbol{P} = \boldsymbol{Q}\boldsymbol{\Lambda}\boldsymbol{Q}^{\top}$$
其中$\boldsymbol{Q}$是正交矩阵，$\boldsymbol{\Lambda}=\text{diag}(\lambda_1,\lambda_2,\ldots,\lambda_n)$是由特征值组成的对角矩阵，且$\lambda_i &gt; 0$。</p>
<p>矩阵$\boldsymbol{P}$的$r$次方根定义为：
$$\boldsymbol{P}^{1/r} = \boldsymbol{Q}\boldsymbol{\Lambda}^{1/r}\boldsymbol{Q}^{\top} = \boldsymbol{Q}\text{diag}(\lambda_1^{1/r},\lambda_2^{1/r},\ldots,\lambda_n^{1/r})\boldsymbol{Q}^{\top}$$</p>
<p><strong>唯一性证明</strong>：假设存在另一个对称正定矩阵$\boldsymbol{B}$使得$\boldsymbol{B}^r = \boldsymbol{P}$，则：
$$\boldsymbol{B}^r = \boldsymbol{Q}\boldsymbol{\Lambda}\boldsymbol{Q}^{\top}$$</p>
<p>由于$\boldsymbol{B}$对称正定，可写为$\boldsymbol{B} = \boldsymbol{Q}_B\boldsymbol{\Lambda}_B\boldsymbol{Q}_B^{\top}$，则：
$$\boldsymbol{Q}_B\boldsymbol{\Lambda}_B^r\boldsymbol{Q}_B^{\top} = \boldsymbol{Q}\boldsymbol{\Lambda}\boldsymbol{Q}^{\top}$$</p>
<p>这意味着$\boldsymbol{B}$和$\boldsymbol{P}$有相同的特征空间和满足$\lambda_{B,i}^r = \lambda_i$的特征值，因此$\lambda_{B,i} = \lambda_i^{1/r}$（取正实根），证明了唯一性。</p>
<h4 id="12-jordan">1.2 基于Jordan标准型的推广<a class="toc-link" href="#12-jordan" title="Permanent link">&para;</a></h4>
<p>对于更一般的可对角化矩阵$\boldsymbol{A}\in\mathbb{C}^{n\times n}$，如果存在分解$\boldsymbol{A} = \boldsymbol{V}\boldsymbol{\Lambda}\boldsymbol{V}^{-1}$，其中$\boldsymbol{\Lambda}$是对角矩阵，则：
$$\boldsymbol{A}^{1/r} = \boldsymbol{V}\boldsymbol{\Lambda}^{1/r}\boldsymbol{V}^{-1}$$</p>
<p>对于非对角化矩阵，需要使用Jordan标准型。设$\boldsymbol{A} = \boldsymbol{V}\boldsymbol{J}\boldsymbol{V}^{-1}$，其中$\boldsymbol{J}$是Jordan标准型：
$$\boldsymbol{J} = \begin{bmatrix}\boldsymbol{J}_1 &amp; &amp; \ &amp; \ddots &amp; \ &amp; &amp; \boldsymbol{J}_k\end{bmatrix}, \quad \boldsymbol{J}_i = \begin{bmatrix}\lambda_i &amp; 1 &amp; &amp; \ &amp; \lambda_i &amp; \ddots &amp; \ &amp; &amp; \ddots &amp; 1 \ &amp; &amp; &amp; \lambda_i\end{bmatrix}$$</p>
<p>对于每个Jordan块$\boldsymbol{J}<em k="0">i = \lambda_i\boldsymbol{I} + \boldsymbol{N}$（$\boldsymbol{N}$为幂零矩阵），使用二项式展开：
$$\boldsymbol{J}_i^{1/r} = \lambda_i^{1/r}(\boldsymbol{I} + \lambda_i^{-1}\boldsymbol{N})^{1/r} = \lambda_i^{1/r}\sum</em>^k$$
其中$m$是Jordan块的大小，$\boldsymbol{N}^m = 0$保证了级数的有限性。}^{m-1}\binom{1/r}{k}\lambda_i^{-k}\boldsymbol{N</p>
<h4 id="13">1.3 函数演算视角<a class="toc-link" href="#13" title="Permanent link">&para;</a></h4>
<p>从函数演算（functional calculus）的角度，对于连续函数$f(x) = x^{1/r}$和矩阵$\boldsymbol{P}$：
$$f(\boldsymbol{P}) = \frac{1}{2\pi i}\oint_{\Gamma} f(z)(z\boldsymbol{I}-\boldsymbol{P})^{-1}dz$$
其中$\Gamma$是包含$\boldsymbol{P}$所有特征值的围道。</p>
<p>对于对称正定矩阵，可以简化为：
$$\boldsymbol{P}^{1/r} = \frac{1}{\pi}\int_0^{\infty} \lambda^{1/r-1}(\lambda\boldsymbol{I}+\boldsymbol{P})^{-1}\boldsymbol{P}\,d\lambda$$</p>
<p>这个积分表示为数值积分方法（如Gauss-Legendre积分）提供了理论基础。</p>
<h3 id="2-newton-schulz">2. Newton-Schulz迭代法的详细推导<a class="toc-link" href="#2-newton-schulz" title="Permanent link">&para;</a></h3>
<h4 id="21">2.1 牛顿法的矩阵推广<a class="toc-link" href="#21" title="Permanent link">&para;</a></h4>
<p>考虑方程$\boldsymbol{X}^r = \boldsymbol{P}$，目标是求解$\boldsymbol{X} = \boldsymbol{P}^{1/r}$。定义算子方程：
$$F(\boldsymbol{X}) = \boldsymbol{X}^r - \boldsymbol{P} = 0$$</p>
<p>牛顿法的迭代格式为：
$$\boldsymbol{X}_{k+1} = \boldsymbol{X}_k - [DF(\boldsymbol{X}_k)]^{-1}F(\boldsymbol{X}_k)$$</p>
<p>计算Fréchet导数$DF(\boldsymbol{X})[\boldsymbol{H}]$：
$$DF(\boldsymbol{X})[\boldsymbol{H}] = \lim_{\epsilon\to 0}\frac{(\boldsymbol{X}+\epsilon\boldsymbol{H})^r - \boldsymbol{X}^r}{\epsilon}$$</p>
<p>对于$r=2$的情况：
$$DF(\boldsymbol{X})[\boldsymbol{H}] = \boldsymbol{X}\boldsymbol{H} + \boldsymbol{H}\boldsymbol{X}$$</p>
<p>一般情况下，利用二项式定理：
$$(\boldsymbol{X}+\epsilon\boldsymbol{H})^r = \sum_{j=0}^{r}\binom{r}{j}\boldsymbol{X}^{r-j}(\epsilon\boldsymbol{H})^j$$</p>
<p>因此：
$$DF(\boldsymbol{X})[\boldsymbol{H}] = \sum_{j=1}^{r}\binom{r}{j}\sum_{p_1+\cdots+p_j=r-j}\boldsymbol{X}^{p_1}\boldsymbol{H}\boldsymbol{X}^{p_2}\cdots\boldsymbol{H}\boldsymbol{X}^{p_{j+1}}$$</p>
<p>其中求和遍历所有满足$p_1+\cdots+p_{j+1}=r-j$的非负整数组合。</p>
<h4 id="22-schulz">2.2 Schulz迭代的引入<a class="toc-link" href="#22-schulz" title="Permanent link">&para;</a></h4>
<p>直接求解$DF(\boldsymbol{X})[\boldsymbol{H}] = -F(\boldsymbol{X})$计算量很大。Schulz迭代通过考虑逆矩阵的计算来简化。</p>
<p>对于$\boldsymbol{Y} = \boldsymbol{X}^{-1}$，我们有$\boldsymbol{Y}^{-r} = \boldsymbol{P}$，等价于$\boldsymbol{P}\boldsymbol{Y}^r = \boldsymbol{I}$。</p>
<p>定义$\boldsymbol{Z}<em k_1="k+1">k = \boldsymbol{P}\boldsymbol{Y}_k^r$，目标是让$\boldsymbol{Z}_k\to\boldsymbol{I}$。当$\boldsymbol{Z}_k\approx\boldsymbol{I}$时，可以用泰勒展开：
$$\boldsymbol{Y}</em>$$} = \boldsymbol{Y}_k(2\boldsymbol{I}-\boldsymbol{Z}_k) \quad \text{(对于}r=1\text{的情况)</p>
<p>对于一般的$r$次方根，Newton-Schulz迭代格式为：
$$\boldsymbol{X}_{k+1} = \boldsymbol{X}_k + \frac{1}{r}\boldsymbol{X}_k(\boldsymbol{I}-\boldsymbol{X}_k^r\boldsymbol{P}^{-1})$$</p>
<p>当$\boldsymbol{P}$不易求逆时，改用逆r次方根的形式：
$$\boldsymbol{Y}_{k+1} = \boldsymbol{Y}_k\left[a\boldsymbol{I} + b(\boldsymbol{P}\boldsymbol{Y}_k^r) + c(\boldsymbol{P}\boldsymbol{Y}_k^r)^2\right]$$</p>
<p>这正是文中提出的迭代格式的理论基础。</p>
<h4 id="23">2.3 迭代的局部收敛性<a class="toc-link" href="#23" title="Permanent link">&para;</a></h4>
<p>设$\boldsymbol{X}^<em> = \boldsymbol{P}^{1/r}$，令$\boldsymbol{E}_k = \boldsymbol{X}_k - \boldsymbol{X}^</em>$。展开迭代式：
$$\boldsymbol{X}_{k+1} = \boldsymbol{X}_k + \frac{1}{r}\boldsymbol{X}_k(\boldsymbol{I}-\boldsymbol{X}_k^r\boldsymbol{P}^{-1})$$</p>
<p>代入$\boldsymbol{X}<em k_1="k+1">k = \boldsymbol{X}^<em> + \boldsymbol{E}_k$：
$$\boldsymbol{X}^</em> + \boldsymbol{E}</em>^} = \boldsymbol{X<em> + \boldsymbol{E}_k + \frac{1}{r}(\boldsymbol{X}^</em>+\boldsymbol{E}_k)\left[\boldsymbol{I} - (\boldsymbol{X}^<em>+\boldsymbol{E}_k)^r(\boldsymbol{X}^</em>)^{-r}\right]$$</p>
<p>注意到$(\boldsymbol{X}^<em>)^r = \boldsymbol{P}$，设$\boldsymbol{\Delta}_k = \boldsymbol{X}^{</em>-1}\boldsymbol{E}<em k_1="k+1">k$为相对误差，则：
$$\boldsymbol{E}</em>_k)^r\right]$$} = \boldsymbol{E}_k + \frac{1}{r}(\boldsymbol{X}^*+\boldsymbol{E}_k)\left[\boldsymbol{I} - (\boldsymbol{I}+\boldsymbol{\Delta</p>
<p>利用二项式展开$(\boldsymbol{I}+\boldsymbol{\Delta}<em k_1="k+1">k)^r = \boldsymbol{I} + r\boldsymbol{\Delta}_k + O(|\boldsymbol{\Delta}_k|^2)$：
$$\boldsymbol{E}</em>^} = \frac{1}{r}(\boldsymbol{X<em>+\boldsymbol{E}_k)\left[-r\boldsymbol{\Delta}_k + O(|\boldsymbol{\Delta}_k|^2)\right] = -(\boldsymbol{X}^</em>+\boldsymbol{E}_k)\boldsymbol{\Delta}_k + O(|\boldsymbol{E}_k|^2)$$</p>
<p>简化得：
$$\boldsymbol{E}_{k+1} = -\boldsymbol{X}^*\boldsymbol{\Delta}_k - \boldsymbol{E}_k\boldsymbol{\Delta}_k + O(|\boldsymbol{E}_k|^2) = O(|\boldsymbol{E}_k|^2)$$</p>
<p>这证明了牛顿法具有<strong>二次收敛性</strong>。</p>
<h3 id="3">3. 基于多项式逼近的迭代方法<a class="toc-link" href="#3" title="Permanent link">&para;</a></h3>
<h4 id="31-pade">3.1 Padé逼近的数学基础<a class="toc-link" href="#31-pade" title="Permanent link">&para;</a></h4>
<p>Padé逼近是用有理函数$R_{m,n}(x) = P_m(x)/Q_n(x)$来逼近给定函数$f(x)$，其中$P_m$和$Q_n$分别是$m$次和$n$次多项式。</p>
<p>对于函数$f(x) = (1+x)^{1/r}$在$x=0$附近的Padé逼近$[m/n]$，满足：
$$f(x) - R_{m,n}(x) = O(x^{m+n+1})$$</p>
<p><strong>构造方法</strong>：设$f(x) = \sum_{k=0}^{\infty}c_kx^k$是泰勒级数，要求：
$$P_m(x) = Q_n(x)f(x) + O(x^{m+n+1})$$</p>
<p>这给出$(m+n+1)$个线性方程来确定$P_m$和$Q_n$的系数。</p>
<p>对于$f(x) = (1+x)^{1/r}$，前几项系数为：
$$c_0 = 1, \quad c_1 = \frac{1}{r}, \quad c_2 = \frac{1}{r}\cdot\frac{1-r}{2r}, \quad c_3 = \frac{1}{r}\cdot\frac{1-r}{2r}\cdot\frac{1-2r}{3r}$$</p>
<h4 id="32-22-pade">3.2 [2/2] Padé逼近的显式构造<a class="toc-link" href="#32-22-pade" title="Permanent link">&para;</a></h4>
<p>对于$r=2$的情况，构造$[2/2]$ Padé逼近：
$$R_{2,2}(x) = \frac{a_0 + a_1x + a_2x^2}{b_0 + b_1x + b_2x^2}$$</p>
<p>匹配$f(x) = \sqrt{1+x}$的前5项泰勒展开：
$$f(x) = 1 + \frac{1}{2}x - \frac{1}{8}x^2 + \frac{1}{16}x^3 - \frac{5}{128}x^4 + O(x^5)$$</p>
<p>通过匹配系数得到方程组。归一化$b_0=1$，求解得：
$$R_{2,2}(x) = \frac{1 + \frac{3}{4}x + \frac{1}{8}x^2}{1 + \frac{1}{4}x}$$</p>
<p>应用到矩阵情况，设$\boldsymbol{E}<em 2_2="2,2">k = \boldsymbol{I} - \boldsymbol{P}_k$（其中$\boldsymbol{P}_k$是归一化矩阵），则：
$$\boldsymbol{P}_k^{1/2} \approx (\boldsymbol{I}-\boldsymbol{E}_k)^{1/2} \approx R</em>_k)$$}(-\boldsymbol{E</p>
<h4 id="33-r">3.3 一般r次方根的多项式逼近<a class="toc-link" href="#33-r" title="Permanent link">&para;</a></h4>
<p>对于一般的$r$次方根，考虑函数$g(x) = x^{1/r}$在$x=1$附近的逼近。设$\boldsymbol{P}<em _min="\min">k$的特征值在$[\lambda</em>]$内，定义：
$$\phi(x) = \left(\frac{x-\lambda_{\min}}{\lambda_{\max}-\lambda_{\min}}\right)^{1/r}$$}, \lambda_{\max</p>
<p>构造多项式$p_d(x)$使得：
$$\max_{x\in[\lambda_{\min},\lambda_{\max}]}|p_d(x) - \phi(x)| \to 0, \quad d\to\infty$$</p>
<p>利用<strong>Chebyshev逼近</strong>可以获得最优的逼近多项式。Chebyshev多项式$T_n(x)$在$[-1,1]$上定义为：
$$T_n(\cos\theta) = \cos(n\theta)$$</p>
<p>在区间$[a,b]$上，通过线性变换$x = \frac{b-a}{2}t + \frac{a+b}{2}$转换到$[-1,1]$，然后使用Chebyshev展开：
$$f(x) \approx \sum_{k=0}^{d}c_kT_k(t)$$</p>
<p>其中系数：
$$c_k = \frac{2}{\pi}\int_{-1}^{1}\frac{f(x(t))T_k(t)}{\sqrt{1-t^2}}dt$$</p>
<h4 id="34">3.4 迭代的多项式形式<a class="toc-link" href="#34" title="Permanent link">&para;</a></h4>
<p>文中的迭代格式：
$$\boldsymbol{P}<em t_1="t+1">{t+1} = (a</em>}\boldsymbol{I} + b_{t+1}\boldsymbol{P<em t_1="t+1">t + c</em>_t$$}\boldsymbol{P}_t^2)^r\boldsymbol{P</p>
<p>可以理解为对$\boldsymbol{X}<em t_1="t+1">t = \boldsymbol{P}_t^{1/r}$进行多项式变换：
$$\boldsymbol{X}</em>} = p_t(\boldsymbol{X<em t_1="t+1">t) = a</em>}\boldsymbol{X<em t_1="t+1">t + b</em>}\boldsymbol{X<em t_1="t+1">t^{r+1} + c</em>$$}\boldsymbol{X}_t^{2r+1</p>
<p>这个多项式的设计目标是将特征值从$[\lambda_{\min}, \lambda_{\max}]$映射到更接近$1$的区间。</p>
<p><strong>最优系数选择</strong>：对于标量函数$f_t(x) = a_{t+1}x + b_{t+1}x^{r+1} + c_{t+1}x^{2r+1}$，我们要求：
$$f_t(l_t) = 1-\epsilon, \quad f_t(u_t) = 1+\epsilon$$</p>
<p>并且$f_t$在$(l_t, u_t)$内有两个驻点$x_1, x_2$满足：
$$f_t(x_1) = 1+\epsilon, \quad f_t(x_2) = 1-\epsilon$$</p>
<p>这保证了$f_t$将区间$[l_t, u_t]$映射到$[1-\epsilon, 1+\epsilon]$，实现了区间的收缩。</p>
<h3 id="4-denman-beavers">4. Denman-Beavers迭代的推导<a class="toc-link" href="#4-denman-beavers" title="Permanent link">&para;</a></h3>
<h4 id="41">4.1 基本思想<a class="toc-link" href="#41" title="Permanent link">&para;</a></h4>
<p>Denman-Beavers迭代是一种同时计算矩阵的逆r次方根及其逆的耦合迭代方法。定义：
$$\boldsymbol{Y}_k \to \boldsymbol{P}^{-1/r}, \quad \boldsymbol{Z}_k \to \boldsymbol{P}^{1/r}$$</p>
<p>基本迭代格式为：
\begin{align}
\boldsymbol{Y}<em k_1="k+1">{k+1} &amp;= \frac{1}{2}\boldsymbol{Y}_k(3\boldsymbol{I} - \boldsymbol{Z}_k\boldsymbol{Y}_k) \
\boldsymbol{Z}</em>_k
\end{align}} &amp;= \frac{1}{2}(3\boldsymbol{I} - \boldsymbol{Z}_k\boldsymbol{Y}_k)\boldsymbol{Z</p>
<p>初始化：$\boldsymbol{Y}_0 = \alpha\boldsymbol{I}$，$\boldsymbol{Z}_0 = \alpha^{-1}\boldsymbol{P}$，其中$\alpha$需要选择使得$\boldsymbol{P}/\alpha^r$的特征值接近$1$。</p>
<h4 id="42">4.2 不变量分析<a class="toc-link" href="#42" title="Permanent link">&para;</a></h4>
<p>定义乘积不变量：
$$\boldsymbol{M}_k = \boldsymbol{Z}_k\boldsymbol{Y}_k$$</p>
<p>计算：
\begin{align}
\boldsymbol{M}<em k_1="k+1">{k+1} &amp;= \boldsymbol{Z}</em> \
&amp;= \frac{1}{2}(3\boldsymbol{I} - \boldsymbol{Z}_k\boldsymbol{Y}_k)\boldsymbol{Z}_k \cdot \frac{1}{2}\boldsymbol{Y}_k(3\boldsymbol{I} - \boldsymbol{Z}_k\boldsymbol{Y}_k) \
&amp;= \frac{1}{4}(3\boldsymbol{I} - \boldsymbol{M}_k)\boldsymbol{M}_k(3\boldsymbol{I} - \boldsymbol{M}_k) \
&amp;= \frac{1}{4}(9\boldsymbol{M}_k - 6\boldsymbol{M}_k^2 + \boldsymbol{M}_k^3)
\end{align}}\boldsymbol{Y}_{k+1</p>
<p>这不是严格的不变量，但可以分析其收敛性。</p>
<p>定义另一个不变量：
$$\boldsymbol{S}_k = \boldsymbol{Z}_k^r\boldsymbol{Y}_k^r$$</p>
<p><strong>命题</strong>：如果迭代格式满足$\boldsymbol{Z}<em k_1="k+1">{k+1} = \phi(\boldsymbol{M}_k)\boldsymbol{Z}_k$，$\boldsymbol{Y}</em>} = \boldsymbol{Y<em k_1="k+1">k\phi(\boldsymbol{M}_k)$，其中$\phi$是多项式且$\phi(x)^r = p(x)$，则：
$$\boldsymbol{S}</em>} = \boldsymbol{Z<em k_1="k+1">{k+1}^r\boldsymbol{Y}</em>_k)$$}^r = p(\boldsymbol{M}_k)\boldsymbol{Z}_k^r\boldsymbol{Y}_k^r p(\boldsymbol{M}_k) = p(\boldsymbol{M}_k)\boldsymbol{S}_k p(\boldsymbol{M</p>
<p>如果选择$p(x)$使得$p(1)=1$且$p(\boldsymbol{M}_k)\to\boldsymbol{I}$，则$\boldsymbol{S}_k\to\boldsymbol{S}_0 = \boldsymbol{P}$。</p>
<h4 id="43">4.3 收敛性分析<a class="toc-link" href="#43" title="Permanent link">&para;</a></h4>
<p>设$\boldsymbol{M}<em k_1="k+1">k = \boldsymbol{I} + \boldsymbol{E}_k$，其中$|\boldsymbol{E}_k|$很小。对于标量情况，$m_k = 1+e_k$：
$$m</em>m_k(3-m_k)^2$$} = \frac{1}{4}(9m_k - 6m_k^2 + m_k^3) = \frac{1}{4</p>
<p>代入$m_k = 1+e_k$：
\begin{align}
m_{k+1} &amp;= \frac{1}{4}(1+e_k)(3-1-e_k)^2 \
&amp;= \frac{1}{4}(1+e_k)(2-e_k)^2 \
&amp;= \frac{1}{4}(1+e_k)(4-4e_k+e_k^2) \
&amp;= 1 + \frac{1}{4}(-3e_k^2 + e_k^3)
\end{align}</p>
<p>因此：
$$e_{k+1} = -\frac{3}{4}e_k^2 + O(e_k^3)$$</p>
<p>这表明迭代具有<strong>二次收敛性</strong>，误差每步减少至平方级别。</p>
<h4 id="44-r">4.4 推广到r次方根<a class="toc-link" href="#44-r" title="Permanent link">&para;</a></h4>
<p>对于一般的r次方根，Denman-Beavers型迭代可以写为：
\begin{align}
\boldsymbol{Y}<em k_1="k+1">{k+1} &amp;= \boldsymbol{Y}_k p_r(\boldsymbol{M}_k) \
\boldsymbol{Z}</em>_k
\end{align}} &amp;= p_r(\boldsymbol{M}_k)\boldsymbol{Z</p>
<p>其中$p_r(x)$是设计的多项式，满足$p_r(1)=1$且使得$x\to 1$时$p_r(x)\approx 1$。</p>
<p>一个简单的选择是：
$$p_r(x) = \frac{1}{2r}[(r+1) + (r-1)x]$$</p>
<p>对应的迭代为：
\begin{align}
\boldsymbol{Y}<em k_1="k+1">{k+1} &amp;= \frac{1}{2r}\boldsymbol{Y}_k[(r+1)\boldsymbol{I} + (r-1)\boldsymbol{M}_k] \
\boldsymbol{Z}</em>_k
\end{align}} &amp;= \frac{1}{2r}[(r+1)\boldsymbol{I} + (r-1)\boldsymbol{M}_k]\boldsymbol{Z</p>
<h3 id="5">5. 收敛速度分析<a class="toc-link" href="#5" title="Permanent link">&para;</a></h3>
<h4 id="51">5.1 线性收敛<a class="toc-link" href="#51" title="Permanent link">&para;</a></h4>
<p>最简单的迭代是一阶定点迭代：
$$\boldsymbol{X}_{k+1} = g(\boldsymbol{X}_k)$$</p>
<p>如果$|Dg(\boldsymbol{X}^<em>)| = \rho &lt; 1$，则迭代线性收敛，满足：
$$|\boldsymbol{X}_{k+1} - \boldsymbol{X}^</em>| \leq \rho|\boldsymbol{X}_k - \boldsymbol{X}^*|$$</p>
<p><strong>收敛步数估计</strong>：要达到误差$\epsilon$，需要：
$$k \geq \frac{\log(\epsilon/|\boldsymbol{X}_0-\boldsymbol{X}^*|)}{\log\rho}$$</p>
<h4 id="52">5.2 二次收敛（牛顿法）<a class="toc-link" href="#52" title="Permanent link">&para;</a></h4>
<p>牛顿法满足：
$$|\boldsymbol{X}_{k+1} - \boldsymbol{X}^<em>| \leq C|\boldsymbol{X}_k - \boldsymbol{X}^</em>|^2$$</p>
<p>这意味着有效数字每步翻倍：
$$-\log_{10}|\boldsymbol{E}<em 10="10">{k+1}| \approx 2 \times (-\log</em>_k|)$$}|\boldsymbol{E</p>
<p><strong>收敛步数估计</strong>：设初始误差为$e_0$，目标误差为$\epsilon$，则：
$$k \approx \log_2\log\frac{e_0}{\epsilon}$$</p>
<p>例如，从$e_0=10^{-2}$到$\epsilon=10^{-16}$，只需：
$$k \approx \log_2(16-2) = \log_2(14) \approx 3.8 \approx 4\text{步}$$</p>
<h4 id="53">5.3 高阶收敛<a class="toc-link" href="#53" title="Permanent link">&para;</a></h4>
<p>文中提出的迭代方法通过优化多项式系数，可以达到更高阶的收敛。对于迭代：
$$x_{k+1} = f(x_k) = ax_k + bx_k^{r+1} + cx_k^{2r+1}$$</p>
<p>在$x^*=1$附近展开：
$$f(x) = f(1) + f'(1)(x-1) + \frac{f''(1)}{2}(x-1)^2 + \frac{f^{(3)}(1)}{6}(x-1)^3 + \cdots$$</p>
<p>为了达到高阶收敛，我们要求：
$$f(1) = 1, \quad f'(1) = 1, \quad f''(1) = 0, \quad \cdots$$</p>
<p>计算导数：
\begin{align}
f'(x) &amp;= a + b(r+1)x^r + c(2r+1)x^{2r} \
f''(x) &amp;= br(r+1)x^{r-1} + c(2r)(2r+1)x^{2r-1}
\end{align}</p>
<p>在$x=1$处：
\begin{align}
f(1) &amp;= a + b + c = 1 \
f'(1) &amp;= a + b(r+1) + c(2r+1) = 1 \
f''(1) &amp;= br(r+1) + c(2r)(2r+1) = 0
\end{align}</p>
<p>从第三个方程得：
$$c = -\frac{br(r+1)}{2r(2r+1)}$$</p>
<p>这给出了系数之间的约束关系。通过进一步的优化（如文中的极值点条件），可以确定具体的系数值。</p>
<p><strong>收敛阶估计</strong>：如果满足$f^{(j)}(1)=0$对所有$j=1,2,\ldots,p-1$，则收敛阶至少为$p$：
$$|e_{k+1}| \leq C|e_k|^p$$</p>
<h3 id="6">6. 数值稳定性分析<a class="toc-link" href="#6" title="Permanent link">&para;</a></h3>
<h4 id="61">6.1 条件数的影响<a class="toc-link" href="#61" title="Permanent link">&para;</a></h4>
<p>矩阵$\boldsymbol{P}$的条件数定义为：
$$\kappa(\boldsymbol{P}) = |\boldsymbol{P}||\boldsymbol{P}^{-1}| = \frac{\lambda_{\max}}{\lambda_{\min}}$$</p>
<p>对于r次方根计算，条件数变为：
$$\kappa(\boldsymbol{P}^{1/r}) = \left(\frac{\lambda_{\max}}{\lambda_{\min}}\right)^{1/r} = \kappa(\boldsymbol{P})^{1/r}$$</p>
<p>这意味着计算r次方根实际上改善了条件数，这是一个有利因素。</p>
<p>然而，迭代过程的稳定性还取决于每步的局部条件数。定义迭代函数的条件数：
$$\kappa_k = \frac{|Df(\boldsymbol{X}<em k_1="k+1">k)||\boldsymbol{X}</em>$$}|}{|\boldsymbol{X}_k|</p>
<h4 id="62">6.2 舍入误差的累积<a class="toc-link" href="#62" title="Permanent link">&para;</a></h4>
<p>在浮点运算中，每步迭代引入舍入误差$\boldsymbol{\delta}<em k_1="k+1">k$：
$$\tilde{\boldsymbol{X}}</em>_k$$} = f(\tilde{\boldsymbol{X}}_k) + \boldsymbol{\delta</p>
<p>其中$|\boldsymbol{\delta}<em k_1="k+1">k| \leq u|\boldsymbol{X}</em>$）。}|$，$u$是机器精度（如单精度$u\approx 10^{-7}$，双精度$u\approx 10^{-16</p>
<p>误差传播满足：
$$\tilde{\boldsymbol{E}}_{k+1} = Df(\boldsymbol{X}_k)\tilde{\boldsymbol{E}}_k + \boldsymbol{\delta}_k$$</p>
<p>累积误差界为：
$$|\tilde{\boldsymbol{E}}<em j="0">k| \leq \prod</em>}^{k-1}|Df(\boldsymbol{X<em j="0">j)||\tilde{\boldsymbol{E}}_0| + \sum</em>_j|$$}^{k-1}\left(\prod_{i=j+1}^{k-1}|Df(\boldsymbol{X}_i)|\right)|\boldsymbol{\delta</p>
<p>对于二次收敛的方法，$|Df(\boldsymbol{X}_k)| \approx 2|\boldsymbol{E}_k|$在靠近收敛时趋于$0$，因此累积误差项逐渐减小。</p>
<h4 id="63">6.3 小特征值的处理<a class="toc-link" href="#63" title="Permanent link">&para;</a></h4>
<p>当$\boldsymbol{P}$有非常小的特征值$\lambda_{\min}$时，$\boldsymbol{P}^{-1/r}$会有非常大的特征值$\lambda_{\min}^{-1/r}$，这导致数值不稳定。</p>
<p>文中提出的解决方案是正则化：
$$\boldsymbol{P}_0 = \frac{\boldsymbol{P}}{\sqrt{\tr(\boldsymbol{P}^2)}} + \epsilon\boldsymbol{I}$$</p>
<p><strong>正则化效果分析</strong>：设$\boldsymbol{P} = \boldsymbol{Q}\text{diag}(\lambda_1,\ldots,\lambda_n)\boldsymbol{Q}^{\top}$，则：
$$\boldsymbol{P}_0 = \boldsymbol{Q}\text{diag}\left(\frac{\lambda_1}{\sqrt{\sum\lambda_i^2}}+\epsilon, \ldots, \frac{\lambda_n}{\sqrt{\sum\lambda_i^2}}+\epsilon\right)\boldsymbol{Q}^{\top}$$</p>
<p>最小特征值变为：
$$\lambda_{\min}(\boldsymbol{P}_0) \geq \epsilon$$</p>
<p>这确保了条件数的上界：
$$\kappa(\boldsymbol{P}_0) \leq \frac{1+\epsilon}{\epsilon}$$</p>
<h4 id="64">6.4 向后误差分析<a class="toc-link" href="#64" title="Permanent link">&para;</a></h4>
<p>设计算得到的$\tilde{\boldsymbol{Y}} \approx \boldsymbol{P}^{-1/r}$，定义相对残差：
$$\text{relres} = \frac{|\boldsymbol{P}\tilde{\boldsymbol{Y}}^r - \boldsymbol{I}|_F}{|\boldsymbol{P}|_F}$$</p>
<p>向后稳定的算法保证：
$$\tilde{\boldsymbol{Y}}^r = (\boldsymbol{P}+\boldsymbol{\Delta P})^{-1}$$
其中$|\boldsymbol{\Delta P}| \leq O(u)|\boldsymbol{P}|$。</p>
<p>对于文中的迭代算法，每步的局部向后误差为$O(u)$，经过$k$步后，累积向后误差为$O(ku)$，在迭代步数不太多时（如$k\leq 10$）仍然保持良好的向后稳定性。</p>
<h3 id="7">7. 不同条件数下的误差界<a class="toc-link" href="#7" title="Permanent link">&para;</a></h3>
<h4 id="71">7.1 理论误差界<a class="toc-link" href="#71" title="Permanent link">&para;</a></h4>
<p>对于条件数为$\kappa$的矩阵$\boldsymbol{P}$，计算$\boldsymbol{P}^{1/r}$的相对误差满足：
$$\frac{|\boldsymbol{P}^{1/r} - \tilde{\boldsymbol{P}}^{1/r}|}{|\boldsymbol{P}^{1/r}|} \leq \frac{1}{r}\kappa(\boldsymbol{P}^{1/r})\frac{|\boldsymbol{\Delta P}|}{|\boldsymbol{P}|} = \frac{1}{r}\kappa^{1/r}\frac{|\boldsymbol{\Delta P}|}{|\boldsymbol{P}|}$$</p>
<p>这表明误差界随$r$增大而减小，这是r次方根计算的一个优势。</p>
<h4 id="72">7.2 不同条件数的数值实验<a class="toc-link" href="#72" title="Permanent link">&para;</a></h4>
<p>考虑不同条件数$\kappa = 10, 10^2, 10^3, 10^4$的情况：</p>
<p><strong>Case 1</strong>: $\kappa = 10$
- 理论误差界：$\frac{1}{r}\kappa^{1/r}u \approx \frac{10^{1/r}}{r}u$
- 对于$r=2$：$\approx 1.58u$
- 对于$r=4$：$\approx 0.44u$</p>
<p><strong>Case 2</strong>: $\kappa = 10^4$
- 理论误差界：$\frac{1}{r}(10^4)^{1/r}u$
- 对于$r=2$：$\approx 50u$
- 对于$r=4$：$\approx 2.5u$</p>
<p>这说明即使对于病态矩阵，r次方根的计算仍然比直接求逆稳定得多。</p>
<h4 id="73">7.3 特征值分布的影响<a class="toc-link" href="#73" title="Permanent link">&para;</a></h4>
<p>特征值的分布也影响收敛速度。定义谱比：
$$\rho = \frac{\lambda_{\max} - \lambda_{\min}}{\lambda_{\max} + \lambda_{\min}}$$</p>
<p>收敛速度与$\rho$相关：
$$|\boldsymbol{E}_k| \leq C\rho^{2^k}|\boldsymbol{E}_0|$$</p>
<p>对于谱半径接近的情况（$\rho\to 0$），收敛非常快；对于谱分布很宽的情况（$\rho\to 1$），需要更多迭代步数。</p>
<h3 id="8">8. 初始化策略的比较<a class="toc-link" href="#8" title="Permanent link">&para;</a></h3>
<h4 id="81">8.1 策略一：基于迹的缩放<a class="toc-link" href="#81" title="Permanent link">&para;</a></h4>
<p>$$\alpha_1 = \frac{1}{\tr(\boldsymbol{P})}$$</p>
<p><strong>优点</strong>：计算简单，只需$O(n)$时间。
<strong>缺点</strong>：可能过度缩放，特别是当特征值分布不均匀时。</p>
<p><strong>分析</strong>：设$\lambda_i$是特征值，则$\tr(\boldsymbol{P}) = \sum_{i=1}^n\lambda_i$。缩放后的特征值为$\lambda_i/\sum_j\lambda_j$。如果一个特征值特别大，其他都很小，则小特征值会被过度缩小。</p>
<h4 id="82-frobenius">8.2 策略二：基于Frobenius范数的缩放<a class="toc-link" href="#82-frobenius" title="Permanent link">&para;</a></h4>
<p>$$\alpha_2 = \frac{1}{\sqrt{\tr(\boldsymbol{P}^2)}} = \frac{1}{|\boldsymbol{P}|_F}$$</p>
<p><strong>优点</strong>：更平衡，缩放后的特征值形成单位向量（在$\ell^2$意义下）。
<strong>缺点</strong>：需要计算$\tr(\boldsymbol{P}^2)$，但可以用$\langle\boldsymbol{P},\boldsymbol{P}^{\top}\rangle_F$高效计算。</p>
<p><strong>分析</strong>：缩放后$\sum_{i=1}^n(\lambda_i/\alpha_2)^2 = 1$，保证了特征值的$\ell^2$范数为$1$，这比迹缩放更紧。</p>
<h4 id="83">8.3 策略三：基于谱半径的缩放<a class="toc-link" href="#83" title="Permanent link">&para;</a></h4>
<p>$$\alpha_3 = \rho(\boldsymbol{P}) = \max_i|\lambda_i|$$</p>
<p><strong>优点</strong>：保证所有特征值在$[-1,1]$内，理论上最优。
<strong>缺点</strong>：计算谱半径需要$O(n^3)$时间（幂迭代或特征值分解），与直接求方根的复杂度相当。</p>
<p><strong>分析</strong>：这是理想的缩放，但计算代价太高，实际不可行。</p>
<h4 id="84">8.4 策略四：自适应缩放<a class="toc-link" href="#84" title="Permanent link">&para;</a></h4>
<p>结合前两种策略，使用：
$$\alpha_4 = \min\left(\frac{1}{\sqrt{\tr(\boldsymbol{P}^2)}}, \frac{c}{\sqrt[r]{\tr(\boldsymbol{P})}}\right)$$
其中$c&gt;1$是安全因子。</p>
<p><strong>优点</strong>：在大多数情况下使用Frobenius范数缩放，在极端情况下使用更保守的迹缩放。
<strong>缺点</strong>：需要额外的判断逻辑。</p>
<h4 id="85">8.5 数值比较<a class="toc-link" href="#85" title="Permanent link">&para;</a></h4>
<p>对于一个测试矩阵，特征值为$\{1, 0.5, 0.1, 0.01, 0.001\}$：</p>
<table>
<thead>
<tr>
<th>策略</th>
<th>$\alpha$</th>
<th>缩放后最小特征值</th>
<th>缩放后最大特征值</th>
<th>条件数</th>
<th>迭代步数</th>
</tr>
</thead>
<tbody>
<tr>
<td>迹</td>
<td>0.618</td>
<td>0.0006</td>
<td>0.618</td>
<td>1030</td>
<td>8</td>
</tr>
<tr>
<td>Frobenius</td>
<td>1.124</td>
<td>0.0011</td>
<td>1.124</td>
<td>1022</td>
<td>7</td>
</tr>
<tr>
<td>谱半径</td>
<td>1.000</td>
<td>0.0010</td>
<td>1.000</td>
<td>1000</td>
<td>6</td>
</tr>
</tbody>
</table>
<p>结论：Frobenius范数缩放提供了计算代价和性能的良好平衡。</p>
<h3 id="9-schur">9. 与Schur分解方法的对比<a class="toc-link" href="#9-schur" title="Permanent link">&para;</a></h3>
<h4 id="91-schur">9.1 Schur分解方法<a class="toc-link" href="#91-schur" title="Permanent link">&para;</a></h4>
<p>Schur分解将矩阵分解为：
$$\boldsymbol{P} = \boldsymbol{U}\boldsymbol{T}\boldsymbol{U}^*$$
其中$\boldsymbol{U}$是酉矩阵，$\boldsymbol{T}$是上三角矩阵（复数）或拟上三角矩阵（实数）。</p>
<p>计算r次方根：
$$\boldsymbol{P}^{1/r} = \boldsymbol{U}\boldsymbol{T}^{1/r}\boldsymbol{U}^*$$</p>
<p>其中$\boldsymbol{T}^{1/r}$通过求解矩阵方程：
$$\boldsymbol{T}^{1/r}\boldsymbol{T}^{1/r}\cdots\boldsymbol{T}^{1/r} = \boldsymbol{T}$$</p>
<p>使用块递归算法。</p>
<p><strong>复杂度</strong>：
- Schur分解：$O(n^3)$
- 上三角矩阵方根：$O(n^3)$
- 总计：$O(n^3)$</p>
<h4 id="92">9.2 迭代方法的复杂度<a class="toc-link" href="#92" title="Permanent link">&para;</a></h4>
<p>每步迭代包括：
- 矩阵-矩阵乘法：$O(n^3)$
- 矩阵幂运算：$O(rn^3)$（需要计算$\boldsymbol{P}^r$）</p>
<p>对于$k$步迭代：
- 总计：$O(krn^3)$</p>
<p>当$k$较小（如4-6步）且$r$不太大时，总复杂度与Schur分解相当。</p>
<h4 id="93">9.3 并行性分析<a class="toc-link" href="#93" title="Permanent link">&para;</a></h4>
<p><strong>Schur分解</strong>：
- QR迭代本质上是串行的
- 难以并行化</p>
<p><strong>迭代方法</strong>：
- 矩阵乘法高度可并行
- 可利用GPU加速</p>
<p>在现代硬件上，矩阵乘法的实际性能远超理论预期，因为：
- 高度优化的BLAS库（如MKL、cuBLAS）
- 硬件加速（Tensor Core等）</p>
<p><strong>实际性能比较</strong>（GPU环境）：
- Schur分解：受限于串行QR迭代
- 迭代方法：充分利用并行矩阵乘法</p>
<p>在大规模矩阵（$n&gt;1000$）上，迭代方法通常更快。</p>
<h4 id="94">9.4 数值稳定性对比<a class="toc-link" href="#94" title="Permanent link">&para;</a></h4>
<p><strong>Schur分解</strong>：
- 理论上非常稳定（向后稳定）
- 对所有条件数的矩阵都适用</p>
<p><strong>迭代方法</strong>：
- 对良态矩阵稳定
- 对病态矩阵需要正则化
- 累积误差随迭代步数增加</p>
<p><strong>建议</strong>：
- 对于条件数$\kappa &lt; 10^4$：优先使用迭代方法（更快）
- 对于条件数$\kappa &gt; 10^4$：考虑Schur分解（更稳定）
- 对于极大规模问题：迭代方法（可并行）</p>
<h3 id="10">10. 实际计算复杂度的精细分析<a class="toc-link" href="#10" title="Permanent link">&para;</a></h3>
<h4 id="101">10.1 基本操作计数<a class="toc-link" href="#101" title="Permanent link">&para;</a></h4>
<p>记矩阵维度为$n\times n$，基本操作的浮点运算次数（FLOPs）：</p>
<p><strong>矩阵-矩阵乘法</strong>：$\boldsymbol{C} = \boldsymbol{A}\boldsymbol{B}$
- FLOPs：$2n^3$（$n^3$次乘法，$n^3$次加法）</p>
<p><strong>矩阵-矩阵加法</strong>：$\boldsymbol{C} = \boldsymbol{A} + \boldsymbol{B}$
- FLOPs：$n^2$</p>
<p><strong>标量-矩阵乘法</strong>：$\boldsymbol{C} = c\boldsymbol{A}$
- FLOPs：$n^2$</p>
<h4 id="102">10.2 单步迭代的复杂度<a class="toc-link" href="#102" title="Permanent link">&para;</a></h4>
<p>考虑文中的单步迭代：
$$\boldsymbol{W} = a\boldsymbol{I} + b\boldsymbol{P}<em t_1="t+1">t + c\boldsymbol{P}_t^2$$
$$\boldsymbol{G}</em>} = \boldsymbol{G<em t_1="t+1">t\boldsymbol{W}^s$$
$$\boldsymbol{P}</em>_t$$} = \boldsymbol{W}^r\boldsymbol{P</p>
<p><strong>步骤分解</strong>：
1. 计算$\boldsymbol{P}<em t_1="t+1">t^2$：$2n^3$ FLOPs
2. 计算$a\boldsymbol{I} + b\boldsymbol{P}_t + c\boldsymbol{P}_t^2$：$3n^2$ FLOPs
3. 计算$\boldsymbol{W}^s$（假设$s\leq 3$，需要$\lceil\log_2 s\rceil$次乘法）：
   - 如$s=2$：$2n^3$ FLOPs
   - 如$s=3$：$4n^3$ FLOPs（$\boldsymbol{W}^2$再乘$\boldsymbol{W}$）
4. 计算$\boldsymbol{G}_t\boldsymbol{W}^s$：$2mn^2$ FLOPs（假设$\boldsymbol{G}\in\mathbb{R}^{m\times n}$）
5. 类似计算$\boldsymbol{P}</em>$</p>
<p><strong>总计单步</strong>（对于$s=r=2$）：
$$\text{FLOPs} \approx 2n^3 + 2n^3 + 2mn^2 + 2n^3 + 2n^3 = 8n^3 + 2mn^2$$</p>
<p>对于方阵$m=n$：约$10n^3$ FLOPs。</p>
<h4 id="103">10.3 总复杂度与收敛步数的权衡<a class="toc-link" href="#103" title="Permanent link">&para;</a></h4>
<p>假设需要$k$步迭代达到目标精度：
$$\text{总FLOPs} \approx 10kn^3$$</p>
<p>对比特征分解方法：
- 特征分解：约$20n^3$ FLOPs（LAPACK的<code>dsyevd</code>）
- 构造结果：$2n^3$ FLOPs
- 总计：约$22n^3$ FLOPs</p>
<p><strong>平衡点</strong>：当$k\leq 2$时，迭代方法更快。</p>
<p>从文中的数值结果看，对于良态矩阵，$k=4\sim 6$步通常足够，因此：
- 理论FLOPs：$40\sim 60n^3$
- 但实际上矩阵乘法可高度优化和并行化</p>
<h4 id="104">10.4 内存访问模式分析<a class="toc-link" href="#104" title="Permanent link">&para;</a></h4>
<p><strong>迭代方法</strong>：
- 主要操作：矩阵乘法
- 内存访问模式：规则、可预测
- 缓存友好性：高（BLAS库优化）</p>
<p><strong>Schur分解</strong>：
- 包含多种操作：Householder变换、Givens旋转等
- 内存访问模式：不规则
- 缓存友好性：中等</p>
<p><strong>实际性能</strong>：在现代硬件上，内存带宽往往是瓶颈。迭代方法由于更好的缓存利用率，实际性能可能优于理论预测。</p>
<h4 id="105">10.5 低精度计算的优势<a class="toc-link" href="#105" title="Permanent link">&para;</a></h4>
<p>对于bfloat16等低精度格式：
- 内存带宽需求减半
- Tensor Core加速（在支持的硬件上）
- 迭代方法更容易适配低精度</p>
<p><strong>混合精度策略</strong>：
- 迭代过程使用bfloat16或float16
- 最后一步使用float32提高精度
- 可以在保持精度的同时大幅提速</p>
<h4 id="106">10.6 大规模分布式计算<a class="toc-link" href="#106" title="Permanent link">&para;</a></h4>
<p>对于超大规模矩阵（如$n&gt;10^5$），需要分布式计算：</p>
<p><strong>迭代方法</strong>：
- 矩阵乘法可分块并行：$\boldsymbol{C}<em ik="ik">{ij} = \sum_k \boldsymbol{A}</em>$
- 通信量：$O(n^2/p)$每个节点，其中$p$是节点数
- 扩展性：良好}\boldsymbol{B}_{kj</p>
<p><strong>Schur分解</strong>：
- 分布式QR迭代复杂
- 通信频繁
- 扩展性：较差</p>
<p>对于大规模问题，迭代方法明显占优。</p>
<h3 id="11_1">11. 算法的实现细节与优化技巧<a class="toc-link" href="#11_1" title="Permanent link">&para;</a></h3>
<h4 id="111">11.1 数值稳定的矩阵幂计算<a class="toc-link" href="#111" title="Permanent link">&para;</a></h4>
<p>计算$\boldsymbol{W}^r$时，如果直接连乘可能导致数值问题。使用二进制幂算法：</p>
<div class="highlight"><pre><span></span><code><span class="k">function</span><span class="w"> </span><span class="nf">MatrixPower</span><span class="p">(</span>W, r<span class="p">):</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">r</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">:</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">I</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">r</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">W</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">r</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">even</span><span class="p">:</span>
<span class="w">        </span><span class="n">H</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">MatrixPower</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="w"> </span><span class="n">r</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">H</span><span class="w"> </span><span class="p">@</span><span class="w"> </span><span class="n">H</span>
<span class="w">    </span><span class="k">else</span><span class="p">:</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">W</span><span class="w"> </span><span class="p">@</span><span class="w"> </span><span class="n">MatrixPower</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="w"> </span><span class="n">r</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>

<p>这将乘法次数从$r-1$减少到$O(\log r)$。</p>
<h4 id="112">11.2 避免显式求逆<a class="toc-link" href="#112" title="Permanent link">&para;</a></h4>
<p>文中的算法避免了显式求逆，这是重要的稳定性保证。对于需要求逆的情况，使用线性系统求解：
$$\boldsymbol{X} = \boldsymbol{A}^{-1}\boldsymbol{B} \quad\Rightarrow\quad \boldsymbol{A}\boldsymbol{X} = \boldsymbol{B}$$</p>
<p>使用LU分解或Cholesky分解求解，避免直接计算$\boldsymbol{A}^{-1}$。</p>
<h4 id="113">11.3 早停策略<a class="toc-link" href="#113" title="Permanent link">&para;</a></h4>
<p>监控相对变化：
$$\delta_k = \frac{|\boldsymbol{P}_{k+1} - \boldsymbol{P}_k|_F}{|\boldsymbol{P}_k|_F}$$</p>
<p>当$\delta_k &lt; \epsilon_{\text{tol}}$（如$10^{-6}$）时停止迭代，避免不必要的计算和累积误差。</p>
<h4 id="114">11.4 残差监控<a class="toc-link" href="#114" title="Permanent link">&para;</a></h4>
<p>除了监控迭代变化，还应监控实际残差：
$$r_k = |\boldsymbol{P}\boldsymbol{Y}_k^r - \boldsymbol{I}|_F$$</p>
<p>这是最终精度的直接度量。</p>
<h4 id="115">11.5 异常检测<a class="toc-link" href="#115" title="Permanent link">&para;</a></h4>
<p>在迭代过程中检测数值异常：
- 检查NaN或Inf
- 检查矩阵范数是否过大（如$&gt; 10^{10}$）
- 检查对称性破坏（对于对称矩阵）</p>
<p>一旦检测到异常，立即停止并报告，避免错误传播。</p>
<h3 id="12">12. 理论结果的总结与展望<a class="toc-link" href="#12" title="Permanent link">&para;</a></h3>
<h4 id="121">12.1 主要理论贡献<a class="toc-link" href="#121" title="Permanent link">&para;</a></h4>
<p>本文的主要理论贡献包括：</p>
<ol>
<li>
<p><strong>统一框架</strong>：将r次方根和逆r次方根的计算统一到一个迭代框架中。</p>
</li>
<li>
<p><strong>最优系数</strong>：通过求解极值问题，得到了每步迭代的理论最优系数。</p>
</li>
<li>
<p><strong>收敛性保证</strong>：证明了在合理假设下迭代的收敛性和收敛速度。</p>
</li>
<li>
<p><strong>数值稳定性</strong>：提供了稳定的初始化和正则化策略。</p>
</li>
</ol>
<h4 id="122">12.2 与经典算法的关系<a class="toc-link" href="#122" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>算法</th>
<th>收敛阶</th>
<th>每步复杂度</th>
<th>总复杂度（到$\epsilon$精度）</th>
<th>并行性</th>
</tr>
</thead>
<tbody>
<tr>
<td>Newton-Schulz</td>
<td>2</td>
<td>$O(n^3)$</td>
<td>$O(n^3\log\log(1/\epsilon))$</td>
<td>高</td>
</tr>
<tr>
<td>Denman-Beavers</td>
<td>2</td>
<td>$O(n^3)$</td>
<td>$O(n^3\log\log(1/\epsilon))$</td>
<td>高</td>
</tr>
<tr>
<td>本文方法</td>
<td>$\geq 2$</td>
<td>$O(rn^3)$</td>
<td>$O(rn^3\log\log(1/\epsilon))$</td>
<td>高</td>
</tr>
<tr>
<td>Schur分解</td>
<td>-</td>
<td>$O(n^3)$</td>
<td>$O(n^3)$</td>
<td>低</td>
</tr>
<tr>
<td>Padé逼近</td>
<td>$m+n$</td>
<td>$O(n^3)$</td>
<td>$O(n^3)$</td>
<td>中</td>
</tr>
</tbody>
</table>
<h4 id="123">12.3 开放问题与未来方向<a class="toc-link" href="#123" title="Permanent link">&para;</a></h4>
<ol>
<li>
<p><strong>最优初始化</strong>：是否存在$O(n^2)$复杂度的最优初始化策略？</p>
</li>
<li>
<p><strong>自适应步长</strong>：能否根据当前误差自动调整系数$a,b,c$？</p>
</li>
<li>
<p><strong>矩阵函数推广</strong>：该框架能否推广到其他矩阵函数，如$\log(\boldsymbol{P})$或$\exp(\boldsymbol{P})$？</p>
</li>
<li>
<p><strong>结构矩阵优化</strong>：对于稀疏、对称、Toeplitz等结构矩阵，能否利用结构性质进一步加速？</p>
</li>
<li>
<p><strong>随机化算法</strong>：结合随机投影技术，能否处理超大规模问题？</p>
</li>
</ol>
<h4 id="124">12.4 实际应用建议<a class="toc-link" href="#124" title="Permanent link">&para;</a></h4>
<p>基于本文的理论分析，实际使用时的建议：</p>
<p><strong>场景一：高精度科学计算</strong>
- 使用双精度或更高精度
- 使用完整的迭代步数（6-10步）
- 监控残差确保精度</p>
<p><strong>场景二：机器学习（如AdamW优化器）</strong>
- 使用单精度或混合精度
- 使用较少迭代步数（4-6步）
- 加正则化$\epsilon\approx 10^{-4}$</p>
<p><strong>场景三：深度学习推理</strong>
- 使用bfloat16或int8量化
- 使用最少迭代步数（3-4步）
- 侧重速度而非极致精度</p>
<p><strong>场景四：分布式大规模计算</strong>
- 优先考虑迭代方法（可并行）
- 使用早停策略减少通信
- 考虑异步迭代变体</p>
<p>通过本节的详细推导，我们从多个角度深入理解了矩阵r次方根计算的理论基础、算法设计、数值性质和实际应用。这些理论结果不仅解释了文中算法的工作原理，也为进一步的研究和优化提供了坚实的数学基础。</p>
                </div>

                <!-- Previous/Next Navigation -->
                <nav class="post-navigation" aria-label="文章导航">
                    <div class="row g-3">
                        <div class="col-6">
                            
                            <a href="矩阵平方根和逆平方根的高效计算.html" class="nav-link-prev">
                                <div class="nav-direction"><i class="fas fa-chevron-left"></i> 上一篇</div>
                                <div class="nav-title">#333 矩阵平方根和逆平方根的高效计算</div>
                            </a>
                            
                        </div>
                        <div class="col-6">
                            
                            <a href="流形上的最速下降1-sgd-超球面.html" class="nav-link-next">
                                <div class="nav-direction">下一篇 <i class="fas fa-chevron-right"></i></div>
                                <div class="nav-title">#335 流形上的最速下降：1.  SGD + 超球面</div>
                            </a>
                            
                        </div>
                    </div>
                </nav>

                <!-- Back to Home -->
                <div class="text-center mt-4 mb-4">
                    <a href="../index.html" class="btn btn-outline-primary">
                        <i class="fas fa-arrow-left"></i> 返回首页
                    </a>
                </div>
            </div>

            <!-- Sidebar (TOC) -->
            <div class="col-lg-3">
                <aside class="sidebar">
                    
                    <div class="toc-sidebar">
                        <h5 class="toc-title"><i class="fas fa-list"></i> 目录</h5>
                        <div class="toc-content">
                            <div class="toc">
<ul>
<li><a href="#rr">矩阵r次方根和逆r次方根的高效计算</a><ul>
<li><a href="#_1">前情回顾</a></li>
<li><a href="#_2">一般形式</a></li>
<li><a href="#_3">迭代系数</a></li>
<li><a href="#_4">初始分析</a></li>
<li><a href="#_5">计算结果</a></li>
<li><a href="#_6">测试一下</a></li>
<li><a href="#_7">文章小结</a></li>
<li><a href="#_8">公式推导与注释</a><ul>
<li><a href="#1-r">1. 矩阵r次方根的精确定义与理论基础</a></li>
<li><a href="#2-newton-schulz">2. Newton-Schulz迭代法的详细推导</a></li>
<li><a href="#3">3. 基于多项式逼近的迭代方法</a></li>
<li><a href="#4-denman-beavers">4. Denman-Beavers迭代的推导</a></li>
<li><a href="#5">5. 收敛速度分析</a></li>
<li><a href="#6">6. 数值稳定性分析</a></li>
<li><a href="#7">7. 不同条件数下的误差界</a></li>
<li><a href="#8">8. 初始化策略的比较</a></li>
<li><a href="#9-schur">9. 与Schur分解方法的对比</a></li>
<li><a href="#10">10. 实际计算复杂度的精细分析</a></li>
<li><a href="#11_1">11. 算法的实现细节与优化技巧</a></li>
<li><a href="#12">12. 理论结果的总结与展望</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>

                        </div>
                        <div class="toc-actions">
                            <button class="btn btn-sm btn-outline-secondary" onclick="expandAll()">
                                <i class="fas fa-expand"></i> 全部展开
                            </button>
                            <button class="btn btn-sm btn-outline-secondary" onclick="collapseAll()">
                                <i class="fas fa-compress"></i> 全部折叠
                            </button>
                        </div>
                    </div>
                    

                    <!-- Back to Top Button -->
                    <button id="backToTop" class="back-to-top" title="回到顶部">
                        <i class="fas fa-arrow-up"></i>
                    </button>
                </aside>
            </div>
        </div>
    </article>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>
                博客来源: <a href="https://spaces.ac.cn" target="_blank">科学空间</a> |
                内容经过整理并添加详细数学推导
            </p>
            <p>
                Powered by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>
            </p>
        </div>
    </footer>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>

    <!-- Syntax highlighting -->
    <script>hljs.highlightAll();</script>

    <!-- Back to top functionality -->
    <script>
        // Show/hide back to top button based on scroll position
        window.addEventListener('scroll', function() {
            const backToTop = document.getElementById('backToTop');
            if (window.pageYOffset > 300) {
                backToTop.classList.add('show');
            } else {
                backToTop.classList.remove('show');
            }
        });

        // Smooth scroll to top
        document.getElementById('backToTop').addEventListener('click', function() {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        });

        // Sticky TOC sidebar
        window.addEventListener('scroll', function() {
            const sidebar = document.querySelector('.sidebar');
            if (!sidebar) return;

            const sidebarTop = sidebar.offsetTop;
            const scrollTop = window.pageYOffset;

            if (scrollTop > sidebarTop - 20) {
                sidebar.classList.add('sticky');
            } else {
                sidebar.classList.remove('sticky');
            }
        });
    </script>
</body>
</html>