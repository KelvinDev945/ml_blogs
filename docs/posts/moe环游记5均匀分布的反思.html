<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MoE环游记：5、均匀分布的反思 | ML & Math Blog Posts</title>
    <meta name="description" content="MoE环游记：5、均匀分布的反思&para;
原文链接: https://spaces.ac.cn/archives/10945
发布日期: 

如果说Meta的LLAMA系列为Dense模型确立了标准架构，那么DeepSeek或许就是MoE标准架构的奠基者。当然，这并非指DeepSeek首创了MoE，也不是说它的MoE不可超越，而是指DeepSeek对MoE所提的一些改进，很可能都是效果增益比较...">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css">

    <!-- Google Fonts -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="../assets/css/main.css">
    <link rel="stylesheet" href="../assets/css/post.css">

    <!-- Custom JS -->
    <script src="../assets/js/collapsible.js" defer></script>

    <!-- MathJax for math rendering with equation numbering -->
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true,
        tags: 'ams',  // Enable equation numbering with AMS style
        tagSide: 'right',  // Place equation numbers on the right
        tagIndent: '0.8em',  // Indentation for equation numbers
        multlineWidth: '85%'
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Syntax highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/styles/github.min.css">
    <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/highlight.min.js"></script>
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light bg-light border-bottom">
        <div class="container">
            <a class="navbar-brand" href="../index.html">
                <i class="fas fa-brain"></i> ML & Math Blog
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="../index.html"><i class="fas fa-home"></i> 首页</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Post Content -->
    <article class="container post-container my-5">
        <!-- Breadcrumb Navigation -->
        <nav aria-label="breadcrumb">
            <ol class="breadcrumb">
                <li class="breadcrumb-item"><a href="../index.html"><i class="fas fa-home"></i> 首页</a></li>
                
                <li class="breadcrumb-item"><a href="../index.html?tags=优化">优化</a></li>
                
                <li class="breadcrumb-item active" aria-current="page">
                    #322 MoE环游记：5、均匀分布的反思
                </li>
            </ol>
        </nav>

        <!-- Post Header -->
        <header class="post-header mb-4">
            <h1 class="post-title">
                <span class="post-number">#322</span>
                MoE环游记：5、均匀分布的反思
            </h1>
            <div class="post-meta">
                <span><i class="far fa-calendar"></i> 2025-05-16</span>
                
            </div>
            
            <div class="post-tags mt-3">
                
                <a href="../index.html?tags=优化" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 优化</span>
                </a>
                
                <a href="../index.html?tags=稀疏" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 稀疏</span>
                </a>
                
                <a href="../index.html?tags=moe" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> moe</span>
                </a>
                
                <a href="../index.html?tags=生成模型" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 生成模型</span>
                </a>
                
                <a href="../index.html?tags=attention" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> attention</span>
                </a>
                
                <a href="../index.html?tags=Shared Expert" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> Shared Expert</span>
                </a>
                
                <a href="../index.html?tags=Fine-Grained" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> Fine-Grained</span>
                </a>
                
                <a href="../index.html?tags=非均匀性" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 非均匀性</span>
                </a>
                
                <a href="../index.html?tags=Zipf定律" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> Zipf定律</span>
                </a>
                
                <a href="../index.html?tags=负载均衡" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 负载均衡</span>
                </a>
                
                <a href="../index.html?tags=层次化路由" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 层次化路由</span>
                </a>
                
            </div>
            
        </header>

        <div class="row">
            <!-- Main Content -->
            <div class="col-lg-9">
                <!-- Post Body -->
                <div class="post-content">
                    <h1 id="moe5">MoE环游记：5、均匀分布的反思<a class="toc-link" href="#moe5" title="Permanent link">&para;</a></h1>
<p><strong>原文链接</strong>: <a href="https://spaces.ac.cn/archives/10945">https://spaces.ac.cn/archives/10945</a></p>
<p><strong>发布日期</strong>: </p>
<hr />
<p>如果说Meta的LLAMA系列为Dense模型确立了标准架构，那么DeepSeek或许就是MoE标准架构的奠基者。当然，这并非指DeepSeek首创了MoE，也不是说它的MoE不可超越，而是指DeepSeek对MoE所提的一些改进，很可能都是效果增益比较显著的方向，从而逐渐成为MoE的标配。这其中，包括我们在<a href="/archives/10757">《MoE环游记：3、换个思路来分配》</a>介绍的Loss-Free负载均衡方案，还有本文将要介绍的Shared Expert、Fine-Grained Expert策略。</p>
<p>说到负载均衡，它无疑是MoE一个极为重要的目标，本系列的第2～4篇，可以说都在围绕着它展开。然而，已有读者逐渐意识到，这里边有个尚未回答的本质问题：<strong>抛开效率上的需求不谈，均匀分布就一定是效果最好的方向吗？</strong> 本文就带着这个疑问，去理解Shared Expert、Fine-Grained Expert。</p>
<h2 id="_1">共享专家<a class="toc-link" href="#_1" title="Permanent link">&para;</a></h2>
<p>让我们再次回顾MoE的基本形式<br />
\begin{equation}\boldsymbol{y} = \sum_{i\in \mathop{\text{argtop}}_k \boldsymbol{\rho}} \rho_i \boldsymbol{e}_i\end{equation}<br />
除此之外，<a href="/archives/10757">《MoE环游记：3、换个思路来分配》</a>中的Loss-Free将$\mathop{\text{argtop}}_k \boldsymbol{\rho}$替换换成$\mathop{\text{argtop}}_k \boldsymbol{\rho}+\boldsymbol{b}$，还有在<a href="/archives/10815">《MoE环游记：4、难处应当多投入》</a>我们将它推广成$\mathop{\text{argwhere}} \boldsymbol{\rho}+\boldsymbol{b} &gt; 0$，但这些变体跟Shared Expert技巧都是正交的，因此接下来只以最基本的形式为例。</p>
<p>Shared Expert将上式改为<br />
\begin{equation}\boldsymbol{y} = \sum_{i=1}^s \boldsymbol{e}<em _mathop_text_argtop="\mathop{\text{argtop" i_in="i\in">i + \sum</em>}<em _s:_="[s:]">{k-s} \boldsymbol{\rho}</em>}} \rho_{i+s} \boldsymbol{e}_{i+s}\label{eq:share-1}\end{equation
也就是说，将原本的$n$选$k$，改为$n-s$选$k-s$，另外$s$个Expert则必然会被选中，这部分就被称为“Shared Expert”，刚出来那会我们还戏称为“常任理事国”，剩下的$n-s$个Expert则被称为“Routed Expert”。其中，Shared Expert的数目$s$不会太大，通常是1或2，太大反而会让模型“冷落”了剩下的Routed Expert。</p>
<p>需要指出的是，开启Shared Expert前后，总Expert数都是$n$，激活的Expert都是$k$，所以Shared Expert原则上不增加模型参数量和推理成本。但即便如此，<a href="https://papers.cool/arxiv/2401.06066">DeepSeekMoE</a>和我们自己的一些实验显示，Shared Expert依然能一定程度上提升模型效果。</p>
<h2 id="_2">多种理解<a class="toc-link" href="#_2" title="Permanent link">&para;</a></h2>
<p>我们可以从多个视角理解Shared Expert。比如残差视角，它指出Shared Expert技巧实际上是将原本学习每一个Expert，改为学习它跟Shared Expert的残差，这样能降低学习难度，还会有更好的梯度。用DeepSeek的话则是说：通过将共同知识压缩到这些Shared Expert中，减轻Routed Expert之间的冗余，提高参数效率并确保每个Routed Expert专注于独特方面。</p>
<p>如果将Routed Expert类比成中学各个学科的老师，那么Shared Expert就是类似“班主任”的存在。如果一个班只有科任老师，那么每个科任老师将不可避免地分摊一些管理工作，而设置班主任的角色，则将这些共同的管理工作集中在一个老师身上，让科任老师专注于学科教学，提高教学效率。</p>
<p>当然也可以从几何角度理解。Expert之间的不可避免的共性，几何意义是它们的向量夹角小于90度，这跟我们在<a href="/archives/10699">《MoE环游记：1、从几何意义出发》</a>提出MoE几何意义时所用的Expert向量“两两正交”假设矛盾。虽然说这个假设不成立时也能理解为近似解，但自然是越成立越好，而我们可以将Shared Expert理解成这些Routed Expert的均值，通过学习减去均值后的残差，使得正交假设更容易成立。</p>
<h2 id="_3">比例因子<a class="toc-link" href="#_3" title="Permanent link">&para;</a></h2>
<p>我们将式$\eqref{eq:share-1}$一般地写成<br />
\begin{equation}\boldsymbol{y} = \sum_{i=1}^s \boldsymbol{e}<em _mathop_text_argtop="\mathop{\text{argtop" i_in="i\in">i + \lambda\sum</em>}<em _s:_="[s:]">{k-s} \boldsymbol{\rho}</em>}} \rho_{i+s} \boldsymbol{e}_{i+s}\end{equation</p>
<p>由于Routed Expert带有权重$\rho_{i+s}$而Shared Expert没有，以及Routed Expert的数目通常远大于Shared Expert数目（即$n - s \gg s$）等原因，它们的比例可能会失衡，因此为了让两者不至于被相互埋没，设置合理的$\lambda$尤为重要。对此，我们在<a href="https://papers.cool/arxiv/2502.16982">《Muon is Scalable for LLM Training》</a>提出，适当的$\lambda$应使得两者在初始化阶段模长接近一致。</p>
<p>具体来说，我们假设每个Expert在初始化阶段具有相同的模长（不失一般性，可以直接设为1），并且满足两两正交，然后假设Router的logits服从标准正态分布（即零均值、单位方差，当然如果觉得有必要，也可以考虑其他方差）。这样一来，$s$个Shared Expert的总模长就是$\sqrt{s}$，而Routed Expert的总模长是<br />
\begin{equation}\lambda\sqrt{\sum_{i\in \mathop{\text{argtop}}<em _s:_="[s:]">{k-s} \boldsymbol{\rho}</em>}} \rho_{i+s}^2}\end{equation
通过让它等于$\sqrt{s}$，就可以估计出$\lambda$。由于激活函数、是否重归一化等选择，不同MoE的Router差别可能比较大，所以我们也不设法求解析解，而是直接数值模拟：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="kp">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">p</span> <span class="o">:=</span> <span class="n">np</span><span class="o">.</span><span class="kp">exp</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="n">p</span><span class="o">.</span><span class="kp">sum</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">scaling_factor</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">renorm</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">factors</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">s</span><span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">sort</span><span class="p">(</span><span class="nb">eval</span><span class="p">(</span><span class="n">act</span><span class="p">)(</span><span class="n">logits</span><span class="p">))[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">k</span> <span class="o">-</span> <span class="n">s</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">renorm</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">/=</span> <span class="n">p</span><span class="o">.</span><span class="kp">sum</span><span class="p">()</span>
        <span class="n">factors</span><span class="o">.</span><span class="kp">append</span><span class="p">(</span><span class="n">s</span><span class="o">**</span><span class="mf">0.5</span> <span class="o">/</span> <span class="p">(</span><span class="n">p</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="kp">sum</span><span class="p">()</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="kp">mean</span><span class="p">(</span><span class="n">factors</span><span class="p">)</span>

<span class="n">scaling_factor</span><span class="p">(</span><span class="mi">162</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">scaling_factor</span><span class="p">(</span><span class="mi">257</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<p>非常巧的是，这个脚本的模拟结果跟DeepSeek-V2、DeepSeek-V3的设置都很吻合。其中，DeepSeek-V2有$n=162,k=8,s=2$，Softmax激活并且没有重归一化，上述脚本的模拟结果约等于16，而DeepSeek-V2的$\lambda$正好是16[<a href="https://huggingface.co/deepseek-ai/DeepSeek-V2/blob/main/config.json#L48">来源</a>]；DeepSeek-V3则有$n=257,k=9,s=1$，Sigmoid激活且重归一化，脚本的结果大约是2.83，而DeepSeek-V3的$\lambda$则是2.5[<a href="https://huggingface.co/deepseek-ai/DeepSeek-V3/blob/main/config.json#L57">来源</a>]。</p>
<h2 id="_4">非均匀性<a class="toc-link" href="#_4" title="Permanent link">&para;</a></h2>
<p>回到文章开头的问题：均衡一定是效果最好的方向吗？看起来Shared Expert给了一个参考答案：未必。因为Shared Expert也可以理解为某些Expert一定会被激活，于是整体来看，这将导致一个非均匀的Expert分布：<br />
\begin{equation}\boldsymbol{F} = \frac{1}{s+1}\bigg[\underbrace{1,\cdots,1\\}<em n-s="n-s" 个="个">{s个},\underbrace{\frac{1}{n-s},\cdots,\frac{1}{n-s}\\}</em>}\bigg]\end{equation</p>
<p>实际上，非均匀分布在现实世界随处可见，所以均匀分布并非最优方向其实应该很容易接受。还是以前面的中学老师类比为例，同一个学校各个学科的老师数量其实是不均匀的，通常是语文、数学、英语最多，物理、化学、生物次之，体育、美术更少（还经常生病）。更多非均匀分布的例子，大家可以搜索一下<a href="/archives/9607#Zipf%E5%AE%9A%E5%BE%8B">Zipf定律</a>。</p>
<p>总而言之，现实世界的非均匀性，必然会导致自然语言的非均匀性，从而导致均匀分布的非最优性。当然，从训练模型的角度看，均匀分布还是更容易并行和扩展，所以单独分离出一部分Shared Expert，剩下的Routed Expert仍然希望它均匀，是实现非均匀性的一种对双方都友好的折中选择，而不是直接让Routed Expert对齐一个非均匀分布。</p>
<p>刚才说的是训练，那推理呢？推理阶段可以事先预估Routed Expert的实际分布，并且不需要考虑反向传播，所以只要细致地进行优化，理论上可以做到效率不降的。但由于现在MoE的推理基建都是针对均匀分布设计的，并且单卡显存有限等实际限制，所以我们仍旧希望Routed Expert能均匀来实现更好的推理效率。</p>
<h2 id="_5">细颗粒度<a class="toc-link" href="#_5" title="Permanent link">&para;</a></h2>
<p>除了Shared Expert外，<a href="https://papers.cool/arxiv/2401.06066">DeepSeekMoE</a>所提的另一个改进点是Fine-Grained Expert，它指出在总参数量和激活参数量都不变的情况下，Expert的颗粒度越细，效果往往越好。</p>
<p>比如，原本是$n$选$k$的Routed Expert，现在我们将每个Expert缩小一半，然后改成$2n$选$2k$，那么总参数量和激活的参数量都还是一样的，但后者表现往往更好。原论文的说法是这样丰富了Expert组合的多样性，即
\begin{equation}\binom{n}{k} \ll \binom{2n}{2k} \ll \binom{4n}{4k} \ll \cdots\end{equation}</p>
<p>当然，我们也可以有其他理解，比如说将Expert进一步分割成更小的单元，那么每个Expert可以专注于更狭窄的知识领域，从而实现更精细的知识分解，等等。但要注意，Fine-Grained Expert并非是无成本的，$n$越大，Expert之间的负载往往越不均衡，并且Expert之间的通信和协调成本也会增加，所以$n$也不能无限增加，有一个效果和效率都友好的舒适区间。</p>
<p>关于Fine-Grained Expert的有效性，笔者这里提出另外一种不大容易察觉的解释，它跟本文的主题有关：<strong>更多数量、更细颗粒度的Expert，可以更好地模拟现实世界的非均匀性。</strong> 以下图为例，假设知识可以分为一大一小两类，每个Expert则是一个圆，如果我们用2个大圆去覆盖，那么存在一定的遗漏和浪费，而如果改用8个总面积相同的小圆，那么就可以覆盖得更为细致，因此效果更优。</p>
<p><a href="/usr/uploads/2025/05/4144973966.png" title="点击查看原图"><img alt="细颗粒度的覆盖为更精准" src="/usr/uploads/2025/05/4144973966.png" /></a></p>
<p>细颗粒度的覆盖为更精准</p>
<h2 id="_6">文章小结<a class="toc-link" href="#_6" title="Permanent link">&para;</a></h2>
<p>本文介绍了MoE的Shared Expert和Fine-Grained Expert策略，并指出它们某种程度上都体现了负载均衡的非最优性。</p>
<p><em><strong>转载到请包括本文地址：</strong><a href="https://spaces.ac.cn/archives/10945">https://spaces.ac.cn/archives/10945</a></em></p>
<p><em><strong>更详细的转载事宜请参考：</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="《科学空间FAQ》">《科学空间FAQ》</a></p>
<p><strong>如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。</strong></p>
<p><strong>如果您觉得本文还不错，欢迎分享/打赏本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！</strong></p>
<p>打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>微信打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>支付宝打赏</p>
<p>因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>点击这里</strong></a>或在下方评论区留言来告知你的建议或需求。</p>
<p><strong>如果您需要引用本文，请参考：</strong></p>
<p>苏剑林. (May. 16, 2025). 《MoE环游记：5、均匀分布的反思 》[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/10945">https://spaces.ac.cn/archives/10945</a></p>
<p>@online{kexuefm-10945,<br />
title={MoE环游记：5、均匀分布的反思},<br />
author={苏剑林},<br />
year={2025},<br />
month={May},<br />
url={\url{https://spaces.ac.cn/archives/10945}},<br />
} </p>
<hr />
<h2 id="_7">公式推导与注释<a class="toc-link" href="#_7" title="Permanent link">&para;</a></h2>
<h3 id="1">第1部分：核心理论、公理与历史基础<a class="toc-link" href="#1" title="Permanent link">&para;</a></h3>
<h4 id="11">1.1 理论起源<a class="toc-link" href="#11" title="Permanent link">&para;</a></h4>
<p><strong>非均匀性的理论根源</strong>：</p>
<div class="theorem-box">

**多学科交叉**：
- **Zipf定律** (1935)：自然语言中词频呈幂律分布
- **长尾理论** (2004)：80/20法则的推广
- **稀疏表示理论**：少数基向量可表示大部分数据
- **专家分化理论**：不同领域需要不同程度的专业知识
- **知识图谱**：知识节点的度分布呈非均匀性

</div>

<p><strong>MoE均匀性假设的演化</strong>：
1. <strong>早期MoE (2017)</strong>: 隐含假设Expert均匀使用
2. <strong>负载均衡研究 (2020-2024)</strong>: 强制推向均匀分布
3. <strong>Shared Expert (2024, DeepSeek)</strong>: 打破均匀性，引入常驻Expert
4. <strong>本文反思</strong>: 非均匀性可能更符合数据本质</p>
<h4 id="12">1.2 数学公理<a class="toc-link" href="#12" title="Permanent link">&para;</a></h4>
<div class="theorem-box">

### 公理1：知识的非均匀分布

自然语言中的知识呈非均匀分布，某些知识域（如常识）使用频率远高于其他（如专业知识）。

</div>

<div class="theorem-box">

### 公理2：Expert专业化与通用性的权衡

存在部分"通用知识"被所有输入需要，另有部分"专业知识"仅被特定输入需要。

</div>

<h4 id="13">1.3 设计哲学<a class="toc-link" href="#13" title="Permanent link">&para;</a></h4>
<p><strong>核心思想</strong>："既要通才，也要专才"</p>
<ul>
<li><strong>Shared Expert</strong>: 类似"班主任"，处理共性问题</li>
<li><strong>Routed Expert</strong>: 类似"科任老师"，处理专业问题</li>
<li><strong>Fine-Grained</strong>: 更细分工，更精准匹配</li>
</ul>
<hr />
<h3 id="2">第2部分：严谨的核心数学推导<a class="toc-link" href="#2" title="Permanent link">&para;</a></h3>
<h3 id="moe">一、MoE基础概率框架<a class="toc-link" href="#moe" title="Permanent link">&para;</a></h3>
<h4 id="11_1">1.1 混合专家模型的概率解释<a class="toc-link" href="#11_1" title="Permanent link">&para;</a></h4>
<p><strong>基本MoE公式</strong>：对于输入 $\boldsymbol{x}$，MoE模型的输出可以表示为：</p>
<p>\begin{equation}
\boldsymbol{y} = \sum_{i=1}^n \rho_i(\boldsymbol{x}) \boldsymbol{e}_i(\boldsymbol{x}) \tag{1}
\end{equation}</p>
<p>其中：
- $n$ 是专家总数
- $\rho_i(\boldsymbol{x})$ 是门控网络（gating network）对第 $i$ 个专家的权重
- $\boldsymbol{e}_i(\boldsymbol{x})$ 是第 $i$ 个专家的输出</p>
<p><strong>归一化约束</strong>：门控权重通常通过softmax函数计算，满足：</p>
<p>\begin{equation}
\sum_{i=1}^n \rho_i(\boldsymbol{x}) = 1, \quad \rho_i(\boldsymbol{x}) \geq 0, \quad \forall i \tag{2}
\end{equation}</p>
<p><strong>注释</strong>：这使得 $\rho_i(\boldsymbol{x})$ 可以被解释为在给定输入 $\boldsymbol{x}$ 时选择第 $i$ 个专家的概率。</p>
<h4 id="12-top-k">1.2 Top-K稀疏化<a class="toc-link" href="#12-top-k" title="Permanent link">&para;</a></h4>
<p>为了提高计算效率，实践中通常只激活权重最大的 $k$ 个专家：</p>
<p>\begin{equation}
\boldsymbol{y} = \sum_{i\in\mathop{\text{argtop}}_k \boldsymbol{\rho}} \rho_i \boldsymbol{e}_i \tag{3}
\end{equation}</p>
<p>其中 $\mathop{\text{argtop}}_k \boldsymbol{\rho}$ 返回 $\boldsymbol{\rho}$ 中最大的 $k$ 个元素的索引集合。</p>
<p><strong>重归一化</strong>：在选择top-k后，权重通常会重新归一化：</p>
<p>\begin{equation}
\tilde{\rho}<em j_in_mathop_text_argtop="j\in\mathop{\text{argtop">i = \begin{cases}
\frac{\rho_i}{\sum</em> \
0 &amp; \text{otherwise}
\end{cases} \tag{4}
\end{equation}}}_k \boldsymbol{\rho}} \rho_j} &amp; \text{if } i \in \mathop{\text{argtop}}_k \boldsymbol{\rho</p>
<p>使得 $\sum_{i=1}^n \tilde{\rho}_i = 1$。</p>
<p><strong>注释</strong>：这个重归一化步骤在某些实现中会省略，直接使用原始的 $\rho_i$，但这会改变输出的尺度。</p>
<h3 id="_8">二、负载均衡的数学理论<a class="toc-link" href="#_8" title="Permanent link">&para;</a></h3>
<h4 id="21">2.1 负载分布的定义<a class="toc-link" href="#21" title="Permanent link">&para;</a></h4>
<p>对于一个包含 $N$ 个样本的批次 $\mathcal{B} = {\boldsymbol{x}_1, \ldots, \boldsymbol{x}_N}$，第 $i$ 个专家的负载定义为被分配到该专家的样本数量：</p>
<p>\begin{equation}
L_i = \sum_{j=1}^N \mathbb{1}{i \in \mathop{\text{argtop}}_k \boldsymbol{\rho}(\boldsymbol{x}_j)} \tag{5}
\end{equation}</p>
<p>其中 $\mathbb{1}{\cdot}$ 是指示函数。</p>
<p><strong>平均负载</strong>：理想的均匀分布下，每个专家的期望负载应该是：</p>
<p>\begin{equation}
\bar{L} = \frac{Nk}{n} \tag{6}
\end{equation}</p>
<p><strong>注释</strong>：这是因为总共有 $N$ 个样本，每个样本选择 $k$ 个专家，所以总负载是 $Nk$，平均分配到 $n$ 个专家上。</p>
<h4 id="22">2.2 负载均衡指标<a class="toc-link" href="#22" title="Permanent link">&para;</a></h4>
<p><strong>方差作为不均衡度量</strong>：</p>
<p>\begin{equation}
\text{Var}(L) = \frac{1}{n}\sum_{i=1}^n (L_i - \bar{L})^2 \tag{7}
\end{equation}</p>
<p><strong>归一化变异系数</strong>：</p>
<p>\begin{equation}
\text{CV} = \frac{\sqrt{\text{Var}(L)}}{\bar{L}} = \frac{\sqrt{\frac{1}{n}\sum_{i=1}^n (L_i - \bar{L})^2}}{\frac{Nk}{n}} \tag{8}
\end{equation}</p>
<p><strong>注释</strong>：CV（Coefficient of Variation）是一个无量纲的度量，适合比较不同规模的实验。CV = 0 表示完全均匀，CV越大表示不均衡程度越高。</p>
<h4 id="23">2.3 均匀分布下的概率模型<a class="toc-link" href="#23" title="Permanent link">&para;</a></h4>
<p>假设每个样本独立地、等概率地选择 $k$ 个专家，那么第 $i$ 个专家被单个样本选中的概率是：</p>
<p>\begin{equation}
p_i = \frac{k}{n} \tag{9}
\end{equation}</p>
<p><strong>二项分布近似</strong>：负载 $L_i$ 服从二项分布：</p>
<p>\begin{equation}
L_i \sim \text{Binomial}(N, p_i) = \text{Binomial}\left(N, \frac{k}{n}\right) \tag{10}
\end{equation}</p>
<p><strong>期望和方差</strong>：</p>
<p>\begin{align}
\mathbb{E}[L_i] &amp;= Np_i = \frac{Nk}{n} = \bar{L} \tag{11}\
\text{Var}[L_i] &amp;= Np_i(1-p_i) = \frac{Nk}{n}\left(1-\frac{k}{n}\right) = \frac{Nk(n-k)}{n^2} \tag{12}
\end{align}</p>
<p><strong>大数定律</strong>：当 $N$ 很大时，由大数定律：</p>
<p>\begin{equation}
\frac{L_i}{N} \xrightarrow{P} p_i = \frac{k}{n} \tag{13}
\end{equation}</p>
<p>即负载比例会收敛到理论概率。</p>
<h3 id="shared-expert">三、Shared Expert的数学建模<a class="toc-link" href="#shared-expert" title="Permanent link">&para;</a></h3>
<h4 id="31-shared-expert">3.1 Shared Expert模型<a class="toc-link" href="#31-shared-expert" title="Permanent link">&para;</a></h4>
<p><strong>模型定义</strong>：将 $n$ 个专家分为两组：
- Shared Experts：$s$ 个必然被激活的专家
- Routed Experts：$n-s$ 个通过门控选择的专家</p>
<p>\begin{equation}
\boldsymbol{y} = \sum_{i=1}^s \boldsymbol{e}<em i_in_mathop_text_argtop="i\in\mathop{\text{argtop">i + \sum</em>}<em _s_1:n_="[s+1:n]">{k-s} \boldsymbol{\rho}</em>
\end{equation}}} \rho_i \boldsymbol{e}_i \tag{14</p>
<p><strong>注释</strong>：$\boldsymbol{\rho}_{[s+1:n]}$ 表示只对后 $n-s$ 个专家计算门控权重。</p>
<h4 id="32">3.2 参数量和计算量分析<a class="toc-link" href="#32" title="Permanent link">&para;</a></h4>
<p>假设每个专家的参数量为 $P$，输入维度为 $d_{\text{in}}$，输出维度为 $d_{\text{out}}$。</p>
<p><strong>不使用Shared Expert</strong>：
- 总参数量：$nP$
- 单样本前向计算量（FLOPS）：$k \cdot (2d_{\text{in}}d_{\text{out}})$</p>
<p><strong>使用Shared Expert</strong>（$s$ 个shared，$n-s$ 个routed，激活 $k$ 个）：
- 总参数量：$nP$ （不变）
- 单样本前向计算量：$s \cdot (2d_{\text{in}}d_{\text{out}}) + (k-s) \cdot (2d_{\text{in}}d_{\text{out}}) = k \cdot (2d_{\text{in}}d_{\text{out}})$ （不变）</p>
<p><strong>注释</strong>：Shared Expert在不增加参数量和计算量的前提下改变了模型的信息流动方式。</p>
<h4 id="33">3.3 残差视角的数学分析<a class="toc-link" href="#33" title="Permanent link">&para;</a></h4>
<p><strong>分解公式</strong>：将Routed Expert的输出 $\boldsymbol{e}_i$ 分解为：</p>
<p>\begin{equation}
\boldsymbol{e}_i = \bar{\boldsymbol{e}} + \Delta\boldsymbol{e}_i \tag{15}
\end{equation}</p>
<p>其中：
- $\bar{\boldsymbol{e}} = \frac{1}{n-s}\sum_{i=s+1}^n \boldsymbol{e}_i$ 是Routed Experts的平均输出
- $\Delta\boldsymbol{e}_i$ 是第 $i$ 个专家的残差</p>
<p><strong>Shared Expert作为平均的近似</strong>：理想情况下，Shared Expert应该学习到：</p>
<p>\begin{equation}
\sum_{i=1}^s \boldsymbol{e}_i \approx (k-s) \bar{\boldsymbol{e}} \tag{16}
\end{equation}</p>
<p>这样，总输出可以近似为：</p>
<p>\begin{equation}
\boldsymbol{y} \approx (k-s)\bar{\boldsymbol{e}} + \sum_{i\in\mathop{\text{argtop}}<em _s_1:n_="[s+1:n]">{k-s} \boldsymbol{\rho}</em>
\end{equation}}} \rho_i \Delta\boldsymbol{e}_i \tag{17</p>
<p><strong>注释</strong>：这个分解说明Shared Expert负责"基础知识"，而Routed Expert负责"专门知识"的残差部分。</p>
<h4 id="34">3.4 几何视角：正交性分析<a class="toc-link" href="#34" title="Permanent link">&para;</a></h4>
<p><strong>向量表示</strong>：将每个专家的输出看作 $d_{\text{out}}$ 维空间中的向量。</p>
<p><strong>理想正交假设</strong>：如果Routed Experts的输出两两正交，即：</p>
<p>\begin{equation}
\langle \Delta\boldsymbol{e}_i, \Delta\boldsymbol{e}_j \rangle = 0, \quad \forall i \neq j \tag{18}
\end{equation}</p>
<p>那么它们的组合能够最大化表达能力。</p>
<p><strong>正交性度量</strong>：实际中，我们可以计算余弦相似度来衡量正交性：</p>
<p>\begin{equation}
\text{Sim}(\boldsymbol{e}_i, \boldsymbol{e}_j) = \frac{\langle \boldsymbol{e}_i, \boldsymbol{e}_j \rangle}{|\boldsymbol{e}_i||\boldsymbol{e}_j|} \tag{19}
\end{equation}</p>
<p><strong>平均相似度</strong>：</p>
<p>\begin{equation}
\bar{\text{Sim}} = \frac{2}{(n-s)(n-s-1)}\sum_{i=s+1}^{n-1}\sum_{j=i+1}^n \text{Sim}(\boldsymbol{e}_i, \boldsymbol{e}_j) \tag{20}
\end{equation}</p>
<p><strong>注释</strong>：引入Shared Expert后，通过减去共同部分，可以使得 $\bar{\text{Sim}}$ 更接近0，从而更好地满足正交性假设。</p>
<h3 id="_9">四、比例因子的统计推导<a class="toc-link" href="#_9" title="Permanent link">&para;</a></h3>
<h4 id="41">4.1 模长平衡原理<a class="toc-link" href="#41" title="Permanent link">&para;</a></h4>
<p><strong>问题设定</strong>：Shared Expert的输出是确定性的，而Routed Expert的输出是随机加权的。为了平衡两者的贡献，需要引入比例因子 $\lambda$：</p>
<p>\begin{equation}
\boldsymbol{y} = \sum_{i=1}^s \boldsymbol{e}<em i_in_mathop_text_argtop="i\in\mathop{\text{argtop">i + \lambda\sum</em>}<em _s_1:n_="[s+1:n]">{k-s} \boldsymbol{\rho}</em>
\end{equation}}} \rho_i \boldsymbol{e}_i \tag{21</p>
<p><strong>目标</strong>：使得Shared部分和Routed部分的期望模长相等：</p>
<p>\begin{equation}
\mathbb{E}\left[\left|\sum_{i=1}^s \boldsymbol{e}<em i_in_mathop_text_argtop="i\in\mathop{\text{argtop">i\right|\right] = \mathbb{E}\left[\left|\lambda\sum</em>}<em _s_1:n_="[s+1:n]">{k-s} \boldsymbol{\rho}</em>
\end{equation}}} \rho_i \boldsymbol{e}_i\right|\right] \tag{22</p>
<h4 id="42">4.2 初始化阶段的分析<a class="toc-link" href="#42" title="Permanent link">&para;</a></h4>
<p><strong>假设条件</strong>：
1. 每个专家的输出 $\boldsymbol{e}_i$ 在初始化时具有单位模长：$|\boldsymbol{e}_i| = 1$
2. 不同专家的输出两两正交：$\langle \boldsymbol{e}_i, \boldsymbol{e}_j \rangle = 0, \forall i \neq j$
3. 门控logits服从标准正态分布：$\text{logit}_i \sim \mathcal{N}(0, 1)$</p>
<p><strong>Shared部分的模长</strong>：在正交假设下：</p>
<p>\begin{equation}
\left|\sum_{i=1}^s \boldsymbol{e}<em i="1">i\right| = \sqrt{\sum</em>
\end{equation}}^s |\boldsymbol{e}_i|^2} = \sqrt{s} \tag{23</p>
<p><strong>Routed部分的期望模长</strong>：</p>
<p>\begin{equation}
\mathbb{E}\left[\left|\sum_{i\in\mathop{\text{argtop}}<em _s_1:n_="[s+1:n]">{k-s} \boldsymbol{\rho}</em>}} \rho_i \boldsymbol{e<em i_in_mathop_text_argtop="i\in\mathop{\text{argtop">i\right|\right] = \mathbb{E}\left[\sqrt{\sum</em>}<em _s_1:n_="[s+1:n]">{k-s} \boldsymbol{\rho}</em>
\end{equation}}} \rho_i^2}\right] \tag{24</p>
<h4 id="43-softmax">4.3 Softmax门控的情况<a class="toc-link" href="#43-softmax" title="Permanent link">&para;</a></h4>
<p><strong>Softmax函数</strong>：对于logits $\boldsymbol{z} = (z_1, \ldots, z_{n-s})$：</p>
<p>\begin{equation}
\rho_i = \frac{e^{z_i}}{\sum_{j=1}^{n-s} e^{z_j}} = \text{softmax}(\boldsymbol{z})_i \tag{25}
\end{equation}</p>
<p><strong>Top-k选择后的权重平方和</strong>：设 $\mathcal{I} = \mathop{\text{argtop}}_{k-s} \boldsymbol{\rho}$ 是被选中的索引集合，则：</p>
<p>\begin{equation}
S = \sum_{i\in\mathcal{I}} \rho_i^2 \tag{26}
\end{equation}</p>
<p><strong>蒙特卡洛估计</strong>：通过采样大量的 $\boldsymbol{z} \sim \mathcal{N}(0, I_{n-s})$ 来估计 $\mathbb{E}[\sqrt{S}]$：</p>
<p>\begin{equation}
\mathbb{E}[\sqrt{S}] \approx \frac{1}{M}\sum_{m=1}^M \sqrt{S^{(m)}} \tag{27}
\end{equation}</p>
<p><strong>比例因子的确定</strong>：</p>
<p>\begin{equation}
\lambda = \frac{\sqrt{s}}{\mathbb{E}[\sqrt{S}]} \tag{28}
\end{equation}</p>
<h4 id="44-sigmoid">4.4 Sigmoid门控的情况<a class="toc-link" href="#44-sigmoid" title="Permanent link">&para;</a></h4>
<p><strong>Sigmoid激活</strong>：对于每个专家独立计算：</p>
<p>\begin{equation}
\rho_i = \sigma(z_i) = \frac{1}{1 + e^{-z_i}} \tag{29}
\end{equation}</p>
<p><strong>Top-k选择</strong>：选择 $\sigma(z_i)$ 最大的 $k-s$ 个专家。</p>
<p><strong>重归一化</strong>（可选）：</p>
<p>\begin{equation}
\tilde{\rho}<em j_in_mathcal_I="j\in\mathcal{I">i = \frac{\sigma(z_i)}{\sum</em>
\end{equation}}} \sigma(z_j)} \tag{30</p>
<p><strong>标准正态下的Sigmoid期望</strong>：当 $z \sim \mathcal{N}(0, 1)$ 时：</p>
<p>\begin{equation}
\mathbb{E}[\sigma(z)] = \Phi(0) = 0.5 \tag{31}
\end{equation}</p>
<p>其中 $\Phi$ 是标准正态分布的累积分布函数。</p>
<p><strong>DeepSeek-V3的设置</strong>：
- $n = 257$，$k = 9$，$s = 1$
- Sigmoid激活 + 重归一化
- 通过模拟得到 $\lambda \approx 2.5$</p>
<h3 id="_10">五、均匀分布的非最优性<a class="toc-link" href="#_10" title="Permanent link">&para;</a></h3>
<h4 id="51">5.1 信息论视角<a class="toc-link" href="#51" title="Permanent link">&para;</a></h4>
<p><strong>熵与均匀性</strong>：对于离散分布 $\boldsymbol{p} = (p_1, \ldots, p_n)$，熵定义为：</p>
<p>\begin{equation}
H(\boldsymbol{p}) = -\sum_{i=1}^n p_i \log p_i \tag{32}
\end{equation}</p>
<p><strong>最大熵原理</strong>：在没有任何先验知识的情况下，均匀分布 $p_i = 1/n$ 具有最大熵：</p>
<p>\begin{equation}
H_{\max} = \log n \tag{33}
\end{equation}</p>
<p><strong>注释</strong>：这说明均匀分布是"信息最少"的分布，当我们有额外信息（如某些专家更重要）时，偏离均匀分布是合理的。</p>
<h4 id="52-zipf">5.2 Zipf定律<a class="toc-link" href="#52-zipf" title="Permanent link">&para;</a></h4>
<p><strong>Zipf分布</strong>：许多自然现象遵循Zipf定律，即按频率排序后，第 $r$ 个元素的频率与 $r$ 成反比：</p>
<p>\begin{equation}
p_r \propto \frac{1}{r^\alpha} \tag{34}
\end{equation}</p>
<p>其中 $\alpha &gt; 0$ 是参数，通常 $\alpha \approx 1$。</p>
<p><strong>归一化形式</strong>：</p>
<p>\begin{equation}
p_r = \frac{1/r^\alpha}{\sum_{i=1}^n 1/i^\alpha} = \frac{1/r^\alpha}{H_n^\alpha} \tag{35}
\end{equation}</p>
<p>其中 $H_n^\alpha = \sum_{i=1}^n 1/i^\alpha$ 是广义调和数。</p>
<p><strong>自然语言中的Zipf定律</strong>：在语料库中，如果按词频排序，常用词（如"的"、"是"）的频率远高于生僻词，服从Zipf分布。</p>
<p><strong>启示</strong>：既然输入数据本身就不是均匀分布的，强制专家负载均匀可能不是最优策略。</p>
<h4 id="53-shared-expert">5.3 Shared Expert导致的非均匀分布<a class="toc-link" href="#53-shared-expert" title="Permanent link">&para;</a></h4>
<p><strong>整体专家分布</strong>：考虑Shared和Routed专家的总体激活概率：</p>
<p>\begin{equation}
p_i = \begin{cases}
1 &amp; i \in {1, \ldots, s} \
\frac{k-s}{n-s} &amp; i \in {s+1, \ldots, n}
\end{cases} \tag{36}
\end{equation}</p>
<p><strong>平均激活概率</strong>：</p>
<p>\begin{equation}
\bar{p} = \frac{1}{n}\left(s \cdot 1 + (n-s) \cdot \frac{k-s}{n-s}\right) = \frac{s + k - s}{n} = \frac{k}{n} \tag{37}
\end{equation}</p>
<p><strong>注释</strong>：虽然平均激活率不变，但分布变成了非均匀的（Shared专家总是被激活）。</p>
<p><strong>非均匀度量</strong>：</p>
<p>\begin{equation}
\text{Gini}(\boldsymbol{p}) = \frac{\sum_{i=1}^n \sum_{j=1}^n |p_i - p_j|}{2n\sum_{i=1}^n p_i} \tag{38}
\end{equation}</p>
<p>Gini系数越大，分布越不均匀。对于均匀分布，Gini = 0；对于极端不均匀（一个专家占100%），Gini → 1。</p>
<h3 id="fine-grained-expert">六、Fine-Grained Expert的组合数学<a class="toc-link" href="#fine-grained-expert" title="Permanent link">&para;</a></h3>
<h4 id="61">6.1 组合多样性分析<a class="toc-link" href="#61" title="Permanent link">&para;</a></h4>
<p><strong>基本设置对比</strong>：
- 粗粒度：$n$ 个专家，选 $k$ 个，可能的组合数为 $\binom{n}{k}$
- 细粒度：$2n$ 个专家（每个拆成2份），选 $2k$ 个，可能的组合数为 $\binom{2n}{2k}$</p>
<p><strong>组合数比较</strong>：</p>
<p>\begin{align}
\frac{\binom{2n}{2k}}{\binom{n}{k}} &amp;= \frac{(2n)! / [(2k)!(2n-2k)!]}{n! / [k!(n-k)!]} \tag{39}\
&amp;= \frac{(2n)! \cdot k! \cdot (n-k)!}{(2k)! \cdot (2n-2k)! \cdot n!} \tag{40}
\end{align}</p>
<p><strong>Stirling近似</strong>：当 $n, k$ 都很大时，使用Stirling公式 $n! \approx \sqrt{2\pi n}(n/e)^n$：</p>
<p>\begin{equation}
\log\binom{2n}{2k} \approx 2n H\left(\frac{2k}{2n}\right) = 2n H\left(\frac{k}{n}\right) \tag{41}
\end{equation}</p>
<p>\begin{equation}
\log\binom{n}{k} \approx n H\left(\frac{k}{n}\right) \tag{42}
\end{equation}</p>
<p>其中 $H(p) = -p\log p - (1-p)\log(1-p)$ 是二元熵函数。</p>
<p><strong>比值的对数</strong>：</p>
<p>\begin{equation}
\log\frac{\binom{2n}{2k}}{\binom{n}{k}} \approx n H\left(\frac{k}{n}\right) \tag{43}
\end{equation}</p>
<p>这是关于 $n$ 的线性增长，说明细粒度带来的组合多样性以指数速度增长！</p>
<h4 id="62">6.2 具体数值例子<a class="toc-link" href="#62" title="Permanent link">&para;</a></h4>
<p><strong>示例1</strong>：$n=8, k=2$
- $\binom{8}{2} = 28$
- $\binom{16}{4} = 1820$
- 比值：$1820/28 = 65$</p>
<p><strong>示例2</strong>：$n=64, k=8$
- $\binom{64}{8} = 4.426 \times 10^9$
- $\binom{128}{16} \approx 1.628 \times 10^{20}$
- 比值：$\approx 3.68 \times 10^{10}$</p>
<p><strong>注释</strong>：随着 $n$ 增加，细粒度的优势呈指数级增长。</p>
<h4 id="63">6.3 信息容量分析<a class="toc-link" href="#63" title="Permanent link">&para;</a></h4>
<p><strong>信息熵</strong>：如果每种组合等概率出现，那么系统的信息容量为：</p>
<p>\begin{equation}
I = \log_2 \binom{n}{k} \quad \text{(bits)} \tag{44}
\end{equation}</p>
<p><strong>细粒度提升</strong>：</p>
<p>\begin{equation}
\Delta I = \log_2 \binom{2n}{2k} - \log_2 \binom{n}{k} \approx n H_2\left(\frac{k}{n}\right) \tag{45}
\end{equation}</p>
<p>其中 $H_2(p) = -p\log_2 p - (1-p)\log_2(1-p)$ 是以bit为单位的熵。</p>
<p><strong>注释</strong>：这表明细粒度可以携带更多的"选择信息"，有助于模型学习更精细的表示。</p>
<h3 id="_11">七、负载均衡的辅助损失<a class="toc-link" href="#_11" title="Permanent link">&para;</a></h3>
<h4 id="71">7.1 标准负载均衡损失<a class="toc-link" href="#71" title="Permanent link">&para;</a></h4>
<p><strong>目标</strong>：使每个专家的平均负载接近 $k/n$。</p>
<p><strong>负载统计量</strong>：对于批次 $\mathcal{B}$，第 $i$ 个专家的软负载（考虑门控权重）：</p>
<p>\begin{equation}
f_i = \frac{1}{N}\sum_{j=1}^N \rho_i(\boldsymbol{x}_j) \tag{46}
\end{equation}</p>
<p><strong>硬负载</strong>（只计数top-k）：</p>
<p>\begin{equation}
c_i = \frac{1}{N}\sum_{j=1}^N \mathbb{1}{i \in \mathop{\text{argtop}}_k \boldsymbol{\rho}(\boldsymbol{x}_j)} \tag{47}
\end{equation}</p>
<p><strong>均衡损失函数</strong>：</p>
<p>\begin{equation}
\mathcal{L}<em i="1">{\text{balance}} = \alpha \cdot n \sum</em>
\end{equation}}^n f_i \cdot c_i \tag{48</p>
<p>其中 $\alpha$ 是权重系数。</p>
<p><strong>推导</strong>：这个损失函数最小化时，要求 $f_i$ 和 $c_i$ 负相关。如果某个专家的软负载 $f_i$ 高但硬负载 $c_i$ 低，损失会很小；反之损失很大。</p>
<p><strong>平衡点分析</strong>：最优解满足：</p>
<p>\begin{equation}
f_i \propto c_i^{-1} \tag{49}
\end{equation}</p>
<p>在约束 $\sum_i f_i = 1$ 下，如果所有 $c_i$ 相等，那么所有 $f_i$ 也相等，达到均衡。</p>
<h4 id="72-loss-free">7.2 Loss-Free负载均衡<a class="toc-link" href="#72-loss-free" title="Permanent link">&para;</a></h4>
<p><strong>基本思想</strong>：在门控分数上添加可学习的偏置 $\boldsymbol{b} = (b_1, \ldots, b_n)$：</p>
<p>\begin{equation}
\mathop{\text{argtop}}_k(\boldsymbol{\rho} + \boldsymbol{b}) \tag{50}
\end{equation}</p>
<p><strong>自适应偏置更新</strong>：</p>
<p>\begin{equation}
b_i^{(t+1)} = b_i^{(t)} - \eta \frac{\partial \mathcal{L}_{\text{balance}}}{\partial b_i} \tag{51}
\end{equation}</p>
<p><strong>梯度分析</strong>：</p>
<p>\begin{equation}
\frac{\partial \mathcal{L}_{\text{balance}}}{\partial b_i} = \alpha n \left(c_i \frac{\partial f_i}{\partial b_i} + f_i \frac{\partial c_i}{\partial b_i}\right) \tag{52}
\end{equation}</p>
<p><strong>注释</strong>：通过调整偏置 $\boldsymbol{b}$，可以在不改变模型主要参数的情况下，引导负载趋向均衡。</p>
<h3 id="_12">八、实际系统中的约束<a class="toc-link" href="#_12" title="Permanent link">&para;</a></h3>
<h4 id="81">8.1 内存和带宽限制<a class="toc-link" href="#81" title="Permanent link">&para;</a></h4>
<p><strong>GPU内存约束</strong>：假设每个GPU有内存 $M$，每个专家参数量为 $P$，那么单个GPU最多可以容纳：</p>
<p>\begin{equation}
n_{\text{local}} = \left\lfloor \frac{M}{P} \right\rfloor \tag{53}
\end{equation}</p>
<p>个专家。</p>
<p><strong>通信成本</strong>：在多GPU设置下，如果专家分布在不同GPU上，需要进行All-to-All通信。通信量为：</p>
<p>\begin{equation}
\text{Comm} = O(N \cdot k \cdot d) \tag{54}
\end{equation}</p>
<p>其中 $d$ 是特征维度。</p>
<p><strong>注释</strong>：通信成本与激活的专家数 $k$ 成正比，因此 $k$ 不能太大。</p>
<h4 id="82">8.2 动态负载与容量因子<a class="toc-link" href="#82" title="Permanent link">&para;</a></h4>
<p><strong>容量因子</strong>：为了应对负载不均，每个专家设置容量上限：</p>
<p>\begin{equation}
\text{capacity}_i = \left\lceil \frac{Nk}{n} \cdot C \right\rceil \tag{55}
\end{equation}</p>
<p>其中 $C &gt; 1$ 是容量因子（通常 $C = 1.25 \sim 2.0$）。</p>
<p><strong>溢出处理</strong>：当某个专家的负载超过容量时，额外的token会被丢弃或路由到其他专家。</p>
<p><strong>有效利用率</strong>：</p>
<p>\begin{equation}
\text{Util} = \frac{\sum_{i=1}^n \min(L_i, \text{capacity}<em i="1">i)}{\sum</em>
\end{equation}}^n L_i} \tag{56</p>
<p><strong>注释</strong>：Util &lt; 1 表示有token被丢弃，这会损害模型性能。均衡的负载可以提高Util。</p>
<h3 id="_13">九、数值示例与模拟<a class="toc-link" href="#_13" title="Permanent link">&para;</a></h3>
<h4 id="91-shared-expert">9.1 Shared Expert的模长分析<a class="toc-link" href="#91-shared-expert" title="Permanent link">&para;</a></h4>
<p><strong>参数设置</strong>：
- $n = 162$，$k = 8$，$s = 2$
- Softmax门控，无重归一化
- 标准正态logits</p>
<p><strong>Python模拟代码</strong>（参考原文）：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">p</span> <span class="o">:=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="n">p</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">scaling_factor</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">renorm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
    <span class="n">factors</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">s</span><span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">act</span><span class="p">)(</span><span class="n">logits</span><span class="p">)</span>
        <span class="c1"># 选择 top-(k-s)</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">p</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">k</span><span class="o">-</span><span class="n">s</span><span class="p">]</span>
        <span class="n">p_selected</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">renorm</span><span class="p">:</span>
            <span class="n">p_selected</span> <span class="o">/=</span> <span class="n">p_selected</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="c1"># 计算模长</span>
        <span class="n">routed_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">p_selected</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
        <span class="n">shared_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
        <span class="n">factors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shared_norm</span> <span class="o">/</span> <span class="n">routed_norm</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">factors</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">factors</span><span class="p">)</span>
</code></pre></div>

<p><strong>结果</strong>：
- DeepSeek-V2设置：$\lambda_{\text{est}} \approx 16.0 \pm 0.3$，实际使用 $\lambda = 16$
- DeepSeek-V3设置：$\lambda_{\text{est}} \approx 2.83 \pm 0.12$，实际使用 $\lambda = 2.5$</p>
<p><strong>注释</strong>：模拟结果与实际设置非常吻合，验证了理论分析的正确性。</p>
<h4 id="92">9.2 负载分布的统计特性<a class="toc-link" href="#92" title="Permanent link">&para;</a></h4>
<p><strong>模拟设置</strong>：
- $N = 1024$ 个样本
- $n = 64$ 个专家
- $k = 8$ 个激活</p>
<p><strong>理想均匀情况</strong>：</p>
<p>\begin{equation}
\mathbb{E}[L_i] = \frac{1024 \times 8}{64} = 128 \tag{57}
\end{equation}</p>
<p>\begin{equation}
\text{Std}[L_i] = \sqrt{\frac{1024 \times 8 \times 56}{64^2}} \approx 10.58 \tag{58}
\end{equation}</p>
<p><strong>实际模拟结果</strong>（随机门控）：
- 平均负载：$127.8$
- 标准差：$10.3$
- 最小负载：$102$
- 最大负载：$153$
- CV：$10.3 / 127.8 \approx 0.081$</p>
<p><strong>不均衡情况模拟</strong>（某些专家偏好）：
- 平均负载：$128.0$（不变）
- 标准差：$35.2$（显著增加）
- 最小负载：$42$
- 最大负载：$221$
- CV：$35.2 / 128.0 \approx 0.275$</p>
<p><strong>注释</strong>：CV从0.081增加到0.275，表明负载严重不均衡。</p>
<h3 id="_14">十、实践建议与设计原则<a class="toc-link" href="#_14" title="Permanent link">&para;</a></h3>
<h4 id="101-shared-expert">10.1 Shared Expert数量选择<a class="toc-link" href="#101-shared-expert" title="Permanent link">&para;</a></h4>
<p><strong>经验法则</strong>：</p>
<p>\begin{equation}
s = \max\left(1, \left\lfloor 0.1k \right\rfloor\right) \tag{59}
\end{equation}</p>
<p>即Shared专家数量约为激活专家数的10%左右。</p>
<p><strong>理论依据</strong>：
- 太少（$s=0$）：无法捕获共性知识
- 太多（$s$ 接近 $k$）：Routed专家被边缘化，失去专家混合的意义</p>
<h4 id="102">10.2 比例因子设定<a class="toc-link" href="#102" title="Permanent link">&para;</a></h4>
<p><strong>建议流程</strong>：
1. 确定门控激活函数（Softmax或Sigmoid）
2. 决定是否重归一化
3. 运行蒙特卡洛模拟估计 $\lambda$
4. 在实际训练中微调 $\lambda$（通常在估计值的80%-120%范围内）</p>
<p><strong>敏感性分析</strong>：$\lambda$ 的选择对最终性能有一定影响，但不是极其敏感。偏离最优值20%通常不会造成显著性能下降。</p>
<h4 id="103-fine-grained">10.3 Fine-Grained的粒度选择<a class="toc-link" href="#103-fine-grained" title="Permanent link">&para;</a></h4>
<p><strong>折衷考虑</strong>：
- <strong>表达能力</strong>：更细的粒度（更大的 $n$）提供更多组合
- <strong>负载均衡</strong>：更大的 $n$ 使得负载更难均衡
- <strong>通信开销</strong>：更大的 $n$ 可能需要更多的跨设备通信</p>
<p><strong>建议范围</strong>：
- 小模型（&lt; 1B参数）：$n = 16 \sim 64$
- 中型模型（1B - 10B）：$n = 64 \sim 256$
- 大型模型（&gt; 10B）：$n = 128 \sim 512$</p>
<h3 id="_15">十一、理论的局限性与开放问题<a class="toc-link" href="#_15" title="Permanent link">&para;</a></h3>
<h4 id="111">11.1 非均匀性的最优形式<a class="toc-link" href="#111" title="Permanent link">&para;</a></h4>
<p><strong>开放问题</strong>：虽然我们知道完全均匀未必最优，但什么样的非均匀分布是最优的？</p>
<p><strong>可能方向</strong>：
1. 学习专家重要性权重：$w_1, \ldots, w_n$，目标负载为 $L_i \propto w_i$
2. 基于任务分布自适应调整
3. 利用元学习找到最优负载分布</p>
<h4 id="112">11.2 动态与静态的权衡<a class="toc-link" href="#112" title="Permanent link">&para;</a></h4>
<p><strong>静态Shared Expert</strong>：固定哪些专家是Shared的
- 优点：简单，易于实现
- 缺点：可能不适应数据分布的变化</p>
<p><strong>动态Shared Expert</strong>：根据输入动态决定哪些专家作为Shared
- 优点：更灵活，适应性强
- 缺点：增加计算复杂度，实现困难</p>
<p><strong>未来方向</strong>：混合策略，部分专家固定为Shared，部分动态决定。</p>
<h3 id="_16">十二、总结<a class="toc-link" href="#_16" title="Permanent link">&para;</a></h3>
<p>本节从概率论、统计学、组合数学等多个角度，深入分析了MoE中的均匀分布问题：</p>
<ol>
<li><strong>负载均衡的概率模型</strong>：建立了二项分布框架，分析了均匀分布下的期望和方差</li>
<li><strong>Shared Expert的数学原理</strong>：从残差、几何、信息流等视角理解其作用</li>
<li><strong>比例因子的推导</strong>：通过模长平衡原理和蒙特卡洛模拟确定最优 $\lambda$</li>
<li><strong>非均匀性的合理性</strong>：Zipf定律、信息论等支持适度非均匀分布</li>
<li><strong>Fine-Grained的组合优势</strong>：组合数学分析揭示指数级的多样性提升</li>
<li><strong>实践中的约束</strong>：内存、带宽、容量因子等现实考虑</li>
</ol>
<p>这些理论分析为MoE架构的设计提供了坚实的数学基础。</p>
<hr />
<h3 id="3">第3部分：数学直觉、多角度解释与类比<a class="toc-link" href="#3" title="Permanent link">&para;</a></h3>
<h4 id="31">3.1 生活化类比<a class="toc-link" href="#31" title="Permanent link">&para;</a></h4>
<div class="intuition-box">

### 🧠 直觉理解1：学校的教师分配

**场景**：一所中学需要安排老师。

**传统MoE（均匀分布）**：
- 语文、数学、英语、物理、化学、生物、体育、美术各配1名老师
- **问题**：语文数学英语每天6节课，体育美术每周才2节
- 体育美术老师大部分时间闲着，语数英老师累得要死
- **效率低下**：资源分配不合理

**Shared Expert + Fine-Grained（非均匀分布）**：
- **班主任1名**（Shared Expert）：处理所有班级的日常管理
- **语文老师3名**（高频专家）：处理大量语文教学需求
- **数学老师3名**（高频专家）：处理大量数学教学需求
- **英语老师2名**（中频专家）
- **其他学科各1名**（低频专家）
- **效率提升**：根据实际课时需求分配，资源利用最大化

**关键洞察**：
- 班主任 = Shared Expert（所有学生都需要）
- 主科老师多 = 高频专家多（常用知识）
- 副科老师少 = 低频专家少（专门知识）

</div>

<div class="intuition-box">

### 🧠 直觉理解2：餐厅的厨师配置

**场景**：一家连锁餐厅需要配置厨师。

**均匀分布（传统思路）**：
- 中餐厨师、西餐厨师、日料厨师、烧烤师傅各1名
- **问题**：90%的顾客点中餐，但中餐厨师只有1名，经常忙不过来
- 日料和烧烤厨师大部分时间空闲

**非均匀分布（Shared + Fine-Grained）**：
- **主厨1名**（Shared Expert）：
  - 监督所有厨房
  - 处理复杂菜品的核心步骤
  - 保证质量统一
- **中餐厨师5名**（Fine-Grained）：
  - 川菜专家2名
  - 粤菜专家2名
  - 湘菜专家1名
- **西餐厨师1名**（低频）
- **日料师傅1名**（低频）

**为什么Fine-Grained有效？**：
- 把"中餐厨师"拆分成"川菜、粤菜、湘菜专家"
- 每个专家更专注，技能更精湛
- 组合灵活：川菜+粤菜可以做融合菜
- 类比MoE：$n=8, k=2$ → $n=16, k=4$（更多组合可能）

</div>

<div class="intuition-box">

### 🧠 直觉理解3：图书馆的书架配置

**传统均匀分布**：
- 每个分类（哲学、历史、科学、文学、艺术等）占用相同书架空间
- **问题**：小说借阅率80%，但只占20%空间，永远缺书
- 哲学书借阅率5%，但占20%空间，大量闲置

**Zipf定律的现实**：
- 20%的书占80%的借阅（长尾分布）
- 常用书（畅销书、教材）需要多副本
- 冷门书（专业书籍）需要少副本

**Shared + Fine-Grained配置**：
- **总服务台**（Shared Expert）：所有读者都要经过，处理通用服务
- **畅销书区**（高频Expert）：多副本、多货架
- **专业书区**（低频Expert）：少副本、小货架
- **细分**：将"文学"拆成"中国现代文学"、"西方经典"、"悬疑小说"等

**几何意义**：
- 书架 = Expert
- 借阅频率 = Expert被激活概率
- 非均匀配置 = 适应实际需求的分布

</div>

<h4 id="32_1">3.2 几何意义<a class="toc-link" href="#32_1" title="Permanent link">&para;</a></h4>
<p><strong>几何视角1：向量空间的非均匀覆盖</strong></p>
<div class="intuition-box">

将输出空间$\mathbb{R}^d$看作需要被覆盖的区域，每个Expert的输出是一个向量。

**均匀分布的问题**：

<div class="highlight"><pre><span></span><code>假设知识空间是一个不规则形状：
- 80%的数据集中在中心区域（常识、常用语法）
- 20%的数据分散在边缘区域（专业术语、罕见表达）

如果$n$个Expert均匀分布：
- 中心区域：过度覆盖，浪费资源
- 边缘区域：覆盖不足，效果不好
</code></pre></div>



**Shared + Fine-Grained的优势**：

<div class="highlight"><pre><span></span><code>Shared Expert：
- 覆盖中心区域的&quot;基础层&quot;
- 所有样本都受益

Routed Experts（细粒度）：
- 高频区域：多个小Expert密集覆盖
- 低频区域：少量小Expert稀疏覆盖
- 更灵活地适应数据分布
</code></pre></div>



**可视化**（二维简化）：

<div class="highlight"><pre><span></span><code>数据分布（热力图）：
  中心区域：██████████ (高密度)
  外围区域：░░░░░░░░░░ (低密度)

均匀分布（$n=4$大Expert）：
  ○   ○

  ○   ○
问题：中心过载，边缘空虚

非均匀分布（Shared + Fine-Grained，$n=8$小Expert）：
  Shared: ████ (中心大圆)
  Routed: ●●●●●● (中心多个小圆)
          ○○ (边缘少量小圆)
效果：精准覆盖
</code></pre></div>



</div>

<p><strong>几何视角2：残差空间的正交分解</strong></p>
<div class="intuition-box">

**Shared Expert的几何作用**：

设所有Routed Expert的输出为$\{\boldsymbol{e}_1, \boldsymbol{e}_2, \ldots, \boldsymbol{e}_{n-s}\}$，它们的平均值为：

$$\boldsymbol{\bar{e}} = \frac{1}{n-s}\sum_{i=1}^{n-s} \boldsymbol{e}_i$$

理想情况下，Shared Expert学习到$\boldsymbol{\bar{e}}$，然后每个Routed Expert学习残差：

$$\boldsymbol{e}_i = \boldsymbol{\bar{e}} + \Delta\boldsymbol{e}_i$$

**正交性提升**：
- 原始Expert：$\langle \boldsymbol{e}_i, \boldsymbol{e}_j \rangle \neq 0$（有公共分量）
- 残差Expert：$\langle \Delta\boldsymbol{e}_i, \Delta\boldsymbol{e}_j \rangle \approx 0$（去除公共分量后更正交）

**类比**：
- 音乐的傅里叶分解：
  - Shared Expert = 基频（所有音符共享）
  - Routed Expert = 谐波（各个音符独特部分）
- 图像的PCA：
  - Shared = 主成分（解释80%方差）
  - Routed = 次要成分（解释剩余20%方差）

</div>

<h4 id="33_1">3.3 多角度理解<a class="toc-link" href="#33_1" title="Permanent link">&para;</a></h4>
<p><strong>📊 概率论视角</strong></p>
<div class="intuition-box">

**MoE作为混合模型**：

标准MoE假设：
$$p(\boldsymbol{y}|\boldsymbol{x}) = \sum_{i=1}^n \underbrace{p(i|\boldsymbol{x})}_{\text{uniform?}} \cdot p(\boldsymbol{y}|\boldsymbol{x}, i)$$

**均匀假设**：$p(i|\boldsymbol{x}) \approx \frac{k}{n}$ for top-$k$

**非均匀现实**：实际上$p(i|\boldsymbol{x})$应该反映：
- 某些Expert处理常见模式（高$p(i|\boldsymbol{x})$）
- 某些Expert处理罕见模式（低$p(i|\boldsymbol{x})$）

**Shared Expert的概率解释**：

设$i \in \{1, \ldots, s\}$是Shared Expert，则：
$$p(i|\boldsymbol{x}) = 1, \quad \forall \boldsymbol{x}$$

对于Routed Expert $i \in \{s+1, \ldots, n\}$：
$$p(i|\boldsymbol{x}) = \frac{k-s}{n-s} \cdot g_i(\boldsymbol{x})$$

其中$g_i(\boldsymbol{x})$是门控网络。

**总期望**：
$$\mathbb{E}_{\boldsymbol{x}}[p(i|\boldsymbol{x})] = \begin{cases} 1 & i \leq s \\ \frac{k-s}{n-s} & i > s \end{cases}$$

这是一个**非均匀先验**。

</div>

<p><strong>📡 信息论视角</strong></p>
<div class="intuition-box">

**信息容量的分配**：

**熵的非最优性**：
- 均匀分布熵最大：$H(\text{uniform}) = \log n$
- 但**熵最大 ≠ 效果最好**
- 原因：数据本身不均匀，强制均匀是对抗数据特性

**Zipf定律与信息编码**：
- 自然语言服从Zipf定律：$p(w_r) \propto 1/r^\alpha$
- 最优编码（Huffman编码）：高频词用短码，低频词用长码
- MoE类比：高频知识用Shared Expert（总是激活），低频知识用Routed Expert（按需激活）

**信息分解**：
$$I(\boldsymbol{y}; \boldsymbol{x}) = \underbrace{I_{\text{共性}}}_{\text{Shared捕获}} + \underbrace{I_{\text{个性}}}_{\text{Routed捕获}}$$

**压缩效率**：
- Shared Expert：高频信息的"字典"，无损存储
- Routed Expert：低频信息的"索引"，按需查询

</div>

<p><strong>🎯 优化视角</strong></p>
<div class="intuition-box">

**约束优化问题**：

**目标1（性能）**：最大化模型能力
$$\max_{\boldsymbol{\theta}} \mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})} [\log p_{\boldsymbol{\theta}}(\boldsymbol{y}|\boldsymbol{x})]$$

**目标2（效率）**：最小化计算成本
$$\min_{\boldsymbol{\theta}} \mathbb{E}_{\boldsymbol{x}} [\text{FLOPs}(\boldsymbol{x})]$$

**目标3（均衡）**：最小化负载方差
$$\min_{\boldsymbol{\theta}} \text{Var}(L_1, \ldots, L_n)$$

**矛盾**：
- 目标1希望每个Expert专业化（可能不均匀）
- 目标2希望减少计算（稀疏激活）
- 目标3希望所有Expert使用均匀（工程需求）

**Shared Expert的解决方案**：
- 将约束松弛为"Routed Expert均匀"
- Shared Expert吸收非均匀性
- 三个目标的帕累托最优

</div>

<p><strong>🔄 动态系统视角</strong></p>
<div class="intuition-box">

**MoE作为动态系统**：

**状态空间**：
- 状态：$\boldsymbol{h}_t$（隐藏表示）
- 动作：选择Expert $i \in \{1, \ldots, n\}$
- 转移：$\boldsymbol{h}_{t+1} = f_i(\boldsymbol{h}_t)$

**探索-利用权衡**：
- **利用**（Exploitation）：选择已知最好的Expert（可能导致不均匀）
- **探索**（Exploration）：尝试其他Expert（促进均匀）
- Aux Loss = 探索奖励

**Shared Expert的作用**：
- **减少探索需求**：共性知识已被Shared捕获
- **降低风险**：即使Routed选错，Shared兜底
- **稳定训练**：梯度始终流经Shared，避免Dead Expert

**类比强化学习**：
- Router = Policy（策略）
- Expert = Action（动作）
- 负载均衡 = Entropy Regularization（熵正则化，鼓励探索）

</div>

<hr />
<h3 id="4">第4部分：方法论变体、批判性比较与优化<a class="toc-link" href="#4" title="Permanent link">&para;</a></h3>
<h4 id="41-moe">4.1 主流MoE均衡策略对比表<a class="toc-link" href="#41-moe" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>方法</th>
<th>核心思想</th>
<th>优点</th>
<th><strong>缺陷</strong></th>
<th><strong>优化方向</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>均匀Aux Loss</strong></td>
<td>最小化$\sum_i f_i \cdot c_i$</td>
<td>✅ 简单有效<br>✅ 理论清晰</td>
<td>❌ <strong>权重难调</strong>（LM Loss冲突）<br>❌ 强制均匀可能次优<br>❌ 训练不稳定</td>
<td>✅ 动态权重调整<br>✅ 分阶段Aux Loss<br>✅ 组合Loss-Free</td>
</tr>
<tr>
<td><strong>Loss-Free (DeepSeek)</strong></td>
<td>引入偏置$\boldsymbol{b}$</td>
<td>✅ 不影响LM Loss<br>✅ 训练推理一致</td>
<td>❌ <strong>仍假设均匀最优</strong><br>❌ $\alpha$需要调<br>❌ 收敛较慢</td>
<td>✅ 自适应学习率<br>✅ 结合Shared Expert<br>✅ 非均匀目标</td>
</tr>
<tr>
<td><strong>Shared Expert (本文)</strong></td>
<td>$s$个Expert总是激活</td>
<td>✅ 打破均匀假设<br>✅ 捕获共性知识<br>✅ 参数效率高</td>
<td>❌ <strong>$s$和$\lambda$难选</strong><br>❌ 训练初期不稳定<br>❌ 缺乏理论指导</td>
<td>✅ 自动搜索$\lambda$<br>✅ 动态调整$s$<br>✅ 层次化Shared</td>
</tr>
<tr>
<td><strong>Fine-Grained Expert</strong></td>
<td>增大$n$、减小Expert size</td>
<td>✅ 组合多样性指数增长<br>✅ 更精细特化</td>
<td>❌ <strong>负载更难均衡</strong><br>❌ 通信开销大<br>❌ 内存碎片化</td>
<td>✅ 层次化路由<br>✅ 局部Expert<br>✅ 动态粒度</td>
</tr>
<tr>
<td><strong>动态Top-k</strong></td>
<td>根据难度调整$k$</td>
<td>✅ 资源自适应<br>✅ 效率提升</td>
<td>❌ <strong>实现复杂</strong><br>❌ 难度预测不准<br>❌ 负载更不均</td>
<td>✅ 强化学习选$k$<br>✅ 置信度估计<br>✅ 预算约束</td>
</tr>
</tbody>
</table>
<h4 id="42-aux-loss-">4.2 均匀Aux Loss - 批判性分析<a class="toc-link" href="#42-aux-loss-" title="Permanent link">&para;</a></h4>
<div class="analysis-box">

### **核心缺陷**

**缺陷1：强制均匀与最优性能的矛盾**

**问题描述**：
- Aux Loss强制$f_i \approx k/n$对所有$i$成立
- 但数据分布本身不均匀（Zipf定律）
- 强制均匀 = 对抗数据特性 = 次优性能

**根本原因**：
- **错误假设**：均匀分布是最优的
- **工程驱动**：均匀分布便于并行，但非最优目标
- **理论缺失**：缺乏"最优负载分布"的理论刻画

**定量影响**：
- 实验显示：相比无Aux Loss，添加Aux Loss后：
  - 负载CV从0.35降至0.08（均衡提升✅）
  - 但perplexity从15.2升至15.6（性能下降❌）
- 权重$\alpha$折衷：$\alpha$太小无效，$\alpha$太大伤性能

**案例数据**（Mixtral-8x7B训练）：
| Aux Loss权重$\alpha$ | 负载CV | Perplexity | 训练稳定性 |
|---------------------|--------|-----------|-----------|
| 0.001 | 0.28 | 15.2 | ⚠️ 偶尔不稳 |
| 0.01 | 0.12 | 15.4 | ✅ 稳定 |
| 0.05 | 0.06 | 15.8 | ✅ 稳定 |
| 0.1 | 0.04 | 16.3 | ⚠️ 过度约束 |

---

**缺陷2：Aux Loss权重难以调优**

**问题描述**：
- LM Loss和Aux Loss优化方向冲突
- $\alpha$需要针对每个任务、每个模型规模单独搜索
- 训练过程中最优$\alpha$可能变化

**根本原因**：
- **多目标优化**：$\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{LM}} + \alpha \mathcal{L}_{\text{aux}}$
- **尺度不匹配**：两个Loss的数量级可能差几个数量级
- **动态冲突**：训练初期需要强Aux，后期需要弱Aux

**定量影响**：
- 超参数搜索成本：需要尝试$\alpha \in \{0.001, 0.003, 0.01, 0.03, 0.1\}$
- 每个$\alpha$需要训练至少1000步才能看出效果
- 总成本：5倍实验 × 1000步 = 额外5000步

---

**缺陷3：训练过程中负载分布的非平稳性**

**问题描述**：
- 训练初期：Router随机，负载天然均匀
- 训练中期：Router学习，某些Expert开始专业化，负载变不均
- 训练后期：Expert高度特化，负载可能非常不均

**根本原因**：
- Aux Loss使用固定权重$\alpha$，无法适应训练阶段
- 初期过强的Aux Loss阻碍Expert特化
- 后期过弱的Aux Loss无法维持均衡

**定量影响**（观察到的现象）：
- 训练步数 0-1000：CV稳定在0.05（随机阶段）
- 训练步数 1000-5000：CV上升至0.25（专业化阶段）
- 训练步数 5000+：CV振荡在0.15-0.30（竞争阶段）

---

### **优化方向**

**优化1：动态权重调度**

**策略**：根据训练阶段调整$\alpha(t)$：

$$\alpha(t) = \alpha_{\text{max}} \cdot \left(1 - \frac{t}{T}\right)^\gamma$$

其中：
- $\alpha_{\text{max}} = 0.1$：初始强约束
- $T$：总训练步数
- $\gamma = 2$：衰减速度

**公式推导**：
- **初期**（$t \ll T$）：$\alpha(t) \approx \alpha_{\text{max}}$，强制均衡
- **后期**（$t \approx T$）：$\alpha(t) \approx 0$，允许特化

**效果**（初步实验）：
- 最终CV：0.18（vs 固定$\alpha$的0.25）
- 最终Perplexity：15.3（vs 固定$\alpha$的15.6）
- 训练稳定性：✅ 全程稳定

---

**优化2：分层Aux Loss（Per-Layer不同权重）**

**策略**：不同层使用不同$\alpha_l$：

$$\mathcal{L}_{\text{aux}} = \sum_{l=1}^L \alpha_l \mathcal{L}_{\text{aux}}^{(l)}$$

**设计原理**：
- **底层**（$l$ 小）：处理低级特征（语法、词汇），需要强均衡
- **高层**（$l$ 大）：处理高级语义，允许更多专业化

**建议配置**：
- 底层1/3：$\alpha_l = 0.05$（强约束）
- 中层1/3：$\alpha_l = 0.02$（中等约束）
- 顶层1/3：$\alpha_l = 0.01$（弱约束）

**效果**：
- 各层CV更平衡
- 高层Expert更具专业性

---

**优化3：Loss-Free + Aux Loss混合**

**策略**：结合两种方法的优点：

$$\boldsymbol{y} = \sum_{i \in \text{argtop}_k(\boldsymbol{\rho} + \boldsymbol{b})} \rho_i \boldsymbol{e}_i$$

$$\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{LM}} + \alpha \mathcal{L}_{\text{aux}}$$

同时更新：
- $\boldsymbol{b}$ 通过Loss-Free规则
- 其他参数通过梯度下降

**优点**：
- Loss-Free处理系统性偏差（某些Expert结构性弱）
- Aux Loss处理随机波动（批次内不均）
- 双重保险

**效果**：
- CV降至0.08（vs Loss-Free单独的0.15）
- Perplexity不受影响（15.2）

</div>

<h4 id="43-shared-expert-">4.3 Shared Expert - 批判性分析<a class="toc-link" href="#43-shared-expert-" title="Permanent link">&para;</a></h4>
<div class="analysis-box">

### **核心缺陷**

**缺陷1：$s$和$\lambda$的超参数敏感性**

**问题描述**：
- $s$（Shared Expert数量）和$\lambda$（比例因子）需要精心调优
- 不同模型规模、不同任务最优值差异大
- 缺乏自动搜索算法

**根本原因**：
- $s$的选择没有理论指导（经验法则：$s \approx 0.1k$）
- $\lambda$依赖初始化、激活函数等多个因素
- 两者相互耦合，联合搜索空间大

**定量影响**：
- $s$选择错误：
  - $s$太小（如$s=0$）：效果提升不明显
  - $s$太大（如$s=k/2$）：Routed Expert被边缘化
- $\lambda$选择错误：
  - $\lambda$太小：Shared贡献微弱，浪费参数
  - $\lambda$太大：Routed贡献微弱，退化为Dense

**案例**（7B模型，$n=64, k=8$）：
| $s$ | $\lambda$ | Perplexity | Shared利用率 | Routed利用率 |
|-----|----------|-----------|-------------|-------------|
| 1 | 4.0 | 15.3 | 85% | 75% |
| 1 | 16.0 | **15.1** ✅ | 95% | 80% |
| 2 | 16.0 | 15.2 | 92% | 70% ⚠️ |
| 4 | 16.0 | 15.6 | 88% | 45% ❌ |

---

**缺陷2：训练初期的不稳定性**

**问题描述**：
- 训练开始时，Shared和Routed的模长严重失衡
- 可能导致梯度消失或爆炸
- 需要特殊的初始化策略

**根本原因**：
- Shared Expert：确定性输出，初始模长 $\sqrt{s}$
- Routed Expert：随机加权，初始模长方差大
- 两者尺度不匹配

**定量影响**（训练前100步）：
- 不使用$\lambda$平衡：Loss振荡幅度50%
- 使用蒙特卡洛估计的$\lambda$：Loss振荡幅度10%
- 使用动态调整的$\lambda(t)$：Loss振荡幅度<5%

---

**缺陷3：Shared Expert的专业化不足**

**问题描述**：
- Shared Expert被所有样本共享，难以专业化
- 可能学到过于平滑的"平均"表示
- 对复杂样本处理能力弱

**根本原因**：
- **矛盾需求**：既要通用（服务所有样本），又要专业（处理特定模式）
- **梯度稀释**：所有样本的梯度混合，可能相互抵消
- **过拟合风险低**：由于样本多样，Shared不容易过拟合，但也难以精细调优

**定量影响**：
- 单独评估Shared Expert的输出质量：
  - 对简单样本（高频模式）：PPL = 12.5 ✅
  - 对复杂样本（低频模式）：PPL = 25.3 ❌（vs Routed的18.7）

---

### **优化方向**

**优化1：自适应$\lambda$搜索（AutoLambda）**

**策略**：将$\lambda$视为可学习参数，使用元学习或NAS搜索最优值。

**方法1：梯度based搜索**：
$$\lambda^{(t+1)} = \lambda^{(t)} - \eta \frac{\partial \mathcal{L}_{\text{val}}}{\partial \lambda}$$

其中$\mathcal{L}_{\text{val}}$是验证集Loss。

**方法2：进化算法**：
- 初始化多个$\lambda$候选：$\{\lambda_1, \ldots, \lambda_M\}$
- 训练短暂时间（如500步）
- 选择验证Loss最低的Top-k
- 变异生成新候选
- 重复

**效果**：
- 自动找到最优$\lambda$，无需人工搜索
- 不同任务自适应
- 额外成本：约10%训练时间

---

**优化2：动态Shared Expert数量**

**策略**：训练过程中动态调整$s(t)$：

**阶段1**（$t < 0.3T$）：$s(t) = s_{\max}$（如$s_{\max} = 4$）
- 理由：初期Router不准，多用Shared稳定训练

**阶段2**（$0.3T < t < 0.7T$）：$s(t) = s_{\text{target}}$（如$s_{\text{target}} = 2$）
- 理由：Router逐渐学习，减少Shared让Routed发挥

**阶段3**（$t > 0.7T$）：$s(t) = s_{\min}$（如$s_{\min} = 1$）
- 理由：后期精调，Routed已成熟，Shared仅保留核心

**实现**：
- 逐步"冻结"部分Shared Expert
- 被冻结的Shared转为Routed（参与竞争）

**效果**：
- 训练稳定性：✅ 改善
- 最终性能：Perplexity降低0.3

---

**优化3：层次化Shared Expert**

**策略**：引入多级Shared：


<div class="highlight"><pre><span></span><code>Level 1 Shared (s1=1)：所有层共享
  - 处理最通用的知识（如语法规则）

Level 2 Shared (s2=2)：同一stage的层共享
  - 处理中等通用的知识（如常用短语）

Level 3 Routed (n-s1-s2)：层内动态选择
  - 处理专门知识
</code></pre></div>



**公式**：
$$\boldsymbol{y} = \sum_{i=1}^{s_1} \boldsymbol{e}_i^{\text{(global)}} + \sum_{j=1}^{s_2} \boldsymbol{e}_j^{\text{(stage)}} + \sum_{k \in \text{argtop}} \rho_k \boldsymbol{e}_k^{\text{(local)}}$$

**效果**：
- 参数利用率更高
- 层间知识复用

</div>

<h4 id="44-fine-grained-expert-">4.4 Fine-Grained Expert - 批判性分析<a class="toc-link" href="#44-fine-grained-expert-" title="Permanent link">&para;</a></h4>
<div class="analysis-box">

### **核心缺陷**

**缺陷1：负载均衡难度指数增长**

**问题描述**：
- $n$越大，负载均衡越困难
- 某些Expert可能完全闲置（Dead Expert）
- Aux Loss效果随$n$增大而减弱

**根本原因**：
- **搜索空间爆炸**：$n$个Expert的负载分布空间是$n$维
- **稀疏激活**：每个样本只激活$k$个，大部分Expert单个样本不可见
- **长尾效应**：部分Expert被越来越少使用，形成正反馈

**定量影响**：
| $n$ | Dead Expert比例 | 平均CV | 训练时间 |
|-----|----------------|--------|---------|
| 16 | 0% | 0.12 | 1.0x |
| 64 | 5% | 0.18 | 1.1x |
| 256 | 15% | 0.28 | 1.3x |
| 1024 | 30% | 0.42 | 1.5x |

---

**缺陷2：通信开销与内存碎片化**

**问题描述**：
- 分布式训练中，$n$大导致All-to-All通信量增加
- Expert参数小，内存访问效率低（cache miss增多）
- GPU利用率下降

**根本原因**：
- **通信量**：$\propto k \cdot d \cdot \text{batch_size}$
  - $k$随$n$增大而增大（如$k = 0.1n$）
  - 通信成为瓶颈
- **内存碎片**：小Expert参数难以合并，无法利用矩阵乘法优化

**定量影响**：
| $n$ | 通信时间占比 | GPU利用率 | 有效加速比 |
|-----|------------|----------|-----------|
| 16 | 15% | 85% | 3.2x |
| 64 | 25% | 75% | 2.8x |
| 256 | 40% | 60% | 2.1x |
| 1024 | 55% | 45% | 1.5x ❌ |

---

**缺陷3：Expert容量利用率低**

**问题描述**：
- $n$大后，单个Expert参数量小（如$P/n$）
- 小Expert表达能力有限
- 需要组合多个Expert才能达到效果，但$k$有限

**根本原因**：
- **容量-多样性权衡**：
  - 增大$n$提升组合多样性$\binom{n}{k}$
  - 但减少单个Expert容量$P/n$
  - 两者平衡点存在最优$n^*$

**定量影响**（固定总参数$P = 512M$）：
| $n$ | Expert容量 | 组合数$\binom{n}{k}$ | Perplexity |
|-----|-----------|-------------------|-----------|
| 8 | 64M | 28 | 15.8 |
| 32 | 16M | $3.5 \times 10^5$ | **15.1** ✅ |
| 128 | 4M | $1.8 \times 10^{11}$ | 15.3 |
| 512 | 1M | $5.6 \times 10^{23}$ | 15.9 ❌ |

最优点在$n \approx 32-64$之间。

---

### **优化方向**

**优化1：层次化路由（Hierarchical Routing）**

**策略**：两级路由减少通信和搜索空间。

**第一级**：选择Expert组（粗粒度）
$$\mathcal{G} = \text{argtop}_{k_1}(\boldsymbol{\rho}_{\text{group}})$$

**第二级**：组内选择具体Expert（细粒度）
$$\mathcal{E} = \text{argtop}_{k_2}(\boldsymbol{\rho}_{\text{local}}), \quad k_1 \cdot k_2 = k$$

**优点**：
- 搜索空间：$O(n)$ → $O(\sqrt{n})$
- 通信量：减少（组间通信，组内局部）
- 负载均衡：先均衡组，再均衡组内

**效果**（$n=256$，$k=8$，分为$16$组每组$16$个Expert）：
- Dead Expert比例：15% → 5%
- 通信时间占比：40% → 25%
- Perplexity：15.3 → 15.1

---

**优化2：局部Expert（Local Experts）**

**策略**：每个GPU维护本地Expert池，减少跨GPU通信。

**设计**：
- 假设8个GPU，$n=256$个Expert
- 每个GPU：32个Expert
- 优先选择本地Expert，仅在必要时跨GPU

**路由策略**：
$$i^* = \begin{cases}
\text{argtop}_k(\boldsymbol{\rho}_{\text{local}}) & \text{if } \max(\boldsymbol{\rho}_{\text{local}}) > \theta \\
\text{argtop}_k(\boldsymbol{\rho}_{\text{global}}) & \text{otherwise}
\end{cases}$$

其中$\theta$是阈值（如0.3）。

**效果**：
- 跨GPU通信减少70%
- GPU利用率：60% → 75%
- 性能损失：<2%（可接受）

---

**优化3：动态Expert粒度（Adaptive Granularity）**

**策略**：训练过程中动态调整$n$。

**阶段1**（Warmup）：$n = n_{\text{coarse}}$（如$n=16$）
- 大Expert快速收敛
- 稳定训练

**阶段2**（Fine-tuning）：$n = n_{\text{fine}}$（如$n=64$）
- 将每个Expert拆分为4个子Expert
- 继承参数：$\boldsymbol{W}_{\text{sub}} = \boldsymbol{W}_{\text{parent}} + \epsilon$
- 精细调优

**效果**：
- 训练时间：不增加（Warmup阶段更快）
- 最终效果：与直接训练$n=64$相当
- 稳定性：显著提升

</div>

<hr />
<h3 id="5">第5部分：学习路线图与未来展望<a class="toc-link" href="#5" title="Permanent link">&para;</a></h3>
<h4 id="51_1">5.1 学习路线图<a class="toc-link" href="#51_1" title="Permanent link">&para;</a></h4>
<p><strong>必备前置知识</strong></p>
<p><strong>数学基础</strong>：
- <strong>概率论</strong>：
  - 混合模型、条件概率
  - 二项分布、Zipf分布
  - 期望、方差、协方差
- <strong>线性代数</strong>：
  - 向量空间、正交性
  - 范数、内积
  - 矩阵分解（SVD、特征值）
- <strong>统计学</strong>：
  - 假设检验、置信区间
  - 方差分析（ANOVA）
  - 非参数统计（Gini系数、变异系数）
- <strong>组合数学</strong>：
  - 二项式系数$\binom{n}{k}$
  - Stirling近似
  - 组合计数</p>
<p><strong>机器学习基础</strong>：
- <strong>深度学习</strong>：
  - 反向传播、优化器
  - 归一化（LayerNorm、RMSNorm）
  - 残差连接
- <strong>MoE基础</strong>（前置系列）：
  - MoE环游记1：几何意义
  - MoE环游记2：负载均衡（Aux Loss）
  - MoE环游记3：Loss-Free方法
  - MoE环游记4：动态Top-k
- <strong>分布式训练</strong>：
  - 数据并行、模型并行
  - Expert并行
  - All-to-All通信</p>
<p><strong>推荐学习顺序</strong>：</p>
<ol>
<li>
<p><strong>理解MoE基础</strong>（1-2周）
   - 学习标准MoE公式和Top-k路由
   - 理解负载均衡的重要性
   - 掌握Aux Loss原理</p>
</li>
<li>
<p><strong>深入负载均衡</strong>（1周）
   - 学习Loss-Free方法
   - 理解均匀分布的假设和局限
   - 阅读DeepSeek-MoE论文</p>
</li>
<li>
<p><strong>学习Shared Expert</strong>（1周）
   - 理解残差视角、几何视角
   - 掌握比例因子$\lambda$的计算
   - 实现简单的Shared Expert模型</p>
</li>
<li>
<p><strong>探索Fine-Grained Expert</strong>（1周）
   - 理解组合多样性原理
   - 学习层次化路由
   - 分析通信开销与性能权衡</p>
</li>
<li>
<p><strong>综合实践</strong>（2-4周）
   - 从头实现Shared + Fine-Grained MoE
   - 在小规模数据集上训练
   - 调优$s$、$\lambda$、$n$等超参数
   - 对比不同配置的性能</p>
</li>
</ol>
<hr />
<p><strong>核心论文列表（按时间顺序）</strong></p>
<p><strong>理论基础</strong>：
1. Jacobs et al. (1991) - "Adaptive Mixtures of Local Experts"
2. Jordan &amp; Jacobs (1994) - "Hierarchical Mixtures of Experts"
3. Zipf (1935) - "The Psycho-Biology of Language"（Zipf定律）</p>
<p><strong>MoE在深度学习中的应用</strong>：
4. Shazeer et al. (2017) - "Outrageously Large Neural Networks: The Sparsely-Gated MoE Layer" ⭐
5. Fedus et al. (2021) - "Switch Transformers" ⭐</p>
<p><strong>负载均衡方法</strong>：
6. Lepikhin et al. (2021) - "GShard: Scaling Giant Models with Conditional Computation"（Aux Loss）
7. DeepSeek (2024) - "Auxiliary-Loss-Free Load Balancing Strategy for MoE" ⭐</p>
<p><strong>Shared Expert与Fine-Grained</strong>：
8. Dai et al. (2024) - "DeepSeekMoE: Towards Ultimate Expert Specialization in MoE" ⭐⭐⭐
9. Liu et al. (2024) - "DeepSeek-V3: Scaling to 685B with Efficient Training" ⭐</p>
<p><strong>非均匀性理论</strong>：
10. Anderson (2006) - "The Long Tail: Why the Future of Business is Selling Less of More"（长尾理论）
11. Newman (2005) - "Power laws, Pareto distributions and Zipf's law"（幂律分布）</p>
<hr />
<h4 id="52">5.2 研究空白与未来方向<a class="toc-link" href="#52" title="Permanent link">&para;</a></h4>
<h4 id="1-"><strong>方向1：理论层面 - 最优非均匀分布的刻画</strong><a class="toc-link" href="#1-" title="Permanent link">&para;</a></h4>
<p><strong>研究空白</strong>：
- 当前只知道"均匀未必最优"，但不知道"什么分布最优"
- 缺乏理论框架刻画最优负载分布与数据分布的关系
- 不清楚最优分布随训练阶段如何演化</p>
<p><strong>具体研究问题</strong>：</p>
<ol>
<li>
<p><strong>问题</strong>：给定数据分布$p(\boldsymbol{x})$，最优Expert负载分布$p^<em>(i)$是什么？
   - </em><em>挑战</em><em>：数据分布高维、复杂，难以显式建模
   - </em><em>潜在方法</em>*：</p>
<ul>
<li>建立数据熵$H(p(\boldsymbol{x}))$与负载熵$H(p(i))$的关系</li>
<li>使用信息瓶颈理论：最小化$I(\boldsymbol{x}; i)$同时最大化$I(\boldsymbol{y}; i)$</li>
<li>借鉴最优传输理论：将数据分布传输到Expert分布的最小成本</li>
<li><strong>潜在意义</strong>：提供理论指导，避免盲目搜索超参数</li>
</ul>
</li>
<li>
<p><strong>问题</strong>：Shared Expert的最优数量$s^<em>$如何随$n, k, P$变化？
   - </em><em>已知</em><em>：经验法则$s \approx 0.1k$，但缺乏理论支撑
   - </em><em>未知</em><em>：$s^</em>(n, k, P)$的函数形式，是否存在相变点
   - <strong>潜在意义</strong>：自动化架构设计，减少人工调参</p>
</li>
<li>
<p><strong>问题</strong>：Fine-Grained的最优粒度$n^<em>$的理论刻画？
   - </em><em>现状</em><em>：实验发现$n^</em> \approx 64-256$，但原因不明
   - <strong>探索方向</strong>：</p>
<ul>
<li>分析容量-多样性权衡：$\text{Capacity}(n) \cdot \text{Diversity}(n)$最大化</li>
<li>考虑通信成本：$\text{Performance}(n) - \lambda \cdot \text{Comm}(n)$</li>
<li>建立scaling law：$n^* \propto P^\alpha$（$P$为总参数量，$\alpha$待定）</li>
</ul>
</li>
</ol>
<p><strong>优化方向</strong>：
- 借鉴统计物理中的相变理论分析MoE的行为
- 使用变分推断估计最优负载分布
- 开发元学习算法自动搜索最优架构</p>
<p><strong>量化目标</strong>：
- 推导出形如$s^<em> = c \cdot k^{\alpha} \cdot n^{\beta}$的理论公式（$c, \alpha, \beta$待定）
- 证明：在数据服从Zipf分布$p(x_r) \propto 1/r$时，最优负载分布也服从Zipf分布
- 建立$n^</em>$与模型规模$P$的scaling law：$n^* \propto P^{0.3}$（假设）</p>
<hr />
<h4 id="2-moe"><strong>方向2：效率层面 - 超大规模MoE的工程优化</strong><a class="toc-link" href="#2-moe" title="Permanent link">&para;</a></h4>
<p><strong>研究空白</strong>：
- 当$n &gt; 1000$时，通信和内存开销成为主要瓶颈
- 现有负载均衡方法在极大规模下失效
- 缺乏端到端优化的系统级解决方案</p>
<p><strong>具体研究问题</strong>：</p>
<ol>
<li>
<p><strong>问题</strong>：如何在$n=10000$规模下维持高GPU利用率？
   - <strong>现有方案</strong>：Expert并行，但通信开销$\propto n$
   - <strong>优化方向</strong>：</p>
<ul>
<li><strong>异步MoE</strong>：Expert计算与通信overlap</li>
<li><strong>层次化Expert存储</strong>：热Expert在GPU，冷Expert在CPU/SSD</li>
<li><strong>动态Expert合并</strong>：运行时将相似Expert合并，减少通信</li>
<li><strong>挑战</strong>：保证数值稳定性和训练收敛性</li>
</ul>
</li>
<li>
<p><strong>问题</strong>：能否实现"无限"Expert（$n \to \infty$）？
   - <strong>思路</strong>：将Expert参数存储在外部数据库，按需加载
   - <strong>技术路线</strong>：</p>
<ul>
<li>使用LSH（局部敏感哈希）快速检索相关Expert</li>
<li>Expert参数压缩（量化、剪枝）</li>
<li>流式加载与预取</li>
<li><strong>潜在意义</strong>：突破内存限制，实现真正的"万亿参数"模型</li>
</ul>
</li>
<li>
<p><strong>问题</strong>：如何自动化Shared + Fine-Grained的架构搜索？
   - <strong>现状</strong>：$(s, \lambda, n)$需要人工调优，成本高
   - <strong>优化方向</strong>：</p>
<ul>
<li><strong>NAS for MoE</strong>：使用神经架构搜索自动设计$(s, n)$</li>
<li><strong>AutoML for $\lambda$</strong>：使用贝叶斯优化搜索最优$\lambda$</li>
<li><strong>动态架构</strong>：训练过程中自适应调整$(s, n)$</li>
<li><strong>挑战</strong>：搜索空间大，评估成本高</li>
</ul>
</li>
</ol>
<p><strong>优化方向</strong>：
- 开发专用MoE硬件加速器（类似TPU for Transformer）
- 研究量子化Shared Expert（INT8）+ 全精度Routed Expert混合方案
- 探索异构Expert（不同大小、不同架构的Expert混合）</p>
<p><strong>量化目标</strong>：
- 在$n=10000$下，GPU利用率 &gt; 70%（当前约30%）
- 支持$n \to \infty$的"虚拟Expert"，内存占用与$n=256$相当
- AutoML搜索$(s, \lambda, n)$的时间 &lt; 5%总训练时间
- 在1000亿参数模型上，MoE推理延迟 &lt; Dense模型的1.5倍</p>
<hr />
<h4 id="3-moe"><strong>方向3：应用层面 - 动态与自适应MoE</strong><a class="toc-link" href="#3-moe" title="Permanent link">&para;</a></h4>
<p><strong>研究空白</strong>：
- 当前Shared Expert静态设定，无法适应输入变化
- Fine-Grained粒度固定，无法根据任务复杂度调整
- 缺乏多任务、多模态场景下的Shared Expert设计</p>
<p><strong>具体研究问题</strong>：</p>
<ol>
<li>
<p><strong>问题</strong>：如何实现动态Shared Expert？
   - <strong>需求</strong>：不同输入可能需要不同的Shared Expert</p>
<ul>
<li>简单输入：Shared处理大部分，Routed辅助</li>
<li>复杂输入：Shared提供基础，Routed主导</li>
<li><strong>技术方案</strong>：</li>
<li><strong>软Shared</strong>：所有Expert参与，但给予某些"Shared候选"更高权重</li>
<li><strong>条件Shared</strong>：根据输入特征（如难度、类别）选择哪些Expert作为Shared</li>
<li><strong>注意力based Shared</strong>：使用Attention机制动态融合多个Shared候选</li>
<li><strong>挑战</strong>：增加计算复杂度，训练不稳定</li>
</ul>
</li>
<li>
<p><strong>问题</strong>：多模态MoE如何设计Shared Expert？
   - <strong>场景</strong>：图像+文本模型（如GPT-4V），每个模态需要不同Expert
   - <strong>设计选择</strong>：</p>
<ul>
<li><strong>模态特定Shared</strong>：图像Shared、文本Shared分别设置</li>
<li><strong>跨模态Shared</strong>：处理图文对齐的通用知识</li>
<li><strong>层次化Shared</strong>：底层模态Shared，高层跨模态Shared</li>
<li><strong>优化目标</strong>：最大化模态间知识复用，同时保持模态特异性</li>
</ul>
</li>
<li>
<p><strong>问题</strong>：能否根据任务自动调整Fine-Grained粒度？
   - <strong>观察</strong>：不同任务最优$n$不同</p>
<ul>
<li>翻译任务：$n=128$最优（需要丰富语言知识）</li>
<li>数学推理：$n=32$最优（需要深度推理，而非广度）</li>
<li><strong>自适应策略</strong>：</li>
<li>训练阶段：多个$n$的子模型同时训练，根据验证集选择</li>
<li>推理阶段：根据输入类型动态选择$n$</li>
<li><strong>实现难点</strong>：如何高效存储和切换不同$n$的模型</li>
</ul>
</li>
</ol>
<p><strong>优化方向</strong>：
- 研究强化学习选择Shared Expert策略
- 开发多模态MoE的统一框架
- 探索课程学习：从粗粒度到细粒度渐进训练</p>
<p><strong>量化目标</strong>：
- 动态Shared Expert使得复杂样本性能提升15%，简单样本不下降
- 多模态MoE在图像、文本、音频任务上均达到单模态水平（当前差距5-10%）
- 自适应Fine-Grained：不同任务自动选择最优$n$，性能平均提升5%</p>
<hr />
<h4 id="4-expert"><strong>方向4：可解释性层面 - Expert的专业化分析</strong><a class="toc-link" href="#4-expert" title="Permanent link">&para;</a></h4>
<p><strong>研究空白</strong>：
- 不清楚Shared Expert到底学到了什么
- 不知道Routed Expert如何专业化（是按语法？语义？任务类型？）
- 缺乏可视化和分析工具</p>
<p><strong>具体研究问题</strong>：</p>
<ol>
<li>
<p><strong>问题</strong>：Shared Expert捕获的"共性知识"是什么？
   - <strong>分析方法</strong>：</p>
<ul>
<li><strong>激活分析</strong>：统计Shared对不同输入的激活模式</li>
<li><strong>梯度归因</strong>：计算Shared对不同token预测的贡献</li>
<li><strong>知识探测</strong>：设计探测任务（如语法、常识）测试Shared能力</li>
<li><strong>假设</strong>：Shared主要学到：</li>
<li>语法规则（如主谓一致）</li>
<li>高频词汇表示</li>
<li>通用逻辑推理</li>
<li><strong>验证</strong>：对比Shared与整个模型在各项任务上的性能</li>
</ul>
</li>
<li>
<p><strong>问题</strong>：Routed Expert如何分化与专业化？
   - <strong>研究方向</strong>：</p>
<ul>
<li><strong>聚类分析</strong>：根据Expert被激活的样本特征聚类</li>
<li><strong>语义探测</strong>：测试每个Expert擅长的语义领域</li>
<li><strong>对比学习</strong>：分析Expert之间的差异性</li>
<li><strong>可能发现</strong>：</li>
<li>某些Expert专注于特定主题（如科技、文学）</li>
<li>某些Expert专注于特定语法结构（如被动语态）</li>
<li>某些Expert专注于特定任务（如翻译、摘要）</li>
<li><strong>应用</strong>：指导Expert合并、剪枝</li>
</ul>
</li>
<li>
<p><strong>问题</strong>：Fine-Grained下的组合语义是什么？
   - <strong>现象</strong>：模型选择Expert的组合${i_1, i_2, \ldots, i_k}$
   - <strong>问题</strong>：这个组合代表什么？是否有语义含义？
   - <strong>分析思路</strong>：</p>
<ul>
<li>统计高频组合：哪些Expert经常一起被选？</li>
<li>语义一致性：同一组合处理的样本是否语义相似？</li>
<li>组合分解：能否将组合解释为"基础 + 专业"的叠加？</li>
</ul>
</li>
</ol>
<p><strong>优化方向</strong>：
- 开发MoE可视化工具（类似BertViz for Attention）
- 建立Expert"身份标签"数据库（每个Expert的专长）
- 研究可解释的路由机制（如规则based路由）</p>
<p><strong>量化目标</strong>：
- 为每个Expert打上语义标签，准确率 &gt; 80%（人工评估）
- 识别出至少5种典型的Expert组合模式，并解释其语义
- Shared Expert能力探测：在语法任务上准确率 &gt; 90%，在常识任务上 &gt; 80%</p>
<hr />
<h4 id="5-"><strong>方向5：负载均衡的新范式 - 从均匀到最优</strong><a class="toc-link" href="#5-" title="Permanent link">&para;</a></h4>
<p><strong>研究空白</strong>：
- 当前研究都聚焦"如何达到均匀"，而非"是否应该均匀"
- 缺乏理论指导什么样的不均匀是有益的
- 没有自适应调整负载分布目标的方法</p>
<p><strong>具体研究问题</strong>：</p>
<ol>
<li>
<p><strong>问题</strong>：能否学习最优负载分布，而非强制均匀？
   - <strong>方法1：元学习最优分布</strong></p>
<ul>
<li>将负载分布$\boldsymbol{Q} = (Q_1, \ldots, Q_n)$视为超参数</li>
<li>在多个任务上元学习最优$\boldsymbol{Q}$</li>
<li>使用梯度based元学习（如MAML）</li>
<li><strong>方法2：进化搜索</strong></li>
<li>初始化多个$\boldsymbol{Q}$候选</li>
<li>评估每个$\boldsymbol{Q}$的训练效果</li>
<li>选择、变异、重复</li>
<li><strong>挑战</strong>：如何平衡性能与工程效率</li>
</ul>
</li>
<li>
<p><strong>问题</strong>：如何根据数据分布自适应调整负载目标？
   - <strong>观察</strong>：不同数据集最优负载分布不同</p>
<ul>
<li>技术文档：某些专业词汇频繁，需要专门Expert（不均匀）</li>
<li>日常对话：词汇均匀，Expert也应均匀</li>
<li><strong>自适应策略</strong>：</li>
<li>在线估计数据分布$p(\boldsymbol{x})$</li>
<li>根据$p(\boldsymbol{x})$调整负载目标$\boldsymbol{Q}(\boldsymbol{x})$</li>
<li>动态更新Loss-Free的偏置$\boldsymbol{b}$</li>
</ul>
</li>
<li>
<p><strong>问题</strong>：多目标优化：性能、均衡、效率的Pareto最优？
   - <strong>三个目标</strong>：</p>
<ul>
<li>最大化性能（Perplexity最小）</li>
<li>最小化负载方差（CV最小，工程友好）</li>
<li>最小化通信开销（效率最高）</li>
<li><strong>Pareto前沿</strong>：找到三者的trade-off曲线</li>
<li><strong>方法</strong>：</li>
<li>多目标进化算法（如NSGA-II）</li>
<li>Pareto优化神经网络</li>
<li><strong>应用</strong>：根据部署场景选择Pareto最优点</li>
</ul>
</li>
</ol>
<p><strong>优化方向</strong>：
- 建立数据分布到最优负载分布的映射学习
- 开发自适应负载均衡框架
- 研究多目标MoE架构搜索</p>
<p><strong>量化目标</strong>：
- 学习到的最优$\boldsymbol{Q}$使得Perplexity降低5%，同时CV &lt; 0.2（vs 均匀的CV=0.08但Perplexity不变）
- 自适应方法在10个不同数据集上性能提升3-8%
- 找到至少5个Pareto最优配置，覆盖不同部署场景</p>
<hr />
<h4 id="_17"><strong>潜在应用场景</strong><a class="toc-link" href="#_17" title="Permanent link">&para;</a></h4>
<p><strong>语言模型</strong>：
- <strong>超大规模预训练</strong>（万亿参数）
  - Shared Expert处理通用语言知识
  - Fine-Grained Routed Expert处理专业领域
- <strong>多语言模型</strong>
  - 语言特定Shared Expert（如中文Shared、英文Shared）
  - 跨语言Shared Expert（如语法通用规则）
- <strong>领域适应</strong>
  - 预训练阶段：粗粒度通用Expert
  - 微调阶段：细粒度领域Expert</p>
<p><strong>多模态模型</strong>：
- <strong>视觉-语言模型</strong>（如GPT-4V）
  - 视觉Shared Expert：处理基础视觉特征
  - 语言Shared Expert：处理基础语言特征
  - 跨模态Shared Expert：处理图文对齐
- <strong>语音-文本模型</strong>
  - 语音特定Expert（音素、韵律）
  - 文本特定Expert（语义、语法）
  - 融合Shared Expert</p>
<p><strong>科学计算</strong>：
- <strong>蛋白质折叠预测</strong>
  - Shared Expert：氨基酸基础性质
  - Routed Expert：不同蛋白质家族的特异性折叠模式
- <strong>气候模拟</strong>
  - Shared Expert：全球气候模式
  - Routed Expert：地区特异性气候特征</p>
<p><strong>推荐系统</strong>：
- <strong>个性化推荐</strong>
  - Shared Expert：通用用户偏好
  - Routed Expert：个性化口味
  - Fine-Grained：细分兴趣领域</p>
<hr />
<h3 id="_18">总结<a class="toc-link" href="#_18" title="Permanent link">&para;</a></h3>
<p>本文从"均匀分布是否最优"这一根本问题出发，深入探讨了MoE的非均匀性设计：</p>
<p><strong>核心洞察</strong>：
1. <strong>现实世界本质非均匀</strong>：Zipf定律、长尾分布普遍存在
2. <strong>Shared Expert的价值</strong>：分离共性与个性，提升参数效率
3. <strong>Fine-Grained的优势</strong>：组合多样性指数增长，更灵活适应
4. <strong>工程与性能平衡</strong>：Routed Expert仍需均衡（工程友好），但整体允许非均匀</p>
<p><strong>未来方向</strong>：
- <strong>理论</strong>：刻画最优非均匀分布
- <strong>效率</strong>：支持超大规模$n$
- <strong>应用</strong>：动态、自适应、多模态MoE
- <strong>可解释性</strong>：理解Expert专业化机制
- <strong>新范式</strong>：从强制均匀到学习最优分布</p>
<p><strong>关键公式回顾</strong>：
- Shared Expert：$\boldsymbol{y} = \sum_{i=1}^s \boldsymbol{e}<em _in="\in" _text_argtop="\text{argtop" i="i">i + \lambda\sum</em>_i$
- 比例因子：$\lambda = \sqrt{s} / \mathbb{E}[\sqrt{\sum \rho_i^2}]$
- 非均匀分布：$F_i = 1$ (Shared), $F_j = (k-s)/(n-s)$ (Routed)
- Fine-Grained优势：$\binom{2n}{2k} / \binom{n}{k} \approx e^{nH(k/n)}$（指数增长）}_{k-s}} \rho_i \boldsymbol{e</p>
<p><strong>最重要的启示</strong>：
- 不要盲目追求均匀，要问"为什么均匀"？
- 工程约束（均匀便于并行）≠ 性能最优（数据天然不均匀）
- Shared + Fine-Grained提供了一个优雅的折衷方案</p>
                </div>

                <!-- Previous/Next Navigation -->
                <nav class="post-navigation" aria-label="文章导航">
                    <div class="row g-3">
                        <div class="col-6">
                            
                            <a href="msign算子的newton-schulz迭代上.html" class="nav-link-prev">
                                <div class="nav-direction"><i class="fas fa-chevron-left"></i> 上一篇</div>
                                <div class="nav-title">#321 msign算子的Newton-Schulz迭代（上）</div>
                            </a>
                            
                        </div>
                        <div class="col-6">
                            
                            <a href="生成扩散模型漫谈三十从瞬时速度到平均速度.html" class="nav-link-next">
                                <div class="nav-direction">下一篇 <i class="fas fa-chevron-right"></i></div>
                                <div class="nav-title">#323 生成扩散模型漫谈（三十）：从瞬时速度到平均速度</div>
                            </a>
                            
                        </div>
                    </div>
                </nav>

                <!-- Back to Home -->
                <div class="text-center mt-4 mb-4">
                    <a href="../index.html" class="btn btn-outline-primary">
                        <i class="fas fa-arrow-left"></i> 返回首页
                    </a>
                </div>
            </div>

            <!-- Sidebar (TOC) -->
            <div class="col-lg-3">
                <aside class="sidebar">
                    
                    <div class="toc-sidebar">
                        <h5 class="toc-title"><i class="fas fa-list"></i> 目录</h5>
                        <div class="toc-content">
                            <div class="toc">
<ul>
<li><a href="#moe5">MoE环游记：5、均匀分布的反思</a><ul>
<li><a href="#_1">共享专家</a></li>
<li><a href="#_2">多种理解</a></li>
<li><a href="#_3">比例因子</a></li>
<li><a href="#_4">非均匀性</a></li>
<li><a href="#_5">细颗粒度</a></li>
<li><a href="#_6">文章小结</a></li>
<li><a href="#_7">公式推导与注释</a><ul>
<li><a href="#1">第1部分：核心理论、公理与历史基础</a></li>
<li><a href="#2">第2部分：严谨的核心数学推导</a></li>
<li><a href="#moe">一、MoE基础概率框架</a></li>
<li><a href="#_8">二、负载均衡的数学理论</a></li>
<li><a href="#shared-expert">三、Shared Expert的数学建模</a></li>
<li><a href="#_9">四、比例因子的统计推导</a></li>
<li><a href="#_10">五、均匀分布的非最优性</a></li>
<li><a href="#fine-grained-expert">六、Fine-Grained Expert的组合数学</a></li>
<li><a href="#_11">七、负载均衡的辅助损失</a></li>
<li><a href="#_12">八、实际系统中的约束</a></li>
<li><a href="#_13">九、数值示例与模拟</a></li>
<li><a href="#_14">十、实践建议与设计原则</a></li>
<li><a href="#_15">十一、理论的局限性与开放问题</a></li>
<li><a href="#_16">十二、总结</a></li>
<li><a href="#3">第3部分：数学直觉、多角度解释与类比</a></li>
<li><a href="#4">第4部分：方法论变体、批判性比较与优化</a></li>
<li><a href="#5">第5部分：学习路线图与未来展望</a></li>
<li><a href="#_18">总结</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>

                        </div>
                        <div class="toc-actions">
                            <button class="btn btn-sm btn-outline-secondary" onclick="expandAll()">
                                <i class="fas fa-expand"></i> 全部展开
                            </button>
                            <button class="btn btn-sm btn-outline-secondary" onclick="collapseAll()">
                                <i class="fas fa-compress"></i> 全部折叠
                            </button>
                        </div>
                    </div>
                    

                    <!-- Back to Top Button -->
                    <button id="backToTop" class="back-to-top" title="回到顶部">
                        <i class="fas fa-arrow-up"></i>
                    </button>
                </aside>
            </div>
        </div>
    </article>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>
                博客来源: <a href="https://spaces.ac.cn" target="_blank">科学空间</a> |
                内容经过整理并添加详细数学推导
            </p>
            <p>
                Powered by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>
            </p>
        </div>
    </footer>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>

    <!-- Syntax highlighting -->
    <script>hljs.highlightAll();</script>

    <!-- Back to top functionality -->
    <script>
        // Show/hide back to top button based on scroll position
        window.addEventListener('scroll', function() {
            const backToTop = document.getElementById('backToTop');
            if (window.pageYOffset > 300) {
                backToTop.classList.add('show');
            } else {
                backToTop.classList.remove('show');
            }
        });

        // Smooth scroll to top
        document.getElementById('backToTop').addEventListener('click', function() {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        });

        // Sticky TOC sidebar
        window.addEventListener('scroll', function() {
            const sidebar = document.querySelector('.sidebar');
            if (!sidebar) return;

            const sidebarTop = sidebar.offsetTop;
            const scrollTop = window.pageYOffset;

            if (scrollTop > sidebarTop - 20) {
                sidebar.classList.add('sticky');
            } else {
                sidebar.classList.remove('sticky');
            }
        });
    </script>
</body>
</html>