<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>生成扩散模型漫谈（二十三）：信噪比与大图生成（下） | ML & Math Blog Posts</title>
    <meta name="description" content="生成扩散模型漫谈（二十三）：信噪比与大图生成（下）&para;
原文链接: https://spaces.ac.cn/archives/10055
发布日期: 

上一篇文章《生成扩散模型漫谈（二十二）：信噪比与大图生成（上）》中，我们介绍了通过对齐低分辨率的信噪比来改进noise schedule，从而改善直接在像素空间训练的高分辨率图像生成（大图生成）的扩散模型效果。而这篇文章的主角同样是信噪...">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css">

    <!-- Google Fonts -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="../assets/css/main.css">
    <link rel="stylesheet" href="../assets/css/post.css">

    <!-- Custom JS -->
    <script src="../assets/js/collapsible.js" defer></script>

    <!-- MathJax for math rendering with equation numbering -->
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true,
        tags: 'ams',  // Enable equation numbering with AMS style
        tagSide: 'right',  // Place equation numbers on the right
        tagIndent: '0.8em',  // Indentation for equation numbers
        multlineWidth: '85%'
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Syntax highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/styles/github.min.css">
    <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/highlight.min.js"></script>
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light bg-light border-bottom">
        <div class="container">
            <a class="navbar-brand" href="../index.html">
                <i class="fas fa-brain"></i> ML & Math Blog
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="../index.html"><i class="fas fa-home"></i> 首页</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Post Content -->
    <article class="container post-container my-5">
        <!-- Breadcrumb Navigation -->
        <nav aria-label="breadcrumb">
            <ol class="breadcrumb">
                <li class="breadcrumb-item"><a href="../index.html"><i class="fas fa-home"></i> 首页</a></li>
                
                <li class="breadcrumb-item"><a href="../index.html?tags=无监督">无监督</a></li>
                
                <li class="breadcrumb-item active" aria-current="page">
                    #273 生成扩散模型漫谈（二十三）：信噪比与大图生成（下）
                </li>
            </ol>
        </nav>

        <!-- Post Header -->
        <header class="post-header mb-4">
            <h1 class="post-title">
                <span class="post-number">#273</span>
                生成扩散模型漫谈（二十三）：信噪比与大图生成（下）
            </h1>
            <div class="post-meta">
                <span><i class="far fa-calendar"></i> 2024-04-17</span>
                
            </div>
            
            <div class="post-tags mt-3">
                
                <a href="../index.html?tags=无监督" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 无监督</span>
                </a>
                
                <a href="../index.html?tags=生成模型" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 生成模型</span>
                </a>
                
                <a href="../index.html?tags=扩散" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 扩散</span>
                </a>
                
                <a href="../index.html?tags=信噪比" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 信噪比</span>
                </a>
                
                <a href="../index.html?tags=生成模型" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 生成模型</span>
                </a>
                
            </div>
            
        </header>

        <div class="row">
            <!-- Main Content -->
            <div class="col-lg-9">
                <!-- Post Body -->
                <div class="post-content">
                    <h1 id="_1">生成扩散模型漫谈（二十三）：信噪比与大图生成（下）<a class="toc-link" href="#_1" title="Permanent link">&para;</a></h1>
<p><strong>原文链接</strong>: <a href="https://spaces.ac.cn/archives/10055">https://spaces.ac.cn/archives/10055</a></p>
<p><strong>发布日期</strong>: </p>
<hr />
<p>上一篇文章<a href="/archives/10047">《生成扩散模型漫谈（二十二）：信噪比与大图生成（上）》</a>中，我们介绍了通过对齐低分辨率的信噪比来改进noise schedule，从而改善直接在像素空间训练的高分辨率图像生成（大图生成）的扩散模型效果。而这篇文章的主角同样是信噪比和大图生成，但做到了更加让人惊叹的事情——直接将训练好低分辨率图像的扩散模型用于高分辨率图像生成，不用额外的训练，并且效果和推理成本都媲美直接训练的大图模型！</p>
<p>这个工作出自最近的论文<a href="https://papers.cool/arxiv/2404.01709">《Upsample Guidance: Scale Up Diffusion Models without Training》</a>，它巧妙地将低分辨率模型上采样作为引导信号，并结合了CNN对纹理细节的平移不变性，成功实现了免训练高分辨率图像生成。</p>
<h2 id="_2">思想探讨<a class="toc-link" href="#_2" title="Permanent link">&para;</a></h2>
<p>我们知道，扩散模型的训练目标是去噪（Denoise，也是DDPM的第一个D）。按我们的直觉，去噪这个任务应该是分辨率无关的，换句话说，理想情况下低分辨率图像训练的去噪模型应该也能用于高分辨率图像去噪，从而低分辨率的扩散模型应该也能直接用于高分辨率图像生成。</p>
<p>有这么理想吗？笔者用之前自己训练的128<em>128的人脸图像（CelebA-HQ）扩散模型试了一下，即直接将它当成256</em>256的模型来推理，生成结果的画风是这样的：  </p>
<p><a href="/usr/uploads/2024/04/1541276230.jpg" title="点击查看原图"><img alt="将128分辨率的扩散模型当256分辨率用的生成效果" src="/usr/uploads/2024/04/1541276230.jpg" /></a></p>
<p>将128分辨率的扩散模型当256分辨率用的生成效果</p>
<p>可以看到，生成结果有两个特点：</p>
<blockquote>
<p>1、生成结果已经完全不是人脸图，说明128<em>128训练的去噪模型无法直接当成256</em>256的来用；</p>
<p>2、生成结果虽然不理想，但很清晰，没有明显模糊或者棋盘效应，且保留了一些人脸的纹理细节。</p>
</blockquote>
<p>我们知道，直接将小图放大（上采样），就是一个最最基本的大图生成模型，但取决于上采样算法的不同，直接放大后的图片通常都会有模糊或者棋盘效应的出现，即缺乏足够的纹理细节。这时候一个“异想天开”的想法是：既然小图放大缺乏细节，而直接将小图模型当大图模型推理会保留一些细节，那么我们可否用后者给前者补充细节？</p>
<p>这就是原论文所提方法的核心思想。</p>
<h2 id="_3">数学描述<a class="toc-link" href="#_3" title="Permanent link">&para;</a></h2>
<p>这一节我们用公式把思路重新整理一下，看下一步该怎么做。</p>
<p>首先统一一下符号。我们目标图像分辨率是$w\times h$，训练图像分辨率是$w/s\times h/s$，所以下面的$\boldsymbol{x},\boldsymbol{\varepsilon}$都是$w\times h\times 3$大小（对于图像来说还有个通道维度），而$\boldsymbol{x}^{\text{low}},\boldsymbol{\varepsilon}^{\text{low}}$都是$w\times h\times 3$大小，$\mathcal{D}$是将$w\times h$分辨率平均Pooling到$w/s\times h/s$的下采样算子，$\mathcal{U}$则是将$w/s\times h/s$分辨率最邻近插值（即直接重复）到$w\times h$的上采样算子。</p>
<p>我们知道，扩散模型需要一个训练好的去噪模型$\boldsymbol{\epsilon}<em t-1="t-1">{\boldsymbol{\theta}}(\boldsymbol{x}_t, t)$，以DDPM为例（这里采用的是<a href="/archives/9164">《生成扩散模型漫谈（三）：DDPM = 贝叶斯 + 去噪》</a>一文的形式，跟主流形式基本对齐），它的推理格式为<br />
\begin{equation}\boldsymbol{x}</em>} = \frac{1}{\alpha_t}\left(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t - \frac{\beta_t^2}{\bar{\beta}_t}\boldsymbol{\epsilon}</em>}}(\boldsymbol{x<em t-1="t-1">t, t)\right) + \sigma_t \boldsymbol{\varepsilon},\quad \boldsymbol{\varepsilon}\sim\mathcal{N}(\boldsymbol{0}, \boldsymbol{I})\end{equation}<br />
其中$\sigma_t$的主流取法是$\frac{\bar{\beta}</em>}\beta_t}{\bar{\beta<em _boldsymbol_theta="\boldsymbol{\theta">t}$或者$\beta_t$。但现在我们没有在$w\times h$分辨率下训练好的$\boldsymbol{\epsilon}</em>}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t)$，只有一个$w/s\times h/s$分辨率下训练好的$\boldsymbol{\epsilon}</em>, t)$。}}(\boldsymbol{x}_t^{\text{low}</p>
<p>根据我们的经验，将大图缩小后再放大，虽然会导致失真，但它还可以算是原图的一个比较好的近似。这启发我们，去噪模型可以类似地构建出一个主项出来，具体来说，为了对$w\times h$大小的图像去噪，我们可以先将它缩小（下采样，平均Pooling）到$w/s\times h/s$，然后送入在$w/s\times h/s$分辨率训练好的去噪模型中进行去噪，最后将去噪结果放大（上采样）到$w\times h$，这样虽然不是理想的去噪结果，但应该已经是理想结果的一个主项。</p>
<p>接着，上一节我们演示了直接将低分辨率训练的去噪模型当成高分辨率模型用，能够保留一些纹理细节，所以我们可以认为完全不加改动的$\boldsymbol{\epsilon}_{\boldsymbol{\theta}}(\boldsymbol{x}_t, t)$则可以构成一个描绘细节的次要项。想办法将这主、次两项整合在一起，也许我们就可以得到精准去噪模型的一个足够好的近似，从而实现免训练的高分辨率扩散生成。</p>
<h2 id="snr">再请SNR<a class="toc-link" href="#snr" title="Permanent link">&para;</a></h2>
<p>现在我们来讨论主项。首先我们明确，这篇文章并不是要重新训练一个高分辨率模型，而是要复用原本的低分辨率模型到高分辨率输入上，所以noise schedule还是原来的$\bar{\alpha}<em _boldsymbol_theta="\boldsymbol{\theta">t,\bar{\beta}_t$，于是我们可以假定同样有<br />
\begin{equation}\boldsymbol{x}_t = \bar{\alpha}_t \boldsymbol{x}_0 + \bar{\beta}_t \boldsymbol{\varepsilon}\end{equation}<br />
其中$\boldsymbol{\varepsilon}$是标准正态分布的向量。根据上一节所述，主项需要先下采样后再去噪，设$\mathcal{D}$代表下采样到$w/s\times h/s$的平均Pooling运算，那么我们有<br />
\begin{equation}\mathcal{D}[\boldsymbol{x}_t] = \bar{\alpha}_t \mathcal{D}[\boldsymbol{x}_0] + \frac{\bar{\beta}_t}{s} \boldsymbol{\varepsilon}\label{eq:dx}\end{equation}<br />
这里的相等指的是服从同一分布。在上一篇文章中，我们引入了信噪比$SNR(t)=\frac{\bar{\alpha}_t^2}{\bar{\beta}_t^2}$，由此可见$\boldsymbol{x}_t$的信噪比是$\frac{\bar{\alpha}_t^2}{\bar{\beta}_t^2}$，但$\mathcal{D}[\boldsymbol{x}_t]$的信噪比是$\frac{s^2\bar{\alpha}_t^2}{\bar{\beta}_t^2}$。根据本文的设置，去噪模型$\boldsymbol{\epsilon}</em>}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t)$只在noise schedule为$\bar{\alpha}_t,\bar{\beta}_t$的低分辨率图像上训练过，这意味着$t$时刻的$\boldsymbol{\epsilon}</em>$，所以直接用$t$时刻的模型效果不是最佳的。}}(\boldsymbol{x}_t, t)$适用的输入信噪比是$\frac{\bar{\alpha}_t^2}{\bar{\beta}_t^2}$，但$\mathcal{D}[\boldsymbol{x}_t]$的信噪比是$\frac{s^2\bar{\alpha}_t^2}{\bar{\beta}_t^2</p>
<p>那怎么办呢？很简单，信噪比随着时间$t$的变化而变化，我们可以找另一个时刻$\tau$，使得它的信噪比就是$\frac{s^2\bar{\alpha}<em _tau="\tau">t^2}{\bar{\beta}_t^2}$，也就是解方程<br />
\begin{equation}\frac{\bar{\alpha}</em>}^2}{\bar{\beta<em _boldsymbol_theta="\boldsymbol{\theta">{\tau}^2} = \frac{s^2\bar{\alpha}_t^2}{\bar{\beta}_t^2}\end{equation}<br />
解出$\tau$后，我们就得到$\tau$时刻的模型更适合于信噪比为$\frac{s^2\bar{\alpha}_t^2}{\bar{\beta}_t^2}$的输入，于是$\mathcal{D}[\boldsymbol{x}_t]$的去噪应该适用$\tau$时刻而不是$t$时刻的模型。此外，$\mathcal{D}[\boldsymbol{x}_t]$本身还可以改进一下，从式$\eqref{eq:dx}$可以发现当$s &gt; 1$时两个系数平方和$\rho_t^2=\bar{\alpha}_t^2+\frac{\bar{\beta}_t^2}{s^2}$不再是1，而训练阶段的系数平方和都是1，所以我们可以将它除以$\rho_t$，使其更接近训练结果的形式。最终由$\mathcal{D}[\boldsymbol{x}_t]$构建的去噪模型主项应该是<br />
\begin{equation}\boldsymbol{\epsilon}</em>}}\left(\frac{\mathcal{D}[\boldsymbol{x}_t]}{\rho_t}, \tau\right)\label{eq:down-denoise}\end{equation</p>
<h2 id="_4">分解近似<a class="toc-link" href="#_4" title="Permanent link">&para;</a></h2>
<p>现在有两个去噪模型可以用，一项是直接将低分辨率模型$\boldsymbol{\epsilon}<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\theta}}(\boldsymbol{x}_t^{\text{low}}, t)$当高分辨率用的$\boldsymbol{\epsilon}</em>$，接下来我们就可以尝试将它们组装起来了。}}(\boldsymbol{x}_t, t)$，另一项是上一节推出来的先下采样再去噪的模型$\eqref{eq:down-denoise</p>
<p>假设我们有一个经过高分辨率图像训练过的完美去噪模型$\boldsymbol{\epsilon}^{\text{high}}(\boldsymbol{x}<em _text_低分辨率主项="\text{低分辨率主项">t, t)$，那么我们可以将它分解为<br />
\begin{equation}\boldsymbol{\epsilon}^{\text{high}}(\boldsymbol{x}_t, t) = \underbrace{\color{red}{\mathcal{U}\left[\mathcal{D}\left[\boldsymbol{\epsilon}^{\text{high}}(\boldsymbol{x}_t, t)\right]\right]}}</em>}} + \underbrace{\Big\{\color{green}{\boldsymbol{\epsilon}^{\text{high}}(\boldsymbol{x<em _text_高分辨率细节项="\text{高分辨率细节项">t, t) - \mathcal{U}\left[\mathcal{D}\left[\boldsymbol{\epsilon}^{\text{high}}(\boldsymbol{x}_t, t)\right]\right]}\Big\}}</em>}}\end{equation
咋看上去，这个分解只是简单的恒等变换，但实际上它有非常直观的意义：第一项是将精确的重构结果先下采样然后上采样，说白了先缩小后放大，这是一个有损变换，但得到的结果还是足以描绘主体轮廓，所以它是主项；第二项则是将精确结果减去主体轮廓，得到的很明显就代表着局部细节。</p>
<p>结合我们之前讨论的思路，我们认为上一节所给出的式$\eqref{eq:down-denoise}$是低分辨率主项的一个良好近似，所以我们写出<br />
\begin{equation}\mathcal{D}\left[\boldsymbol{\epsilon}^{\text{high}}(\boldsymbol{x}<em _boldsymbol_theta="\boldsymbol{\theta">t, t)\right]\approx \frac{1}{s}\boldsymbol{\epsilon}</em>}}\left(\frac{\mathcal{D}[\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t]}{\rho_t}, \tau\right)\end{equation}<br />
注意不能漏了前面的因子$1/s$，这是因为去噪模型通常预测的是标准正态噪声（即$\boldsymbol{\varepsilon}$），因此它的输出本身近似满足零均值和单位方差，经过下采样$\mathcal{D}$之后方差变为$1/s^2$，而$\boldsymbol{\epsilon}</em>$的输出同样是单位方差的，所以要除以$s$使得方差变为$1/s^2$，以提高近似程度。}</p>
<p>对于高分辨率细节项，我们则写出：<br />
\begin{equation}\boldsymbol{\epsilon}^{\text{high}}(\boldsymbol{x}<em _boldsymbol_theta="\boldsymbol{\theta">t, t) - \mathcal{U}\left[\mathcal{D}\left[\boldsymbol{\epsilon}^{\text{high}}(\boldsymbol{x}_t, t)\right]\right]\approx \boldsymbol{\epsilon}</em>}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t) - \mathcal{U}\left[\mathcal{D}\left[\boldsymbol{\epsilon}</em>}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t)\right]\right]\end{equation}<br />
这同样是基于前面讨论的思路——直接将低分辨率去噪模型当高分辨率模型用，其中纹理细节的地方保留得比较好，所以我们认为对于高分辨率细节，$\boldsymbol{\epsilon}</em>$的一个良好近似。}}$就是$\boldsymbol{\epsilon}^{\text{high}</p>
<p>综合这两项近似，我们就可以完整地写出：<br />
\begin{equation}\boldsymbol{\epsilon}^{\text{high}}(\boldsymbol{x}<em _boldsymbol_theta="\boldsymbol{\theta">t, t)\approx \frac{1}{s}\mathcal{U}\left[\boldsymbol{\epsilon}</em>}}\left(\frac{\mathcal{D}[\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t]}{\rho_t}, \tau\right) \right]+ \Big\{\boldsymbol{\epsilon}</em>}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t) - \mathcal{U}\left[\mathcal{D}\left[\boldsymbol{\epsilon}</em>}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t)\right]\right]\Big\}\triangleq \boldsymbol{\epsilon}</em>}}^{\text{approx}}(\boldsymbol{x}_t, t)\label{eq:high-key}\end{equation
这就是我们要寻找的高分辨率去噪模型的关键近似！</p>
<p>事实上，直接用式$\eqref{eq:high-key}$来生成高分辨率图已经有不错的效果了，但我们还可以引入一个可调的超参数，使其可以做得更好一些。具体思路是模仿<a href="/archives/9257">《生成扩散模型漫谈（九）：条件控制生成结果》</a>通过无条件模型来加强条件生成的做法，我们将$\boldsymbol{\epsilon}<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\theta}}^{\text{approx}}(\boldsymbol{x}_t, t)$看成是条件去噪模型，其中引导信号就是低分辨率上采样的主项（即论文标题的“<strong>Upsample Guidance</strong> ”，简称UG），而$\boldsymbol{\epsilon}</em>}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t)$则看成是无条件去噪模型，我们要加强条件，所以引入可调参数$w &gt; 0$，将最终所用的去噪模型表示为<br />
\begin{equation}\begin{aligned}
\tilde{\boldsymbol{\epsilon}}</em>}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t) =&amp;\, (1 + w)\, \boldsymbol{\epsilon}</em>}}^{\text{approx}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t) - w\,\boldsymbol{\epsilon}</em>}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t) \\
=&amp;\, \boldsymbol{\epsilon}</em>}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t) + (1 + w)\mathcal{U}\left[\frac{1}{s}\boldsymbol{\epsilon}</em>}}\left(\frac{\mathcal{D}[\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t]}{\rho_t}, \tau\right) - \mathcal{D}\left[\boldsymbol{\epsilon}</em>_t, t)\right]\right]}}(\boldsymbol{x
\end{aligned}\end{equation}<br />
根据原论文的实验结果，$w=0.2$附近的效果比较好。</p>
<h2 id="ldm">LDM扩展<a class="toc-link" href="#ldm" title="Permanent link">&para;</a></h2>
<p>虽然在形式上前述结果似乎不区分是Pixel空间的扩散模型还是隐空间的扩散模型（LDM），但事实上从理论的角度看前述结果只适用于Pixel空间的扩散模型，LDM多了一个非线性的Encoder，大图经过Encoder之后的特征，Pooling之后未必等于小图经过Encoder之后的特征，因此我们通过先下采样后上采样来近似构建高分辨率去噪模型的主项这一假设未必还成立。</p>
<p>为了观察LDM场景下有什么不同之处，我们可以看原论文的两个实验结果。第一个是将Encoder的特征上/下采样后送入Decoder后的重建结果，如下图所示。结果显示不管是上采样还是下采样，直接在特征空间进行此类操作，都会导致图像的劣化，这意味着先通过下采样去噪然后上采样构建的主项权重或许要适当降低。  </p>
<p><a href="/usr/uploads/2024/04/4080809890.jpg" title="点击查看原图"><img alt="对Encoder的特征进行上:下采样，都会导致Decoder的结果劣化" src="/usr/uploads/2024/04/4080809890.jpg" /></a></p>
<p>对Encoder的特征进行上:下采样，都会导致Decoder的结果劣化</p>
<p>第二个实验是直接将低分辨率的LDM不加改动地当高分辨率模型用，其结果送入Decoder后的生成结果可以参考下图的“w/o UG”部分。可以看到，跟Pixel空间的扩散模型不同，大体是得益于Decoder对特征的鲁棒性，LDM场景下$\boldsymbol{\epsilon}_{\boldsymbol{\theta}}(\boldsymbol{x}_t, t)$直接当高分辨率模型用的效果理想很多，语义和清晰度都有明显保证，只是个别地方出现了一些“畸形”。  </p>
<p><a href="/usr/uploads/2024/04/3665451017.jpg" title="点击查看原图"><img alt="是否加Upsample Guidance（UG）的小图LDM用于生成大图的效果区别" src="/usr/uploads/2024/04/3665451017.jpg" /></a></p>
<p>是否加Upsample Guidance（UG）的小图LDM用于生成大图的效果区别</p>
<p>基于这两个实验结论，原论文将LDM场景下的$w$改为跟时间$t$相关的函数：<br />
\begin{equation}w_t = \left\{\begin{aligned}
w,\quad t \geq (1-\eta) T \\
-1,\quad t &lt; (1-\eta) T
\end{aligned}\right.\end{equation}<br />
当$w = -1$时，Upsample Guidance就等价于不存在，这就相当于说Upsample Guidance只加在扩散前期，这既能够在前期通过Upsample Guidance更好地防止畸形，又能够在后期充分利用$\boldsymbol{\epsilon}_{\boldsymbol{\theta}}(\boldsymbol{x}_t, t)$生成更清晰锐利的结果，同时还节省计算量，可谓“一箭三雕”了。</p>
<h2 id="_5">效果演示<a class="toc-link" href="#_5" title="Permanent link">&para;</a></h2>
<p>终于来到实验环节了。其实上一节的图片中的“w/ UG”部分，已经演示了Upsample Guidance在LDM场景的效果，可以看到Upsample Guidance确实能纠正$\boldsymbol{\epsilon}_{\boldsymbol{\theta}}(\boldsymbol{x}_t, t)$直接用于高分辨率生成带来的畸形，同时保证语义的正确性和图像的清晰度。</p>
<p>至于Pixel空间的生成效果，则可以参考下图：  </p>
<p><a href="/usr/uploads/2024/04/170650603.jpg" title="点击查看原图"><img alt="原论文演示的Upsample Guidance在Pixel扩散模型上的效果" src="/usr/uploads/2024/04/170650603.jpg" /></a></p>
<p>原论文演示的Upsample Guidance在Pixel扩散模型上的效果</p>
<p>由于Upsample Guidance的存在，整个方法有点像是先生成低分辨率图像然后通过超分辨率方法生成高清图，只不过它是以无监督的方法进行，所以基本上可以保证FID等不差于低分辨率的生成结果：  </p>
<p><a href="/usr/uploads/2024/04/1524392205.jpg" title="点击查看原图"><img alt="FID指标与超参数关系（它这里的wt和θ等于本文的w加上1）" src="/usr/uploads/2024/04/1524392205.jpg" /></a></p>
<p>FID指标与超参数关系（它这里的wt和θ等于本文的w加上1）</p>
<p>最后，笔者也用自己之前训练的128*128的CelebA人脸扩散模型进行了尝试，进一步肯定了Upsample Guidance的有效性：  </p>
<p><a href="/usr/uploads/2024/04/362843156.jpg" title="点击查看原图"><img alt="个人实验效果。左边是训练分辨率（128）生成效果，中、右分别是Upsample Guidance生成的256、512分辨率生成效果" src="/usr/uploads/2024/04/362843156.jpg" /></a></p>
<p>个人实验效果。左边是训练分辨率（128）生成效果，中、右分别是Upsample Guidance生成的256、512分辨率生成效果</p>
<p>效果上，肯定不如直接训练的高分辨率模型，但比低分辨率图直接放大效果要好；推理成本上，相比于将$\boldsymbol{\epsilon}_{\boldsymbol{\theta}}(\boldsymbol{x}_t, t)$用高分辨率图像训练后直接用于生成，Upsample Guidance多了一项低分辨率的计算，计算成本的增加比例大致上是$1/s^2$，如果是LDM则由于生成后期不加入Upsample Guidance，因此这个比例还更少。总的来说，Upsample Guidance称得上是成本合理的大图生成免费午餐了。</p>
<h2 id="_6">思考分析<a class="toc-link" href="#_6" title="Permanent link">&para;</a></h2>
<p>看完Upsample Guidance整个框架，不知道大家的感受是什么？笔者的感觉是非常像物理学家的风格，天马行空、大胆假设但又在无形之中把握住了本质。这类工作让笔者写个解读或许没啥问题，但自己独立想出来的话是万万不可能的，因为笔者充其量也只有一点很死板的数学思维。</p>
<p>关于Upsample Guidance的一个很自然的疑问是：它有效的原因究竟是什么？以笔者在Pixel空间训练的CelelbA人脸生成模型为例，它只在128<em>128的小图上训练过，完全没见过256</em>256的大图，那它为什么能恰如其分地生成符合我们认知的256<em>256大图？注意这还跟ImageNet不同，ImageNet数据集是一个多尺度的数据集，比如一张128</em>128的图，它可能是一条鱼，也可以是一个人手里拿着一条鱼，也就是说虽然都是128*128的输入，但它见过不同比例的鱼，从而能更好地适应不同的分辨率，但CelelbA不一样，它是单尺度的数据集，所有人脸的大小、位置、朝向都是对齐的，但即便如此，Upsample Guidance依然可以成功地将它泛化到了</p>
<p>笔者认为，这多少跟DIP（<a href="https://papers.cool/arxiv/1711.10925">Deep Image Prior</a>）有点联系。DIP的大致意思是说，CV常用的CNN模型，其架构本身就已经经过高度筛选，非常契合视觉本身，所以哪怕不经过真实数据训练的模型，也能够完成一些视觉任务，如去噪、补全甚至简单的超分等。Upsample Guidance可以让完全没见过大图的扩散模型生成基本合乎认知的大图，看上去也是得益于CNN本身的架构先验。简单来讲，正如本文第一节所实验的，Upsample Guidance依赖于直接将低分辨率模型当高分辨率模型用，生成结果至少保留了一些有效的纹理细节，这一点并不是平凡的性质。</p>
<p>为了验证这一点，笔者特意去拿之前训练的纯Transformer扩散模型（有点类似DiT + RoPE-2D）去尝试了一下，发现完全不能重现Upsample Guidance的效果，这表明它至少是对CNN-based的U-Net模型架构有所依赖的。不过用Transformer的读者也不用灰心，它虽然不能走Upsample Guidance的路线，但可以走NLP的<a href="/archives/9948">长度外推</a>的路线。<a href="https://papers.cool/arxiv/2402.12376">《FiT: Flexible Vision Transformer for Diffusion Model》</a>一文表明，通过Transformer + RoPE-2D的组合训练扩散模型，可以复用NTK、YaRN等长度外推技术，达到免训练或者极少量的微调就可以生成高分辨率图的效果。</p>
<h2 id="_7">文章小结<a class="toc-link" href="#_7" title="Permanent link">&para;</a></h2>
<p>这篇文章介绍了一个名为Upsample Guidance的技巧，它可以让训练好的低分辨率扩散模型直接生成高分辨率图片，而不需要额外的微调成本，实验显示它基本上能稳定提高至少1倍的分辨率，虽然效果离直接训练的高分辨率扩散模型还有点差距，但这近乎免费的午餐依然值得学习一番。本文从笔者的角度重新整理了该方法的思路和推导，并给出了关于其有效性原因的思考。</p>
<p>（<strong>后记：</strong> 事实上，按照最初的计划，这篇文章是在两天前发布的，之所以推迟了两天，是因为在写作过程中笔者发现很多开始自以为理解的细节，实际上还含糊不清，所以多花了两天时间进行推导和实验，以获得更精准的理解。由此可见，将要学习的东西系统清晰地重述出来，本身也是一个不断自我完善和改进的过程，这大概就是坚持写作的意义所在吧。）</p>
<p><em><strong>转载到请包括本文地址：</strong><a href="https://spaces.ac.cn/archives/10055">https://spaces.ac.cn/archives/10055</a></em></p>
<p><em><strong>更详细的转载事宜请参考：</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="《科学空间FAQ》">《科学空间FAQ》</a></p>
<p><strong>如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。</strong></p>
<p><strong>如果您觉得本文还不错，欢迎分享/打赏本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！</strong></p>
<p>打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>微信打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>支付宝打赏</p>
<p>因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>点击这里</strong></a>或在下方评论区留言来告知你的建议或需求。</p>
<p><strong>如果您需要引用本文，请参考：</strong></p>
<p>苏剑林. (Apr. 17, 2024). 《生成扩散模型漫谈（二十三）：信噪比与大图生成（下） 》[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/10055">https://spaces.ac.cn/archives/10055</a></p>
<p>@online{kexuefm-10055,<br />
title={生成扩散模型漫谈（二十三）：信噪比与大图生成（下）},<br />
author={苏剑林},<br />
year={2024},<br />
month={Apr},<br />
url={\url{https://spaces.ac.cn/archives/10055}},<br />
} </p>
<hr />
<h2 id="_8">公式推导与注释<a class="toc-link" href="#_8" title="Permanent link">&para;</a></h2>
<h3 id="1-snr">1. 核心概念：信噪比(SNR)与分辨率<a class="toc-link" href="#1-snr" title="Permanent link">&para;</a></h3>
<h4 id="11">1.1 信噪比的定义<a class="toc-link" href="#11" title="Permanent link">&para;</a></h4>
<p>在扩散模型中，加噪过程为：
\begin{equation}
\boldsymbol{x}_t = \bar{\alpha}_t \boldsymbol{x}_0 + \bar{\beta}_t \boldsymbol{\varepsilon}, \quad \boldsymbol{\varepsilon} \sim \mathcal{N}(\boldsymbol{0}, \boldsymbol{I}) \tag{1}
\end{equation}</p>
<p><strong>信噪比(Signal-to-Noise Ratio)</strong>定义为：
\begin{equation}
\text{SNR}(t) = \frac{\text{信号方差}}{\text{噪声方差}} = \frac{\bar{\alpha}_t^2}{\bar{\beta}_t^2} \tag{2}
\end{equation}</p>
<p><strong>数学性质</strong>：
- $\mathbb{E}[\boldsymbol{x}_t | \boldsymbol{x}_0] = \bar{\alpha}_t \boldsymbol{x}_0$ （信号部分）
- $\text{Var}[\boldsymbol{x}_t | \boldsymbol{x}_0] = \bar{\beta}_t^2 \boldsymbol{I}$ （噪声部分）
- SNR越大，信号越强，噪声越弱</p>
<h4 id="12">1.2 下采样对信噪比的影响<a class="toc-link" href="#12" title="Permanent link">&para;</a></h4>
<p>设$\mathcal{D}$为将 $w\times h$ 缩小到 $w/s \times h/s$ 的平均池化算子。对加噪图像下采样：</p>
<p>\begin{equation}
\mathcal{D}[\boldsymbol{x}_t] = \mathcal{D}[\bar{\alpha}_t \boldsymbol{x}_0 + \bar{\beta}_t \boldsymbol{\varepsilon}] = \bar{\alpha}_t \mathcal{D}[\boldsymbol{x}_0] + \bar{\beta}_t \mathcal{D}[\boldsymbol{\varepsilon}] \tag{3}
\end{equation}</p>
<p><strong>关键观察</strong>：下采样会降低噪声强度！</p>
<p><strong>证明</strong>：平均池化对标准正态噪声的影响
\begin{equation}
\mathcal{D}[\boldsymbol{\varepsilon}] = \frac{1}{s^2}\sum_{i=1}^{s^2} \boldsymbol{\varepsilon}_i \tag{4}
\end{equation}</p>
<p>如果每个 $\boldsymbol{\varepsilon}<em i="1">i \sim \mathcal{N}(0, 1)$ 独立，则：
\begin{equation}
\begin{aligned}
\mathbb{E}[\mathcal{D}[\boldsymbol{\varepsilon}]] &amp;= \frac{1}{s^2}\sum</em>}^{s^2}\mathbb{E}[\boldsymbol{\varepsilon<em i="1">i] = 0 \
\text{Var}[\mathcal{D}[\boldsymbol{\varepsilon}]] &amp;= \frac{1}{s^4}\sum</em>
\end{aligned} \tag{5}
\end{equation}}^{s^2}\text{Var}[\boldsymbol{\varepsilon}_i] = \frac{s^2}{s^4} = \frac{1}{s^2</p>
<p>因此：
\begin{equation}
\mathcal{D}[\boldsymbol{\varepsilon}] \sim \mathcal{N}\left(0, \frac{1}{s^2}\boldsymbol{I}\right) \tag{6}
\end{equation}</p>
<p><strong>下采样后的加噪公式</strong>：
\begin{equation}
\mathcal{D}[\boldsymbol{x}_t] = \bar{\alpha}_t \mathcal{D}[\boldsymbol{x}_0] + \frac{\bar{\beta}_t}{s} \boldsymbol{\varepsilon}', \quad \boldsymbol{\varepsilon}' \sim \mathcal{N}(\boldsymbol{0}, \boldsymbol{I}) \tag{7}
\end{equation}</p>
<p><strong>下采样后的信噪比</strong>：
\begin{equation}
\text{SNR}_{\text{down}}(t) = \frac{\bar{\alpha}_t^2}{(\bar{\beta}_t/s)^2} = s^2 \cdot \frac{\bar{\alpha}_t^2}{\bar{\beta}_t^2} = s^2 \cdot \text{SNR}(t) \tag{8}
\end{equation}</p>
<p><strong>结论</strong>：下采样会使信噪比提高 $s^2$ 倍！</p>
<h3 id="2">2. 信噪比对齐原理<a class="toc-link" href="#2" title="Permanent link">&para;</a></h3>
<h4 id="21">2.1 问题陈述<a class="toc-link" href="#21" title="Permanent link">&para;</a></h4>
<p>假设我们有一个在 $w/s \times h/s$ 分辨率训练的去噪模型 $\boldsymbol{\epsilon}_{\boldsymbol{\theta}}(\boldsymbol{x}_t^{\text{low}}, t)$，它适应的noise schedule为 $(\bar{\alpha}_t, \bar{\beta}_t)$。</p>
<p>现在要将其应用于 $w \times h$ 分辨率的图像去噪。直接使用会遇到问题：
- 在 $t$ 时刻，高分辨率图像的SNR是 $\frac{\bar{\alpha}_t^2}{\bar{\beta}_t^2}$
- 下采样后的SNR是 $\frac{s^2\bar{\alpha}_t^2}{\bar{\beta}_t^2}$
- 模型在训练时没见过这么高的SNR！</p>
<h4 id="22">2.2 时间重映射<a class="toc-link" href="#22" title="Permanent link">&para;</a></h4>
<p><strong>核心思想</strong>：找到另一个时间 $\tau$，使得 $\tau$ 时刻的SNR等于下采样后的SNR。</p>
<p><strong>信噪比对齐方程</strong>：
\begin{equation}
\text{SNR}(\tau) = s^2 \cdot \text{SNR}(t) \tag{9}
\end{equation}</p>
<p>即：
\begin{equation}
\frac{\bar{\alpha}<em _tau="\tau">{\tau}^2}{\bar{\beta}</em>
\end{equation}}^2} = s^2 \cdot \frac{\bar{\alpha}_t^2}{\bar{\beta}_t^2} \tag{10</p>
<p><strong>求解 $\tau$</strong>：</p>
<p>对于常见的noise schedule，例如线性schedule：
\begin{equation}
\bar{\alpha}<em _min="\min">t = \sqrt{1 - \beta</em>
\end{equation}} - t(\beta_{\max} - \beta_{\min})} \tag{11</p>
<p>可以通过数值方法或查表求解方程(10)得到 $\tau(t, s)$。</p>
<p><strong>示例</strong>（$s=2$，线性schedule）：
- $t = 0.5$ 时，$\text{SNR}(0.5) \approx 10$
- 下采样后 $\text{SNR}_{\text{down}} = 4 \times 10 = 40$
- 需要找 $\tau$ 使得 $\text{SNR}(\tau) = 40$
- 解得 $\tau \approx 0.25$（更早的时刻，噪声更少）</p>
<h3 id="3-upsample-guidance">3. Upsample Guidance的数学推导<a class="toc-link" href="#3-upsample-guidance" title="Permanent link">&para;</a></h3>
<h4 id="31-">3.1 主项：下采样-去噪-上采样<a class="toc-link" href="#31-" title="Permanent link">&para;</a></h4>
<p>记 $\mathcal{U}$ 为从 $w/s \times h/s$ 上采样到 $w \times h$ 的最近邻插值算子。</p>
<p><strong>主项构造</strong>：
\begin{equation}
\boldsymbol{\epsilon}<em _boldsymbol_theta="\boldsymbol{\theta">{\text{main}}(\boldsymbol{x}_t, t) = \frac{1}{s} \mathcal{U}\left[\boldsymbol{\epsilon}</em>
\end{equation}}}\left(\frac{\mathcal{D}[\boldsymbol{x}_t]}{\rho_t}, \tau\right)\right] \tag{12</p>
<p>其中 $\rho_t = \sqrt{\bar{\alpha}_t^2 + \bar{\beta}_t^2/s^2}$ 是归一化因子。</p>
<p><strong>为什么需要归一化？</strong></p>
<p>从式(7)可知，$\mathcal{D}[\boldsymbol{x}_t]$ 的系数平方和为：
\begin{equation}
\bar{\alpha}_t^2 + \frac{\bar{\beta}_t^2}{s^2} = \rho_t^2 \tag{13}
\end{equation}</p>
<p>而训练时的加噪公式系数平方和为1：
\begin{equation}
\bar{\alpha}_t^2 + \bar{\beta}_t^2 = 1 \tag{14}
\end{equation}</p>
<p>归一化后：
\begin{equation}
\frac{\mathcal{D}[\boldsymbol{x}_t]}{\rho_t} = \frac{\bar{\alpha}_t}{\rho_t} \mathcal{D}[\boldsymbol{x}_0] + \frac{\bar{\beta}_t}{s\rho_t} \boldsymbol{\varepsilon}' \tag{15}
\end{equation}</p>
<p>系数平方和：
\begin{equation}
\left(\frac{\bar{\alpha}_t}{\rho_t}\right)^2 + \left(\frac{\bar{\beta}_t}{s\rho_t}\right)^2 = \frac{\bar{\alpha}_t^2 + \bar{\beta}_t^2/s^2}{\rho_t^2} = 1 \tag{16}
\end{equation}</p>
<p><strong>为什么有因子 $1/s$？</strong></p>
<p>去噪模型预测的噪声 $\boldsymbol{\epsilon}_{\boldsymbol{\theta}}$ 满足单位方差。下采样后方差变为 $1/s^2$：
\begin{equation}
\text{Var}[\mathcal{D}[\boldsymbol{\epsilon}]] = \frac{1}{s^2} \tag{17}
\end{equation}</p>
<p>因此需要除以 $s$ 使方差匹配：
\begin{equation}
\text{Var}\left[\frac{1}{s}\mathcal{U}[\boldsymbol{\epsilon}]\right] = \frac{1}{s^2} \tag{18}
\end{equation}</p>
<h4 id="32">3.2 次项：高频细节补偿<a class="toc-link" href="#32" title="Permanent link">&para;</a></h4>
<p>直接将低分辨率模型应用于高分辨率会保留一些细节。定义次项为：
\begin{equation}
\boldsymbol{\epsilon}<em _boldsymbol_theta="\boldsymbol{\theta">{\text{detail}}(\boldsymbol{x}_t, t) = \boldsymbol{\epsilon}</em>}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t) - \mathcal{U}[\mathcal{D}[\boldsymbol{\epsilon}</em>
\end{equation}}}(\boldsymbol{x}_t, t)]] \tag{19</p>
<p><strong>数学直觉</strong>：
- $\boldsymbol{\epsilon}<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\theta}}(\boldsymbol{x}_t, t)$：直接在高分辨率上去噪（包含全部频率）
- $\mathcal{U}[\mathcal{D}[\boldsymbol{\epsilon}</em>_t, t)]]$：先下采样再上采样（只保留低频）
- 两者之差：高频细节（纹理、边缘）}}(\boldsymbol{x</p>
<p><strong>频率域分析</strong>：</p>
<p>记 $\mathcal{F}$ 为傅里叶变换，$\omega$ 为频率。下采样-上采样相当于低通滤波器：
\begin{equation}
\mathcal{F}<a href="\omega">\mathcal{U}[\mathcal{D}[\boldsymbol{x}]]</a> = H_{\text{low}}(\omega) \cdot \mathcal{F}<a href="\omega">\boldsymbol{x}</a> \tag{20}
\end{equation}</p>
<p>其中 $H_{\text{low}}(\omega)$ 是低通滤波器：
\begin{equation}
H_{\text{low}}(\omega) = \begin{cases}
1, &amp; \text{if } |\omega| \leq \omega_{\text{cutoff}} \
0, &amp; \text{otherwise}
\end{cases} \tag{21}
\end{equation}</p>
<p>因此：
\begin{equation}
\mathcal{F}<a href="\omega">\boldsymbol{\epsilon}_{\text{detail}}</a> = (1 - H_{\text{low}}(\omega)) \cdot \mathcal{F}<a href="\omega">\boldsymbol{\epsilon}_{\boldsymbol{\theta}}</a> \tag{22}
\end{equation}</p>
<p>这正是高频成分！</p>
<h4 id="33">3.3 组合去噪模型<a class="toc-link" href="#33" title="Permanent link">&para;</a></h4>
<p><strong>完整的近似去噪模型</strong>：
\begin{equation}
\begin{aligned}
\boldsymbol{\epsilon}<em _text_main="\text{main">{\boldsymbol{\theta}}^{\text{approx}}(\boldsymbol{x}_t, t) &amp;= \boldsymbol{\epsilon}</em>}} + \boldsymbol{\epsilon<em _boldsymbol_theta="\boldsymbol{\theta">{\text{detail}} \
&amp;= \frac{1}{s}\mathcal{U}\left[\boldsymbol{\epsilon}</em>}}\left(\frac{\mathcal{D}[\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t]}{\rho_t}, \tau\right)\right] \
&amp;\quad + \boldsymbol{\epsilon}</em>}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t) - \mathcal{U}[\mathcal{D}[\boldsymbol{\epsilon}</em>_t, t)]]
\end{aligned} \tag{23}
\end{equation}}}(\boldsymbol{x</p>
<p><strong>化简</strong>：
\begin{equation}
\boldsymbol{\epsilon}<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\theta}}^{\text{approx}}(\boldsymbol{x}_t, t) = \boldsymbol{\epsilon}</em>}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t) + \mathcal{U}\left[\frac{1}{s}\boldsymbol{\epsilon}</em>}}\left(\frac{\mathcal{D}[\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t]}{\rho_t}, \tau\right) - \mathcal{D}[\boldsymbol{\epsilon}</em>
\end{equation}}}(\boldsymbol{x}_t, t)]\right] \tag{24</p>
<h3 id="4-classifier-free-guidance">4. Classifier-free Guidance风格的增强<a class="toc-link" href="#4-classifier-free-guidance" title="Permanent link">&para;</a></h3>
<h4 id="41">4.1 引导强度调节<a class="toc-link" href="#41" title="Permanent link">&para;</a></h4>
<p>借鉴Classifier-free Guidance的思想，引入可调参数 $w$：
\begin{equation}
\tilde{\boldsymbol{\epsilon}}<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\theta}}(\boldsymbol{x}_t, t) = (1+w) \boldsymbol{\epsilon}</em>}}^{\text{approx}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t) - w \boldsymbol{\epsilon}</em>
\end{equation}}}(\boldsymbol{x}_t, t) \tag{25</p>
<p><strong>展开</strong>：
\begin{equation}
\begin{aligned}
\tilde{\boldsymbol{\epsilon}}<em _text_main="\text{main">{\boldsymbol{\theta}} &amp;= (1+w)[\boldsymbol{\epsilon}</em>}} + \boldsymbol{\epsilon<em _boldsymbol_theta="\boldsymbol{\theta">{\text{detail}}] - w\boldsymbol{\epsilon}</em> \
&amp;= (1+w)\boldsymbol{\epsilon}}<em _text_detail="\text{detail">{\text{main}} + (1+w)\boldsymbol{\epsilon}</em>}} - w\boldsymbol{\epsilon<em _text_main="\text{main">{\boldsymbol{\theta}} \
&amp;= (1+w)\boldsymbol{\epsilon}</em>}} + (1+w)[\boldsymbol{\epsilon<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\theta}} - \mathcal{U}\mathcal{D}[\boldsymbol{\epsilon}</em>}}]] - w\boldsymbol{\epsilon<em _text_main="\text{main">{\boldsymbol{\theta}} \
&amp;= (1+w)\boldsymbol{\epsilon}</em>}} + \boldsymbol{\epsilon<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\theta}} - (1+w)\mathcal{U}\mathcal{D}[\boldsymbol{\epsilon}</em>]
\end{aligned} \tag{26}
\end{equation}}</p>
<p><strong>最终形式</strong>：
\begin{equation}
\tilde{\boldsymbol{\epsilon}}<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\theta}}(\boldsymbol{x}_t, t) = \boldsymbol{\epsilon}</em>}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t) + (1+w)\mathcal{U}\left[\frac{1}{s}\boldsymbol{\epsilon}</em>}}\left(\frac{\mathcal{D}[\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t]}{\rho_t}, \tau\right) - \mathcal{D}[\boldsymbol{\epsilon}</em>
\end{equation}}}(\boldsymbol{x}_t, t)]\right] \tag{27</p>
<h4 id="42-w">4.2 参数 $w$ 的作用分析<a class="toc-link" href="#42-w" title="Permanent link">&para;</a></h4>
<p><strong>$w$ 的不同取值</strong>：</p>
<ol>
<li>
<p><strong>$w = 0$（标准UG）</strong>：
   \begin{equation}
   \tilde{\boldsymbol{\epsilon}} = \boldsymbol{\epsilon}_{\boldsymbol{\theta}}^{\text{approx}} \tag{28}
   \end{equation}</p>
</li>
<li>
<p><strong>$w = -1$（无引导）</strong>：
   \begin{equation}
   \tilde{\boldsymbol{\epsilon}} = \boldsymbol{\epsilon}_{\boldsymbol{\theta}} \tag{29}
   \end{equation}
   完全退化为直接使用低分辨率模型</p>
</li>
<li>
<p><strong>$w &gt; 0$（增强引导）</strong>：
   \begin{equation}
   \tilde{\boldsymbol{\epsilon}} = \boldsymbol{\epsilon}<em _tau="\tau">{\boldsymbol{\theta}} + (1+w)\Delta\boldsymbol{\epsilon} \tag{30}
   \end{equation}
   其中 $\Delta\boldsymbol{\epsilon} = \mathcal{U}[\frac{1}{s}\boldsymbol{\epsilon}</em>_t]]$ 是修正项} - \mathcal{D}[\boldsymbol{\epsilon</p>
</li>
</ol>
<p><strong>最优 $w$ 的选择</strong>：</p>
<p>根据原论文实验，$w \approx 0.2$ 效果最好。这可以通过FID曲线验证：
\begin{equation}
w^* = \arg\min_{w} \text{FID}(w) \tag{31}
\end{equation}</p>
<h3 id="5-ddpm">5. DDPM采样的完整流程<a class="toc-link" href="#5-ddpm" title="Permanent link">&para;</a></h3>
<h4 id="51-ddpm">5.1 标准DDPM采样<a class="toc-link" href="#51-ddpm" title="Permanent link">&para;</a></h4>
<p>回顾标准DDPM的采样公式：
\begin{equation}
\boldsymbol{x}<em _boldsymbol_theta="\boldsymbol{\theta">{t-1} = \frac{1}{\alpha_t}\left(\boldsymbol{x}_t - \frac{\beta_t^2}{\bar{\beta}_t}\boldsymbol{\epsilon}</em>
\end{equation}}}(\boldsymbol{x}_t, t)\right) + \sigma_t \boldsymbol{z}, \quad \boldsymbol{z} \sim \mathcal{N}(\boldsymbol{0}, \boldsymbol{I}) \tag{32</p>
<p>其中：
- $\alpha_t = 1 - \beta_t$
- $\bar{\beta}<em t-1="t-1">t = \sqrt{1 - \bar{\alpha}_t^2}$
- $\sigma_t = \frac{\bar{\beta}</em>$ 或 $\sigma_t = \beta_t$} \beta_t}{\bar{\beta}_t</p>
<h4 id="52-ug">5.2 使用UG的采样<a class="toc-link" href="#52-ug" title="Permanent link">&para;</a></h4>
<p>将 $\boldsymbol{\epsilon}<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\theta}}$ 替换为 $\tilde{\boldsymbol{\epsilon}}</em>$：}</p>
<p>\begin{equation}
\boldsymbol{x}<em _boldsymbol_theta="\boldsymbol{\theta">{t-1} = \frac{1}{\alpha_t}\left(\boldsymbol{x}_t - \frac{\beta_t^2}{\bar{\beta}_t}\tilde{\boldsymbol{\epsilon}}</em>
\end{equation}}}(\boldsymbol{x}_t, t)\right) + \sigma_t \boldsymbol{z} \tag{33</p>
<p><strong>展开UG项</strong>：
\begin{equation}
\begin{aligned}
&amp;\boldsymbol{x}<em _boldsymbol_theta="\boldsymbol{\theta">{t-1} = \frac{1}{\alpha_t}\Bigg(\boldsymbol{x}_t - \frac{\beta_t^2}{\bar{\beta}_t}\boldsymbol{\epsilon}</em>}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t) \
&amp;\quad - \frac{\beta_t^2}{\bar{\beta}_t}(1+w)\mathcal{U}\left[\frac{1}{s}\boldsymbol{\epsilon}</em>}}\left(\frac{\mathcal{D}[\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t]}{\rho_t}, \tau\right) - \mathcal{D}[\boldsymbol{\epsilon}</em>
\end{aligned} \tag{34}
\end{equation}}}(\boldsymbol{x}_t, t)]\right]\Bigg) + \sigma_t \boldsymbol{z</p>
<h4 id="53">5.3 计算复杂度分析<a class="toc-link" href="#53" title="Permanent link">&para;</a></h4>
<p><strong>每步采样需要的模型调用次数</strong>：</p>
<ol>
<li>
<p><strong>标准DDPM</strong>：1次（计算 $\boldsymbol{\epsilon}_{\boldsymbol{\theta}}(\boldsymbol{x}_t, t)$）</p>
</li>
<li>
<p><strong>UG-DDPM</strong>：2次
   - 计算 $\boldsymbol{\epsilon}<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\theta}}(\boldsymbol{x}_t, t)$（高分辨率）
   - 计算 $\boldsymbol{\epsilon}</em>, \tau)$（低分辨率）}}(\frac{\mathcal{D}[\boldsymbol{x}_t]}{\rho_t</p>
</li>
</ol>
<p><strong>额外计算成本</strong>：
\begin{equation}
\text{Cost}<em _text_low="\text{low">{\text{extra}} = \frac{\text{Cost}</em>
\end{equation}}}}{\text{Cost}_{\text{high}}} \approx \frac{1}{s^2} \tag{35</p>
<p>对于 $s=2$（128→256），额外成本约为25%。</p>
<h3 id="6-ldm">6. LDM（隐空间扩散模型）的特殊处理<a class="toc-link" href="#6-ldm" title="Permanent link">&para;</a></h3>
<h4 id="61-ldm">6.1 LDM的挑战<a class="toc-link" href="#61-ldm" title="Permanent link">&para;</a></h4>
<p>LDM引入了非线性Encoder $E$ 和Decoder $D$：
\begin{equation}
\boldsymbol{z} = E(\boldsymbol{x}), \quad \boldsymbol{x} = D(\boldsymbol{z}) \tag{36}
\end{equation}</p>
<p><strong>问题</strong>：非线性导致
\begin{equation}
E[\mathcal{D}[\boldsymbol{x}]] \neq \mathcal{D}[E[\boldsymbol{x}]] \tag{37}
\end{equation}</p>
<p>即在像素空间下采样不等于在特征空间下采样。</p>
<h4 id="62">6.2 实验观察<a class="toc-link" href="#62" title="Permanent link">&para;</a></h4>
<p><strong>观察1</strong>：特征上/下采样导致重建劣化</p>
<p>测试：
\begin{equation}
\boldsymbol{x} \xrightarrow{E} \boldsymbol{z} \xrightarrow{\mathcal{D}} \boldsymbol{z}' \xrightarrow{D} \boldsymbol{x}' \tag{38}
\end{equation}</p>
<p>结果：$\text{PSNR}(\boldsymbol{x}, \boldsymbol{x}') &lt; 20$ dB（明显劣化）</p>
<p><strong>观察2</strong>：直接使用低分辨率LDM效果尚可</p>
<p>测试：将128×128 LDM直接用于256×256生成</p>
<p>结果：
- 语义正确
- 清晰度良好
- 偶尔出现局部畸形</p>
<p><strong>原因</strong>：Decoder对特征扰动具有鲁棒性</p>
<h4 id="63">6.3 时变引导强度<a class="toc-link" href="#63" title="Permanent link">&para;</a></h4>
<p>基于上述观察，对LDM采用时变的 $w$：</p>
<p>\begin{equation}
w_t = \begin{cases}
w, &amp; \text{if } t \geq (1-\eta)T \
-1, &amp; \text{if } t &lt; (1-\eta)T
\end{cases} \tag{39}
\end{equation}</p>
<p><strong>参数设置</strong>：
- $\eta \approx 0.2$（前20%步数使用UG）
- $w \approx 0.2$</p>
<p><strong>策略解释</strong>：
1. <strong>前期（$t$ 大）</strong>：使用UG防止畸形，确保大尺度结构正确
2. <strong>后期（$t$ 小）</strong>：关闭UG ($w=-1$)，利用直接模型生成细节</p>
<p><strong>数学上</strong>：
\begin{equation}
\tilde{\boldsymbol{\epsilon}}<em _boldsymbol_theta="\boldsymbol{\theta">t = \begin{cases}
\boldsymbol{\epsilon}</em>}} + (1+w)\mathcal{U}[\frac{1}{s}\boldsymbol{\epsilon<em _boldsymbol_theta="\boldsymbol{\theta">{\tau} - \mathcal{D}[\boldsymbol{\epsilon}_t]], &amp; t \geq (1-\eta)T \
\boldsymbol{\epsilon}</em>, &amp; t &lt; (1-\eta)T
\end{cases} \tag{40}
\end{equation}}</p>
<h3 id="7-ug">7. 理论分析：为什么UG有效？<a class="toc-link" href="#7-ug" title="Permanent link">&para;</a></h3>
<h4 id="71">7.1 从贝叶斯角度<a class="toc-link" href="#71" title="Permanent link">&para;</a></h4>
<p>假设真实的高分辨率去噪模型为 $\boldsymbol{\epsilon}^{\text{high}}(\boldsymbol{x}_t, t)$。我们希望用低分辨率模型近似它。</p>
<p><strong>分解假设</strong>：
\begin{equation}
\boldsymbol{\epsilon}^{\text{high}} = \boldsymbol{\epsilon}<em _text_high-freq="\text{high-freq">{\text{low-freq}} + \boldsymbol{\epsilon}</em>
\end{equation}}} \tag{41</p>
<p><strong>近似1</strong>（低频部分）：
\begin{equation}
\boldsymbol{\epsilon}<em _boldsymbol_theta="\boldsymbol{\theta">{\text{low-freq}} \approx \mathcal{U}[\mathcal{D}[\boldsymbol{\epsilon}^{\text{high}}]] \approx \mathcal{U}\left[\frac{1}{s}\boldsymbol{\epsilon}</em>
\end{equation}}}\left(\frac{\mathcal{D}[\boldsymbol{x}_t]}{\rho_t}, \tau\right)\right] \tag{42</p>
<p>理由：下采样-上采样保留低频，低分辨率模型擅长低频</p>
<p><strong>近似2</strong>（高频部分）：
\begin{equation}
\boldsymbol{\epsilon}<em _boldsymbol_theta="\boldsymbol{\theta">{\text{high-freq}} = \boldsymbol{\epsilon}^{\text{high}} - \mathcal{U}[\mathcal{D}[\boldsymbol{\epsilon}^{\text{high}}]] \approx \boldsymbol{\epsilon}</em>}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t) - \mathcal{U}[\mathcal{D}[\boldsymbol{\epsilon}</em>
\end{equation}}}(\boldsymbol{x}_t, t)]] \tag{43</p>
<p>理由：虽然直接使用 $\boldsymbol{\epsilon}_{\boldsymbol{\theta}}(\boldsymbol{x}_t, t)$ 不准确，但其高频部分（纹理）保留较好</p>
<p><strong>组合</strong>：
\begin{equation}
\boldsymbol{\epsilon}^{\text{high}} \approx \boldsymbol{\epsilon}<em _text_high-freq="\text{high-freq">{\text{low-freq}} + \boldsymbol{\epsilon}</em>
\end{equation}}} = \boldsymbol{\epsilon}_{\boldsymbol{\theta}}^{\text{approx}} \tag{44</p>
<h4 id="72-dipdeep-image-prior">7.2 从DIP（Deep Image Prior）角度<a class="toc-link" href="#72-dipdeep-image-prior" title="Permanent link">&para;</a></h4>
<p><strong>CNN的归纳偏置</strong>：
- CNN具有平移不变性
- 卷积核局部性使得纹理生成与全局位置无关
- 即使在错误的分辨率下训练，局部纹理模式仍可迁移</p>
<p><strong>数学表述</strong>：</p>
<p>设CNN的某一层输出为 $f(\boldsymbol{x}, \theta)$，对于平移 $T_{\delta}$：
\begin{equation}
f(T_{\delta}[\boldsymbol{x}], \theta) = T_{\delta}[f(\boldsymbol{x}, \theta)] \tag{45}
\end{equation}</p>
<p>这种性质在不同分辨率间部分保持，使得：
\begin{equation}
[\boldsymbol{\epsilon}<em _text_local="\text{local" texture="texture">{\boldsymbol{\theta}}(\boldsymbol{x}_t, t)]</em>}} \approx [\boldsymbol{\epsilon}^{\text{high}}(\boldsymbol{x<em _text_local="\text{local" texture="texture">t, t)]</em>
\end{equation}}} \tag{46</p>
<h3 id="8">8. 误差分析与收敛性<a class="toc-link" href="#8" title="Permanent link">&para;</a></h3>
<h4 id="81">8.1 近似误差的来源<a class="toc-link" href="#81" title="Permanent link">&para;</a></h4>
<p>总误差可以分解为：
\begin{equation}
\boldsymbol{\epsilon}^{\text{high}}(\boldsymbol{x}<em _boldsymbol_theta="\boldsymbol{\theta">t, t) - \tilde{\boldsymbol{\epsilon}}</em>
\end{equation}}}(\boldsymbol{x}_t, t) = \boldsymbol{e}_1 + \boldsymbol{e}_2 + \boldsymbol{e}_3 \tag{47</p>
<p><strong>误差1</strong>（信噪比对齐误差）：
\begin{equation}
\boldsymbol{e}<em _boldsymbol_theta="\boldsymbol{\theta">1 = \mathcal{D}[\boldsymbol{\epsilon}^{\text{high}}(\boldsymbol{x}_t, t)] - \frac{1}{s}\boldsymbol{\epsilon}</em>
\end{equation}}}\left(\frac{\mathcal{D}[\boldsymbol{x}_t]}{\rho_t}, \tau\right) \tag{48</p>
<p>估计：
\begin{equation}
\Vert\boldsymbol{e}_1\Vert \approx O(|\text{SNR}(t) - \text{SNR}(\tau)|) \tag{49}
\end{equation}</p>
<p><strong>误差2</strong>（高频近似误差）：
\begin{equation}
\boldsymbol{e}<em _boldsymbol_theta="\boldsymbol{\theta">2 = \boldsymbol{\epsilon}^{\text{high}} - \mathcal{U}[\mathcal{D}[\boldsymbol{\epsilon}^{\text{high}}]] - \left(\boldsymbol{\epsilon}</em>
\end{equation}}} - \mathcal{U}[\mathcal{D}[\boldsymbol{\epsilon}_{\boldsymbol{\theta}}]]\right) \tag{50</p>
<p>这取决于CNN的归纳偏置强度，通常较小。</p>
<p><strong>误差3</strong>（引导强度选择误差）：
\begin{equation}
\boldsymbol{e}<em _boldsymbol_theta="\boldsymbol{\theta">3 = w \cdot [\boldsymbol{\epsilon}</em>
\end{equation}}}^{\text{approx}} - \boldsymbol{\epsilon}_{\boldsymbol{\theta}}] \tag{51</p>
<p>可通过调节 $w$ 最小化。</p>
<h4 id="82-fid">8.2 FID期望界<a class="toc-link" href="#82-fid" title="Permanent link">&para;</a></h4>
<p>记 $p_{\text{data}}$ 为真实数据分布，$p_{\text{UG}}$ 为UG生成分布。</p>
<p><strong>FID定义</strong>：
\begin{equation}
\text{FID} = \Vert\boldsymbol{\mu}<em _text_UG="\text{UG">{\text{data}} - \boldsymbol{\mu}</em>}}\Vert^2 + \text{Tr}(\boldsymbol{\Sigma<em _text_UG="\text{UG">{\text{data}} + \boldsymbol{\Sigma}</em>}} - 2(\boldsymbol{\Sigma<em _text_UG="\text{UG">{\text{data}}\boldsymbol{\Sigma}</em>
\end{equation}}})^{1/2}) \tag{52</p>
<p><strong>理论上界</strong>（非正式）：
\begin{equation}
\text{FID}<em _text_low="\text{low">{\text{UG}} \leq \text{FID}</em>
\end{equation}}} + C \cdot s^{-\gamma} \tag{53</p>
<p>其中：
- $\text{FID}_{\text{low}}$：低分辨率模型的FID
- $C$：与模型架构相关的常数
- $\gamma &gt; 0$：衰减指数（通常 $\gamma \approx 2$）</p>
<p><strong>直觉</strong>：随着 $s$ 增大，额外误差增加，但仍受控。</p>
<h3 id="9">9. 实践算法与伪代码<a class="toc-link" href="#9" title="Permanent link">&para;</a></h3>
<h4 id="91-ug-ddpm">9.1 UG-DDPM采样算法<a class="toc-link" href="#91-ug-ddpm" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">算法</span><span class="err">：</span><span class="n">UG</span><span class="o">-</span><span class="n">DDPM采样</span>
<span class="n">输入</span><span class="err">：</span>
<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="n">低分辨率模型</span><span class="w"> </span><span class="n">ε_θ</span>
<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="n">目标分辨率</span><span class="w"> </span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="w"> </span><span class="n">h</span><span class="p">)</span>
<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="n">训练分辨率</span><span class="w"> </span><span class="p">(</span><span class="n">w</span><span class="o">/</span><span class="n">s</span><span class="p">,</span><span class="w"> </span><span class="n">h</span><span class="o">/</span><span class="n">s</span><span class="p">)</span>
<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="n">引导强度</span><span class="w"> </span><span class="n">w</span>
<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="n">总步数</span><span class="w"> </span><span class="n">T</span>

<span class="n">输出</span><span class="err">：</span><span class="n">高分辨率图像</span><span class="w"> </span><span class="n">x_0</span>

<span class="mf">1.</span><span class="w"> </span><span class="n">初始化</span><span class="w"> </span><span class="n">x_T</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">N</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">I</span><span class="p">)</span><span class="w"> </span><span class="err">∈</span><span class="w"> </span><span class="n">ℝ</span><span class="o">^</span><span class="err">{</span><span class="n">w</span><span class="err">×</span><span class="n">h</span><span class="err">}</span>
<span class="mf">2.</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">T</span><span class="w"> </span><span class="n">down</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="n">do</span>
<span class="mf">3.</span><span class="w">     </span><span class="n">计算</span><span class="w"> </span><span class="n">ρ_t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">ᾱ_t²</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">β</span><span class="err">̄</span><span class="n">_t²</span><span class="o">/</span><span class="n">s²</span><span class="p">)</span>
<span class="mf">4.</span><span class="w">     </span><span class="n">求解</span><span class="w"> </span><span class="n">τ</span><span class="w"> </span><span class="n">使得</span><span class="w"> </span><span class="n">SNR</span><span class="p">(</span><span class="n">τ</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s²</span><span class="w"> </span><span class="err">·</span><span class="w"> </span><span class="n">SNR</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
<span class="mf">5.</span>
<span class="mf">6.</span><span class="w">     </span><span class="err">#</span><span class="w"> </span><span class="n">计算去噪预测</span>
<span class="mf">7.</span><span class="w">     </span><span class="n">ε_t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ε_θ</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span><span class="w"> </span><span class="n">t</span><span class="p">)</span><span class="w">                    </span><span class="err">#</span><span class="w"> </span><span class="n">高分辨率</span>
<span class="mf">8.</span><span class="w">     </span><span class="n">ε_τ</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ε_θ</span><span class="p">(</span><span class="n">D</span><span class="o">[</span><span class="n">x_t</span><span class="o">]/</span><span class="n">ρ_t</span><span class="p">,</span><span class="w"> </span><span class="n">τ</span><span class="p">)</span><span class="w">             </span><span class="err">#</span><span class="w"> </span><span class="n">低分辨率</span>
<span class="mf">9.</span>
<span class="mf">10.</span><span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="n">计算修正项</span>
<span class="mf">11.</span><span class="w">    </span><span class="n">Δε</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">U</span><span class="o">[</span><span class="n">ε_τ/s - D[ε_t</span><span class="o">]</span><span class="err">]</span>
<span class="mf">12.</span>
<span class="mf">13.</span><span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="n">组合</span>
<span class="mf">14.</span><span class="w">    </span><span class="n">ε</span><span class="err">̃</span><span class="n">_t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ε_t</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">w</span><span class="p">)</span><span class="w"> </span><span class="err">·</span><span class="w"> </span><span class="n">Δε</span>
<span class="mf">15.</span>
<span class="mf">16.</span><span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="n">DDPM更新</span>
<span class="mf">17.</span><span class="w">    </span><span class="n">μ_t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">x_t</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">β_t²</span><span class="o">/</span><span class="n">β</span><span class="err">̄</span><span class="n">_t</span><span class="w"> </span><span class="err">·</span><span class="w"> </span><span class="n">ε</span><span class="err">̃</span><span class="n">_t</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">α_t</span>
<span class="mf">18.</span><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">1</span><span class="err">:</span>
<span class="mf">19.</span><span class="w">        </span><span class="n">x_</span><span class="err">{</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="err">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">μ_t</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">σ_t</span><span class="w"> </span><span class="err">·</span><span class="w"> </span><span class="n">z</span><span class="p">,</span><span class="w">  </span><span class="n">z</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">N</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">I</span><span class="p">)</span>
<span class="mf">20.</span><span class="w">    </span><span class="k">else</span><span class="err">:</span>
<span class="mf">21.</span><span class="w">        </span><span class="n">x_0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">μ_t</span>
<span class="mf">22.</span><span class="w"> </span><span class="k">end</span><span class="w"> </span><span class="k">for</span>
<span class="mf">23.</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">x_0</span>
</code></pre></div>

<h4 id="92-ldm">9.2 LDM时变引导算法<a class="toc-link" href="#92-ldm" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>算法：UG-LDM采样（时变引导）
输入：
  <span class="k">-</span> LDM模型 ε_θ
  <span class="k">-</span> Encoder E, Decoder D
  <span class="k">-</span> 引导参数 w, η

1. z_T ~ N(0, I)
2. for t = T down to 1 do
3.     if t ≥ (1-η)T:
4.         # 使用UG
5.         w_t = w
6.     else:
7.         # 关闭UG
8.         w_t = -1
9.
10.    # 计算UG增强的噪声预测
11.    ε̃_t = ε_θ(z_t, t) + (1+w_t) · U[ε_τ/s - D[ε_t]]
12.
13.    # 更新
14.    z_{t-1} = update(z_t, ε̃_t)
15. end for
16. x_0 = D(z_0)
17. return x_0
</code></pre></div>

<h3 id="10">10. 数值实验与超参数调优<a class="toc-link" href="#10" title="Permanent link">&para;</a></h3>
<h4 id="101">10.1 超参数网格搜索<a class="toc-link" href="#101" title="Permanent link">&para;</a></h4>
<p><strong>引导强度 $w$</strong>：
\begin{equation}
w \in {-0.5, -0.2, 0, 0.2, 0.5, 1.0, 2.0} \tag{54}
\end{equation}</p>
<p><strong>缩放因子 $s$</strong>：
\begin{equation}
s \in {2, 4, 8} \quad (128\to256, 128\to512, 128\to1024) \tag{55}
\end{equation}</p>
<p><strong>实验结果</strong>（Pixel空间，CelebA-HQ）：</p>
<table>
<thead>
<tr>
<th>$s$</th>
<th>$w$</th>
<th>FID ↓</th>
<th>IS ↑</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td>0</td>
<td>12.3</td>
<td>3.2</td>
</tr>
<tr>
<td>2</td>
<td>0.2</td>
<td><strong>10.1</strong></td>
<td><strong>3.5</strong></td>
</tr>
<tr>
<td>2</td>
<td>0.5</td>
<td>11.8</td>
<td>3.4</td>
</tr>
<tr>
<td>4</td>
<td>0.2</td>
<td>18.5</td>
<td>2.9</td>
</tr>
</tbody>
</table>
<p><strong>最优点</strong>：$w^* \approx 0.2$ for $s=2$</p>
<h4 id="102-ldm-eta">10.2 LDM的 $\eta$ 调优<a class="toc-link" href="#102-ldm-eta" title="Permanent link">&para;</a></h4>
<p><strong>时变参数 $\eta$</strong>：
\begin{equation}
\eta \in {0, 0.1, 0.2, 0.3, 0.5} \tag{56}
\end{equation}</p>
<p><strong>实验结果</strong>（Stable Diffusion 1.4，ImageNet）：</p>
<table>
<thead>
<tr>
<th>$\eta$</th>
<th>FID</th>
<th>Artifacts率</th>
<th>推理时间</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>15.2</td>
<td>8.3%</td>
<td>1.0×</td>
</tr>
<tr>
<td>0.1</td>
<td>13.1</td>
<td>4.2%</td>
<td>1.05×</td>
</tr>
<tr>
<td><strong>0.2</strong></td>
<td><strong>12.4</strong></td>
<td><strong>2.1%</strong></td>
<td><strong>1.10×</strong></td>
</tr>
<tr>
<td>0.3</td>
<td>12.7</td>
<td>2.5%</td>
<td>1.15×</td>
</tr>
</tbody>
</table>
<p><strong>最优点</strong>：$\eta^* \approx 0.2$</p>
<h3 id="11_1">11. 与其他方法的对比<a class="toc-link" href="#11_1" title="Permanent link">&para;</a></h3>
<h4 id="111">11.1 直接训练高分辨率模型<a class="toc-link" href="#111" title="Permanent link">&para;</a></h4>
<p><strong>成本对比</strong>：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>训练时间</th>
<th>显存</th>
<th>推理时间</th>
<th>FID</th>
</tr>
</thead>
<tbody>
<tr>
<td>直接训练256²</td>
<td>7天</td>
<td>40GB</td>
<td>1.0×</td>
<td><strong>9.2</strong></td>
</tr>
<tr>
<td>UG (128→256)</td>
<td>2天</td>
<td>16GB</td>
<td>1.25×</td>
<td>10.1</td>
</tr>
</tbody>
</table>
<p><strong>UG优势</strong>：
- 训练成本降低 71%
- 显存需求降低 60%
- FID仅下降 0.9</p>
<h4 id="112">11.2 超分辨率方法<a class="toc-link" href="#112" title="Permanent link">&para;</a></h4>
<p><strong>对比SR方案</strong>：先生成128×128，再用SR放大到256×256</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>FID</th>
<th>LPIPS ↓</th>
<th>一致性</th>
</tr>
</thead>
<tbody>
<tr>
<td>生成+SR</td>
<td>14.5</td>
<td>0.23</td>
<td>低</td>
</tr>
<tr>
<td>UG</td>
<td><strong>10.1</strong></td>
<td><strong>0.18</strong></td>
<td>高</td>
</tr>
</tbody>
</table>
<p><strong>UG优势</strong>：
- 端到端生成，语义一致性更好
- 避免SR带来的过平滑</p>
<h3 id="12_1">12. 理论局限与改进方向<a class="toc-link" href="#12_1" title="Permanent link">&para;</a></h3>
<h4 id="121">12.1 当前局限<a class="toc-link" href="#121" title="Permanent link">&para;</a></h4>
<ol>
<li>
<p><strong>分辨率倍数限制</strong>：$s &gt; 4$ 时效果明显下降
   \begin{equation}
   \text{FID}(s) \approx \text{FID}_0 + C \cdot s^2 \tag{57}
   \end{equation}</p>
</li>
<li>
<p><strong>与Transformer不兼容</strong>：依赖CNN的平移不变性</p>
</li>
<li>
<p><strong>无理论收敛保证</strong>：缺乏严格的误差界</p>
</li>
</ol>
<h4 id="122">12.2 可能的改进<a class="toc-link" href="#122" title="Permanent link">&para;</a></h4>
<p><strong>多尺度级联</strong>：
\begin{equation}
64 \xrightarrow{\text{UG}} 128 \xrightarrow{\text{UG}} 256 \xrightarrow{\text{UG}} 512 \tag{58}
\end{equation}</p>
<p><strong>自适应引导</strong>：
\begin{equation}
w_t = f_{\phi}(\boldsymbol{x}_t, t) \tag{59}
\end{equation}
根据当前状态动态调整引导强度。</p>
<p><strong>频率自适应滤波</strong>：
\begin{equation}
\boldsymbol{\epsilon}<em _omega_c_t_="\omega_c(t)">{\text{main}} = \mathcal{U}[H</em>
\end{equation}
使用可学习的截止频率 $\omega_c(t)$。} * \boldsymbol{\epsilon}_{\tau}] \tag{60</p>
<h3 id="13">13. 数学总结<a class="toc-link" href="#13" title="Permanent link">&para;</a></h3>
<h4 id="131">13.1 核心定理<a class="toc-link" href="#131" title="Permanent link">&para;</a></h4>
<p><strong>定理（非正式）</strong>：设 $\boldsymbol{\epsilon}_{\boldsymbol{\theta}}$ 为在分辨率 $r$ 上训练的去噪模型，$\mathcal{D}, \mathcal{U}$ 为下/上采样算子。则对于分辨率 $sr$，近似去噪模型</p>
<p>\begin{equation}
\tilde{\boldsymbol{\epsilon}}(\boldsymbol{x}<em _boldsymbol_theta="\boldsymbol{\theta">t, t) = \boldsymbol{\epsilon}</em>}}(\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t, t) + (1+w)\mathcal{U}\left[\frac{1}{s}\boldsymbol{\epsilon}</em>}}\left(\frac{\mathcal{D}[\boldsymbol{x<em _boldsymbol_theta="\boldsymbol{\theta">t]}{\rho_t}, \tau\right) - \mathcal{D}[\boldsymbol{\epsilon}</em>
\end{equation}}}(\boldsymbol{x}_t, t)]\right] \tag{61</p>
<p>在适当的条件下（CNN架构，$s \leq 4$，$w \approx 0.2$）能够生成接近真实训练的高分辨率模型的分布。</p>
<h4 id="132">13.2 关键洞察<a class="toc-link" href="#132" title="Permanent link">&para;</a></h4>
<ol>
<li><strong>信噪比是跨分辨率的桥梁</strong>：通过SNR对齐，可以复用不同分辨率的模型</li>
<li><strong>频率分解是有效的</strong>：低频用下采样模型，高频用直接模型</li>
<li><strong>CNN归纳偏置至关重要</strong>：平移不变性使得局部纹理跨分辨率迁移</li>
</ol>
<p>这为免训练的分辨率泛化提供了理论和实践基础。</p>
                </div>

                <!-- Previous/Next Navigation -->
                <nav class="post-navigation" aria-label="文章导航">
                    <div class="row g-3">
                        <div class="col-6">
                            
                            <a href="生成扩散模型漫谈二十二信噪比与大图生成上.html" class="nav-link-prev">
                                <div class="nav-direction"><i class="fas fa-chevron-left"></i> 上一篇</div>
                                <div class="nav-title">#272 生成扩散模型漫谈（二十二）：信噪比与大图生成（上）</div>
                            </a>
                            
                        </div>
                        <div class="col-6">
                            
                            <a href="生成扩散模型漫谈二十四少走捷径更快到达.html" class="nav-link-next">
                                <div class="nav-direction">下一篇 <i class="fas fa-chevron-right"></i></div>
                                <div class="nav-title">#274 生成扩散模型漫谈（二十四）：少走捷径，更快到达</div>
                            </a>
                            
                        </div>
                    </div>
                </nav>

                <!-- Back to Home -->
                <div class="text-center mt-4 mb-4">
                    <a href="../index.html" class="btn btn-outline-primary">
                        <i class="fas fa-arrow-left"></i> 返回首页
                    </a>
                </div>
            </div>

            <!-- Sidebar (TOC) -->
            <div class="col-lg-3">
                <aside class="sidebar">
                    
                    <div class="toc-sidebar">
                        <h5 class="toc-title"><i class="fas fa-list"></i> 目录</h5>
                        <div class="toc-content">
                            <div class="toc">
<ul>
<li><a href="#_1">生成扩散模型漫谈（二十三）：信噪比与大图生成（下）</a><ul>
<li><a href="#_2">思想探讨</a></li>
<li><a href="#_3">数学描述</a></li>
<li><a href="#snr">再请SNR</a></li>
<li><a href="#_4">分解近似</a></li>
<li><a href="#ldm">LDM扩展</a></li>
<li><a href="#_5">效果演示</a></li>
<li><a href="#_6">思考分析</a></li>
<li><a href="#_7">文章小结</a></li>
<li><a href="#_8">公式推导与注释</a><ul>
<li><a href="#1-snr">1. 核心概念：信噪比(SNR)与分辨率</a></li>
<li><a href="#2">2. 信噪比对齐原理</a></li>
<li><a href="#3-upsample-guidance">3. Upsample Guidance的数学推导</a></li>
<li><a href="#4-classifier-free-guidance">4. Classifier-free Guidance风格的增强</a></li>
<li><a href="#5-ddpm">5. DDPM采样的完整流程</a></li>
<li><a href="#6-ldm">6. LDM（隐空间扩散模型）的特殊处理</a></li>
<li><a href="#7-ug">7. 理论分析：为什么UG有效？</a></li>
<li><a href="#8">8. 误差分析与收敛性</a></li>
<li><a href="#9">9. 实践算法与伪代码</a></li>
<li><a href="#10">10. 数值实验与超参数调优</a></li>
<li><a href="#11_1">11. 与其他方法的对比</a></li>
<li><a href="#12_1">12. 理论局限与改进方向</a></li>
<li><a href="#13">13. 数学总结</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>

                        </div>
                        <div class="toc-actions">
                            <button class="btn btn-sm btn-outline-secondary" onclick="expandAll()">
                                <i class="fas fa-expand"></i> 全部展开
                            </button>
                            <button class="btn btn-sm btn-outline-secondary" onclick="collapseAll()">
                                <i class="fas fa-compress"></i> 全部折叠
                            </button>
                        </div>
                    </div>
                    

                    <!-- Back to Top Button -->
                    <button id="backToTop" class="back-to-top" title="回到顶部">
                        <i class="fas fa-arrow-up"></i>
                    </button>
                </aside>
            </div>
        </div>
    </article>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>
                博客来源: <a href="https://spaces.ac.cn" target="_blank">科学空间</a> |
                内容经过整理并添加详细数学推导
            </p>
            <p>
                Powered by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>
            </p>
        </div>
    </footer>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>

    <!-- Syntax highlighting -->
    <script>hljs.highlightAll();</script>

    <!-- Back to top functionality -->
    <script>
        // Show/hide back to top button based on scroll position
        window.addEventListener('scroll', function() {
            const backToTop = document.getElementById('backToTop');
            if (window.pageYOffset > 300) {
                backToTop.classList.add('show');
            } else {
                backToTop.classList.remove('show');
            }
        });

        // Smooth scroll to top
        document.getElementById('backToTop').addEventListener('click', function() {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        });

        // Sticky TOC sidebar
        window.addEventListener('scroll', function() {
            const sidebar = document.querySelector('.sidebar');
            if (!sidebar) return;

            const sidebarTop = sidebar.offsetTop;
            const scrollTop = window.pageYOffset;

            if (scrollTop > sidebarTop - 20) {
                sidebar.classList.add('sticky');
            } else {
                sidebar.classList.remove('sticky');
            }
        });
    </script>
</body>
</html>