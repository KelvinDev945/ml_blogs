<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>低秩近似之路（五）：CUR | ML & Math Blog Posts</title>
    <meta name="description" content="低秩近似之路（五）：CUR
原文链接: https://spaces.ac.cn/archives/10662
发布日期: 

再次回到低秩近似之路上。在《低秩近似之路（四）：ID》中，我们介绍了“插值分解（Interpolative Decomposition，ID）”，这是为矩阵$\boldsymbol{M}\in\mathbb{R}^{n\times m}$寻找$\boldsymbol{C}...">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css">

    <!-- Google Fonts -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="../assets/css/main.css">
    <link rel="stylesheet" href="../assets/css/post.css">

    <!-- MathJax for math rendering -->
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Syntax highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/styles/github.min.css">
    <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/highlight.min.js"></script>
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light bg-light border-bottom">
        <div class="container">
            <a class="navbar-brand" href="../index.html">
                <i class="fas fa-brain"></i> ML & Math Blog
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="../index.html"><i class="fas fa-home"></i> 首页</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Post Content -->
    <article class="container post-container my-5">
        <!-- Post Header -->
        <header class="post-header mb-4">
            <h1 class="post-title">低秩近似之路（五）：CUR</h1>
            <div class="post-meta">
                <span><i class="far fa-calendar"></i> </span>
                
                <span class="ms-3">
                    <i class="fas fa-link"></i>
                    <a href="https://spaces.ac.cn/archives/10662" target="_blank">原文链接</a>
                </span>
                
            </div>
            
            <div class="post-tags mt-3">
                
                <span class="tag"><i class="fas fa-tag"></i> 近似</span>
                <span class="tag"><i class="fas fa-tag"></i> 最优</span>
                <span class="tag"><i class="fas fa-tag"></i> 矩阵</span>
                <span class="tag"><i class="fas fa-tag"></i> 低秩</span>
                <span class="tag"><i class="fas fa-tag"></i> 生成模型</span>
                
            </div>
            
        </header>

        <!-- Post Body -->
        <div class="post-content">
            <h1 id="cur">低秩近似之路（五）：CUR</h1>
<p><strong>原文链接</strong>: <a href="https://spaces.ac.cn/archives/10662">https://spaces.ac.cn/archives/10662</a></p>
<p><strong>发布日期</strong>: </p>
<hr />
<p>再次回到低秩近似之路上。在<a href="/archives/10501">《低秩近似之路（四）：ID》</a>中，我们介绍了“插值分解（Interpolative Decomposition，ID）”，这是为矩阵$\boldsymbol{M}\in\mathbb{R}^{n\times m}$寻找$\boldsymbol{C}\boldsymbol{Z}$形式的近似的过程，其中$\boldsymbol{C}\in\mathbb{R}^{n\times r}$是矩阵$\boldsymbol{M}$的若干列，而$\boldsymbol{Z}\in\mathbb{R}^{r\times m}$是任意矩阵。</p>
<p>这篇文章我们将介绍CUR分解，它跟插值分解的思想一脉相承，都是以原始矩阵的行、列为“骨架”来构建原始矩阵的近似，跟ID只用行或列之一不同，CUR分解同时用到了行和列。</p>
<h2 id="_1">基本定义</h2>
<p>其实这不是本站第一次出现CUR分解了。早在<a href="/archives/8180">《Nyströmformer：基于矩阵分解的线性化Attention方案》</a>我们就介绍过矩阵的Nyström近似，它实际上就是CUR分解，后来在<a href="/archives/9336">《利用CUR分解加速交互式相似度模型的检索》</a>还介绍了CUR分解在降低交互式相似度模型的检索复杂度的应用。</p>
<p>CUR分解能有这些应用，关键在于它名称中的“C”和“R”。具体来说，CUR分解试图为矩阵$\boldsymbol{M}\in\mathbb{R}^{n\times m}$寻找如下形式的近似：<br />
\begin{equation}\mathop{\text{argmin}}<em _:_S_1_="[:,S_1]">{S_1,S_2,\boldsymbol{\mathcal{U}}}\Vert \underbrace{\boldsymbol{M}</em>}<em _S_2_:_="[S_2,:]">{\boldsymbol{\mathcal{C}}}\boldsymbol{\mathcal{U}}\underbrace{\boldsymbol{M}</em>}<em S_boldsymbol_Z="S,\boldsymbol{Z">{\boldsymbol{\mathcal{R}}} - \boldsymbol{M}\Vert_F^2\quad\text{s.t.}\quad \left\{\begin{aligned}&amp;S_1\subset\{0,1,\cdots,m-1\},|S_1|=r\\<br />
&amp;S_2\subset\{0,1,\cdots,n-1\},|S_2|=r \\<br />
&amp;\boldsymbol{\mathcal{U}}\in\mathbb{R}^{r\times r}<br />
\end{aligned}\right.\end{equation}<br />
为了区分SVD的$\boldsymbol{U}$，这里用了花体的$\boldsymbol{\mathcal{C}},\boldsymbol{\mathcal{U}},\boldsymbol{\mathcal{R}}$。作为对比，上一篇介绍的ID是<br />
\begin{equation}\mathop{\text{argmin}}</em>}}\Vert \underbrace{\boldsymbol{M<em _boldsymbol_C="\boldsymbol{C">{[:,S]}}</em>}}\boldsymbol{Z} - \boldsymbol{M}\Vert_F^2\quad\text{s.t.}\quad \left\{\begin{aligned<br />
&amp;S\subset\{0,1,\cdots,m-1\},|S|=r\\<br />
&amp;\boldsymbol{Z}\in\mathbb{R}^{r\times m}<br />
\end{aligned}\right.\end{equation}<br />
而SVD找的低秩近似是<br />
\begin{equation}\mathop{\text{argmin}}<em _:_:r_="[:,:r]">{\boldsymbol{U},\boldsymbol{\Sigma},\boldsymbol{V}}\Vert \boldsymbol{U}</em>}\boldsymbol{\Sigma<em _:_:r_="[:,:r]">{[:r,:r]}\boldsymbol{V}</em>}^{\top} - \boldsymbol{M}\Vert_F^2\quad\text{s.t.}\quad \left\{\begin{aligned<br />
&amp;\boldsymbol{U}\in\mathbb{R}^{n\times n}, \boldsymbol{U}^{\top}\boldsymbol{U} = \boldsymbol{I}<em _min_n_m_="\min(n,m)">n \\<br />
&amp;\boldsymbol{V}\in\mathbb{R}^{m\times n}, \boldsymbol{V}^{\top}\boldsymbol{V} = \boldsymbol{I}_m \\<br />
&amp;\boldsymbol{\Sigma}=\text{diag}(\sigma_1,\cdots,\sigma</em>})\in\mathbb{R}_{\geq 0}^{n\times m<br />
\end{aligned}\right.\end{equation}<br />
在<a href="/archives/10407">SVD篇</a>我们证明过，SVD可以找到$r$秩近似的最优解，但它本身的计算复杂度高，并且$\boldsymbol{U},\boldsymbol{V}$的物理意义并不直观。相比之下，CUR分解用原本矩阵的列$\boldsymbol{\mathcal{C}}$和行$\boldsymbol{\mathcal{R}}$替代了$\boldsymbol{\mathcal{U}},\boldsymbol{V}$，虽然在近似程度方面不如SVD，但在可解释性、储存成本、计算成本等方面都更优。</p>
<p>从外观上来看，SVD近似的左右矩阵$\boldsymbol{U},\boldsymbol{V}$更复杂而中间矩阵$\boldsymbol{\Sigma}$更简单，而CUR分解则相反，它是左右矩阵左右矩阵$\boldsymbol{\mathcal{C}},\boldsymbol{\mathcal{R}}$更简单而中间矩阵$\boldsymbol{\mathcal{U}}$更复杂。</p>
<h2 id="u">U的选择</h2>
<p>很明显，CUR分解的难度在于行列的选择，因为当$\boldsymbol{\mathcal{C}},\boldsymbol{\mathcal{R}}$给定后，$\boldsymbol{\mathcal{U}}$的最优解是可以利用<a href="/archives/10366">伪逆</a>解析地表示出来：<br />
\begin{equation}\boldsymbol{\mathcal{U}}^* = \boldsymbol{\mathcal{C}}^{\dagger}\boldsymbol{M}\boldsymbol{\mathcal{R}}^{\dagger}\end{equation}<br />
求解过程可以参考伪逆篇的推导。其实这个解也很直观，假设$\boldsymbol{\mathcal{C}},\boldsymbol{\mathcal{R}}$都是可逆矩阵的话，那么方程$\boldsymbol{\mathcal{C}}\boldsymbol{\mathcal{U}}\boldsymbol{\mathcal{R}}=\boldsymbol{M}$的解自然是$\boldsymbol{\mathcal{U}}=\boldsymbol{\mathcal{C}}^{-1}\boldsymbol{M}\boldsymbol{\mathcal{R}}^{-1}$，而不可逆的时候就把逆${}^{-1}$换成伪逆${}^{\dagger}$。</p>
<p>除了这个理论最优解外，CUR分解还有一个经常用的、某种意义上更为直观的选择：<br />
\begin{equation}\boldsymbol{\mathcal{U}} = \boldsymbol{M}_{[S_2,S_1]}^{\dagger}\end{equation}<br />
注意切片运算的优先级高于转置和伪逆，所以这个$\boldsymbol{\mathcal{U}}$实际上就是$\boldsymbol{\mathcal{C}},\boldsymbol{\mathcal{R}}$的公共部分组成的子矩阵的伪逆。</p>
<p>怎么理解这个选择呢？通过交换行列，我们可以让被选中的行列都排在前面，并假设$\boldsymbol{M}<em _boldsymbol_M="\boldsymbol{M">{[S_2,S_1]}$可逆，那么该结果可以用分块矩阵写成<br />
\begin{equation}\underbrace{\begin{pmatrix}\boldsymbol{A} &amp; \boldsymbol{B} \\ \boldsymbol{C} &amp; \boldsymbol{D}\end{pmatrix}}</em>}} \approx \underbrace{\begin{pmatrix}\boldsymbol{A} \\ \boldsymbol{C}\end{pmatrix}<em _boldsymbol_mathcal_U="\boldsymbol{\mathcal{U">{\boldsymbol{\mathcal{C}}}\,\,\underbrace{\boldsymbol{A}^{-1}}</em>}}}\,\,\underbrace{\begin{pmatrix}\boldsymbol{A} &amp; \boldsymbol{B}\end{pmatrix}}_{\boldsymbol{\mathcal{R}}} = \begin{pmatrix}\boldsymbol{A} &amp; \boldsymbol{B} \\ \boldsymbol{C} &amp; \boldsymbol{C}\boldsymbol{A}^{-1}\boldsymbol{B}\end{pmatrix}\label{eq:id-abcd}\end{equation<br />
可以看到，此时的CUR分解精确地重建出了选出来的$\boldsymbol{A},\boldsymbol{B},\boldsymbol{C}$（或者说$\boldsymbol{\mathcal{C}},\boldsymbol{\mathcal{R}}$），并用$\boldsymbol{C}\boldsymbol{A}^{-1}\boldsymbol{B}$来近似$\boldsymbol{D}$，此时的CUR分解相当于一种“矩阵补全（Matrix Completion）”方法。</p>
<p>值得指出的是，由于两个$\boldsymbol{\mathcal{U}}$都用到了伪逆，且伪逆的定义并不要求方阵，所以最一般的CUR分解其实不要求$\boldsymbol{\mathcal{C}}$/$\boldsymbol{\mathcal{R}}$具有相同的列数/行数，如果有必要，我们可以为$\boldsymbol{\mathcal{C}}$/$\boldsymbol{\mathcal{R}}$选择不同数量的列/行。</p>
<h2 id="_2">行列选择</h2>
<p>解决完$\boldsymbol{\mathcal{U}}$之后，下面主要就是$\boldsymbol{\mathcal{C}},\boldsymbol{\mathcal{R}}$的选择了。由于行、列的选择本质上是等价的，所以下面我们以列的选择为例。</p>
<p>也就是说，下面我们的任务就是从矩阵$\boldsymbol{M}$中选出$r$个关键列，作为它的“骨架”，也可以叫做“轮廓”、“草图”等，这个问题我们其实在上两篇文章（即<a href="/archives/10427">CR篇</a>和<a href="/archives/10501">ID篇</a>）已经探究过，里边的方案也可以用来构建CUR分解的$\boldsymbol{\mathcal{C}},\boldsymbol{\mathcal{R}}$，包括</p>
<blockquote>
<p>1、选择模长最大的$r$列；</p>
<p>2、以模长为权随机采样$r$列；</p>
<p>3、均匀随机采样$r$列；</p>
<p>4、按列驱QR分解选择前$r$列。</p>
</blockquote>
<p>这些方案各有优劣，都有它们的适用场景和隐含假设。除此之外，我们也可以考虑一些更直观的做法，比如考虑到关键列的含义似乎跟“聚类中心”相似，所以我们可以将$n$个列向量聚成$k$类，然后选择距离聚类中心最近的$k$个向量。当$n$实在太大时，又可以先随机抽取一部分，然后再在这些向量中执行上述选择算法。</p>
<p>总的来说，列选择是矩阵近似中的一个经典问题，英文关键词是Randomized Linear Algebra、Column Subset Selection等，大家一搜就可以找到很多资料。</p>
<h2 id="_3">杠杆分数</h2>
<p>当然，作为一篇新文章，最好还是要介绍一些新方法，所以接下来我们再介绍另外两种列选择的思路。第一种我们称为“杠杆分数（Leverage Scores）”，它是通过线性回归的思想来进行列选择。</p>
<p>首先，我们将矩阵$\boldsymbol{M}$视为$m$个$n$维样本，然后相应地有$m$个$d$维向量构成目标矩阵$\boldsymbol{Y}$，我们的任务是用$\boldsymbol{M}$预测$\boldsymbol{Y}$，模型采用最简单的线性模型，优化目标是最小二乘<br />
\begin{equation}\boldsymbol{W}^<em> = \mathop{\text{argmin}}_{\boldsymbol{W}} \Vert\boldsymbol{Y} - \boldsymbol{W}\boldsymbol{M}\Vert_F^2\label{eq:linear-loss}\end{equation}<br />
这个目标我们在伪逆篇已经解决过，答案是$\boldsymbol{W}^</em> = \boldsymbol{Y}\boldsymbol{M}^{\dagger}$，假设$n &lt; m$且$\boldsymbol{M}$的秩为$n$，那么可以进一步写出$\boldsymbol{W}^<em> = \boldsymbol{Y}\boldsymbol{M}^{\top}(\boldsymbol{M}\boldsymbol{M}^{\top})^{-1}$，于是我们有<br />
\begin{equation}\hat{\boldsymbol{Y}} = \boldsymbol{W}^</em>\boldsymbol{M} = \boldsymbol{Y}\boldsymbol{M}^{\top}(\boldsymbol{M}\boldsymbol{M}^{\top})^{-1}\boldsymbol{M} = \boldsymbol{Y}\boldsymbol{H}\end{equation}<br />
这里$\boldsymbol{H}=\boldsymbol{M}^{\top}(\boldsymbol{M}\boldsymbol{M}^{\top})^{-1}\boldsymbol{M}$称为“帽子矩阵（Hat Matrix）”，据说是因为它将$\boldsymbol{Y}$变成$\hat{\boldsymbol{Y}}$，就像是给$\boldsymbol{Y}$带上了一定帽子（即$\hat{}$）。设$\boldsymbol{m}<em i_i="i,i">i$是$\boldsymbol{M}$的第$i$个列向量，在这里也就是第$i$个样本，那么我们认为<br />
\begin{equation}\boldsymbol{H}</em>} = \boldsymbol{m<em i_i="i,i">i^{\top}(\boldsymbol{M}\boldsymbol{M}^{\top})^{-1}\boldsymbol{m}_i\end{equation}<br />
衡量了该样本在预测$\hat{\boldsymbol{Y}}$时的作用，这就是“杠杆分数（Leverage Scores）”。我们认为选出$r$个关键列，就相当于要选出$r$个最重要的样本，于是可以选择$\boldsymbol{H}</em>$最大的$r$列。</p>
<p>当$\boldsymbol{M}\boldsymbol{M}^{\top}$不可逆时，论文<a href="https://papers.cool/arxiv/1511.07263">《Input Sparsity Time Low-Rank Approximation via Ridge Leverage Score Sampling》</a>将Leverage Scores推广为“Ridge Leverage Score”，实际就是在目标$\eqref{eq:linear-loss}$基础上加了个正则项使其可逆。但实际上我们知道，伪逆的概念是不要求满秩的，所以可以直接通过SVD来计算伪逆，这就不需要额外引入正则项了。</p>
<p>设$\boldsymbol{M}$的SVD为$\boldsymbol{U}\boldsymbol{\Sigma}\boldsymbol{V}^{\top}$，那么<br />
\begin{equation}\boldsymbol{H} = \boldsymbol{M}^{\dagger}\boldsymbol{M} = (\boldsymbol{V}\boldsymbol{\Sigma}^{\dagger}\boldsymbol{U}^{\top})(\boldsymbol{U}\boldsymbol{\Sigma}\boldsymbol{V}^{\top}) = \boldsymbol{V}(\boldsymbol{\Sigma}^{\dagger}\boldsymbol{\Sigma})\boldsymbol{V}^{\top}\end{equation}<br />
假设$\boldsymbol{M}$的秩为$\gamma$（$\gamma$不是$r$），那么按照伪逆的计算规则，$\boldsymbol{\Sigma}^{\dagger}\boldsymbol{\Sigma}$是一个$m\times m$的对角矩阵，对角线上前$\gamma$个元素全是1，其余是0，所以<br />
\begin{equation}\boldsymbol{H} = \boldsymbol{V}<em _:_:_gamma_="[:,:\gamma]">{[:,:\gamma]}\boldsymbol{V}</em>}^{\top}\quad\Rightarrow\quad \boldsymbol{H<em _i-1_:_gamma_="[i-1,:\gamma]">{i,i} = \Vert\boldsymbol{V}</em>}\Vert^2\end{equation<br />
注意，$\boldsymbol{H}<em _i-1_:_gamma_="[i-1,:\gamma]">{i,i}$表示$\boldsymbol{H}$的第$i$行、$i$列元素，计数从1开始，但切片的规则按照Python来，计数从0开始，所以最后的切片是${}</em>}$。现在我们看到，要计算$\boldsymbol{M}$的列的杠杆分数，只需要将它SVD为$\boldsymbol{U}\boldsymbol{\Sigma}\boldsymbol{V}^{\top}$，然后计算$\boldsymbol{V<em _:_:_gamma_="[:,:\gamma]">{[:,:\gamma]}$各行的模长平方；同理，要计算行的杠杆分数，则只需要计算$\boldsymbol{U}</em>$各行的模长平方。</p>
<p>由于$\boldsymbol{V}$本身是正交矩阵，因此恒成立<br />
\begin{equation}\sum_{i=1}^m \boldsymbol{H}<em i="1">{i,i} = \sum</em>}^m\Vert\boldsymbol{V<em i_i="i,i">{[i-1,:\gamma]}\Vert^2 = \gamma\end{equation}<br />
因此除了选杠杆分数最大的$r$列之外，还可以构造分布$p_i = \boldsymbol{H}</em> / \gamma$来随机采样。</p>
<p>杠杆分数跟$\boldsymbol{M}$的秩$\gamma$相关，而$\boldsymbol{M}$的秩等于$\boldsymbol{M}$的非零奇异值个数，所以它会被接近零的奇异值影响，但这些偏小的奇异值实际作用不大，所以实践中$\gamma$一般取$\boldsymbol{M}$较显著的奇异值（主奇异值）个数。杠杆分数的另一个问题是需要先SVD，实践中多数会采用一些近似SVD算法。至于近似SVD算法的内容，我们后面有机会再谈了。</p>
<h2 id="deim">DEIM法</h2>
<p>另外一种要介绍的列选择方法叫做<a href="https://papers.cool/arxiv/1407.5516">DEIM</a>，全称是Discrete Empirical Interpolation Method，这里也不去考究这个名称的来源了，但大致上可以确定的是，杠杆分数和DEIM都是CUR分解常用的列选择方法，而且DEIM跟CUR分解的联系更为密切，所以近年来愈加流行。</p>
<p>DEIM的出发点是恒等式$\eqref{eq:id-abcd}$，在该式的$\boldsymbol{\mathcal{C}},\boldsymbol{\mathcal{U}},\boldsymbol{\mathcal{R}}$之下，CUR分解的误差取决于$\Vert \boldsymbol{D} - \boldsymbol{C}\boldsymbol{A}^{-1}\boldsymbol{B}\Vert_F$。什么时候这个式子会小呢？直观的想法是$\boldsymbol{A}$比较大，$\boldsymbol{B},\boldsymbol{C},\boldsymbol{D}$都比较小时，整个式子肯定也很小。但$\boldsymbol{A}$是一个矩阵，怎么衡量大小呢？行列式的绝对值可以作为一个参考指标。所以，一个可行方案是选择让$\boldsymbol{M}_{[S_2,S_1]}$行列式绝对值最大的对应行列。</p>
<p>当然，这个方案只有理论价值，因为精确找到行列式绝对值最大的子矩阵也是NP-Hard的，但它提供了一个目标，我们可以尝试找一个贪心解，当$r=1$时，找绝对值最大的行列式也就是找绝对值最大的元素，这是可以接受的，然后可以递归下去。DEIM沿用了这个思路，但它不是从$\boldsymbol{M}$出发，而是借鉴了杠杆分数的做法，从SVD之后的$\boldsymbol{V}$出发。</p>
<p>杠杆分数将 <em>从$\boldsymbol{M}$找关键列</em> 转化为 <em _:_:_gamma_="[:,:\gamma]">从$\boldsymbol{V}</em>$，我们只需要选择行。}$找关键行_ ，排序指标是行模长平方，DEIM则试图通过为$\boldsymbol{V}$找CUR近似来找关键行。可$\boldsymbol{M}$的CUR还没解决，现在又来一个$\boldsymbol{V}$的CUR，不是越搞越复杂？不会，这里还是简化一点的，因为$\boldsymbol{V}$是$\boldsymbol{M}$的SVD结果，它按照奇异值大小排序过了，所以我们可以认为$\boldsymbol{V}$的列已经按重要性排好序了，因此最重要的$r$列必然是$\boldsymbol{V}_{[:,:r]</p>
<p>如前面所述，求解思路是贪心算法，最重要的列自然是第一列$\boldsymbol{V}<em>{[:,0]}$，那最重要的行呢？我们要选择它跟第一列相交的行列时绝对值最大的那一行，说白了就是第一列绝对值对大的元素所在的那一行，这样我们就有了初始行列。假设我们已经选出了$k$个关键行，下标集为$S_k$，那怎么选出第$k+1$关键行呢？首先，我们知道由 _已选出的$k$行</em> 和 <em>前$k$列</em> 构建的CUR近似是$\boldsymbol{V}<em _S_k_:k_="[S_k,:k]">{[:,:k]}\boldsymbol{V}</em>}^{-1}\boldsymbol{V<em _:_k_="[:,k]">{[S_k,:]}$，第$k+1$列的误差是<br />
\begin{equation}\boldsymbol{V}</em>} - \boldsymbol{V<em _S_k_:k_="[S_k,:k]">{[:,:k]}\boldsymbol{V}</em>}^{-1}\boldsymbol{V}_{[S_k,k]}\end{equation<br />
由式$\eqref{eq:id-abcd}$我们知道此种CUR近似能恢复所选的行和列，所以上式中已被选出的$k$行对应的分量必然为零，因此剩余的绝对值最大的非零元素必然不在已选出的$k$行之中，我们选择它的所在行作为第$k+1$个关键行。</p>
<p>简而言之，DEIM利用奇异值分解已经为$\boldsymbol{V}$的列向量排好序的特点，将CUR分解转化为一个单纯的行搜索问题，减少了搜索方向，然后通过贪心算法求解，每一步的选择依据是误差最大元素所在行。更详细的介绍和证明可以参考<a href="https://papers.cool/arxiv/1407.5516">《A DEIM Induced CUR Factorization》</a>和<a href="https://personal.math.vt.edu/embree/cur_talk.pdf">《CUR Matrix Factorizations: Algorithms, Analysis, Applications》</a>。</p>
<h2 id="_4">文章小结</h2>
<p>本文介绍了CUR分解，它可以视为上一篇文章介绍的插值分解（ID）的进一步延伸，特点是同时以原始矩阵的若干行与列作为骨架来构建低秩近似。</p>
<p><em><strong>转载到请包括本文地址：</strong><a href="https://spaces.ac.cn/archives/10662">https://spaces.ac.cn/archives/10662</a></em></p>
<p><em><strong>更详细的转载事宜请参考：</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="《科学空间FAQ》">《科学空间FAQ》</a></p>
<p><strong>如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。</strong></p>
<p><strong>如果您觉得本文还不错，欢迎分享/打赏本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！</strong></p>
<p>打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>微信打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>支付宝打赏</p>
<p>因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>点击这里</strong></a>或在下方评论区留言来告知你的建议或需求。</p>
<p><strong>如果您需要引用本文，请参考：</strong></p>
<p>苏剑林. (Jan. 12, 2025). 《低秩近似之路（五）：CUR 》[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/10662">https://spaces.ac.cn/archives/10662</a></p>
<p>@online{kexuefm-10662,<br />
title={低秩近似之路（五）：CUR},<br />
author={苏剑林},<br />
year={2025},<br />
month={Jan},<br />
url={\url{https://spaces.ac.cn/archives/10662}},<br />
} </p>
<hr />
<h2 id="_5">公式推导与注释</h2>
<p>TODO: 添加详细的数学公式推导和注释</p>
        </div>

        <!-- Back to Home -->
        <div class="text-center mt-5 mb-4">
            <a href="../index.html" class="btn btn-outline-primary">
                <i class="fas fa-arrow-left"></i> 返回首页
            </a>
        </div>
    </article>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>
                博客来源: <a href="https://spaces.ac.cn" target="_blank">科学空间</a> |
                内容经过整理并添加详细数学推导
            </p>
            <p>
                Powered by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>
            </p>
        </div>
    </footer>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>

    <!-- Syntax highlighting -->
    <script>hljs.highlightAll();</script>
</body>
</html>
