<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>低秩近似之路（二）：SVD | ML & Math Blog Posts</title>
    <meta name="description" content="低秩近似之路（二）：SVD&para;
原文链接: https://spaces.ac.cn/archives/10407
发布日期: 

上一篇文章中我们介绍了“伪逆”，它关系到给定矩阵$\boldsymbol{M}$和$\boldsymbol{A}$（或$\boldsymbol{B}$）时优化目标$\Vert \boldsymbol{A}\boldsymbol{B} - \boldsymbol...">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css">

    <!-- Google Fonts -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="../assets/css/main.css">
    <link rel="stylesheet" href="../assets/css/post.css">

    <!-- Custom JS -->
    <script src="../assets/js/collapsible.js" defer></script>

    <!-- MathJax for math rendering with equation numbering -->
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true,
        tags: 'ams',  // Enable equation numbering with AMS style
        tagSide: 'right',  // Place equation numbers on the right
        tagIndent: '0.8em',  // Indentation for equation numbers
        multlineWidth: '85%'
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Syntax highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/styles/github.min.css">
    <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/highlight.min.js"></script>
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light bg-light border-bottom">
        <div class="container">
            <a class="navbar-brand" href="../index.html">
                <i class="fas fa-brain"></i> ML & Math Blog
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="../index.html"><i class="fas fa-home"></i> 首页</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Post Content -->
    <article class="container post-container my-5">
        <!-- Breadcrumb Navigation -->
        <nav aria-label="breadcrumb">
            <ol class="breadcrumb">
                <li class="breadcrumb-item"><a href="../index.html"><i class="fas fa-home"></i> 首页</a></li>
                
                <li class="breadcrumb-item"><a href="../index.html?tags=详细推导">详细推导</a></li>
                
                <li class="breadcrumb-item active" aria-current="page">
                    #145 低秩近似之路（二）：SVD
                </li>
            </ol>
        </nav>

        <!-- Post Header -->
        <header class="post-header mb-4">
            <h1 class="post-title">
                <span class="post-number">#145</span>
                低秩近似之路（二）：SVD
            </h1>
            <div class="post-meta">
                <span><i class="far fa-calendar"></i> 2024-10-01</span>
                
            </div>
            
            <div class="post-tags mt-3">
                
                <a href="../index.html?tags=详细推导" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 详细推导</span>
                </a>
                
                <a href="../index.html?tags=近似" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 近似</span>
                </a>
                
                <a href="../index.html?tags=最优" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 最优</span>
                </a>
                
                <a href="../index.html?tags=矩阵" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 矩阵</span>
                </a>
                
                <a href="../index.html?tags=SVD" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> SVD</span>
                </a>
                
                <a href="../index.html?tags=低秩" class="tag-link">
                    <span class="tag"><i class="fas fa-tag"></i> 低秩</span>
                </a>
                
            </div>
            
        </header>

        <div class="row">
            <!-- Main Content -->
            <div class="col-lg-9">
                <!-- Post Body -->
                <div class="post-content">
                    <h1 id="svd">低秩近似之路（二）：SVD<a class="toc-link" href="#svd" title="Permanent link">&para;</a></h1>
<p><strong>原文链接</strong>: <a href="https://spaces.ac.cn/archives/10407">https://spaces.ac.cn/archives/10407</a></p>
<p><strong>发布日期</strong>: </p>
<hr />
<p>上一篇文章中我们介绍了“<a href="/archives/10366">伪逆</a>”，它关系到给定矩阵$\boldsymbol{M}$和$\boldsymbol{A}$（或$\boldsymbol{B}$）时优化目标$\Vert \boldsymbol{A}\boldsymbol{B} - \boldsymbol{M}\Vert_F^2$的最优解。这篇文章我们来关注$\boldsymbol{A},\boldsymbol{B}$都不给出时的最优解，即<br />
\begin{equation}\mathop{\text{argmin}}_{\boldsymbol{A},\boldsymbol{B}}\Vert \boldsymbol{A}\boldsymbol{B} - \boldsymbol{M}\Vert_F^2\label{eq:loss-ab}\end{equation}<br />
其中$\boldsymbol{A}\in\mathbb{R}^{n\times r}, \boldsymbol{B}\in\mathbb{R}^{r\times m}, \boldsymbol{M}\in\mathbb{R}^{n\times m},r &lt; \min(n,m)$。说白了，这就是要寻找矩阵$\boldsymbol{M}$的“最优$r$秩近似（秩不超过$r$的最优近似）”。而要解决这个问题，就需要请出大名鼎鼎的“SVD（奇异值分解）”了。虽然本系列把伪逆作为开篇，但它的“名声”远不如SVD，听过甚至用过SVD但没听说过伪逆的应该大有人在，包括笔者也是先了解SVD后才看到伪逆。</p>
<p>接下来，我们将围绕着矩阵的最优低秩近似来展开介绍SVD。</p>
<h2 id="_1">结论初探<a class="toc-link" href="#_1" title="Permanent link">&para;</a></h2>
<p>对于任意矩阵$\boldsymbol{M}\in\mathbb{R}^{n\times m}$，都可以找到如下形式的奇异值分解（SVD，Singular Value Decomposition）：<br />
\begin{equation}\boldsymbol{M} = \boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}\end{equation}<br />
其中$\boldsymbol{U}\in\mathbb{R}^{n\times n},\boldsymbol{V}\in\mathbb{R}^{m\times m}$都是正交矩阵，$\boldsymbol{\Sigma}\in\mathbb{R}^{n\times m}$是非负对角矩阵：<br />
\begin{equation}\boldsymbol{\Sigma}_{i,j} = \left\{\begin{aligned}&amp;\sigma_i, &amp;i = j \\ &amp;0,&amp;i \neq j\end{aligned}\right.\end{equation}<br />
对角线元素默认从大到小排序，即$\sigma_1\geq \sigma_2\geq\sigma_3\geq\cdots\geq 0$，这些对角线元素就称为奇异值（Singular Value）。从数值计算角度看，我们可以只保留$\boldsymbol{\Sigma}$中非零元素，将$\boldsymbol{U},\boldsymbol{\Sigma},\boldsymbol{V}$的大小降低到$n\times r, r\times r, m\times r$（$r$是$\boldsymbol{M}$的秩），保留完整的正交矩阵则更便于理论分析。</p>
<p>SVD对于复矩阵同样成立，但需要将正交矩阵改为酉矩阵，转置改为共轭转置，但这里我们主要聚焦于跟机器学习关系更为密切的实矩阵结果。SVD的基础理论包括存在性、计算方法以及它与最优低秩近似的联系等，这些内容笔者后面都会给出自己的理解。</p>
<p>在二维平面下，SVD有非常直观的几何意义。二维的正交矩阵主要就是旋转（还有反射，但几何直观的话可以不那么严谨），所以$\boldsymbol{M}\boldsymbol{x}=\boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}\boldsymbol{x}$意味着任何对（列）向量$x$的线性变换，都可以分解为<strong>旋转</strong> 、<strong>拉伸</strong> 、<strong>旋转</strong> 三个步骤，如下图所示：  </p>
<p><a href="/usr/uploads/2024/09/1489641175.png" title="点击查看原图"><img alt="SVD的几何意义" src="/usr/uploads/2024/09/1489641175.png" /></a></p>
<p>SVD的几何意义</p>
<h2 id="_2">一些应用<a class="toc-link" href="#_2" title="Permanent link">&para;</a></h2>
<p>不管是理论分析还是数值计算，SVD都有非常广泛的应用，其背后的原理之一是常用的矩阵/向量范数对正交变换具有不变性，所以SVD左右两个正交矩阵夹着中间一个对角矩阵的特点，往往能用来将很多矩阵相关的优化目标转换为等价的非负对角矩阵特例，起到简化问题的作用。</p>
<h3 id="_3">伪逆通解<a class="toc-link" href="#_3" title="Permanent link">&para;</a></h3>
<p>以伪逆为例，当$\boldsymbol{A}\in\mathbb{R}^{n\times r}$的秩为$r$时，我们有<br />
\begin{equation}\boldsymbol{A}^{\dagger} = \mathop{\text{argmin}}<em>{\boldsymbol{B}\in\mathbb{R}^{r\times n}}\Vert \boldsymbol{A}\boldsymbol{B} - \boldsymbol{I}_n\Vert_F^2\end{equation}<br />
上一篇文章我们通过求导得出了$\boldsymbol{A}^{\dagger}$的表达式，然后又花了一些心思推广到$\boldsymbol{A}$的秩小于$r$的情形。但如果引入SVD的话，那么问题就简化得多了。我们可以将$\boldsymbol{A}$分解为$\boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}$，然后将$\boldsymbol{B}$表示成$\boldsymbol{V} \boldsymbol{Z} \boldsymbol{U}^{\top}$，注意我们没有规定$\boldsymbol{Z}$是对角阵，所以$\boldsymbol{B}=\boldsymbol{V} \boldsymbol{Z} \boldsymbol{U}^{\top}$总是可以做到的，于是<br />
\begin{equation}\begin{aligned}
\min</em>\boldsymbol{B}\Vert \boldsymbol{A}\boldsymbol{B} - \boldsymbol{I}<em>n\Vert_F^2 =&amp;\, \min</em>\boldsymbol{Z}\Vert \boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}\boldsymbol{V} \boldsymbol{Z} \boldsymbol{U}^{\top} - \boldsymbol{I}<em>n\Vert_F^2 \\
=&amp;\, \min</em>\boldsymbol{Z}\Vert \boldsymbol{U}(\boldsymbol{\Sigma} \boldsymbol{Z} - \boldsymbol{I}<em>n) \boldsymbol{U}^{\top}\Vert_F^2 \\
=&amp;\, \min</em>\boldsymbol{Z}\Vert \boldsymbol{\Sigma} \boldsymbol{Z} - \boldsymbol{I}<em _:r_:r_="[:r,:r]">n\Vert_F^2
\end{aligned}\end{equation}<br />
最后一个等号是基于我们上一篇文章证明过的结论“正交变换不改变$F$范数”，这样我们就将问题简化成对角阵$\boldsymbol{\Sigma}$的伪逆了。接着我们可以用分块矩阵的形式将$\boldsymbol{\Sigma} \boldsymbol{Z} - \boldsymbol{I}_n$表示为<br />
\begin{equation}\begin{aligned}\boldsymbol{\Sigma} \boldsymbol{Z} - \boldsymbol{I}_n =&amp;\, \begin{pmatrix}\boldsymbol{\Sigma}</em>} \\ \boldsymbol{0<em _:r_:r_="[:r,:r]">{(n-r)\times r}\end{pmatrix} \begin{pmatrix}\boldsymbol{Z}</em>} &amp; \boldsymbol{Z<em r_times_n-r_="r\times(n-r)">{[:r,r:]}\end{pmatrix} - \begin{pmatrix}\boldsymbol{I}_r &amp; \boldsymbol{0}</em>} \\ \boldsymbol{0<em n-r="n-r">{(n-r)\times r} &amp; \boldsymbol{I}</em> \\}\end{pmatrix
=&amp;\, \begin{pmatrix}\boldsymbol{\Sigma}<em _:r_:r_="[:r,:r]">{[:r,:r]}\boldsymbol{Z}</em>} - \boldsymbol{I<em _:r_:r_="[:r,:r]">r &amp; \boldsymbol{\Sigma}</em>}\boldsymbol{Z<em _n-r_times="(n-r)\times" r="r">{[:r,r:]}\\ \boldsymbol{0}</em>} &amp; -\boldsymbol{I<em _:r_:r_="[:r,:r]">{n-r}\end{pmatrix}<br />
\end{aligned}\end{equation}<br />
这里的切片就按照Python数组的规则来理解。从最后的形式可以看出，要使得$\boldsymbol{\Sigma} \boldsymbol{Z} - \boldsymbol{I}_n$的$F$范数最小，唯一解是$\boldsymbol{Z}</em>}=\boldsymbol{\Sigma<em _:r_r:_="[:r,r:]">{[:r,:r]}^{-1}$，$\boldsymbol{Z}</em>$，于是在SVD下就有}=\boldsymbol{0}_{r\times(n-r)}$，说白了，$\boldsymbol{Z}$就是将$\boldsymbol{\Sigma}^{\top}$的非零元素都取倒数然后转置，我们将它记为$\boldsymbol{\Sigma}^{\dagger<br />
\begin{equation}\boldsymbol{A}=\boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}\quad\Rightarrow\quad \boldsymbol{A}^{\dagger} = \boldsymbol{V}\boldsymbol{\Sigma}^{\dagger}\boldsymbol{U}^{\top}\end{equation}<br />
可以进一步证明这个结果也适用于秩小于$r$的$\boldsymbol{A}$，所以它是一个通用的形式，一些教程也直接将它作为伪逆的定义。此外，我们也可以观察到这个形式不区分左伪逆和右伪逆，这表明同一个矩阵的左伪逆和右伪逆是相等的，因此在说伪逆的时候不用特别区分左右。</p>
<h3 id="_4">矩阵范数<a class="toc-link" href="#_4" title="Permanent link">&para;</a></h3>
<p>利用正交变换不改变$F$范数的结论，我们还可以得到<br />
\begin{equation}\Vert \boldsymbol{M}\Vert_F^2 = \Vert \boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}\Vert_F^2 = \Vert \boldsymbol{\Sigma} \Vert_F^2 = \sum_{i=1}^{\min(n,m)}\sigma_i^2\end{equation}<br />
也就是说奇异值的平方和等于$F$范数的平方。除了$F$范数外，SVD也可以用来计算“谱范数”。上一篇文章我们提到，$F$范数只是矩阵范数的一种，另一种常用的矩阵范数是基于向量的范数诱导出来的谱范数，它定义为：<br />
\begin{equation}\Vert \boldsymbol{M}\Vert_2 = \max_{\Vert \boldsymbol{x}\Vert = 1} \Vert \boldsymbol{M}\boldsymbol{x}\Vert\end{equation}<br />
注意等号右端出现的范数都是向量的范数（模长，$2$-范数），因此上述定义是明确的。由于它是向量的$2$-范数所诱导出来的，所以它也称为矩阵的$2$-范数。数值上，矩阵的谱范数等于它的最大奇异值，即$\Vert \boldsymbol{M}\Vert_2 = \sigma_1$。要证明这一点，只需要将$\boldsymbol{M}$做SVD为$\boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}$，然后代入谱范数的定义<br />
\begin{equation}\max_{\Vert \boldsymbol{x}\Vert = 1} \Vert \boldsymbol{M}\boldsymbol{x}\Vert = \max_{\Vert \boldsymbol{x}\Vert = 1} \Vert \boldsymbol{U}\boldsymbol{\Sigma} (\boldsymbol{V}^{\top}\boldsymbol{x})\Vert = \max_{\Vert \boldsymbol{y}\Vert = 1} \Vert \boldsymbol{\Sigma} \boldsymbol{y}\Vert\end{equation}<br />
第二个等号正是利用了正交矩阵不改变向量范数的特点。现在我们相当于将问题简化成为对角阵$\boldsymbol{\Sigma}$的谱范数，这个比较简单，设$\boldsymbol{y} = (y_1,y_2,\cdots,y_m)$，那么<br />
\begin{equation}\Vert \boldsymbol{\Sigma} \boldsymbol{y}\Vert^2 = \sum_{i=1}^m \sigma_i^2 y_i^2 \leq \sum_{i=1}^m \sigma_1^2 y_i^2 = \sigma_1^2\sum_{i=1}^m y_i^2 = \sigma_1^2\end{equation}<br />
所以$\Vert \boldsymbol{\Sigma} \boldsymbol{y}\Vert$不超过$\sigma_1$，并且$\boldsymbol{y}=(1,0,\cdots,0)$时取到等号，因此$\Vert \boldsymbol{M}\Vert_2=\sigma_1$。对比$F$范数的结果，我们还可以发现恒成立$\Vert \boldsymbol{M}\Vert_2\leq \Vert \boldsymbol{M}\Vert_F$。</p>
<h3 id="_5">低秩近似<a class="toc-link" href="#_5" title="Permanent link">&para;</a></h3>
<p>最后我们再回到本文的主题最优低秩近似，也就是目标$\eqref{eq:loss-ab}$。将$\boldsymbol{M}$分解为$\boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}$，那么我们就可以写出<br />
\begin{equation}\begin{aligned}
\Vert \boldsymbol{A}\boldsymbol{B} - \boldsymbol{M}\Vert_F^2 =&amp;\, \Vert \boldsymbol{U}\boldsymbol{U}^{\top}\boldsymbol{A}\boldsymbol{B}\boldsymbol{V}\boldsymbol{V}^{\top} - \boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}\Vert_F^2 \\
=&amp;\, \Vert \boldsymbol{U}(\boldsymbol{U}^{\top}\boldsymbol{A}\boldsymbol{B}\boldsymbol{V} - \boldsymbol{\Sigma}) \boldsymbol{V}^{\top}\Vert_F^2 \\
=&amp;\, \Vert \boldsymbol{U}^{\top}\boldsymbol{A}\boldsymbol{B}\boldsymbol{V} - \boldsymbol{\Sigma}\Vert_F^2
\end{aligned}\end{equation}<br />
注意$\boldsymbol{U}^{\top}\boldsymbol{A}\boldsymbol{B}\boldsymbol{V}$仍可以代表任意秩不超过$r$的矩阵，所以通过SVD我们将矩阵$\boldsymbol{M}$的最优$r$秩近似简化成了非负对角阵$\boldsymbol{\Sigma}$的最优$r$秩近似。</p>
<p>在<a href="/archives/10226">《对齐全量微调！这是我看过最精彩的LoRA改进（一）》</a>中我们用同样思路求解过一个类似的优化问题：<br />
\begin{equation}\mathop{\text{argmin}}_{\boldsymbol{A},\boldsymbol{B}} \Vert \boldsymbol{A}\boldsymbol{A}^{\top}\boldsymbol{M} + \boldsymbol{M}\boldsymbol{B}^{\top}\boldsymbol{B} - \boldsymbol{M}\Vert_F^2\end{equation}<br />
利用SVD和正交变换不改变$F$范数，可以得到<br />
\begin{equation}\begin{aligned}
&amp;\,\Vert \boldsymbol{A}\boldsymbol{A}^{\top}\boldsymbol{M} + \boldsymbol{M}\boldsymbol{B}^{\top}\boldsymbol{B} - \boldsymbol{M}\Vert_F^2 \\
=&amp;\, \Vert \boldsymbol{A}\boldsymbol{A}^{\top}\boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top} + \boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}\boldsymbol{B}^{\top}\boldsymbol{B} - \boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}\Vert_F^2 \\
=&amp;\, \Vert \boldsymbol{U}\boldsymbol{U}^{\top}\boldsymbol{A}\boldsymbol{A}^{\top}\boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top} + \boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}\boldsymbol{B}^{\top}\boldsymbol{B}\boldsymbol{V}\boldsymbol{V}^{\top} - \boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}\Vert_F^2 \\
=&amp;\, \Vert \boldsymbol{U}[(\boldsymbol{U}^{\top}\boldsymbol{A})(\boldsymbol{U}^{\top}\boldsymbol{A})^{\top}\boldsymbol{\Sigma} + \boldsymbol{\Sigma} (\boldsymbol{B}\boldsymbol{V})^{\top} (\boldsymbol{B}\boldsymbol{V}) - \boldsymbol{\Sigma}] \boldsymbol{V}^{\top}\Vert_F^2 \\
=&amp;\, \Vert (\boldsymbol{U}^{\top}\boldsymbol{A})(\boldsymbol{U}^{\top}\boldsymbol{A})^{\top}\boldsymbol{\Sigma} + \boldsymbol{\Sigma} (\boldsymbol{B}\boldsymbol{V})^{\top} (\boldsymbol{B}\boldsymbol{V}) - \boldsymbol{\Sigma}\Vert_F^2 \\
\end{aligned}\end{equation}<br />
这就将原本一般矩阵$\boldsymbol{M}$的优化问题转化为$\boldsymbol{M}$是非负对角阵的特例，降低了分析难度。注意如果$\boldsymbol{A},\boldsymbol{B}$的秩不超过$r$，那么$\boldsymbol{A}\boldsymbol{A}^{\top}\boldsymbol{M} + \boldsymbol{M}\boldsymbol{B}^{\top}\boldsymbol{B}$的秩顶多为$2r$（假设$2r &lt; \min(n,m)$），所以原始问题也是在求$\boldsymbol{M}$的最优$2r$秩近似，转化为非负对角阵后就是求非负对角阵的最优$2r$秩近似，跟前一个问题本质上是一样的。</p>
<h2 id="_6">理论基础<a class="toc-link" href="#_6" title="Permanent link">&para;</a></h2>
<p>肯定了SVD的作用后，我们就需要补充一些理论证明了。首先要确保SVD的存在性，其次要找出至少一种计算方案，这样SVD的各种应用才算是切实可行的，接下来我们将用同一个过程把这两个问题一起解决掉。</p>
<h3 id="_7">谱之定理<a class="toc-link" href="#_7" title="Permanent link">&para;</a></h3>
<p>在此之前，我们需要先引入一个“谱定理”，它既可以说是SVD的特例，也可以说是SVD的基础：</p>
<blockquote>
<p><strong>谱定理</strong> 对于任意实对称矩阵$\boldsymbol{M}\in\mathbb{R}^{n\times n}$，都存在谱分解（也称特征值分解） \begin{equation}\boldsymbol{M} = \boldsymbol{U}\boldsymbol{\Lambda} \boldsymbol{U}^{\top}\end{equation} 其中$\boldsymbol{U},\boldsymbol{\Lambda}\in\mathbb{R}^{n\times n}$，$\boldsymbol{U}$是正交矩阵，$\boldsymbol{\Lambda}=\text{diag}(\lambda_1,\cdots,\lambda_n)$是对角矩阵。</p>
</blockquote>
<p>说白了，谱定理就是断言任何实对称矩阵都可以被正交矩阵对角化，这基于如下两点性质：</p>
<blockquote>
<p>1、实对称矩阵的特征值和特征向量都是实的；</p>
<p>2、实对称矩阵不同特征值对应的特征向量是正交的。</p>
</blockquote>
<p>这两点性质的证明其实很简单，这里就不展开了。基于这两点我们可以立马得出，如果实对称矩阵$\boldsymbol{M}$有$n$个不同的特征值，那么谱定理成立：<br />
\begin{equation}\begin{aligned} \boldsymbol{M}\boldsymbol{u}<em>1 = \lambda_1 \boldsymbol{u}_1 \\
\boldsymbol{M}\boldsymbol{u}_2 = \lambda_2 \boldsymbol{u}_2\\
\vdots \\
\boldsymbol{M}\boldsymbol{u}_n = \lambda_n \boldsymbol{u}_n\end{aligned} \quad\Rightarrow\quad \boldsymbol{M}\underbrace{(\boldsymbol{u}_1, \boldsymbol{u}_2, \cdots, \boldsymbol{u}_n)}</em>\boldsymbol{U} = \underbrace{(\boldsymbol{u}<em>1, \boldsymbol{u}_2, \cdots, \boldsymbol{u}_n)}</em>\boldsymbol{U}\underbrace{\begin{pmatrix}\lambda_1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \lambda_2 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \lambda_n \\
\end{pmatrix}}_{\boldsymbol{\Lambda}}\end{equation}<br />
其中$\lambda_1,\lambda_2,\cdots,\lambda_n$是特征值，$\boldsymbol{u}_1,\boldsymbol{u}_2,\cdots,\boldsymbol{u}_n$是对应的单位特征（列）向量，写成矩阵乘法形式就是$\boldsymbol{M}\boldsymbol{U}=\boldsymbol{U}\boldsymbol{\Lambda}$，所以$\boldsymbol{M} = \boldsymbol{U}\boldsymbol{\Lambda} \boldsymbol{U}^{\top}$。证明的难点是如何拓展到有相等特征值的情形，但在思考完整的证明之前，我们可以先从一个不严谨的角度感受一下，这个不等特征值的结果是一定可以推广到一般情形的。</p>
<p>为什么这样说呢？从数值角度看，两个实数绝对相等的概率几乎为零，所以根本不需要考虑特征值相等的情形；用更数学的话说，那就是特征值不等的实矩阵在全体实矩阵中稠密，所以我们总可以找到一簇矩阵$\boldsymbol{M}<em _epsilon="\epsilon">{\epsilon}$，当$\epsilon &gt; 0$时它的特征值两两不等，当$\epsilon \to 0$时它等于$\boldsymbol{M}$。这样一来，每个$\boldsymbol{M}</em>}$我们都可以分解为$\boldsymbol{U<em _epsilon="\epsilon">{\epsilon}\boldsymbol{\Lambda} </em>$的谱分解。}\boldsymbol{U}_{\epsilon}^{\top}$，取$\epsilon\to 0$就得到$\boldsymbol{M</p>
<h3 id="_8">数学归纳<a class="toc-link" href="#_8" title="Permanent link">&para;</a></h3>
<p>不幸的是，上面这段话只能作为一个直观但不严谨的理解方式，因为将这段话转化为严格的证明还是很困难的。事实上，严格证明谱定理的最简单方法可能是数学归纳法，即在任意$n-1$阶实对称方阵都可以谱分解的假设上，我们证明$\boldsymbol{M}$也可以谱分解。</p>
<p>证明的关键思路是将$\boldsymbol{M}$分解为某个特征向量及其$n-1$维正交子空间，从而可以应用归纳假设。具体来说，设$\lambda_1$是$\boldsymbol{M}$的一个非零特征值，$\boldsymbol{u}<em 1_times="1\times" _n-1_="(n-1)">1$是对应的单位特征向量，那么有$\boldsymbol{M}\boldsymbol{u}_1 = \lambda_1 \boldsymbol{u}_1$，我们可以补充$n-1$个跟$\boldsymbol{u}_1$正交的单位向量$\boldsymbol{Q}=(\boldsymbol{q}_2,\cdots,\boldsymbol{q}_n)$，使得$(\boldsymbol{u}_1,\boldsymbol{q}_2,\cdots,\boldsymbol{q}_n)=(\boldsymbol{u}_1,\boldsymbol{Q})$成为一个正交矩阵。现在我们考虑<br />
\begin{equation}(\boldsymbol{u}_1,\boldsymbol{Q})^{\top} \boldsymbol{M} (\boldsymbol{u}_1, \boldsymbol{Q}) = \begin{pmatrix}\boldsymbol{u}_1^{\top} \boldsymbol{M} \boldsymbol{u}_1 &amp; \boldsymbol{u}_1^{\top} \boldsymbol{M} \boldsymbol{Q} \\ \boldsymbol{Q}^{\top} \boldsymbol{M} \boldsymbol{u}_1 &amp; \boldsymbol{Q}^{\top} \boldsymbol{M} \boldsymbol{Q}\end{pmatrix} = \begin{pmatrix}\lambda_1 &amp; \boldsymbol{0}</em>} \\ \boldsymbol{0<em 1_times="1\times" _n-1_="(n-1)">{(n-1)\times 1} &amp; \boldsymbol{Q}^{\top} \boldsymbol{M} \boldsymbol{Q}\end{pmatrix}\end{equation}<br />
注意到$\boldsymbol{Q}^{\top} \boldsymbol{M} \boldsymbol{Q}$是一个$n-1$阶方阵，并且很明显是一个实对称矩阵，所以根据假设它可以谱分解为$\boldsymbol{V} \boldsymbol{\Lambda}_2 \boldsymbol{V}^{\top}$，这里$\boldsymbol{V}$是$n-1$阶正交矩阵，$\boldsymbol{\Lambda}_2$是$n-1$阶对角阵，那么我们有$(\boldsymbol{Q}\boldsymbol{V})^{\top} \boldsymbol{M} \boldsymbol{Q}\boldsymbol{V}= \boldsymbol{\Lambda}_2$。根据这个结果，我们考虑$\boldsymbol{U} = (\boldsymbol{u}_1, \boldsymbol{Q}\boldsymbol{V})$，可以验证它也是一个正交矩阵，并且<br />
\begin{equation}\boldsymbol{U}^{\top}\boldsymbol{M} \boldsymbol{U} = (\boldsymbol{u}_1,\boldsymbol{Q}\boldsymbol{V})^{\top} \boldsymbol{M} (\boldsymbol{u}_1, \boldsymbol{Q}\boldsymbol{V}) = \begin{pmatrix}\lambda_1 &amp; \boldsymbol{0}</em>} \\ \boldsymbol{0}_{(n-1)\times 1} &amp; \boldsymbol{\Lambda}_2\end{pmatrix}\end{equation<br />
也就是说$\boldsymbol{U}$正是可以将$\boldsymbol{M}$对角化的正交矩阵，所以$\boldsymbol{M}$可以完成谱分解，这就完成了数学归纳法最关键的一步。</p>
<h3 id="_9">奇异分解<a class="toc-link" href="#_9" title="Permanent link">&para;</a></h3>
<p>至此，所有准备工作都已经就绪，我们可以正式证明SVD的存在性，并给出一个实际计算的方案。</p>
<p>上一节我们引入了谱分解，不难发现它跟SVD的相似性，但也有两点明显区别：1、谱分解只适用于实对称矩阵，SVD适用于任意实矩阵；2、SVD的对角阵$\boldsymbol{\Sigma}$是非负的，但谱分解的$\boldsymbol{\Lambda}$则未必。那么，它们具体联系是什么呢？容易验证，如果$\boldsymbol{M}$的SVD为$\boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}$，那么<br />
\begin{equation}\begin{aligned}
\boldsymbol{M}\boldsymbol{M}^{\top} = \boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}\boldsymbol{V}\boldsymbol{\Sigma}^{\top} \boldsymbol{U}^{\top} = \boldsymbol{U}\boldsymbol{\Sigma}\boldsymbol{\Sigma}^{\top} \boldsymbol{U}^{\top}\\
\boldsymbol{M}^{\top}\boldsymbol{M} = \boldsymbol{V}\boldsymbol{\Sigma}^{\top} \boldsymbol{U}^{\top}\boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top} = \boldsymbol{V}\boldsymbol{\Sigma}^{\top}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}\\
\end{aligned}\end{equation}<br />
注意到$\boldsymbol{\Sigma}\boldsymbol{\Sigma}^{\top}$和$\boldsymbol{\Sigma}^{\top}\boldsymbol{\Sigma}$都是对角阵，所以这意味着$\boldsymbol{M}\boldsymbol{M}^{\top}$和$\boldsymbol{M}^{\top}\boldsymbol{M}$的谱分解分别是$\boldsymbol{U}\boldsymbol{\Sigma}^2 \boldsymbol{U}^{\top}$和$\boldsymbol{V}\boldsymbol{\Sigma}^2 \boldsymbol{V}^{\top}$。这看起来将$\boldsymbol{M}\boldsymbol{M}^{\top}$、$\boldsymbol{M}^{\top}\boldsymbol{M}$分别做谱分解就可以得到$\boldsymbol{M}$的SVD了？确实没错，这可以作为SVD的一种计算方式，但我们无法直接通过它证明这样得出的$\boldsymbol{U},\boldsymbol{\Sigma},\boldsymbol{V}$满足$\boldsymbol{M}=\boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}$。</p>
<p>解决问题的关键是只对$\boldsymbol{M}\boldsymbol{M}^{\top}$或$\boldsymbol{M}^{\top}\boldsymbol{M}$之一做谱分解，然后通过另外的方法构造另一侧的正交矩阵。不失一般性，我们设$\boldsymbol{M}$的秩为$r \leq m$，考虑对$\boldsymbol{M}^{\top}\boldsymbol{M}$做谱分解为$\boldsymbol{V}\boldsymbol{\Lambda} \boldsymbol{V}^{\top}$，注意$\boldsymbol{M}^{\top}\boldsymbol{M}$是一个半正定矩阵，所以$\boldsymbol{\Lambda}$是非负的，并且假设对角线元素已经从大到小排列，秩$r$意味着只有前$r$个$\lambda_i$是大于0的，我们定义<br />
\begin{equation}\boldsymbol{\Sigma}<em _:r_:r_="[:r,:r]">{[:r,:r]} = (\boldsymbol{\Lambda}</em>})^{1/2},\quad \boldsymbol{U<em _:m_:r_="[:m,:r]">{[:n,:r]} = \boldsymbol{M}\boldsymbol{V}</em>}\boldsymbol{\Sigma<em _:n_:r_="[:n,:r]">{[:r,:r]}^{-1}\end{equation}<br />
可以验证<br />
\begin{equation}\begin{aligned}
\boldsymbol{U}</em>}^{\top}\boldsymbol{U<em _:r_:r_="[:r,:r]">{[:n,:r]} =&amp;\, \boldsymbol{\Sigma}</em>}^{-1}\boldsymbol{V<em _:m_:r_="[:m,:r]">{[:m,:r]}^{\top} \boldsymbol{M}^{\top}\boldsymbol{M}\boldsymbol{V}</em>}\boldsymbol{\Sigma<em _:r_:r_="[:r,:r]">{[:r,:r]}^{-1} \\
=&amp;\, \boldsymbol{\Sigma}</em>}^{-1}\boldsymbol{V<em _:m_:r_="[:m,:r]">{[:m,:r]}^{\top} \boldsymbol{V}\boldsymbol{\Lambda} \boldsymbol{V}^{\top}\boldsymbol{V}</em>}\boldsymbol{\Sigma<em _:r_:r_="[:r,:r]">{[:r,:r]}^{-1} \\
=&amp;\, \boldsymbol{\Sigma}</em>}^{-1}\boldsymbol{I<em _:m_:r_="[:m,:r]">{[:r,:m]}\boldsymbol{\Lambda} \boldsymbol{I}</em>}\boldsymbol{\Sigma<em _:r_:r_="[:r,:r]">{[:r,:r]}^{-1} \\
=&amp;\, \boldsymbol{\Sigma}</em>}^{-1}\boldsymbol{\Lambda<em _:r_:r_="[:r,:r]">{[:r,:r]}\boldsymbol{\Sigma}</em> \\}^{-1
=&amp;\, \boldsymbol{I}<em _:n_:r_="[:n,:r]">r \\
\end{aligned}\end{equation}<br />
这里约定切片的优先级高于转置、求逆等矩阵运算，即$\boldsymbol{U}</em>}^{\top}=(\boldsymbol{U<em _:r_:r_="[:r,:r]">{[:n,:r]})^{\top}$、$\boldsymbol{\Sigma}</em>}^{-1}=(\boldsymbol{\Sigma<em _:n_:r_="[:n,:r]">{[:r,:r]})^{-1}$等。上述结果表明$\boldsymbol{U}</em>$是正交矩阵的一部份。接着我们有<br />
\begin{equation}\boldsymbol{U}<em _:r_:r_="[:r,:r]">{[:n,:r]}\boldsymbol{\Sigma}</em>}\boldsymbol{V<em _:m_:r_="[:m,:r]">{[:m,:r]}^{\top} = \boldsymbol{M}\boldsymbol{V}</em>}\boldsymbol{\Sigma<em _:r_:r_="[:r,:r]">{[:r,:r]}^{-1}\boldsymbol{\Sigma}</em>}\boldsymbol{V<em _:m_:r_="[:m,:r]">{[:m,:r]}^{\top} = \boldsymbol{M}\boldsymbol{V}</em>}\boldsymbol{V<em _:m_:r_="[:m,:r]">{[:m,:r]}^{\top}\end{equation}<br />
注意$\boldsymbol{M}\boldsymbol{V}\boldsymbol{V}^{\top} = \boldsymbol{M}$是恒成立的，而$\boldsymbol{V}</em>}$是$\boldsymbol{V}$的前$r$列，根据$\boldsymbol{M}^{\top}\boldsymbol{M}=\boldsymbol{V}\boldsymbol{\Lambda} \boldsymbol{V}^{\top}$我们有可以写出$(\boldsymbol{M}\boldsymbol{V})^{\top}\boldsymbol{M}\boldsymbol{V} = \boldsymbol{\Lambda}$，我们记$\boldsymbol{V}=(\boldsymbol{v<em _:m_:r_="[:m,:r]">1,\boldsymbol{v}_2,\cdots,\boldsymbol{v}_m)$，那么就有$\Vert \boldsymbol{M}\boldsymbol{v}_i\Vert^2=\lambda_i$，由于秩$r$的设定，所以当$i &gt; r$时$\lambda_i=0$，这意味着此时的$\boldsymbol{M}\boldsymbol{v}_i$实际上是一个零向量，所以<br />
\begin{equation}\begin{aligned}\boldsymbol{M} = \boldsymbol{M}\boldsymbol{V}\boldsymbol{V}^{\top} =&amp;\, (\boldsymbol{M}\boldsymbol{V}</em>}, \boldsymbol{M}\boldsymbol{V<em _:m_:r_="[:m,:r]">{[:m,r:]})\begin{pmatrix}\boldsymbol{V}</em>}^{\top} \\ \boldsymbol{V<em _:m_:r_="[:m,:r]">{[:m,r:]}^{\top}\end{pmatrix} \\[8pt]<br />
=&amp;\, (\boldsymbol{M}\boldsymbol{V}</em>}, \boldsymbol{0<em _:m_:r_="[:m,:r]">{m\times(m-r)} )\begin{pmatrix}\boldsymbol{V}</em>}^{\top} \\ \boldsymbol{V<em _:m_:r_="[:m,:r]">{[:m,r:]}^{\top}\end{pmatrix}\\[8pt]<br />
=&amp;\, \boldsymbol{M}\boldsymbol{V}</em>}\boldsymbol{V<em _:n_:r_="[:n,:r]">{[:m,:r]}^{\top}<br />
\end{aligned}\end{equation}<br />
这表明$\boldsymbol{U}</em>}\boldsymbol{\Sigma<em _:m_:r_="[:m,:r]">{[:r,:r]}\boldsymbol{V}</em>}^{\top}=\boldsymbol{M}$，再结合$\boldsymbol{U<em _:r_:r_="[:r,:r]">{[:n,:r]}$是正交矩阵的一部分这一事实，我们已经得到了$\boldsymbol{M}$的SVD的关键部分，我们只需要将$\boldsymbol{\Sigma}</em>$。}$补零成$n\times m$大小的$\boldsymbol{\Sigma}$，将$\boldsymbol{U}_{[:n,:r]}$补全为$n\times n$的正交矩阵$\boldsymbol{U}$，那么就得到完整的SVD形式$\boldsymbol{M}=\boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top</p>
<h2 id="_10">近似定理<a class="toc-link" href="#_10" title="Permanent link">&para;</a></h2>
<p>最后，别忘了我们的最终目标是开始的优化问题$\eqref{eq:loss-ab}$。有了SVD后，我们就可以给出答案了：</p>
<blockquote>
<p>如果$\boldsymbol{M}\in\mathbb{R}^{n\times m}$的SVD为$\boldsymbol{U}\boldsymbol{\Sigma} \boldsymbol{V}^{\top}$，那么$\boldsymbol{M}$的最优$r$秩近似为$\boldsymbol{U}<em _:r_:r_="[:r,:r]">{[:n,:r]}\boldsymbol{\Sigma}</em>$。} \boldsymbol{V}_{[:m,:r]}^{\top</p>
</blockquote>
<p>这称为“<strong>Eckart-Young-Mirsky定理</strong> ”。在介绍SVD应用的“低秩近似”一节中，我们表明通过SVD可以将一般矩阵的最优$r$秩近似问题简化为非负对角阵的$r$秩近似，所以“Eckart-Young-Mirsky定理”相当于说非负对角阵的最优$r$秩近似就是只保留对角线最大的$r$个元素的矩阵。</p>
<p>可能有读者认为“这难道不是显然成立吗？”，但事实是虽然结论很符合直觉，但它确实不是显然成立的。下面我们就聚焦于求解：<br />
\begin{equation}\min_{\boldsymbol{A},\boldsymbol{B}}\Vert \boldsymbol{A}\boldsymbol{B} - \boldsymbol{\Sigma}\Vert_F^2\end{equation}<br />
其中$\boldsymbol{A}\in\mathbb{R}^{n\times r}, \boldsymbol{B}\in\mathbb{R}^{r\times m}, \boldsymbol{\Sigma}\in\mathbb{R}^{n\times m},r &lt; \min(n,m)$。如果给定$\boldsymbol{A}$的话，$\boldsymbol{B}$的最优解我们在上一篇文章中已经求出，结果是$\boldsymbol{A}^{\dagger} \boldsymbol{\Sigma}$，所以我们有<br />
\begin{equation}\min_{\boldsymbol{A},\boldsymbol{B}}\Vert \boldsymbol{A}\boldsymbol{B} - \boldsymbol{\Sigma}\Vert_F^2 = \min_\boldsymbol{A}\Vert (\boldsymbol{A}\boldsymbol{A}^{\dagger} - \boldsymbol{I}<em>n)\boldsymbol{\Sigma}\Vert_F^2\end{equation}<br />
设矩阵$\boldsymbol{A}$的SVD为$\boldsymbol{U}</em>\boldsymbol{A}\boldsymbol{\Sigma}<em>\boldsymbol{A} \boldsymbol{V}</em>\boldsymbol{A}^{\top}$，那么$\boldsymbol{A}^{\dagger}=\boldsymbol{V}<em>\boldsymbol{A} \boldsymbol{\Sigma}</em>\boldsymbol{A}^{\dagger} \boldsymbol{U}<em>\boldsymbol{A}^{\top}$，以及<br />
\begin{equation}\begin{aligned}
\Vert (\boldsymbol{A}\boldsymbol{A}^{\dagger} - \boldsymbol{I}_n)\boldsymbol{\Sigma}\Vert_F^2 =&amp;\, \Vert (\boldsymbol{U}</em>\boldsymbol{A}\boldsymbol{\Sigma}<em>\boldsymbol{A} \boldsymbol{V}</em>\boldsymbol{A}^{\top}\boldsymbol{V}<em>\boldsymbol{A} \boldsymbol{\Sigma}</em>\boldsymbol{A}^{\dagger} \boldsymbol{U}<em>\boldsymbol{A}^{\top} - \boldsymbol{I}_n)\boldsymbol{\Sigma}\Vert_F^2 \\
=&amp;\, \Vert (\boldsymbol{U}</em>\boldsymbol{A}\boldsymbol{\Sigma}<em>\boldsymbol{A} \boldsymbol{\Sigma}</em>\boldsymbol{A}^{\dagger} \boldsymbol{U}<em>\boldsymbol{A}^{\top} - \boldsymbol{I}_n)\boldsymbol{\Sigma}\Vert_F^2 \\
=&amp;\, \Vert \boldsymbol{U}</em>\boldsymbol{A} (\boldsymbol{\Sigma}<em>\boldsymbol{A} \boldsymbol{\Sigma}</em>\boldsymbol{A}^{\dagger} - \boldsymbol{I}<em>n)\boldsymbol{U}</em>\boldsymbol{A}^{\top}\boldsymbol{\Sigma}\Vert_F^2 \\
=&amp;\, \Vert (\boldsymbol{\Sigma}<em>\boldsymbol{A} \boldsymbol{\Sigma}</em>\boldsymbol{A}^{\dagger} - \boldsymbol{I}<em>n)\boldsymbol{U}</em>\boldsymbol{A}^{\top}\boldsymbol{\Sigma}\Vert_F^2 \\
\end{aligned}\end{equation}<br />
由伪逆的计算公式知$\boldsymbol{\Sigma}<em>\boldsymbol{A} \boldsymbol{\Sigma}</em>\boldsymbol{A}^{\dagger}$是一个对角阵，并且对角线上前$r_\boldsymbol{A}$个元素为1（$r_\boldsymbol{A}\leq r$是$\boldsymbol{A}$的秩），其余都是0，所以$(\boldsymbol{\Sigma}<em>\boldsymbol{A} \boldsymbol{\Sigma}</em>\boldsymbol{A}^{\dagger} - \boldsymbol{I}<em>n)\boldsymbol{U}</em>\boldsymbol{A}^{\top}$相当于只保留正交矩阵$\boldsymbol{U}<em>\boldsymbol{A}^{\top}$的后$k=n-r</em>\boldsymbol{A}$行，所以最终可以简化成<br />
\begin{equation}\min_\boldsymbol{A}\Vert (\boldsymbol{A}\boldsymbol{A}^{\dagger} - \boldsymbol{I}<em k_boldsymbol_U="k,\boldsymbol{U">n)\boldsymbol{\Sigma}\Vert_F^2 = \min</em>}}\Vert \boldsymbol{U}\boldsymbol{\Sigma}\Vert_F^2\quad\text{s.t.}\quad k\geq n-r, \boldsymbol{U}\in\mathbb{R}^{k\times n}, \boldsymbol{U}\boldsymbol{U}^{\top} = \boldsymbol{I<em i="1">k\end{equation}<br />
现在根据$F$范数定义可以写出<br />
\begin{equation}\Vert \boldsymbol{U}\boldsymbol{\Sigma}\Vert_F^2=\sum</em>}^k \sum_{j=1}^n u_{i,j}^2 \sigma_j^2 =\sum_{j=1}^n \sigma_j^2 \underbrace{\sum_{i=1}^k u_{i,j}^2<em j="1">{w_j}=\sum</em>}^n \sigma_j^2 w_j\end{equation
注意到$0 \leq w_j \leq 1$，以及$w_1+w_2+\cdots+w_n = k$，在此约束下最右端的最小值只能是最小的$k$个$\sigma_j^2$之和，又因为$\sigma_j$已经从大到小排好序，所以
\begin{equation}\min_{k,\boldsymbol{U}}\Vert \boldsymbol{U}\boldsymbol{\Sigma}\Vert_F^2=\min_k \sum_{j=n-k+1}^n \sigma_j^2 = \sum_{j=r+1}^n \sigma_j^2\end{equation}<br />
也就是说，$\boldsymbol{\Sigma}$与它的最优$r$秩近似的误差（$F$范数平方）是$\sum\limits_{j=r+1}^n \sigma_j^2$，这正好是保留对角线最大的$r$个元素后所产生的误差，所以我们证明了“非负对角阵的最优$r$秩近似就是只保留对角线最大的$r$个元素的矩阵”。当然，这只能说是一个解，我们没有否定多解的可能性。</p>
<p>值得指出的是，Eckart-Young-Mirsky定理不仅对$F$范数成立，还对谱范数成立，谱范数的证明实际上还简单一点，这里就不展开了，有兴趣的读者自行参考维基百科“<a href="https://en.wikipedia.org/wiki/Low-rank_approximation">Low-rank approximation</a>”条目。</p>
<h2 id="_11">文章小结<a class="toc-link" href="#_11" title="Permanent link">&para;</a></h2>
<p>本文的主角是声名显赫的SVD（奇异值分解），想必不少读者已经对它有所了解。在这篇文章中，我们主要围绕着SVD与低秩近似的相关内容进行展开，对SVD的存在性、计算以及与低秩近似的联系等理论内容给出了尽可能简单的证明过程。</p>
<p><em><strong>转载到请包括本文地址：</strong><a href="https://spaces.ac.cn/archives/10407">https://spaces.ac.cn/archives/10407</a></em></p>
<p><em><strong>更详细的转载事宜请参考：</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="《科学空间FAQ》">《科学空间FAQ》</a></p>
<p><strong>如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。</strong></p>
<p><strong>如果您觉得本文还不错，欢迎分享/打赏本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！</strong></p>
<p>打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>微信打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>支付宝打赏</p>
<p>因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>点击这里</strong></a>或在下方评论区留言来告知你的建议或需求。</p>
<p><strong>如果您需要引用本文，请参考：</strong></p>
<p>苏剑林. (Oct. 01, 2024). 《低秩近似之路（二）：SVD 》[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/10407">https://spaces.ac.cn/archives/10407</a></p>
<p>@online{kexuefm-10407,<br />
title={低秩近似之路（二）：SVD},<br />
author={苏剑林},<br />
year={2024},<br />
month={Oct},<br />
url={\url{https://spaces.ac.cn/archives/10407}},<br />
} </p>
<hr />
<h2 id="_12">公式推导与注释<a class="toc-link" href="#_12" title="Permanent link">&para;</a></h2>
<p>本节提供低秩近似和SVD相关定理的极详细数学推导，从多个角度（矩阵分析、最优化理论、数值线性代数）深入理解这些核心结果。</p>
<h3 id="eckart-young-mirsky">一、Eckart-Young-Mirsky定理的完整证明<a class="toc-link" href="#eckart-young-mirsky" title="Permanent link">&para;</a></h3>
<h4 id="11">1.1 定理陈述<a class="toc-link" href="#11" title="Permanent link">&para;</a></h4>
<p><strong>定理（Eckart-Young-Mirsky, 1936）</strong>：设$\boldsymbol{M}\in\mathbb{R}^{n\times m}$的奇异值分解为
\begin{equation}
\boldsymbol{M} = \boldsymbol{U}\boldsymbol{\Sigma}\boldsymbol{V}^{\top} = \sum_{i=1}^{\rho}\sigma_i\boldsymbol{u}<em>i\boldsymbol{v}_i^{\top}
\end{equation}
其中$\rho=\text{rank}(\boldsymbol{M})$，$\sigma_1\geq\sigma_2\geq\cdots\geq\sigma</em>\rho &gt; 0$是奇异值。定义截断SVD
\begin{equation}
\boldsymbol{M}<em i="1">r = \sum</em>}^r\sigma_i\boldsymbol{u<em _:n_:r_="[:n,:r]">i\boldsymbol{v}_i^{\top} = \boldsymbol{U}</em>}\boldsymbol{\Sigma<em _:m_:r_="[:m,:r]">{[:r,:r]}\boldsymbol{V}</em>
\end{equation}
则对于任意秩不超过$r$的矩阵$\boldsymbol{X}\in\mathbb{R}^{n\times m}$，有
\begin{equation}
\Vert\boldsymbol{M} - \boldsymbol{M}}^{\top<em r_1="r+1">r\Vert_F \leq \Vert\boldsymbol{M} - \boldsymbol{X}\Vert_F
\end{equation}
且
\begin{equation}
\Vert\boldsymbol{M} - \boldsymbol{M}_r\Vert_2 \leq \Vert\boldsymbol{M} - \boldsymbol{X}\Vert_2
\end{equation}
当且仅当$\boldsymbol{X} = \boldsymbol{M}_r$时等号成立（在$F$范数意义下，如果$\sigma_r &gt; \sigma</em>$）。</p>
<h4 id="12-frobenius">1.2 Frobenius范数下的证明<a class="toc-link" href="#12-frobenius" title="Permanent link">&para;</a></h4>
<p><strong>证明思路</strong>：利用SVD的正交不变性和变分原理。</p>
<p><strong>步骤1：正交不变性化简</strong></p>
<p>设$\boldsymbol{X}$是任意秩不超过$r$的矩阵。由于$\boldsymbol{U}$和$\boldsymbol{V}$是正交矩阵，我们有
\begin{equation}
\begin{aligned}
\Vert\boldsymbol{M} - \boldsymbol{X}\Vert_F^2 &amp;= \Vert\boldsymbol{U}^{\top}(\boldsymbol{M} - \boldsymbol{X})\boldsymbol{V}\Vert_F^2 \
&amp;= \Vert\boldsymbol{U}^{\top}\boldsymbol{M}\boldsymbol{V} - \boldsymbol{U}^{\top}\boldsymbol{X}\boldsymbol{V}\Vert_F^2 \
&amp;= \Vert\boldsymbol{\Sigma} - \boldsymbol{U}^{\top}\boldsymbol{X}\boldsymbol{V}\Vert_F^2
\end{aligned}
\end{equation}</p>
<p>注意到$\boldsymbol{Y} = \boldsymbol{U}^{\top}\boldsymbol{X}\boldsymbol{V}$仍然是秩不超过$r$的矩阵（正交变换不改变秩）。因此问题简化为：
\begin{equation}
\min_{\text{rank}(\boldsymbol{X})\leq r}\Vert\boldsymbol{M} - \boldsymbol{X}\Vert_F^2 = \min_{\text{rank}(\boldsymbol{Y})\leq r}\Vert\boldsymbol{\Sigma} - \boldsymbol{Y}\Vert_F^2
\end{equation}</p>
<p><strong>步骤2：对角矩阵的最优近似</strong></p>
<p>现在考虑对角矩阵$\boldsymbol{\Sigma}$的最优秩$r$近似。设$\boldsymbol{\Sigma}$的大小为$n\times m$，我们将其分解为
\begin{equation}
\boldsymbol{\Sigma} = \begin{pmatrix}
\sigma_1 &amp; 0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \
0 &amp; \sigma_2 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \ddots &amp; \vdots \
0 &amp; 0 &amp; \cdots &amp; \sigma_{\min(n,m)} &amp; \cdots &amp; 0
\end{pmatrix}
\end{equation}</p>
<p>对于任意秩不超过$r$的矩阵$\boldsymbol{Y}$，我们有SVD分解$\boldsymbol{Y} = \boldsymbol{P}\boldsymbol{D}\boldsymbol{Q}^{\top}$，其中$\boldsymbol{D}$至多有$r$个非零对角元。</p>
<p><strong>步骤3：Von Neumann迹不等式应用</strong></p>
<p>利用Von Neumann迹不等式（后文详细证明），对于任意矩阵$\boldsymbol{A},\boldsymbol{B}\in\mathbb{R}^{n\times m}$，有
\begin{equation}
\text{tr}(\boldsymbol{A}^{\top}\boldsymbol{B}) \leq \sum_{i=1}^{\min(n,m)}\sigma_i(\boldsymbol{A})\sigma_i(\boldsymbol{B})
\end{equation}
其中$\sigma_i(\boldsymbol{A})$表示$\boldsymbol{A}$的第$i$大奇异值（降序排列）。</p>
<p>对于误差矩阵$\boldsymbol{E} = \boldsymbol{\Sigma} - \boldsymbol{Y}$，我们有
\begin{equation}
\begin{aligned}
\Vert\boldsymbol{E}\Vert_F^2 &amp;= \text{tr}(\boldsymbol{E}^{\top}\boldsymbol{E}) \
&amp;= \text{tr}[(\boldsymbol{\Sigma} - \boldsymbol{Y})^{\top}(\boldsymbol{\Sigma} - \boldsymbol{Y})] \
&amp;= \text{tr}(\boldsymbol{\Sigma}^{\top}\boldsymbol{\Sigma}) - 2\text{tr}(\boldsymbol{\Sigma}^{\top}\boldsymbol{Y}) + \text{tr}(\boldsymbol{Y}^{\top}\boldsymbol{Y}) \
&amp;= \sum_{i=1}^{\rho}\sigma_i^2 - 2\text{tr}(\boldsymbol{\Sigma}^{\top}\boldsymbol{Y}) + \sum_{i=1}^r d_i^2
\end{aligned}
\end{equation}
其中$d_i$是$\boldsymbol{Y}$的奇异值。</p>
<p><strong>步骤4：最小化误差</strong></p>
<p>要最小化$\Vert\boldsymbol{E}\Vert_F^2$，需要最大化$\text{tr}(\boldsymbol{\Sigma}^{\top}\boldsymbol{Y}) - \frac{1}{2}\sum_{i=1}^r d_i^2$。</p>
<p>由Von Neumann不等式，
\begin{equation}
\text{tr}(\boldsymbol{\Sigma}^{\top}\boldsymbol{Y}) \leq \sum_{i=1}^r \sigma_i \cdot d_i
\end{equation}
其中我们注意到$\boldsymbol{Y}$至多有$r$个非零奇异值。</p>
<p>进一步，由Cauchy-Schwarz不等式的加权形式，在约束$\sum_{i=1}^r d_i^2 = c$（常数）下，
\begin{equation}
\sum_{i=1}^r \sigma_i d_i \leq \sqrt{\sum_{i=1}^r \sigma_i^2} \cdot \sqrt{\sum_{i=1}^r d_i^2}
\end{equation}</p>
<p>但更直接的方法是考虑$\boldsymbol{Y}$的最优选择。当$\boldsymbol{Y} = \boldsymbol{\Sigma}<em i="1">r$（即只保留$\boldsymbol{\Sigma}$的前$r$个对角元素）时，
\begin{equation}
\text{tr}(\boldsymbol{\Sigma}^{\top}\boldsymbol{\Sigma}_r) = \sum</em>^r \sigma_i^2
\end{equation}
此时误差为
\begin{equation}
\Vert\boldsymbol{\Sigma} - \boldsymbol{\Sigma}<em i="1">r\Vert_F^2 = \sum</em>\sigma_i^2
\end{equation}}^{\rho}\sigma_i^2 - 2\sum_{i=1}^r\sigma_i^2 + \sum_{i=1}^r\sigma_i^2 = \sum_{i=r+1}^{\rho</p>
<p><strong>步骤5：证明这是全局最优</strong></p>
<p>现在我们证明任何其他秩不超过$r$的矩阵$\boldsymbol{Y}$都不会产生更小的误差。考虑分解
\begin{equation}
\boldsymbol{\Sigma} - \boldsymbol{Y} = \boldsymbol{\Sigma} - \boldsymbol{\Sigma}_r + \boldsymbol{\Sigma}_r - \boldsymbol{Y}
\end{equation}</p>
<p>关键观察：$\boldsymbol{\Sigma} - \boldsymbol{\Sigma}_r$和$\boldsymbol{\Sigma}_r - \boldsymbol{Y}$在适当意义下是"正交"的。具体地，我们可以将矩阵空间分解为两个正交子空间：</p>
<ul>
<li>子空间$\mathcal{S}_1$：由前$r$个奇异向量张成</li>
<li>子空间$\mathcal{S}_2$：由后$\rho-r$个奇异向量张成</li>
</ul>
<p>则$\boldsymbol{\Sigma}_r\in\mathcal{S}_1$，而$\boldsymbol{\Sigma} - \boldsymbol{\Sigma}_r\in\mathcal{S}_2$。</p>
<p>对于任意秩不超过$r$的$\boldsymbol{Y}$，可以将其分解为$\boldsymbol{Y} = \boldsymbol{Y}_1 + \boldsymbol{Y}_2$，其中$\boldsymbol{Y}_1\in\mathcal{S}_1$，$\boldsymbol{Y}_2\in\mathcal{S}_2$。由于$\boldsymbol{Y}$的秩不超过$r$，且$\mathcal{S}_2$的维数为$\rho - r$，根据维数定理，$\boldsymbol{Y}_2$的秩至多为$\min(r, \rho-r)$。</p>
<p>由Pythagorean定理（在Frobenius内积下），
\begin{equation}
\begin{aligned}
\Vert\boldsymbol{\Sigma} - \boldsymbol{Y}\Vert_F^2 &amp;= \Vert(\boldsymbol{\Sigma} - \boldsymbol{\Sigma}<em i="r+1">r) + (\boldsymbol{\Sigma}_r - \boldsymbol{Y})\Vert_F^2 \
&amp;= \Vert\boldsymbol{\Sigma} - \boldsymbol{\Sigma}_r - \boldsymbol{Y}_2\Vert_F^2 + \Vert\boldsymbol{\Sigma}_r - \boldsymbol{Y}_1\Vert_F^2 \
&amp;\geq \Vert\boldsymbol{\Sigma} - \boldsymbol{\Sigma}_r\Vert_F^2 = \sum</em>\sigma_i^2
\end{aligned}
\end{equation}}^{\rho</p>
<p>等号成立当且仅当$\boldsymbol{Y}_2 = \boldsymbol{0}$且$\boldsymbol{Y}_1 = \boldsymbol{\Sigma}_r$，即$\boldsymbol{Y} = \boldsymbol{\Sigma}_r$。</p>
<p>回到原问题，这表明$\boldsymbol{M}<em i="r+1">r = \boldsymbol{U}\boldsymbol{\Sigma}_r\boldsymbol{V}^{\top}$是$\boldsymbol{M}$的最优秩$r$近似，且误差为
\begin{equation}
\Vert\boldsymbol{M} - \boldsymbol{M}_r\Vert_F = \sqrt{\sum</em>
\end{equation}}^{\rho}\sigma_i^2</p>
<h4 id="13">1.3 谱范数下的证明<a class="toc-link" href="#13" title="Permanent link">&para;</a></h4>
<p><strong>定理</strong>：在谱范数（2-范数）意义下，$\boldsymbol{M}<em r_1="r+1">r$也是最优秩$r$近似，且
\begin{equation}
\Vert\boldsymbol{M} - \boldsymbol{M}_r\Vert_2 = \sigma</em>
\end{equation}</p>
<p><strong>证明</strong>：</p>
<p><strong>步骤1：谱范数的性质</strong></p>
<p>回顾谱范数的定义：
\begin{equation}
\Vert\boldsymbol{A}\Vert_2 = \max_{\Vert\boldsymbol{x}\Vert_2=1}\Vert\boldsymbol{A}\boldsymbol{x}\Vert_2 = \sigma_{\max}(\boldsymbol{A})
\end{equation}</p>
<p>对于误差矩阵$\boldsymbol{E}_r = \boldsymbol{M} - \boldsymbol{M}_r$，我们有
\begin{equation}
\boldsymbol{E}_r = \boldsymbol{U}\boldsymbol{\Sigma}\boldsymbol{V}^{\top} - \boldsymbol{U}\boldsymbol{\Sigma}_r\boldsymbol{V}^{\top} = \boldsymbol{U}(\boldsymbol{\Sigma} - \boldsymbol{\Sigma}_r)\boldsymbol{V}^{\top}
\end{equation}</p>
<p>由于正交变换不改变谱范数，
\begin{equation}
\Vert\boldsymbol{E}_r\Vert_2 = \Vert\boldsymbol{\Sigma} - \boldsymbol{\Sigma}_r\Vert_2
\end{equation}</p>
<p>而$\boldsymbol{\Sigma} - \boldsymbol{\Sigma}<em r_1="r+1">r$是对角矩阵，对角元素为$(0,\ldots,0,\sigma</em>,0,\ldots)$，因此
\begin{equation}
\Vert\boldsymbol{\Sigma} - \boldsymbol{\Sigma}},\sigma_{r+2},\ldots,\sigma_{\rho<em r_1="r+1">r\Vert_2 = \sigma</em>
\end{equation}</p>
<p><strong>步骤2：证明最优性</strong></p>
<p>对于任意秩不超过$r$的矩阵$\boldsymbol{X}$，我们需要证明$\Vert\boldsymbol{M} - \boldsymbol{X}\Vert_2 \geq \sigma_{r+1}$。</p>
<p>利用Weyl不等式（奇异值的扰动理论），对于矩阵$\boldsymbol{A},\boldsymbol{B}$，有
\begin{equation}
\sigma_i(\boldsymbol{A} + \boldsymbol{B}) \leq \sigma_j(\boldsymbol{A}) + \sigma_{i-j}(\boldsymbol{B}), \quad \forall i,j
\end{equation}</p>
<p>应用到$\boldsymbol{M} = \boldsymbol{X} + (\boldsymbol{M} - \boldsymbol{X})$，取$i = r+1$，$j = 1$：
\begin{equation}
\sigma_{r+1}(\boldsymbol{M}) \leq \sigma_1(\boldsymbol{X}) + \sigma_r(\boldsymbol{M} - \boldsymbol{X})
\end{equation}</p>
<p>但由于$\text{rank}(\boldsymbol{X}) \leq r$，我们有$\sigma_{r+1}(\boldsymbol{X}) = 0$。</p>
<p>更直接的方法是使用<strong>Ky Fan范数</strong>的性质。定义Ky Fan $k$-范数为
\begin{equation}
\Vert\boldsymbol{A}\Vert_{(k)} = \sum_{i=1}^k \sigma_i(\boldsymbol{A})
\end{equation}</p>
<p>特别地，$\Vert\boldsymbol{A}\Vert_{(1)} = \Vert\boldsymbol{A}\Vert_2$。</p>
<p><strong>引理（Mirsky, 1960）</strong>：对于任意矩阵$\boldsymbol{A},\boldsymbol{B}$和$1\leq k\leq \min(n,m)$，
\begin{equation}
|\Vert\boldsymbol{A}\Vert_{(k)} - \Vert\boldsymbol{B}\Vert_{(k)}| \leq \Vert\boldsymbol{A} - \boldsymbol{B}\Vert_{(k)}
\end{equation}</p>
<p>对于$k=1$（谱范数），这给出
\begin{equation}
|\sigma_1(\boldsymbol{M}) - \sigma_1(\boldsymbol{X})| \leq \Vert\boldsymbol{M} - \boldsymbol{X}\Vert_2
\end{equation}</p>
<p>现在考虑子空间的角度。设$\mathcal{V}_1$是$\boldsymbol{M}$的前$r+1$个右奇异向量张成的子空间，$\mathcal{V}_2$是$\boldsymbol{X}$的所有右奇异向量（至多$r$个）张成的子空间。由维数定理，
\begin{equation}
\dim(\mathcal{V}_1 \cap \mathcal{V}_2^{\perp}) \geq (r+1) - r = 1
\end{equation}</p>
<p>因此存在单位向量$\boldsymbol{v}\in\mathcal{V}_1$使得$\boldsymbol{v}\perp\mathcal{V}_2$，即$\boldsymbol{X}\boldsymbol{v} = \boldsymbol{0}$。此时
\begin{equation}
\Vert(\boldsymbol{M} - \boldsymbol{X})\boldsymbol{v}\Vert_2 = \Vert\boldsymbol{M}\boldsymbol{v}\Vert_2
\end{equation}</p>
<p>由于$\boldsymbol{v}$可以表示为前$r+1$个右奇异向量的线性组合，设$\boldsymbol{v} = \sum_{i=1}^{r+1}c_i\boldsymbol{v}<em i="1">i$，$\sum</em>c_i^2 = 1$，则
\begin{equation}
\Vert\boldsymbol{M}\boldsymbol{v}\Vert_2^2 = \left\Vert\sum_{i=1}^{r+1}\sigma_i c_i\boldsymbol{u}}^{r+1<em i="1">i\right\Vert_2^2 = \sum</em>^2
\end{equation}}^{r+1}\sigma_i^2 c_i^2 \geq \sigma_{r+1}^2\sum_{i=1}^{r+1}c_i^2 = \sigma_{r+1</p>
<p>因此
\begin{equation}
\Vert\boldsymbol{M} - \boldsymbol{X}\Vert_2 \geq \Vert(\boldsymbol{M} - \boldsymbol{X})\boldsymbol{v}\Vert_2 = \Vert\boldsymbol{M}\boldsymbol{v}\Vert_2 \geq \sigma_{r+1}
\end{equation}</p>
<p>这证明了$\boldsymbol{M}_r$在谱范数意义下也是最优的。□</p>
<h3 id="schmidt-mirsky">二、Schmidt-Mirsky定理与扰动分析<a class="toc-link" href="#schmidt-mirsky" title="Permanent link">&para;</a></h3>
<h4 id="21-schmidt-mirsky">2.1 Schmidt-Mirsky定理<a class="toc-link" href="#21-schmidt-mirsky" title="Permanent link">&para;</a></h4>
<p><strong>定理（Schmidt-Mirsky）</strong>：设$\boldsymbol{A},\boldsymbol{B}\in\mathbb{R}^{n\times m}$的奇异值分别为$\sigma_1(\boldsymbol{A})\geq\cdots\geq\sigma_p(\boldsymbol{A})$和$\sigma_1(\boldsymbol{B})\geq\cdots\geq\sigma_p(\boldsymbol{B})$，其中$p=\min(n,m)$。则
\begin{equation}
\sum_{i=1}^k |\sigma_i(\boldsymbol{A}) - \sigma_i(\boldsymbol{B})| \leq \Vert\boldsymbol{A} - \boldsymbol{B}\Vert_{(k)}, \quad k=1,2,\ldots,p
\end{equation}
特别地，当$k=p$时，
\begin{equation}
\sum_{i=1}^p |\sigma_i(\boldsymbol{A}) - \sigma_i(\boldsymbol{B})| \leq \Vert\boldsymbol{A} - \boldsymbol{B}\Vert_F
\end{equation}</p>
<p><strong>证明思路</strong>：利用Von Neumann迹定理和变分原理。</p>
<p><strong>步骤1：Von Neumann迹定理</strong></p>
<p>首先陈述Von Neumann迹定理，这是证明的核心工具。</p>
<p><strong>定理（Von Neumann, 1937）</strong>：对于任意$\boldsymbol{A},\boldsymbol{B}\in\mathbb{R}^{n\times m}$，
\begin{equation}
\text{tr}(\boldsymbol{A}^{\top}\boldsymbol{B}) \leq \sum_{i=1}^p \sigma_i(\boldsymbol{A})\sigma_i(\boldsymbol{B})
\end{equation}
等号成立当且仅当$\boldsymbol{A}$和$\boldsymbol{B}$有相同的奇异向量。</p>
<p><strong>Von Neumann定理的证明</strong>：</p>
<p>设$\boldsymbol{A} = \boldsymbol{U}_A\boldsymbol{\Sigma}_A\boldsymbol{V}_A^{\top}$，$\boldsymbol{B} = \boldsymbol{U}_B\boldsymbol{\Sigma}_B\boldsymbol{V}_B^{\top}$，则
\begin{equation}
\text{tr}(\boldsymbol{A}^{\top}\boldsymbol{B}) = \text{tr}(\boldsymbol{V}_A\boldsymbol{\Sigma}_A\boldsymbol{U}_A^{\top}\boldsymbol{U}_B\boldsymbol{\Sigma}_B\boldsymbol{V}_B^{\top})
\end{equation}</p>
<p>定义$\boldsymbol{P} = \boldsymbol{U}_A^{\top}\boldsymbol{U}_B$，$\boldsymbol{Q} = \boldsymbol{V}_A^{\top}\boldsymbol{V}_B$，它们都是正交矩阵（或半正交矩阵）。则
\begin{equation}
\text{tr}(\boldsymbol{A}^{\top}\boldsymbol{B}) = \text{tr}(\boldsymbol{Q}\boldsymbol{\Sigma}_A\boldsymbol{P}\boldsymbol{\Sigma}_B) = \text{tr}(\boldsymbol{\Sigma}_A\boldsymbol{P}\boldsymbol{\Sigma}_B\boldsymbol{Q})
\end{equation}</p>
<p>展开为
\begin{equation}
\text{tr}(\boldsymbol{A}^{\top}\boldsymbol{B}) = \sum_{i,j,k}\sigma_i(\boldsymbol{A})p_{ij}\sigma_j(\boldsymbol{B})q_{jk}\delta_{ik} = \sum_{i,j}\sigma_i(\boldsymbol{A})\sigma_j(\boldsymbol{B})p_{ij}q_{ji}
\end{equation}</p>
<p>定义$\boldsymbol{C} = \boldsymbol{P}\odot\boldsymbol{Q}^{\top}$（Hadamard积的某种变形），其中$c_{ij} = p_{ij}q_{ji}$。注意到
\begin{equation}
\sum_j |c_{ij}| \leq \sum_j |p_{ij}| \cdot |q_{ji}| \leq 1, \quad \sum_i |c_{ij}| \leq 1
\end{equation}</p>
<p>即$\boldsymbol{C}$的行和列的绝对值之和都不超过1（双随机矩阵的推广）。</p>
<p>根据<strong>Hardy-Littlewood-Pólya不等式</strong>，对于降序排列的序列$a_1\geq\cdots\geq a_p$和$b_1\geq\cdots\geq b_p$，以及满足上述条件的矩阵$\boldsymbol{C}$，有
\begin{equation}
\sum_{i,j}a_i c_{ij} b_j \leq \sum_{i=1}^p a_i b_i
\end{equation}</p>
<p>应用到我们的情形，得到
\begin{equation}
\text{tr}(\boldsymbol{A}^{\top}\boldsymbol{B}) = \sum_{i,j}\sigma_i(\boldsymbol{A})c_{ij}\sigma_j(\boldsymbol{B}) \leq \sum_{i=1}^p\sigma_i(\boldsymbol{A})\sigma_i(\boldsymbol{B})
\end{equation}</p>
<p>等号成立需要$\boldsymbol{C}$是单位矩阵，即$\boldsymbol{P}$和$\boldsymbol{Q}$都是单位矩阵，这意味着$\boldsymbol{A}$和$\boldsymbol{B}$有相同的左右奇异向量。□</p>
<p><strong>步骤2：应用Von Neumann定理证明Schmidt-Mirsky定理</strong></p>
<p>定义$\boldsymbol{E} = \boldsymbol{A} - \boldsymbol{B}$。考虑$\boldsymbol{A}$的前$k$个主奇异向量$\boldsymbol{u}<em i="1">1,\ldots,\boldsymbol{u}_k$和$\boldsymbol{v}_1,\ldots,\boldsymbol{v}_k$，定义投影矩阵
\begin{equation}
\boldsymbol{P}_k = \sum</em>}^k \boldsymbol{u<em i="1">i\boldsymbol{u}_i^{\top}, \quad \boldsymbol{Q}_k = \sum</em>
\end{equation}}^k \boldsymbol{v}_i\boldsymbol{v}_i^{\top</p>
<p>则
\begin{equation}
\boldsymbol{A}<em i="1">k = \boldsymbol{P}_k\boldsymbol{A}\boldsymbol{Q}_k = \sum</em>
\end{equation}}^k\sigma_i(\boldsymbol{A})\boldsymbol{u}_i\boldsymbol{v}_i^{\top</p>
<p>类似地定义$\boldsymbol{B}<em i="1">k$。则
\begin{equation}
\begin{aligned}
\sum</em>}^k\sigma_i(\boldsymbol{A}) &amp;= \text{tr}(\boldsymbol{A<em i="1">k) = \text{tr}(\boldsymbol{P}_k\boldsymbol{A}\boldsymbol{Q}_k) \
&amp;= \text{tr}(\boldsymbol{P}_k\boldsymbol{B}\boldsymbol{Q}_k) + \text{tr}(\boldsymbol{P}_k\boldsymbol{E}\boldsymbol{Q}_k) \
&amp;\leq \sum</em>}^k\sigma_i(\boldsymbol{B}) + \Vert\boldsymbol{P<em _k_="(k)">k\boldsymbol{E}\boldsymbol{Q}_k\Vert</em>
\end{aligned}
\end{equation}</p>
<p>最后一步应用了Von Neumann不等式。进一步，由于$\boldsymbol{P}<em _k_="(k)">k$和$\boldsymbol{Q}_k$是投影，
\begin{equation}
\Vert\boldsymbol{P}_k\boldsymbol{E}\boldsymbol{Q}_k\Vert</em>
\end{equation}} \leq \Vert\boldsymbol{E}\Vert_{(k)</p>
<p>类似地，交换$\boldsymbol{A}$和$\boldsymbol{B}$的角色，得到
\begin{equation}
\sum_{i=1}^k\sigma_i(\boldsymbol{B}) \leq \sum_{i=1}^k\sigma_i(\boldsymbol{A}) + \Vert\boldsymbol{E}\Vert_{(k)}
\end{equation}</p>
<p>结合两个不等式，得到
\begin{equation}
\sum_{i=1}^k|\sigma_i(\boldsymbol{A}) - \sigma_i(\boldsymbol{B})| \leq \Vert\boldsymbol{A} - \boldsymbol{B}\Vert_{(k)}
\end{equation}</p>
<p>特别地，当$k=p$时，$\Vert\boldsymbol{A} - \boldsymbol{B}\Vert_{(p)} = \Vert\boldsymbol{A} - \boldsymbol{B}\Vert_F$。□</p>
<h4 id="22">2.2 相对误差和绝对误差界<a class="toc-link" href="#22" title="Permanent link">&para;</a></h4>
<p>对于低秩近似，我们关心两类误差界：</p>
<p><strong>绝对误差界</strong>：
\begin{equation}
\Vert\boldsymbol{M} - \boldsymbol{M}<em i="r+1">r\Vert_F = \sqrt{\sum</em>}^{\rho}\sigma_i^2}, \quad \Vert\boldsymbol{M} - \boldsymbol{M<em r_1="r+1">r\Vert_2 = \sigma</em>
\end{equation}</p>
<p><strong>相对误差界</strong>：定义相对误差为
\begin{equation}
\varepsilon_F = \frac{\Vert\boldsymbol{M} - \boldsymbol{M}<em i="r+1">r\Vert_F}{\Vert\boldsymbol{M}\Vert_F} = \sqrt{\frac{\sum</em>
\end{equation}
\begin{equation}
\varepsilon_2 = \frac{\Vert\boldsymbol{M} - \boldsymbol{M}}^{\rho}\sigma_i^2}{\sum_{i=1}^{\rho}\sigma_i^2}<em r_1="r+1">r\Vert_2}{\Vert\boldsymbol{M}\Vert_2} = \frac{\sigma</em>
\end{equation}}}{\sigma_1</p>
<p><strong>能量保留率</strong>：截断SVD保留的"能量"（奇异值平方和）比例为
\begin{equation}
\eta_r = \frac{\sum_{i=1}^r\sigma_i^2}{\sum_{i=1}^{\rho}\sigma_i^2} = 1 - \varepsilon_F^2
\end{equation}</p>
<p>在实际应用中，通常选择$r$使得$\eta_r \geq 0.9$或$0.95$，即保留90%或95%的能量。</p>
<h3 id="_13">三、变分法推导最优低秩逼近<a class="toc-link" href="#_13" title="Permanent link">&para;</a></h3>
<h4 id="31">3.1 拉格朗日乘数法<a class="toc-link" href="#31" title="Permanent link">&para;</a></h4>
<p>考虑优化问题
\begin{equation}
\min_{\boldsymbol{X}}\Vert\boldsymbol{M} - \boldsymbol{X}\Vert_F^2 \quad\text{s.t.}\quad\text{rank}(\boldsymbol{X}) \leq r
\end{equation}</p>
<p>将$\boldsymbol{X}$分解为$\boldsymbol{X} = \boldsymbol{A}\boldsymbol{B}$，其中$\boldsymbol{A}\in\mathbb{R}^{n\times r}$，$\boldsymbol{B}\in\mathbb{R}^{r\times m}$。问题变为
\begin{equation}
\min_{\boldsymbol{A},\boldsymbol{B}}\Vert\boldsymbol{M} - \boldsymbol{A}\boldsymbol{B}\Vert_F^2
\end{equation}</p>
<p><strong>步骤1：对$\boldsymbol{B}$求偏导</strong></p>
<p>固定$\boldsymbol{A}$，对$\boldsymbol{B}$求导。定义损失函数
\begin{equation}
L(\boldsymbol{B}) = \text{tr}[(\boldsymbol{M} - \boldsymbol{A}\boldsymbol{B})^{\top}(\boldsymbol{M} - \boldsymbol{A}\boldsymbol{B})]
\end{equation}</p>
<p>展开：
\begin{equation}
L(\boldsymbol{B}) = \text{tr}(\boldsymbol{M}^{\top}\boldsymbol{M}) - 2\text{tr}(\boldsymbol{M}^{\top}\boldsymbol{A}\boldsymbol{B}) + \text{tr}(\boldsymbol{B}^{\top}\boldsymbol{A}^{\top}\boldsymbol{A}\boldsymbol{B})
\end{equation}</p>
<p>对$\boldsymbol{B}$求导（利用矩阵求导公式$\frac{\partial}{\partial\boldsymbol{B}}\text{tr}(\boldsymbol{B}^{\top}\boldsymbol{C}\boldsymbol{B}) = (\boldsymbol{C} + \boldsymbol{C}^{\top})\boldsymbol{B}$）：
\begin{equation}
\frac{\partial L}{\partial\boldsymbol{B}} = -2\boldsymbol{A}^{\top}\boldsymbol{M} + 2\boldsymbol{A}^{\top}\boldsymbol{A}\boldsymbol{B} = 0
\end{equation}</p>
<p>得到
\begin{equation}
\boldsymbol{B}^* = (\boldsymbol{A}^{\top}\boldsymbol{A})^{-1}\boldsymbol{A}^{\top}\boldsymbol{M} = \boldsymbol{A}^{\dagger}\boldsymbol{M}
\end{equation}</p>
<p>（假设$\boldsymbol{A}$列满秩）</p>
<p><strong>步骤2：对$\boldsymbol{A}$求偏导</strong></p>
<p>类似地，固定$\boldsymbol{B}$，得到
\begin{equation}
\boldsymbol{A}^* = \boldsymbol{M}\boldsymbol{B}^{\dagger}
\end{equation}</p>
<p><strong>步骤3：交替优化与SVD的关系</strong></p>
<p>交替优化$\boldsymbol{A}$和$\boldsymbol{B}$会收敛到局部最优。但SVD给出了全局最优的闭式解：
\begin{equation}
\boldsymbol{A}^<em> = \boldsymbol{U}<em _:r_:r_="[:r,:r]">{[:,:r]}\sqrt{\boldsymbol{\Sigma}</em>^}}, \quad \boldsymbol{B</em> = \sqrt{\boldsymbol{\Sigma}<em _:_:r_="[:,:r]">{[:r,:r]}}\boldsymbol{V}</em>
\end{equation}}^{\top</p>
<p>或更简单的分解：
\begin{equation}
\boldsymbol{A}^<em> = \boldsymbol{U}_{[:,:r]}, \quad \boldsymbol{B}^</em> = \boldsymbol{\Sigma}<em _:_:r_="[:,:r]">{[:r,:r]}\boldsymbol{V}</em>
\end{equation}}^{\top</p>
<h4 id="32">3.2 梯度流方法<a class="toc-link" href="#32" title="Permanent link">&para;</a></h4>
<p>考虑Grassmann流形上的梯度下降。设$\boldsymbol{X}(t)$是时间$t$的函数，满足
\begin{equation}
\frac{d\boldsymbol{X}}{dt} = -\nabla_{\boldsymbol{X}}L(\boldsymbol{X}) = 2(\boldsymbol{M} - \boldsymbol{X})\quad\text{with}\quad\text{rank}(\boldsymbol{X}) = r
\end{equation}</p>
<p>在秩约束下的梯度投影为
\begin{equation}
\frac{d\boldsymbol{X}}{dt} = \boldsymbol{P}<em _boldsymbol_X="\boldsymbol{X">{\mathcal{T}</em>)]
\end{equation}
其中$\boldsymbol{P}}}}[2(\boldsymbol{M} - \boldsymbol{X<em _boldsymbol_X="\boldsymbol{X">{\mathcal{T}</em>$是到秩$r$矩阵流形的切空间的投影。}}</p>
<p>这个流会收敛到$\boldsymbol{X}^* = \boldsymbol{M}_r$，即截断SVD。</p>
<h3 id="_14">四、奇异值的几何意义<a class="toc-link" href="#_14" title="Permanent link">&para;</a></h3>
<h4 id="41">4.1 超椭球的半轴长度<a class="toc-link" href="#41" title="Permanent link">&para;</a></h4>
<p>考虑单位球$\mathcal{S} = \{\boldsymbol{x}\in\mathbb{R}^m : \Vert\boldsymbol{x}\Vert_2 = 1\}$在线性变换$\boldsymbol{M}:\mathbb{R}^m\to\mathbb{R}^n$下的像：
\begin{equation}
\boldsymbol{M}(\mathcal{S}) = \{\boldsymbol{M}\boldsymbol{x} : \Vert\boldsymbol{x}\Vert_2 = 1\}
\end{equation}</p>
<p>由SVD $\boldsymbol{M} = \boldsymbol{U}\boldsymbol{\Sigma}\boldsymbol{V}^{\top}$，我们有
\begin{equation}
\boldsymbol{M}\boldsymbol{x} = \boldsymbol{U}\boldsymbol{\Sigma}(\boldsymbol{V}^{\top}\boldsymbol{x})
\end{equation}</p>
<p>设$\boldsymbol{y} = \boldsymbol{V}^{\top}\boldsymbol{x}$，由于$\boldsymbol{V}$是正交矩阵，$\Vert\boldsymbol{y}\Vert_2 = \Vert\boldsymbol{x}\Vert_2 = 1$。则
\begin{equation}
\boldsymbol{\Sigma}\boldsymbol{y} = (\sigma_1 y_1, \sigma_2 y_2, \ldots, \sigma_p y_p, 0, \ldots, 0)^{\top}
\end{equation}</p>
<p>在约束$\sum_{i=1}^p y_i^2 = 1$下，$\boldsymbol{\Sigma}\boldsymbol{y}$的轨迹是一个超椭球，其第$i$个半轴长度为$\sigma_i$。最后应用$\boldsymbol{U}$只是旋转这个超椭球。</p>
<p><strong>结论</strong>：奇异值$\sigma_i$刻画了矩阵$\boldsymbol{M}$将单位球变换为超椭球的各个主轴长度。</p>
<h4 id="42">4.2 最大拉伸方向<a class="toc-link" href="#42" title="Permanent link">&para;</a></h4>
<p>第$i$个奇异值$\sigma_i$和对应的奇异向量$(\boldsymbol{u}<em _substack_boldsymbol_x="\substack{\boldsymbol{x">i,\boldsymbol{v}_i)$满足：
\begin{equation}
\sigma_i = \max</em>}\perp\boldsymbol{v<em i-1="i-1">1,\ldots,\boldsymbol{v}</em>\Vert_2
\end{equation}} \ \Vert\boldsymbol{x}\Vert_2=1}}\Vert\boldsymbol{M}\boldsymbol{x</p>
<p>即$\sigma_i$是在与前$i-1$个右奇异向量正交的子空间中，矩阵$\boldsymbol{M}$的最大拉伸比。</p>
<p><strong>变分刻画（Courant-Fischer定理的矩阵版本）</strong>：
\begin{equation}
\sigma_i = \max_{\dim(\mathcal{V})=i}\min_{\boldsymbol{x}\in\mathcal{V},\Vert\boldsymbol{x}\Vert=1}\Vert\boldsymbol{M}\boldsymbol{x}\Vert_2 = \min_{\dim(\mathcal{W})=m-i+1}\max_{\boldsymbol{x}\in\mathcal{W},\Vert\boldsymbol{x}\Vert=1}\Vert\boldsymbol{M}\boldsymbol{x}\Vert_2
\end{equation}</p>
<h3 id="_15">五、计算复杂度分析<a class="toc-link" href="#_15" title="Permanent link">&para;</a></h3>
<h4 id="51-svd">5.1 完整SVD的计算复杂度<a class="toc-link" href="#51-svd" title="Permanent link">&para;</a></h4>
<p>对于$\boldsymbol{M}\in\mathbb{R}^{n\times m}$，假设$n\geq m$。</p>
<p><strong>方法1：通过$\boldsymbol{M}^{\top}\boldsymbol{M}$的特征值分解</strong></p>
<ol>
<li>计算$\boldsymbol{M}^{\top}\boldsymbol{M}$：$O(nm^2)$</li>
<li>对$m\times m$矩阵进行特征值分解：$O(m^3)$</li>
<li>计算左奇异向量$\boldsymbol{U}$：$O(nm^2)$</li>
</ol>
<p>总复杂度：$O(nm^2 + m^3) \approx O(nm^2)$（当$n\gg m$时）</p>
<p><strong>方法2：Golub-Kahan双对角化</strong></p>
<ol>
<li>双对角化：$O(nm^2)$</li>
<li>对双对角矩阵进行SVD：$O(m^2)$</li>
</ol>
<p>总复杂度：$O(nm^2)$</p>
<p><strong>方法3：分治法（Divide-and-Conquer）</strong></p>
<p>利用分块结构递归计算，复杂度仍为$O(nm^2)$，但常数更小。</p>
<h4 id="52-svd">5.2 截断SVD的计算复杂度<a class="toc-link" href="#52-svd" title="Permanent link">&para;</a></h4>
<p>当我们只需要前$r$个奇异值和奇异向量，且$r\ll\min(n,m)$时，可以使用迭代方法。</p>
<p><strong>Lanczos迭代</strong>（针对对称矩阵$\boldsymbol{M}^{\top}\boldsymbol{M}$或$\boldsymbol{M}\boldsymbol{M}^{\top}$）：</p>
<p>每次迭代的复杂度：$O(nm)$（矩阵-向量乘法）
迭代次数：通常$O(r)$到$O(r\log(1/\epsilon))$，其中$\epsilon$是精度</p>
<p>总复杂度：$O(nmr)$到$O(nmr\log(1/\epsilon))$</p>
<p><strong>随机化SVD</strong>（下一节详述）：</p>
<p>复杂度：$O(nm\log r + (n+m)r^2)$</p>
<p>相比完整SVD的$O(nm\min(n,m))$，当$r\ll\min(n,m)$时有显著加速。</p>
<h3 id="svd_1">六、随机化SVD算法<a class="toc-link" href="#svd_1" title="Permanent link">&para;</a></h3>
<h4 id="61">6.1 算法思想<a class="toc-link" href="#61" title="Permanent link">&para;</a></h4>
<p>随机化SVD（Halko, Martinsson, Tropp, 2011）的核心思想是：</p>
<ol>
<li><strong>随机采样</strong>：构造随机矩阵$\boldsymbol{\Omega}\in\mathbb{R}^{m\times (r+p)}$（$p$是过采样参数，通常取$5\sim 10$）</li>
<li><strong>范围查找</strong>：计算$\boldsymbol{Y} = \boldsymbol{M}\boldsymbol{\Omega}$，则$\boldsymbol{Y}$的列空间近似$\boldsymbol{M}$的前$r$个左奇异向量张成的空间</li>
<li><strong>QR分解</strong>：对$\boldsymbol{Y}$进行QR分解得到$\boldsymbol{Q}$，使得$\boldsymbol{Q}^{\top}\boldsymbol{Q} = \boldsymbol{I}_{r+p}$</li>
<li><strong>投影</strong>：计算$\boldsymbol{B} = \boldsymbol{Q}^{\top}\boldsymbol{M}$</li>
<li><strong>小规模SVD</strong>：对$\boldsymbol{B}\in\mathbb{R}^{(r+p)\times m}$进行SVD：$\boldsymbol{B} = \tilde{\boldsymbol{U}}\tilde{\boldsymbol{\Sigma}}\tilde{\boldsymbol{V}}^{\top}$</li>
<li><strong>恢复</strong>：左奇异向量$\boldsymbol{U} = \boldsymbol{Q}\tilde{\boldsymbol{U}}$</li>
</ol>
<h4 id="62">6.2 算法伪代码<a class="toc-link" href="#62" title="Permanent link">&para;</a></h4>
<pre class="highlight"><code>输入：矩阵 M ∈ ℝ^(n×m)，目标秩 r，过采样参数 p
输出：近似 SVD：U, Σ, V

1. 生成随机高斯矩阵 Ω ∈ ℝ^(m×(r+p))
2. Y = M·Ω                          // O(nm(r+p))
3. [Q, ~] = qr(Y)                   // O(n(r+p)^2)
4. B = Q^T·M                        // O(nm(r+p))
5. [Ũ, Σ, V] = svd(B)              // O((r+p)^2·m)
6. U = Q·Ũ                          // O(n(r+p)^2)
7. 返回 U[:, 1:r], Σ[1:r, 1:r], V[:, 1:r]
</code></pre>

<p><strong>总复杂度</strong>：$O(nm(r+p) + n(r+p)^2 + (r+p)^2 m) \approx O(nm(r+p))$</p>
<p>当$r+p\ll\min(n,m)$时，相比完整SVD的$O(nm\min(n,m))$有数量级的加速。</p>
<h4 id="63">6.3 误差分析<a class="toc-link" href="#63" title="Permanent link">&para;</a></h4>
<p><strong>定理（Halko et al., 2011）</strong>：设$\boldsymbol{M}$的秩为$\rho$，$\boldsymbol{M}<em i="r+1">r$是真实的秩$r$截断SVD，$\hat{\boldsymbol{M}}_r$是随机化SVD的输出。则以概率至少$1 - 10^{-p}$，有
\begin{equation}
\Vert\boldsymbol{M} - \hat{\boldsymbol{M}}_r\Vert_F \leq \left[1 + \frac{4\sqrt{2r\log(r+p)}}{p}\right]\sqrt{\sum</em>
\end{equation}}^{\rho}\sigma_i^2</p>
<p><strong>误差来源</strong>：
1. 随机采样误差：由过采样参数$p$控制
2. 数值稳定性：通过幂迭代改进（见下文）</p>
<h4 id="64">6.4 幂迭代改进<a class="toc-link" href="#64" title="Permanent link">&para;</a></h4>
<p>对于奇异值衰减缓慢的矩阵，可以使用<strong>幂迭代</strong>来增强奇异值的分离：</p>
<p>修改步骤2为：
\begin{equation}
\boldsymbol{Y} = (\boldsymbol{M}\boldsymbol{M}^{\top})^q\boldsymbol{M}\boldsymbol{\Omega}
\end{equation}
其中$q\geq 1$是幂迭代次数。</p>
<p><strong>效果</strong>：奇异值比例从$\sigma_r/\sigma_{r+1}$放大到$(\sigma_r/\sigma_{r+1})^{2q+1}$，从而提高数值精度。</p>
<p><strong>代价</strong>：额外$2q$次矩阵-矩阵乘法，复杂度变为$O(nmq(r+p))$。</p>
<h4 id="65">6.5 实际应用建议<a class="toc-link" href="#65" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>小问题</strong>（$n,m &lt; 10^4$）：直接用完整SVD（LAPACK实现）</li>
<li><strong>中等问题</strong>（$10^4 &lt; n,m &lt; 10^6$，$r &lt; 100$）：随机化SVD</li>
<li><strong>大规模稀疏问题</strong>：结合稀疏矩阵技术和随机化SVD</li>
<li><strong>流式数据/在线更新</strong>：增量SVD或频繁方向算法（Frequent Directions）</li>
</ul>
<h3 id="weyl">七、高级主题：谱范数下的Weyl型不等式<a class="toc-link" href="#weyl" title="Permanent link">&para;</a></h3>
<h4 id="71-weyl">7.1 Weyl不等式<a class="toc-link" href="#71-weyl" title="Permanent link">&para;</a></h4>
<p><strong>定理（Weyl）</strong>：对于$\boldsymbol{A},\boldsymbol{B}\in\mathbb{R}^{n\times m}$，奇异值满足
\begin{equation}
\sigma_{i+j-1}(\boldsymbol{A} + \boldsymbol{B}) \leq \sigma_i(\boldsymbol{A}) + \sigma_j(\boldsymbol{B}), \quad i+j-1\leq\min(n,m)
\end{equation}
和
\begin{equation}
\sigma_{i+j-1}(\boldsymbol{A} + \boldsymbol{B}) \geq |\sigma_i(\boldsymbol{A}) - \sigma_j(\boldsymbol{B})|
\end{equation}</p>
<p>特别地，取$i=j=1$：
\begin{equation}
\sigma_1(\boldsymbol{A} + \boldsymbol{B}) \leq \sigma_1(\boldsymbol{A}) + \sigma_1(\boldsymbol{B})
\end{equation}
即$\Vert\boldsymbol{A} + \boldsymbol{B}\Vert_2 \leq \Vert\boldsymbol{A}\Vert_2 + \Vert\boldsymbol{B}\Vert_2$（三角不等式）。</p>
<h4 id="72">7.2 相对扰动界<a class="toc-link" href="#72" title="Permanent link">&para;</a></h4>
<p><strong>定理</strong>：设$\boldsymbol{M}$和$\boldsymbol{M} + \boldsymbol{E}$的奇异值分别为$\sigma_i$和$\tilde{\sigma}<em r_1="r+1">i$。如果$\Vert\boldsymbol{E}\Vert_2 &lt; \sigma_r - \sigma</em>$（奇异值间隔），则
\begin{equation}
\frac{|\sigma_i - \tilde{\sigma}<em r_1="r+1">i|}{\sigma_i} \leq \frac{\Vert\boldsymbol{E}\Vert_2}{\sigma_r - \sigma</em>, \quad i\leq r
\end{equation}}</p>
<p>这表明当奇异值有较大间隔时，截断SVD对扰动更鲁棒。</p>
<h3 id="_16">八、数值稳定性与条件数<a class="toc-link" href="#_16" title="Permanent link">&para;</a></h3>
<h4 id="81">8.1 条件数<a class="toc-link" href="#81" title="Permanent link">&para;</a></h4>
<p>矩阵$\boldsymbol{M}$的条件数定义为
\begin{equation}
\kappa(\boldsymbol{M}) = \frac{\sigma_1}{\sigma_r} = \frac{\Vert\boldsymbol{M}\Vert_2}{\Vert\boldsymbol{M}^{-1}\Vert_2^{-1}}
\end{equation}
（假设$\boldsymbol{M}$可逆且秩为$r=\min(n,m)$）</p>
<p><strong>物理意义</strong>：条件数衡量了矩阵对输入扰动的敏感度。$\kappa(\boldsymbol{M})$越大，数值计算越不稳定。</p>
<h4 id="82">8.2 低秩近似的条件数<a class="toc-link" href="#82" title="Permanent link">&para;</a></h4>
<p>对于截断SVD $\boldsymbol{M}_r$，条件数为
\begin{equation}
\kappa(\boldsymbol{M}_r) = \frac{\sigma_1}{\sigma_r}
\end{equation}</p>
<p><strong>结论</strong>：截断SVD通过去除小奇异值，可以显著改善条件数，从而提高后续数值计算的稳定性。例如，在求解线性系统$\boldsymbol{M}\boldsymbol{x} = \boldsymbol{b}$时，用$\boldsymbol{M}_r$替代$\boldsymbol{M}$可以得到更稳定的近似解。</p>
<h3 id="_17">九、总结与展望<a class="toc-link" href="#_17" title="Permanent link">&para;</a></h3>
<p>本节提供的详细推导涵盖了SVD低秩近似的核心理论：</p>
<ol>
<li><strong>Eckart-Young-Mirsky定理</strong>：从Frobenius范数和谱范数两个角度证明了截断SVD的最优性</li>
<li><strong>Schmidt-Mirsky定理</strong>：建立了奇异值扰动的精细界</li>
<li><strong>Von Neumann迹定理</strong>：作为许多矩阵不等式的基础工具</li>
<li><strong>变分法</strong>：从优化角度理解低秩近似</li>
<li><strong>几何解释</strong>：奇异值刻画线性变换的拉伸特性</li>
<li><strong>计算复杂度</strong>：完整SVD与截断SVD的权衡</li>
<li><strong>随机化算法</strong>：现代大规模计算的利器</li>
</ol>
<p>这些工具和理论构成了现代数据科学和机器学习中低秩建模的数学基础，从主成分分析（PCA）到推荐系统，从图像压缩到自然语言处理，都离不开SVD及其变体的支持。</p>
<p><strong>进一步阅读方向</strong>：
- 张量分解与高阶SVD
- 非负矩阵分解（NMF）
- 稀疏PCA
- 鲁棒PCA（Robust PCA）
- 动态低秩逼近（在线算法）</p>
                </div>

                <!-- Previous/Next Navigation -->
                <nav class="post-navigation" aria-label="文章导航">
                    <div class="row g-3">
                        <div class="col-6">
                            
                            <a href="softmax后传寻找top-k的光滑近似.html" class="nav-link-prev">
                                <div class="nav-direction"><i class="fas fa-chevron-left"></i> 上一篇</div>
                                <div class="nav-title">#144 Softmax后传：寻找Top-K的光滑近似</div>
                            </a>
                            
                        </div>
                        <div class="col-6">
                            
                            <a href="低秩近似之路三cr.html" class="nav-link-next">
                                <div class="nav-direction">下一篇 <i class="fas fa-chevron-right"></i></div>
                                <div class="nav-title">#146 低秩近似之路（三）：CR</div>
                            </a>
                            
                        </div>
                    </div>
                </nav>

                <!-- Back to Home -->
                <div class="text-center mt-4 mb-4">
                    <a href="../index.html" class="btn btn-outline-primary">
                        <i class="fas fa-arrow-left"></i> 返回首页
                    </a>
                </div>
            </div>

            <!-- Sidebar (TOC) -->
            <div class="col-lg-3">
                <aside class="sidebar">
                    
                    <div class="toc-sidebar">
                        <h5 class="toc-title"><i class="fas fa-list"></i> 目录</h5>
                        <div class="toc-content">
                            <div class="toc">
<ul>
<li><a href="#svd">低秩近似之路（二）：SVD</a><ul>
<li><a href="#_1">结论初探</a></li>
<li><a href="#_2">一些应用</a><ul>
<li><a href="#_3">伪逆通解</a></li>
<li><a href="#_4">矩阵范数</a></li>
<li><a href="#_5">低秩近似</a></li>
</ul>
</li>
<li><a href="#_6">理论基础</a><ul>
<li><a href="#_7">谱之定理</a></li>
<li><a href="#_8">数学归纳</a></li>
<li><a href="#_9">奇异分解</a></li>
</ul>
</li>
<li><a href="#_10">近似定理</a></li>
<li><a href="#_11">文章小结</a></li>
<li><a href="#_12">公式推导与注释</a><ul>
<li><a href="#eckart-young-mirsky">一、Eckart-Young-Mirsky定理的完整证明</a></li>
<li><a href="#schmidt-mirsky">二、Schmidt-Mirsky定理与扰动分析</a></li>
<li><a href="#_13">三、变分法推导最优低秩逼近</a></li>
<li><a href="#_14">四、奇异值的几何意义</a></li>
<li><a href="#_15">五、计算复杂度分析</a></li>
<li><a href="#svd_1">六、随机化SVD算法</a></li>
<li><a href="#weyl">七、高级主题：谱范数下的Weyl型不等式</a></li>
<li><a href="#_16">八、数值稳定性与条件数</a></li>
<li><a href="#_17">九、总结与展望</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>

                        </div>
                        <div class="toc-actions">
                            <button class="btn btn-sm btn-outline-secondary" onclick="expandAll()">
                                <i class="fas fa-expand"></i> 全部展开
                            </button>
                            <button class="btn btn-sm btn-outline-secondary" onclick="collapseAll()">
                                <i class="fas fa-compress"></i> 全部折叠
                            </button>
                        </div>
                    </div>
                    

                    <!-- Back to Top Button -->
                    <button id="backToTop" class="back-to-top" title="回到顶部">
                        <i class="fas fa-arrow-up"></i>
                    </button>
                </aside>
            </div>
        </div>
    </article>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>
                博客来源: <a href="https://spaces.ac.cn" target="_blank">科学空间</a> |
                内容经过整理并添加详细数学推导
            </p>
            <p>
                Powered by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>
            </p>
        </div>
    </footer>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>

    <!-- Syntax highlighting -->
    <script>hljs.highlightAll();</script>

    <!-- Back to top functionality -->
    <script>
        // Show/hide back to top button based on scroll position
        window.addEventListener('scroll', function() {
            const backToTop = document.getElementById('backToTop');
            if (window.pageYOffset > 300) {
                backToTop.classList.add('show');
            } else {
                backToTop.classList.remove('show');
            }
        });

        // Smooth scroll to top
        document.getElementById('backToTop').addEventListener('click', function() {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        });

        // Sticky TOC sidebar
        window.addEventListener('scroll', function() {
            const sidebar = document.querySelector('.sidebar');
            if (!sidebar) return;

            const sidebarTop = sidebar.offsetTop;
            const scrollTop = window.pageYOffset;

            if (scrollTop > sidebarTop - 20) {
                sidebar.classList.add('sticky');
            } else {
                sidebar.classList.remove('sticky');
            }
        });
    </script>
</body>
</html>