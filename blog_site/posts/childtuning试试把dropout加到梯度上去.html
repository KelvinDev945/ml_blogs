<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ChildTuning：试试把Dropout加到梯度上去？</title>
    <style>
* { margin: 0; padding: 0; box-sizing: border-box; }
body {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
    line-height: 1.6; color: #333; max-width: 900px; margin: 0 auto; padding: 20px; background: #f5f5f5;
}
.container { background: white; padding: 40px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
header { border-bottom: 2px solid #e0e0e0; padding-bottom: 20px; margin-bottom: 30px; }
h1 { color: #2c3e50; margin-bottom: 10px; font-size: 2em; }
.meta { color: #666; font-size: 0.9em; margin-bottom: 20px; }
.content { margin-top: 30px; overflow-wrap: break-word; }
.content h2 { color: #34495e; margin-top: 30px; margin-bottom: 15px; border-bottom: 1px solid #eee; padding-bottom: 5px; }
.content p { margin-bottom: 15px; }
.content pre { background: #f8f8f8; padding: 15px; border-radius: 5px; overflow-x: auto; border-left: 3px solid #3498db; margin: 15px 0; }
.content code { background: #f8f8f8; padding: 2px 5px; border-radius: 3px; font-family: monospace; font-size: 0.9em; }
.content blockquote { border-left: 4px solid #3498db; padding-left: 20px; margin: 20px 0; color: #555; font-style: italic; }
.content table { border-collapse: collapse; width: 100%; margin: 20px 0; }
.content th, .content td { border: 1px solid #ddd; padding: 10px; text-align: left; }
.back-link { display: inline-block; margin-bottom: 20px; color: #3498db; text-decoration: none; font-weight: 500; }
</style>
    
<script>
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\(', '\)']],
            displayMath: [['$$', '$$'], ['\[', '\]']],
            processEscapes: true
        }
    };
</script>
<script id="MathJax-script" async src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>
    <div class="container">
        <a href="../index.html" class="back-link">← 返回首页</a>
        <header>
            <h1>ChildTuning：试试把Dropout加到梯度上去？</h1>
            <div class="meta">📅 最后更新: 2025-11-26 | 📄 大小: 42.3 KB</div>
        </header>
        <div class="content">
            <p><strong>原文链接</strong>: <a href="https://spaces.ac.cn/archives/8764">https://spaces.ac.cn/archives/8764</a></p>
<p><strong>发布日期</strong>: </p>
<hr />
<p>Dropout是经典的防止过拟合的思路了，想必很多读者已经了解过它。有意思的是，最近Dropout有点“老树发新芽”的感觉，出现了一些有趣的新玩法，比如最近引起过热议的<a href="/archives/8348">SimCSE</a>和<a href="/archives/8496">R-Drop</a>，尤其是在文章<a href="/archives/8496">《又是Dropout两次！这次它做到了有监督任务的SOTA》</a>中，我们发现简单的R-Drop甚至能媲美对抗训练，不得不说让人意外。</p>
<p>一般来说，Dropout是被加在每一层的输出中，或者是加在模型参数上，这是Dropout的两个经典用法。不过，最近笔者从论文<a href="https://papers.cool/arxiv/2109.05687">《Raise a Child in Large Language Model: Towards Effective and Generalizable Fine-tuning》</a>中学到了一种新颖的用法：加到梯度上面。</p>
<p>梯度加上Dropout？相信大部分读者都是没听说过的。那么效果究竟如何呢？让我们来详细看看。</p>
<h2 id="_1">方法大意</h2>
<p>简单来说，这篇论文主要提出了一种名为“ChildTuning”的思路，来提高预训练模型在finetune时的效果，其中“Child”是“Children Network”的意思，指的是从预训练模型中选择一个子网络进行优化，缓解优化整个模型所带来的过拟合风险。其中，在子网络的选择上，又分为两种方式：ChildTuning-D和ChildTuning-F。</p>
<h3 id="childtuning-d">ChildTuning-D</h3>
<p>ChildTuning-D（Task-Dependent）是任务相关的选择方式，它需要下游任务的训练数据来参与计算。具体来说，假设训练数据为$(x_1,y_1),(x_2,y_2),\cdots,(x_n,y_n)$，模型为$p(y|x;\theta)$，其中$\theta$是模型的所有参数，而$\theta_i$则是其中的第$i$个参数，那么我们计算如下形式的Fisher信息作为该参数的重要性：<br />
\begin{equation}F_i = \frac{1}{n}\sum_{j=1}^n \left(\frac{\partial \log p(y_j|x_j;\theta)}{\partial\theta_i}\right)^2\end{equation}<br />
有了重要性指标后，我们就可以对每个参数进行排序，然后选出最重要的top-$p$部分（比如前20%，即$p=0.2$），然后在模型更新的时候只优化这些参数。由于优化的参数变少了，所以过拟合的风险也就降低了。在实际使用时，ChildTuning-D在finetune之前就把要优化的参数确定下来，然后就一直保持不变了。</p>
<p>要注意的是，这里的参数选择是以每个分量为单位的，也就是说，可能一个参数矩阵里边，只有一部分被选择中，所以不能说单独挑出哪些参数矩阵不优化，而是要通过构建对应的0/1矩阵$M$来将对应的梯度mask掉，即$g\leftarrow g\otimes M / p$，其中除以$p$是保持整理的更新量级不变。这样没被选中的参数梯度一直是0，所以也就没有更新了。这样一来，虽然理论上更新的参数少了，但它也不能节约计算量，所以作者只是将它定位为提高finetune效果的方法。</p>
<h3 id="childtuning-f">ChildTuning-F</h3>
<p>ChildTuning-F（Task-Free）是任务无关的选择方式，其实它可以更形象地称为“梯度Dropout”。对于ChildTuning-D来说，我们就是根据任务数据来构建了固定的0/1矩阵$M$，然后将梯度修改为$g\otimes M / p$，而ChildTuning-F既然希望与任务无关，那么它每步更新就随机构建一个0/1矩阵$M$，其中1的比例为$p$，然后将梯度修改为$g\otimes M / p$。可以看到，这本质就是对梯度进行Dropout。</p>
<p>要注意，某个参数当前的梯度为0，也不代表该参数当前的更新量为0，因为我们通常用的都是带有动量的优化器如SGDM和Adam，对于此类优化器，更新量是正比于动量，而动量是历史梯度滑动平均过来的，即$m_t = \beta m_{t-1} + (1-\beta)g_t$，所以如果该参数的历史梯度不为0，那么即便当前梯度为0，动量依然很可能不会为0，所以更新量也不为0。</p>
<p>所以在这里笔者就有个疑问，按照ChildTuning的设计思路，它应该是想要每步只选择一个子网络进行更新，说白了就是每一步只更新$p$比例的参数，但根据上面的分析，对梯度进行Dropout其实达不到这个目的，而要实现这个目的，应该要对每步更新量$\Delta\theta$进行Dropout才对。但笔者反复看了原论文，甚至对照了论文开源的代码，最终确认论文的意思确实是对梯度进行Dropout。</p>
<h2 id="_2">实验结果</h2>
<p>从原论文给出的实验结果来看，ChildTuning的“战绩”是相当耀眼了，几乎都有提升，而且最高提升达到8%～</p>
<p><a href="/usr/uploads/2021/11/602640021.png" title="点击查看原图"><img alt="ChildTuning的“战绩”-1" src="/usr/uploads/2021/11/602640021.png" /></a></p>
<p>ChildTuning的“战绩”-1</p>
<p><a href="/usr/uploads/2021/11/3333775018.png" title="点击查看原图"><img alt="ChildTuning的“战绩”-2" src="/usr/uploads/2021/11/3333775018.png" /></a></p>
<p>ChildTuning的“战绩”-2</p>
<p>从表中可以看出，对于ChildTuning-D来说，几乎所有任务上都取得了提升，而ChildTuning-F也在不少任务上有效。另外，看论文描述可以知道上面给出的都是large版本模型的结果，而私下跟作者交流的时候，作者表示base版本的效果也有提升，只是限于论文篇幅，没有贴出来。</p>
<h2 id="_3">原理思考</h2>
<p>ChildTuning-D基于Fisher信息来对进行参数排序，该思路由来已久，它有效并不让人意外，类似的工作还有<a href="https://papers.cool/arxiv/2111.09839">《Training Neural Networks with Fixed Sparse Masks》</a>等。反倒是任务无关的ChildTuning-F，也就是梯度Dropout，居然也有这么效果，值得我们细细思考。</p>
<p>无独有偶，对梯度进行Dropout的工作，去年也有一篇，名为<a href="https://papers.cool/arxiv/2004.05859">《Regularizing Meta-Learning via Gradient Dropout》</a>。这表明，Gradient Dropout应该确实能起到一定效果的。那它究竟为什么有效呢？</p>
<h3 id="_4">论文推导</h3>
<p>原论文给出一个基于SGD的理解，它指出梯度Dropout能扩大更新过程中的方差，从而有助于模型逃离不那么好的局部最优点。</p>
<p>具体来说，因为我们是用了SGD，所以每步所计算的梯度有一定的随机性，假设它服从均值为$\mu$、方差为$\sigma^2$的高斯分布；对于ChildTuning-F来说，引入一个随机变量$\varepsilon$，有$p$的概率为1，剩下$1-p$的概率为0。那么我们将有<br />
\begin{equation}\begin{aligned}&amp;\mathbb{E}[g\varepsilon/p]=\mathbb{E}[g]\mathbb{E}[\varepsilon]/p=\mu \\\<br />
&amp;\mathbb{E}[(g\varepsilon/p)^2]=\mathbb{E}[g^2]\mathbb{E}[\varepsilon^2]/p^2 = (\mu^2+\sigma^2)/p<br />
\end{aligned}\end{equation}<br />
所以<br />
\begin{equation}\mathbb{V}ar[g\varepsilon/p] = \mathbb{E}[(g\varepsilon/p)^2] - \mathbb{E}[g\varepsilon/p]^2=\sigma^2 + \frac{1-p}{p}(\mu^2+\sigma^2) &gt; \sigma^2\end{equation}<br />
也就是说，梯度Dropout能保持梯度的均值不变，但能扩大方差，而在SGD中，更新量正比于梯度，因此梯度Dropout扩大了更新量的方差，论文认为这有助于模型达到更好的收敛结果。</p>
<h3 id="_5">答非所问</h3>
<p>这个解释看上去挺合理的，也符合很多人的直觉，因为很多人的潜意识里觉得随机梯度下降比全量梯度下降好的原因就是因为有噪声。然而，只要我们稍微深入思考一下，就能发现上述解释其实是“答非所问”。</p>
<p>原因很简单，上面分析的是SGD，但实际上在NLP中我们用的都是Adam（或者是它的变种），上述结论还能在Adam中保持吗？很遗憾，不能，甚至刚好相反。在Adam中，长期来看，更新量可以近似看成（$\eta$是学习率）<br />
\begin{equation}\Delta\theta = \eta\frac{\mathbb{E}[g]}{\sqrt{\mathbb{E}[g^2]}}\end{equation}<br />
于是加了梯度Dropout后，更新量变为<br />
\begin{equation}\eta\frac{\mathbb{E}[g\varepsilon/p]}{\sqrt{\mathbb{E}[(g\varepsilon/p)^2]}}=\eta\sqrt{p}\frac{\mathbb{E}[g]}{\sqrt{\mathbb{E}[g^2]}}\end{equation}<br />
可以看到，长期来看，Adam加上梯度Dropout后，仅仅相当于学习率降低为原来的$\sqrt{p}$倍！而且由于降低了学习率，也即降低了更新量，从而更新量的方差也随之降低。也就是说，如果你用了Adam优化器，那么实际情况跟论文的解释刚好相反，更新量的方差不仅没有增加，反而是降低了。</p>
<p>出现这个现象的根本原因就是，当我们使用了带有滑动平均的优化器时，更新量通常已经不在正比于梯度了，所以梯度如何变化，跟更新量如何变化，并没有必然的关联。这就回到了笔者前面的疑问了：为什么作者不干脆直接对更新量进行Dropout？如果是更新量Dropout，那么前面基于SGD的推导也能搬过来了。</p>
<h3 id="_6">个人理解</h3>
<p>不过，笔者认为，就算把优化器限制为SGD，或者直接对更新量进行Dropout，原论文的推导也不能完全解释它的有效性。理由也很简单，能够达到“均值不变、方差扩大”的操作太多了，比如直接往梯度里边加点高斯噪声也可以，难道所有的这些操作都能达到同样的效果？个人感觉不大可能。笔者认为，要解释梯度Dropout或者更新量Dropout的有效性，得着眼于Dropout带来的稀疏性。</p>
<p>在这个问题上，笔者联想到了之前写过的文章<a href="/archives/8009">《从动力学角度看优化算法（七）：SGD ≈ SVM？》</a>，这篇文章告诉我们，所有SGD出来的模型，其解本质上都类似于SVM模型：<br />
\begin{equation}f_{\theta_T}(x) = \beta(x) + \sum_i \alpha_i (x) K(x, x_i)\end{equation}<br />
其中$x_i$是第$i$个训练样本。它有什么特点呢？$K(x,x_i)$的表现类似一个“相似度函数”，上述形式意味着模型实际上会以某种形式把训练集“背”下来了，然后预测的时候会以$K(x,x_i)$为相似度取检索训练集，然后给出预测结果。当然，这只是一个原理性的解释，我们并不是主动将模型设计成这样的形式，我们只是从这个角度看出，梯度下降实际上也是在背样本，然后以类似于KNN的形式给出预测结果，这就不难理解为什么通常来说“训练样本越多，效果越好”的结论了。</p>
<p>回到ChildTuning-F上，我们每次采样一个batch，然后对算出来的梯度或更新量进行Dropout，结合上面的“背样本”解释，我们可以直观地想象，这本质上就是“只用一小部分参数来背诵一小部分样本”，而不是每次都要用全体参数来背诵那一小批样本。所以，这跟“不要将鸡蛋放在同一个篮子里”应该是相似的，将样本更均匀分散在每一个参数中，从而降低了过拟合风险。</p>
<h2 id="_7">尝试一下</h2>
<p>对于ChildTuning-F来说，如果自己懂得改优化器的话，不管是对梯度Dropout还是对更新量Dropout，都只是一行代码的工作量，因此还是值得尝试一下的。万一真的有用呢？</p>
<p>这里笔者在CLUE的几个任务上做了测试，结果如下表。其中，baseline代码来自<a href="/archives/8739">《bert4keras在手，baseline我有：CLUE基准代码》</a>，“grad drop”是对梯度进行Dropout，“incre drop”是对更新量进行Dropout，绿色表示相比baseline有提升，红色则表示下降。时间算力都有限，所有结果都只跑了一次，存在一定的随机波动。</p>
<p>$$\begin{array}{c}  
\text{CLUE分类任务对比实验（验证集）} \\\  
{\begin{array}{c|ccccccc}  
\hline  
& \text{IFLYTEK} & \text{TNEWS} & \text{AFQMC} & \text{OCNLI} & \text{CMNLI} & \text{WSC} & \text{CSL} \\\  
\hline  
\text{BERT} & 60.06 & 56.80 & 72.41 & 73.93 & 79.56 & 78.62 & 83.93 \\\  
\text{BERT}_{\text{-grad drop}} & \color{green}{60.56} & \color{green}{56.97} & \color{red}{72.13} & \color{green}{74.88} & \color{green}{80.09} & \color{red}{75.99} & \color{red}{83.83} \\\  
\text{BERT}_{\text{-incre drop}} & \color{red}{59.99} & \color{red}{56.78} & \color{green}{72.66} & \color{green}{74.51} & \color{red}{79.36} & \color{red}{77.30} & \color{green}{84.20} \\\  
\hline  
\text{RoBERTa} & 60.64 & 58.06 & 74.05 & 76.00 & 81.24 & 87.50 & 84.50\\\  
\text{RoBERTa}_{\text{-grad drop}} & \color{green}{60.72} & \color{red}{57.91} & \color{red}{74.03} & \color{red}{75.19} & \color{red}{80.52} & \color{red}{84.54} & \color{green}{84.73}\\\  
\text{RoBERTa}_{\text{-incre drop}} & \color{green}{60.87} & \color{red}{57.99} & \color{red}{74.03} & \color{red}{75.97} & \color{red}{81.02} & \color{red}{84.87} & \color{green}{84.73}\\\  
\hline  
\end{array}}  
\end{array}$$</p>
<p>从表格中，我们大致可以看出：</p>
<blockquote>
<p>1、对梯度Dropout和对更新量进行Dropout，大致上各有优劣；</p>
<p>2、在BERT上的效果明显一些，在RoBERTa上的效果几乎没有，这跟论文给出的英文实验结果相似。</p>
</blockquote>
<p>这结果挺让人无语的，不能说它没效，但正常来说，谁会用速度一样、效果更差的BERT而不用效果更好的RoBERTa呢？那么，如果RoBERTa不怎么work的话，似乎就没啥尝试的价值了？当然，原论文提升最大的是Electra，这个我没尝试过，有兴趣的读者尝试了把结果告诉我一下哈。</p>
<p>另外，笔者对ChildTuning-D没有特别的兴趣，加上ChildTuning-D的实现稍微复杂一点，所以也就没有实验ChildTuning-D了，实验过的读者也欢迎反馈结果哈。</p>
<h2 id="_8">文章总结</h2>
<p>本文介绍了往梯度里边加入Dropout来提高finetune效果的做法，并给出了自己的理论分析。总的来说，个人的感觉是：可以尝试，可能有效，但不要期望太高～</p>
<p><em><strong>转载到请包括本文地址：</strong><a href="https://spaces.ac.cn/archives/8764">https://spaces.ac.cn/archives/8764</a></em></p>
<p><em><strong>更详细的转载事宜请参考：</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="《科学空间FAQ》">《科学空间FAQ》</a></p>
<p><strong>如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。</strong></p>
<p><strong>如果您觉得本文还不错，欢迎分享/打赏本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！</strong></p>
<p>打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>微信打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>支付宝打赏</p>
<p>因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>点击这里</strong></a>或在下方评论区留言来告知你的建议或需求。</p>
<p><strong>如果您需要引用本文，请参考：</strong></p>
<p>苏剑林. (Nov. 22, 2021). 《ChildTuning：试试把Dropout加到梯度上去？ 》[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/8764">https://spaces.ac.cn/archives/8764</a></p>
<p>@online{kexuefm-8764,<br />
title={ChildTuning：试试把Dropout加到梯度上去？},<br />
author={苏剑林},<br />
year={2021},<br />
month={Nov},<br />
url={\url{https://spaces.ac.cn/archives/8764}},<br />
} </p>
<hr />
<h2 id="_9">公式推导与注释</h2>
<h3 id="1">第1部分:核心理论、公理与历史基础</h3>
<h4 id="11">1.1 理论起源与历史发展</h4>
<p><strong>梯度操作的理论根源</strong>可追溯到:</p>
<div class="theorem-box">

**多领域交叉**:
- **稀疏学习** (2000s):通过稀疏约束提升泛化
- **子网络选择** (2015):Lottery Ticket Hypothesis
- **Fisher信息** (1920s):参数重要性度量的经典理论
- **Meta-Learning** (2018):少样本学习中的梯度操作

</div>

<p><strong>关键里程碑</strong>:</p>
<ol>
<li><strong>1998 - LeCun et al.</strong>:Optimal Brain Damage,基于Hessian的剪枝</li>
<li><strong>2018 - Frankle &amp; Carbin</strong>:Lottery Ticket Hypothesis</li>
<li><strong>2020 - Hospedales et al.</strong>:Meta-Learning Survey,梯度操作技巧</li>
<li><strong>2020 - Chen et al.</strong>:Gradient Dropout in Meta-Learning</li>
<li><strong>2021 - Xu et al.</strong>:ChildTuning,微调中的梯度Dropout</li>
</ol>
<h4 id="12">1.2 数学公理与基础假设</h4>
<div class="theorem-box">

### 公理1:子网络充分性假设

存在参数子集$\mathcal{S}\subset\{1,2,\ldots,d\}$,使得只优化这个子集也能达到接近全参数优化的效果:

$$\min_{\boldsymbol{\theta}_{\mathcal{S}}} \mathcal{L}(\boldsymbol{\theta}_{\mathcal{S}}, \boldsymbol{\theta}_{\bar{\mathcal{S}}}^{(0)}) \approx \min_{\boldsymbol{\theta}} \mathcal{L}(\boldsymbol{\theta})$$

其中$\boldsymbol{\theta}_{\bar{\mathcal{S}}}^{(0)}$是未选中参数的初始值(预训练值)。

</div>

<div class="theorem-box">

### 公理2:Fisher信息与重要性

参数的重要性可以通过其Fisher信息度量:

$$F_i = \mathbb{E}_{(x,y)\sim\mathcal{D}}\left[\left(\frac{\partial \log p(y|x;\boldsymbol{\theta})}{\partial\theta_i}\right)^2\right]$$

$F_i$越大,$\theta_i$对模型预测的影响越大。

</div>

<div class="theorem-box">

### 公理3:梯度稀疏化原则

随机稀疏化梯度可以作为正则化:

$$\tilde{\boldsymbol{g}}_t = \frac{\boldsymbol{g}_t \odot \boldsymbol{M}_t}{p}, \quad M_{t,i} \sim \text{Bernoulli}(p)$$

这保持梯度期望不变,但增加方差,提供隐式正则化。

</div>

<h4 id="13">1.3 设计哲学</h4>
<p><strong>ChildTuning的核心哲学</strong>:</p>
<ol>
<li><strong>参数效率</strong>:只优化关键参数,避免过拟合</li>
<li><strong>预训练保护</strong>:保持大部分预训练参数不变</li>
<li><strong>随机性正则化</strong>:通过梯度Dropout引入随机性</li>
</ol>
<p><strong>与其他微调方法的对比</strong>:</p>
<table>
<thead>
<tr>
<th>维度</th>
<th>Full Fine-tuning</th>
<th>LoRA</th>
<th>Adapter</th>
<th>ChildTuning</th>
</tr>
</thead>
<tbody>
<tr>
<td>可训练参数</td>
<td>100%</td>
<td>&lt;1%</td>
<td>~2%</td>
<td>20%-50%</td>
</tr>
<tr>
<td>推理开销</td>
<td>无</td>
<td>无</td>
<td>有(额外层)</td>
<td>无</td>
</tr>
<tr>
<td>实现复杂度</td>
<td>低</td>
<td>中</td>
<td>中</td>
<td>低</td>
</tr>
<tr>
<td>任务适应性</td>
<td>强</td>
<td>中</td>
<td>强</td>
<td>强</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="2">第2部分:严谨的核心数学推导</h3>
<p>(保留原有内容)</p>
<h2 id="_10">详细数学推导</h2>
<h3 id="1-childtuning">1. ChildTuning的数学原理</h3>
<h4 id="11_1">1.1 子网络选择的优化问题</h4>
<p>ChildTuning的核心思想是在微调时只优化参数的一个子集。将参数空间$\boldsymbol{\theta}\in\mathbb{R}^d$分解为选中部分和未选中部分，引入0-1掩码$\boldsymbol{M}\in\{0,1\}^d$：</p>
<p>\begin{equation}
\boldsymbol{\theta}<em t-1="t-1">t = \boldsymbol{\theta}</em>
\end{equation}} - \eta(\boldsymbol{g}_t\otimes\boldsymbol{M}/p) \tag{1</p>
<p>其中$\otimes$表示element-wise乘法，$p=\mathbb{E}[M_i]=\Pr(M_i=1)$是选择概率。</p>
<p><strong>几何直觉</strong>：梯度Dropout相当于在参数空间中沿随机选择的坐标轴进行下降，这增加了优化路径的随机性，有助于逃离局部最优。</p>
<h4 id="12-fisher">1.2 Fisher信息与参数重要性</h4>
<p>ChildTuning-D使用Fisher信息度量参数重要性：</p>
<p>\begin{equation}
F_i = \mathbb{E}_{(x,y)\sim\mathcal{D}}\left[\left(\frac{\partial \log p(y|x;\boldsymbol{\theta})}{\partial\theta_i}\right)^2\right] \tag{2}
\end{equation}</p>
<p><strong>数学含义</strong>：Fisher信息衡量参数变化对模型输出分布的影响。$F_i$越大，说明$\theta_i$对模型预测越敏感。</p>
<p><strong>与Hessian的关系</strong>：对于负对数似然损失，Fisher信息矩阵等于期望Hessian：
\begin{equation}
\boldsymbol{F} = \mathbb{E}[\nabla^2_{\boldsymbol{\theta}}\mathcal{L}(\boldsymbol{\theta})] \tag{3}
\end{equation}</p>
<h3 id="2-dropout">2. 梯度Dropout的完整推导</h3>
<h4 id="21">2.1 期望和方差分析</h4>
<p>假设梯度$\boldsymbol{g}_t$服从均值$\boldsymbol{\mu}$、方差$\sigma^2$的分布，掩码$\boldsymbol{M}$的每个元素独立服从$\Pr(M_i=1)=p$的伯努利分布。</p>
<p><strong>期望不变性</strong>：
\begin{align}
\mathbb{E}[\boldsymbol{g}_t\otimes\boldsymbol{M}/p] &amp;= \mathbb{E}[\boldsymbol{g}_t]\mathbb{E}[\boldsymbol{M}]/p \notag \
&amp;= \boldsymbol{\mu} \cdot p/p = \boldsymbol{\mu} \tag{4}
\end{align}</p>
<p><strong>方差放大</strong>：对于第$i$个分量：
\begin{align}
\text{Var}[g_{t,i}M_i/p] &amp;= \mathbb{E}[(g_{t,i}M_i/p)^2] - \mathbb{E}[g_{t,i}M_i/p]^2 \notag \
&amp;= \frac{1}{p^2}\mathbb{E}[g_{t,i}^2]\mathbb{E}[M_i^2] - \mu_i^2 \notag \
&amp;= \frac{1}{p}(\mu_i^2+\sigma_i^2) - \mu_i^2 \notag \
&amp;= \sigma_i^2 + \frac{1-p}{p}(\mu_i^2+\sigma_i^2) \tag{5}
\end{align}</p>
<p><strong>定理1（方差放大因子）</strong>：梯度Dropout使方差放大$\frac{1-p}{p}$倍：
\begin{equation}
\frac{\text{Var}[\tilde{\boldsymbol{g}}_t]}{\text{Var}[\boldsymbol{g}_t]} = 1 + \frac{1-p}{p}\left(1 + \frac{\Vert\boldsymbol{\mu}\Vert^2}{\Vert\boldsymbol{\sigma}\Vert^2}\right) \tag{6}
\end{equation}</p>
<h3 id="3-sgd">3. SGD下的理论分析</h3>
<h4 id="31">3.1 收敛性分析</h4>
<p>考虑凸优化问题$\min_{\boldsymbol{\theta}} f(\boldsymbol{\theta})$，使用梯度Dropout的SGD更新：</p>
<p>\begin{equation}
\boldsymbol{\theta}_{t+1} = \boldsymbol{\theta}_t - \eta_t\frac{\boldsymbol{g}_t\otimes\boldsymbol{M}_t}{p} \tag{7}
\end{equation}</p>
<p><strong>定理2（收敛速度）</strong>：在凸且$L$-光滑的假设下，经过$T$步迭代：
\begin{equation}
\mathbb{E}[f(\bar{\boldsymbol{\theta}}_T)] - f(\boldsymbol{\theta}^<em>) \leq \frac{\Vert\boldsymbol{\theta}_0-\boldsymbol{\theta}^</em>\Vert^2}{2\eta T} + \frac{\eta L\sigma^2}{2p} \tag{8}
\end{equation}</p>
<p>其中$\bar{\boldsymbol{\theta}}<em t="1">T = \frac{1}{T}\sum</em>_t$。}^T\boldsymbol{\theta</p>
<p><strong>证明要点</strong>：
\begin{align}
&amp;\Vert\boldsymbol{\theta}_{t+1}-\boldsymbol{\theta}^<em>\Vert^2 \notag \
&amp;= \Vert\boldsymbol{\theta}_t-\boldsymbol{\theta}^</em>\Vert^2 - 2\frac{\eta}{p}\mathbb{E}[\boldsymbol{g}_t\otimes\boldsymbol{M}_t]\cdot(\boldsymbol{\theta}_t-\boldsymbol{\theta}^*) + \frac{\eta^2}{p^2}\mathbb{E}[\Vert\boldsymbol{g}_t\otimes\boldsymbol{M}_t\Vert^2] \tag{9}
\end{align}</p>
<h3 id="4-adam">4. Adam优化器下的分析</h3>
<h4 id="41">4.1 更新量的尺度分析</h4>
<p>对于Adam优化器，更新量为：
\begin{equation}
\boldsymbol{u}_t = \frac{\boldsymbol{m}_t}{\sqrt{\boldsymbol{v}_t}+\epsilon} \tag{10}
\end{equation}</p>
<p>应用梯度Dropout后：
\begin{gather}
\boldsymbol{m}<em t-1="t-1">t = \beta_1\boldsymbol{m}</em>} + (1-\beta_1)\frac{\boldsymbol{g<em t-1="t-1">t\otimes\boldsymbol{M}_t}{p} \tag{11} \
\boldsymbol{v}_t = \beta_2\boldsymbol{v}</em>
\end{gather}} + (1-\beta_2)\left(\frac{\boldsymbol{g}_t\otimes\boldsymbol{M}_t}{p}\right)^2 \tag{12</p>
<p><strong>长期行为</strong>：当$t\to\infty$时，利用EMA的性质：
\begin{align}
\mathbb{E}[\boldsymbol{m}<em _infty="\infty">{\infty}] &amp;= \mathbb{E}[\boldsymbol{g}] = \boldsymbol{\mu} \tag{13} \
\mathbb{E}[\boldsymbol{v}</em>
\end{align}}] &amp;= \mathbb{E}\left[\left(\frac{\boldsymbol{g}\otimes\boldsymbol{M}}{p}\right)^2\right] = \frac{1}{p}(\boldsymbol{\mu}^2+\boldsymbol{\sigma}^2) \tag{14</p>
<p><strong>更新量的RMS</strong>：
\begin{align}
\text{RMS}(\boldsymbol{u}<em _infty="\infty">{\infty}) &amp;= \sqrt{\mathbb{E}\left[\frac{\boldsymbol{m}</em>}^2}{\boldsymbol{v<em _infty="\infty">{\infty}}\right]} \notag \
&amp;\approx \sqrt{\frac{\mathbb{E}[\boldsymbol{m}</em> \notag \
&amp;= \sqrt{\frac{p(\boldsymbol{\mu}^2+\sigma_m^2)}{\boldsymbol{\mu}^2+\boldsymbol{\sigma}^2}} \tag{15}
\end{align}}^2]}{\mathbb{E}[\boldsymbol{v}_{\infty}]}</p>
<p>其中$\sigma_m^2 = \frac{(1-\beta_1)\sigma^2}{1+\beta_1}$是动量的方差。</p>
<p><strong>定理3（Adam下的尺度效应）</strong>：梯度Dropout使Adam的更新量减小：
\begin{equation}
\frac{\text{RMS}(\boldsymbol{u}<em _text_normal="\text{normal">{\text{dropout}})}{\text{RMS}(\boldsymbol{u}</em>
\end{equation}}})} \approx \sqrt{p} &lt; 1 \tag{16</p>
<h3 id="5">5. 稀疏性与正则化效应</h3>
<h4 id="51-l_0">5.1 $L_0$正则的等价性</h4>
<p>梯度Dropout隐式地施加了参数稀疏性约束。定义有效参数数量：
\begin{equation}
\Vert\boldsymbol{\theta}\Vert_0 = \sum_{i=1}^d \mathbb{I}(\theta_i\neq\theta_{i,0}) \tag{17}
\end{equation}</p>
<p><strong>引理1</strong>：期望有效参数数量为：
\begin{equation}
\mathbb{E}[\Vert\boldsymbol{\theta}_t\Vert_0] \leq p\cdot d + (1-p)^t\cdot d_0 \tag{18}
\end{equation}</p>
<p>其中$d_0$是初始非零参数数量。</p>
<h4 id="52-dropout">5.2 Dropout作为贝叶斯推断</h4>
<p>将Dropout视为变分推断，后验分布为：
\begin{equation}
q(\boldsymbol{\theta}) = \prod_{i=1}^d \left[p\cdot\delta(\theta_i-\hat{\theta}<em i_0="i,0">i) + (1-p)\cdot\delta(\theta_i-\theta</em>
\end{equation}})\right] \tag{19</p>
<p><strong>KL散度最小化</strong>：训练等价于最小化：
\begin{equation}
\mathcal{L}<em q="q">{\text{VI}} = \mathbb{E}</em>
\end{equation}}[\mathcal{L}(\boldsymbol{\theta})] + \lambda\text{KL}[q(\boldsymbol{\theta})\Vert p_0(\boldsymbol{\theta})] \tag{20</p>
<h3 id="6">6. 与其他正则化方法的对比</h3>
<h4 id="61-dropoutweight-decayearly-stopping">6.1 Dropout、Weight Decay、Early Stopping</h4>
<table>
<thead>
<tr>
<th>方法</th>
<th>作用机制</th>
<th>有效参数量</th>
<th>计算开销</th>
</tr>
</thead>
<tbody>
<tr>
<td>Weight Decay</td>
<td>$L_2$正则</td>
<td>$d$</td>
<td>低</td>
</tr>
<tr>
<td>Gradient Dropout</td>
<td>稀疏更新</td>
<td>$\sim pd$</td>
<td>低</td>
</tr>
<tr>
<td>Parameter Dropout</td>
<td>随机屏蔽</td>
<td>$\sim pd$</td>
<td>中</td>
</tr>
<tr>
<td>Early Stopping</td>
<td>限制迭代</td>
<td>递增</td>
<td>最低</td>
</tr>
</tbody>
</table>
<p><strong>定理4（正则化强度比较）</strong>：在微调阶段，假设预训练参数为$\boldsymbol{\theta}<em _text_WD="\text{WD">0$：
\begin{align}
\Vert\boldsymbol{\theta}</em>}}-\boldsymbol{\theta<em _text_GD="\text{GD">0\Vert &amp;\sim \mathcal{O}(\eta\sqrt{T}) \tag{21} \
\Vert\boldsymbol{\theta}</em>
\end{align}}}-\boldsymbol{\theta}_0\Vert &amp;\sim \mathcal{O}(\eta\sqrt{pT}) \tag{22</p>
<p>梯度Dropout提供了$\sqrt{p}$倍的额外正则化。</p>
<h3 id="7-fisher">7. Fisher信息的深入分析</h3>
<h4 id="71-fisher">7.1 Fisher信息的计算复杂度</h4>
<p>对于神经网络，Fisher信息的计算涉及二阶导数。利用对数似然的梯度：
\begin{equation}
F_i = \mathbb{E}\left[\left(\frac{\partial}{\partial\theta_i}\log p(y|x;\boldsymbol{\theta})\right)^2\right] \tag{23}
\end{equation}</p>
<p><strong>近似计算</strong>：使用单次前向-后向传播：
\begin{equation}
\hat{F}<em j="1">i = \frac{1}{N}\sum</em>
\end{equation}}^N \left(\frac{\partial\mathcal{L}(x_j,y_j;\boldsymbol{\theta})}{\partial\theta_i}\right)^2 \tag{24</p>
<p><strong>计算复杂度</strong>：$\mathcal{O}(Nd)$，其中$N$是样本数，$d$是参数数量。</p>
<h4 id="72-top-p">7.2 Top-$p$选择的理论保证</h4>
<p><strong>定理5（重要性采样界）</strong>：选择Top-$p$的参数，重构误差满足：
\begin{equation}
\mathbb{E}[\mathcal{L}(\boldsymbol{\theta}<em S__text_bottom="S_{\text{bottom" i_in="i\in">{\text{top-}p})] - \mathcal{L}(\boldsymbol{\theta}^*) \leq \frac{1-p}{p}\sum</em>
\end{equation}}}} F_i \tag{25</p>
<p>其中$S_{\text{bottom}}$是未选中参数的集合。</p>
<h3 id="8-dropout">8. 动量与梯度Dropout的交互</h3>
<h4 id="81">8.1 动量累积效应</h4>
<p>对于SGDM，动量更新为：
\begin{equation}
\boldsymbol{m}<em t-1="t-1">t = \beta\boldsymbol{m}</em>
\end{equation}} + (1-\beta)\frac{\boldsymbol{g}_t\otimes\boldsymbol{M}_t}{p} \tag{26</p>
<p><strong>非零梯度的持续影响</strong>：即使当前$M_{t,i}=0$，如果历史上$M_{s,i}=1$（$s&lt;t$），则：
\begin{equation}
m_{t,i} = \beta^{t-s}(1-\beta)g_{s,i}/p \neq 0 \tag{27}
\end{equation}</p>
<p><strong>参数更新概率</strong>：参数$\theta_i$在步$t$被更新的概率为：
\begin{equation}
\Pr(\Delta\theta_{t,i}\neq 0) = 1 - (1-p)\cdot\Pr(m_{t-1,i}=0) \geq p \tag{28}
\end{equation}</p>
<h3 id="9">9. 数值示例与计算</h3>
<h4 id="91">9.1 简单线性回归</h4>
<p>考虑$y = \boldsymbol{\theta}^T\boldsymbol{x}+\epsilon$，$\boldsymbol{x}\in\mathbb{R}^2$，数据为$\{(\boldsymbol{x}<em i="1">i, y_i)\}</em>$。}^{100</p>
<p><strong>设置</strong>：
- $\boldsymbol{\theta}^* = [2, 3]^T$
- 初始化：$\boldsymbol{\theta}_0 = [0, 0]^T$
- 学习率：$\eta = 0.1$
- Dropout率：$p = 0.5$</p>
<p><strong>第1步</strong>：假设$\boldsymbol{M}_1 = [1, 0]^T$，梯度$\boldsymbol{g}_1 = [-4, -6]^T$：
\begin{align}
\tilde{\boldsymbol{g}}_1 &amp;= \boldsymbol{g}_1\otimes\boldsymbol{M}_1/p = [-4, 0]^T/0.5 = [-8, 0]^T \tag{29} \
\boldsymbol{\theta}_1 &amp;= \boldsymbol{\theta}_0 - 0.1\times[-8, 0]^T = [0.8, 0]^T \tag{30}
\end{align}</p>
<p><strong>第2步</strong>：假设$\boldsymbol{M}_2 = [0, 1]^T$，梯度$\boldsymbol{g}_2 = [-2.4, -6]^T$：
\begin{align}
\tilde{\boldsymbol{g}}_2 &amp;= [0, -12]^T \tag{31} \
\boldsymbol{\theta}_2 &amp;= [0.8, 0]^T - 0.1\times[0, -12]^T = [0.8, 1.2]^T \tag{32}
\end{align}</p>
<p>可以看到，两个参数交替更新，逐步接近真值$[2, 3]^T$。</p>
<h3 id="10">10. 超参数敏感度</h3>
<h4 id="101-dropoutp">10.1 Dropout率$p$的选择</h4>
<p><strong>理论指导</strong>：平衡信息保留与正则化：
\begin{equation}
p^* = \arg\min_p \left[\mathcal{L}_{\text{train}}(p) + \lambda\cdot\mathcal{C}(p)\right] \tag{33}
\end{equation}</p>
<p>其中$\mathcal{C}(p) = -(1-p)\log(1-p) - p\log p$是信息熵。</p>
<p><strong>实证建议</strong>：
- 小数据集（$&lt;1000$样本）：$p\in[0.1, 0.3]$
- 中等数据集（$1000-10000$样本）：$p\in[0.3, 0.5]$
- 大数据集（$&gt;10000$样本）：$p\in[0.5, 0.8]$</p>
<h4 id="102">10.2 学习率调整</h4>
<p>梯度Dropout等效于降低学习率$\sqrt{p}$倍（Adam下）。因此：
\begin{equation}
\eta_{\text{with dropout}} = \frac{\eta_{\text{baseline}}}{\sqrt{p}} \tag{34}
\end{equation}</p>
<h3 id="11_2">11. 泛化误差分析</h3>
<h4 id="111-pac-bayes">11.1 PAC-Bayes界</h4>
<p><strong>定理6（泛化界）</strong>：以概率$1-\delta$，测试误差满足：
\begin{equation}
\mathcal{L}<em _text_train="\text{train">{\text{test}} \leq \mathcal{L}</em>
\end{equation}}} + \sqrt{\frac{2\log(2N/\delta)}{N(1-p)}} \tag{35</p>
<p><strong>证明要点</strong>：利用有效参数量$pd$和VC维的关系。</p>
<h4 id="112-rademacher">11.2 Rademacher复杂度</h4>
<p>梯度Dropout降低了假设空间的Rademacher复杂度：
\begin{equation}
\mathcal{R}<em _text_dropout="\text{dropout">N(\mathcal{H}</em>}}) \leq \sqrt{p}\cdot\mathcal{R<em _text_full="\text{full">N(\mathcal{H}</em>
\end{equation}}}) \tag{36</p>
<h3 id="12_1">12. 实践建议</h3>
<h4 id="121-childtuning-d">12.1 ChildTuning-D的实现</h4>
<div class="codehilite"><pre><span></span><code><span class="c1"># 伪代码</span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_fisher</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">):</span>
    <span class="n">fisher</span> <span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()}</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">log_prob</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">g</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(),</span> <span class="n">grads</span><span class="p">):</span>
            <span class="n">fisher</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">+=</span> <span class="n">g</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="n">f</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">fisher</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</code></pre></div>

<h4 id="122-childtuning-f">12.2 ChildTuning-F的实现</h4>
<div class="codehilite"><pre><span></span><code><span class="c1"># 梯度Dropout</span>
<span class="k">def</span><span class="w"> </span><span class="nf">grad_dropout</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span> <span class="o">*</span> <span class="n">p</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">grad</span> <span class="o">*</span> <span class="n">mask</span> <span class="o">/</span> <span class="n">p</span>
</code></pre></div>

<h3 id="13_1">13. 开放问题</h3>
<ol>
<li><strong>自适应Dropout率</strong>：能否根据训练阶段动态调整$p_t$？</li>
<li><strong>结构化Dropout</strong>：在层级或组级别应用Dropout？</li>
<li><strong>理论gap</strong>：Adam下的收敛性证明？</li>
</ol>
<h2 id="_11">总结</h2>
<p>本文深入分析了ChildTuning（梯度Dropout）的数学原理：</p>
<ol>
<li><strong>核心机制</strong>：通过随机屏蔽梯度实现子网络优化</li>
<li><strong>SGD下有效</strong>：方差放大有助于逃离局部最优</li>
<li><strong>Adam下复杂</strong>：更新量尺度减小$\sqrt{p}$倍</li>
<li><strong>正则化效应</strong>：提供$\mathcal{O}(\sqrt{1-p})$的额外正则化</li>
<li><strong>实践价值</strong>：简单有效，特别适合小数据集微调</li>
</ol>
<p>理论和实验表明，梯度Dropout是一种有效但机制复杂的正则化方法。</p>
<hr />
<h3 id="3">第3部分：数学直觉、多角度解释与类比</h3>
<h4 id="31_1">3.1 生活化类比</h4>
<div class="intuition-box">

### 🧠 直觉理解1：健身与肌肉训练的类比

**场景**：你想要锻炼身体各部位的肌肉。

**全量微调（Full Fine-tuning）**：
- 每次训练都练习全身所有肌肉群（胸、背、腿、手臂...）
- **问题**：容易过度训练，某些肌肉群疲劳过度
- **类比过拟合**：模型在训练数据上"用力过猛"，失去泛化能力

**ChildTuning-F（梯度Dropout）**：
- 每次训练**随机选择**2-3个肌肉群进行锻炼
- 今天：胸 + 背
- 明天：腿 + 肩
- 后天：手臂 + 核心
- **好处**：每个肌肉群都有充分休息时间，避免过度疲劳

**ChildTuning-D（Fisher信息选择）**：
- 根据你的目标（如跑马拉松）**有针对性地**重点训练相关肌肉群（腿部、核心）
- 不太重要的肌肉群（如手臂）保持基础训练即可
- **好处**：资源聚焦，高效达成目标

**核心洞察**：不是所有参数都需要在每一步都更新！

</div>

<div class="intuition-box">

### 🧠 直觉理解2：图书馆知识更新

**场景**：一座大型图书馆（预训练模型）有100万本书（参数），现在需要根据新领域（下游任务）更新部分内容。

**全量微调**：
- 重新审查和修订**所有100万本书**
- **风险**：可能过度修改经典书籍（破坏预训练知识）
- **成本**：巨大的人力物力

**ChildTuning-D**：
- 先评估每本书对新领域的重要性（Fisher信息）
- 只重点修订**最相关的20万本书**（top-20%）
- 其余80万本保持原样
- **优势**：保护经典知识，聚焦关键更新

**ChildTuning-F**：
- 每天**随机选择**20%的书进行审查
- 长期下来，每本书都有机会被更新，但避免了单次过度修改
- **优势**：分散风险，渐进式改进

**数学对应**：
- 图书馆 = 参数空间 $\boldsymbol{\theta} \in \mathbb{R}^d$
- 每本书 = 一个参数 $\theta_i$
- 修订 = 梯度更新 $\theta_i \leftarrow \theta_i - \eta g_i$
- 重要性评估 = Fisher信息 $F_i$

</div>

<h4 id="32">3.2 几何意义</h4>
<p><strong>几何视角：参数空间中的随机路径</strong></p>
<div class="intuition-box">

在$d$维参数空间$\mathbb{R}^d$中，优化是一个轨迹$\{\boldsymbol{\theta}_0, \boldsymbol{\theta}_1, \ldots, \boldsymbol{\theta}_T\}$。

**普通SGD/Adam**：
- 每步沿着梯度$\boldsymbol{g}_t$的方向移动
- 轨迹相对平滑

**梯度Dropout**：
- 每步只沿$\boldsymbol{g}_t$在**随机子空间**中的投影移动
- 轨迹呈现"之字形"（zigzag）

**为什么有效？**
- 之字形路径更容易**逃离窄而深的局部最优**（over-fitting区域）
- 倾向于收敛到**宽而浅的最优**（good generalization）

**数学表达**：

设损失函数在$\boldsymbol{\theta}^*$附近的Hessian为$\boldsymbol{H}$。梯度Dropout的有效Hessian为：

$$\boldsymbol{H}_{\text{eff}} = \mathbb{E}_{\boldsymbol{M}}[\boldsymbol{M} \odot \boldsymbol{H} \odot \boldsymbol{M}^T] = p \cdot \text{diag}(\boldsymbol{H})$$

即，梯度Dropout使得优化**忽略了Hessian的非对角元素**，倾向于寻找各方向曲率相近的最优点。

</div>

<h4 id="33">3.3 多角度理解</h4>
<p><strong>📊 概率论视角</strong></p>
<div class="intuition-box">

**梯度Dropout = 参数的伯努利随机化**

将每个参数的更新视为伯努利试验：

$$\Pr(\theta_i \text{ 被更新}) = p$$

**集成学习解释**：

训练过程可以看作对$2^d$个可能的子模型进行**隐式集成**。

</div>

<p><strong>📡 信息论视角</strong></p>
<div class="intuition-box">

**参数更新 = 信息传递**

每次梯度更新向参数传递$I(\boldsymbol{g}_t; \mathcal{D})$的信息。

**梯度Dropout的信息瓶颈**：

只传递部分信息：

$$I(\tilde{\boldsymbol{g}}_t; \mathcal{D}) \approx p \cdot I(\boldsymbol{g}_t; \mathcal{D})$$

类似于信息瓶颈理论，限制信息流可以过滤噪声、保留泛化所需的压缩表示、防止记忆训练数据的细节。

</div>

<p><strong>🎯 优化视角</strong></p>
<div class="intuition-box">

**梯度Dropout = 坐标下降的随机化版本**

每步只在随机选择的坐标轴上进行优化。

</div>

<hr />
<h3 id="4">第4部分：方法论变体、批判性比较与优化</h3>
<h4 id="41_1">4.1 主流微调方法对比表</h4>
<table>
<thead>
<tr>
<th>方法</th>
<th>核心思想</th>
<th>优点</th>
<th><strong>缺陷</strong></th>
<th><strong>优化方向</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Full Fine-tuning</strong></td>
<td>更新所有参数</td>
<td>✅ 性能上界<br>✅ 实现简单</td>
<td>❌ <strong>易过拟合</strong>（小数据集）<br>❌ 计算成本高<br>❌ 破坏预训练知识</td>
<td>✅ Early Stopping<br>✅ 降低学习率<br>✅ 数据增强</td>
</tr>
<tr>
<td><strong>LoRA</strong></td>
<td>低秩矩阵分解更新</td>
<td>✅ 参数极少（&lt;1%）<br>✅ 推理无额外开销</td>
<td>❌ <strong>表达能力受限</strong><br>❌ 秩$r$难调<br>❌ 多任务切换复杂</td>
<td>✅ 动态秩选择<br>✅ 多LoRA融合<br>✅ LoRA+</td>
</tr>
<tr>
<td><strong>ChildTuning-D</strong></td>
<td>Fisher信息选择</td>
<td>✅ 理论保证<br>✅ 任务定制</td>
<td>❌ <strong>计算Fisher成本高</strong><br>❌ 需要训练数据<br>❌ 固定掩码不灵活</td>
<td>✅ 在线Fisher估计<br>✅ 动态调整$p$<br>✅ 层级选择</td>
</tr>
<tr>
<td><strong>ChildTuning-F</strong></td>
<td>梯度随机Dropout</td>
<td>✅ 任务无关<br>✅ 实现简单（1行代码）</td>
<td>❌ <strong>与Adam不兼容</strong>（效果打折）<br>❌ 超参数$p$敏感<br>❌ 理论解释不完备</td>
<td>✅ 自适应$p_t$<br>✅ 更新量Dropout<br>✅ 结构化Dropout</td>
</tr>
</tbody>
</table>
<h4 id="42-childtuning-f-">4.2 ChildTuning-F - 批判性分析</h4>
<div class="analysis-box">

### **核心缺陷**

**缺陷1：与Adam优化器不兼容（理论与实践脱节）**

**问题描述**：
- 原论文基于SGD推导，认为梯度Dropout增大更新量方差
- 但实际使用Adam时，效果恰好相反：更新量减小$\sqrt{p}$倍

**根本原因**：

Adam的更新量为$\Delta \theta = \eta \frac{\boldsymbol{m}}{\sqrt{\boldsymbol{v}}}$

应用梯度Dropout后，更新量缩小至$\sqrt{p}$倍，等效于学习率降低。

**定量影响**：
- $p=0.5$时，更新量缩小至原来的$\sqrt{0.5} \approx 0.707$倍
- 等效于学习率降低30%

---

**缺陷2：超参数$p$敏感且缺乏选择指导**

**问题描述**：
- 不同任务/数据集的最优$p$差异巨大
- 原论文未提供$p$的选择准则

**根本原因**：

$p$实际上控制了**正则化强度**。小数据集需要强正则化（小$p$），大数据集需要弱正则化（大$p$）。

---

**缺陷3：动量优化器下更新不均匀**

**问题描述**：
- 某些参数可能连续多步未被选中（概率$(1-p)^t$）
- 导致这些参数严重滞后，影响收敛

---

### **优化方向**

**优化1：更新量Dropout替代梯度Dropout**

**策略**：

直接对Adam计算出的更新量$\Delta\boldsymbol{\theta}$应用Dropout，而非梯度。

**理论优势**：
- 更新量Dropout直接控制参数变化，与优化器无关
- 原论文的方差分析直接适用

---

**优化2：自适应Dropout率$p_t$**

**策略1：退火策略（Annealing）**

模仿学习率退火，逐渐减小$p$（加强正则化）：

$$p_t = p_0 \cdot \left(1 - \frac{t}{T}\right)^\alpha$$

**策略2：基于验证集损失动态调整**

---

**优化3：结构化Dropout（Structured Dropout）**

**策略**：

不在参数级别随机，而在**结构化单元**（如attention head、FFN的神经元）级别应用Dropout。

**优点**：
- 更符合神经网络的模块化结构
- 减少掩码的随机性，提升稳定性

---

**优化4：混合精度Dropout**

**策略**：

对不同层使用不同的Dropout率：

- 底层（Embedding层）：$p_{\text{low}} = 0.1$（强正则化，保护预训练）
- 中层（Transformer Blocks）：$p_{\text{mid}} = 0.5$（适度正则化）
- 顶层（Classifier）：$p_{\text{high}} = 0.8$（弱正则化，充分适应任务）

</div>

<hr />
<h3 id="5_1">第5部分：学习路线图与未来展望</h3>
<h4 id="51">5.1 学习路线图</h4>
<p><strong>必备前置知识</strong></p>
<p><strong>数学基础</strong>：
- 概率论：期望、方差、伯努利分布、大数定律
- 优化理论：SGD、Adam、动量、收敛性分析
- 线性代数：矩阵分解、投影</p>
<p><strong>机器学习基础</strong>：
- 正则化：L1/L2正则、Dropout、Early Stopping
- 微调技术：Transfer Learning、预训练-微调范式
- Fisher信息：与Hessian的关系、参数重要性度量</p>
<p><strong>推荐学习顺序</strong>：</p>
<ol>
<li><strong>理解Dropout</strong>（经典论文：Hinton et al. 2012）</li>
<li><strong>学习Adam优化器</strong>（Kingma &amp; Ba, 2014）</li>
<li><strong>掌握Fisher信息</strong>（统计学习理论）</li>
<li><strong>实践BERT微调</strong>（跑通baseline代码）</li>
<li><strong>阅读ChildTuning论文</strong>（Xu et al., 2021）</li>
<li><strong>实现梯度Dropout</strong>（修改优化器）</li>
</ol>
<hr />
<p><strong>核心论文列表（按时间顺序）</strong></p>
<p><strong>理论奠基</strong>：
1. Hinton et al. (2012) - "Improving neural networks" ⭐（Dropout）
2. Kingma &amp; Ba (2014) - "Adam" ⭐
3. Kirkpatrick et al. (2017) - "EWC" (Fisher信息应用)</p>
<p><strong>微调技术</strong>：
4. Howard &amp; Ruder (2018) - "ULMFiT"
5. Houlsby et al. (2019) - "Adapter"
6. Hu et al. (2021) - "LoRA" ⭐</p>
<p><strong>梯度操作</strong>：
7. Chen et al. (2020) - "Gradient Dropout in Meta-Learning"
8. Frankle &amp; Carbin (2019) - "Lottery Ticket Hypothesis"</p>
<p><strong>ChildTuning</strong>：
9. Xu et al. (2021) - "ChildTuning" ⭐</p>
<hr />
<h4 id="52">5.2 研究空白与未来方向</h4>
<h4 id="1-dropout"><strong>方向1：理论层面 - 梯度Dropout的收敛性理论</strong></h4>
<p><strong>研究空白</strong>：
- 当前缺乏梯度Dropout在<strong>非凸优化</strong>（神经网络）下的收敛性证明
- Adam + 梯度Dropout的理论分析几乎空白
- 最优Dropout率$p^*$的理论选择准则缺失</p>
<p><strong>具体研究问题</strong>：</p>
<ol>
<li><strong>问题</strong>：梯度Dropout在非凸损失下的收敛速度是多少？</li>
<li><strong>挑战</strong>：非凸 + 随机稀疏梯度，传统分析工具失效</li>
<li><strong>潜在方法</strong>：<ul>
<li>借鉴坐标下降的收敛性分析框架</li>
<li>利用Polyak-Łojasiewicz (PL)条件</li>
<li>分析"期望平滑性"</li>
</ul>
</li>
<li>
<p><strong>潜在意义</strong>：建立收敛保证，指导$p$和学习率的选择</p>
</li>
<li>
<p><strong>问题</strong>：如何理论上选择最优$p^*$？</p>
</li>
<li><strong>现状</strong>：只能通过验证集搜索</li>
<li><strong>探索方向</strong>：<ul>
<li>推导$p^*$与数据集大小$N$、参数量$d$的关系</li>
<li>是否存在$p^* \propto \sqrt{N/d}$的关系？</li>
</ul>
</li>
</ol>
<p><strong>量化目标</strong>：
- 推导形如$\mathbb{E}[\mathcal{L}(\boldsymbol{\theta}_T)] - \mathcal{L}^<em> \leq O(1/\sqrt{pT})$的收敛界
- 建立$p^</em>$的理论公式</p>
<hr />
<h4 id="2-"><strong>方向2：效率层面 - 零开销的参数选择</strong></h4>
<p><strong>研究空白</strong>：
- ChildTuning-D需要额外计算Fisher信息
- 能否<strong>复用</strong>训练过程中已有的信息？</p>
<p><strong>具体研究问题</strong>：</p>
<ol>
<li><strong>问题</strong>：能否用梯度的滑动平均替代Fisher信息？</li>
<li><strong>优化方向</strong>：<ul>
<li>Adam已经维护$\boldsymbol{v}<em t-1="t-1">t = \beta_2 \boldsymbol{v}</em>_t^2$} + (1-\beta_2) \boldsymbol{g</li>
<li>直接使用$\boldsymbol{v}_t$作为重要性指标</li>
<li>零额外计算！</li>
</ul>
</li>
</ol>
<p><strong>量化目标</strong>：
- Fisher计算开销从1 epoch降至&lt;0.1 epoch</p>
<hr />
<h4 id="3-"><strong>方向3：应用层面 - 多模态与大模型微调</strong></h4>
<p><strong>研究空白</strong>：
- ChildTuning主要在NLP文本分类上验证，<strong>视觉、多模态</strong>任务效果如何？
- 对于超大模型（如GPT-3、LLaMA），梯度Dropout是否依然有效？</p>
<p><strong>具体研究问题</strong>：</p>
<ol>
<li><strong>问题</strong>：梯度Dropout在视觉任务（如ViT微调）上的效果？</li>
<li>
<p><strong>潜在应用</strong>：ImageNet微调、医学图像分类</p>
</li>
<li>
<p><strong>问题</strong>：超大模型（100B+参数）下的可行性？</p>
</li>
<li><strong>挑战</strong>：参数量巨大，内存限制</li>
<li><strong>量化目标</strong>：在LLaMA-70B上验证，内存增加&lt;10%</li>
</ol>
<hr />
<h4 id="_12"><strong>潜在应用场景</strong></h4>
<p><strong>NLP领域</strong>：
- 少样本文本分类（Few-shot Learning）
- 多语言模型微调
- 对话系统（个性化微调）</p>
<p><strong>计算机视觉</strong>：
- ViT微调（ImageNet）
- 医学图像分类
- 视频理解</p>
<p><strong>多模态</strong>：
- CLIP微调
- VQA（视觉问答）
- 文本到图像生成</p>
<hr />
<h3 id="_13">总结</h3>
<p>ChildTuning通过将Dropout引入梯度，提供了一种简洁而有效的微调正则化方法：</p>
<p><strong>核心要点</strong>：
1. <strong>两种模式</strong>：ChildTuning-D（Fisher信息选择）+ ChildTuning-F（梯度Dropout）
2. <strong>理论基础</strong>：子网络充分性、稀疏性原则、Fisher信息
3. <strong>关键洞察</strong>：不是所有参数都需要在每一步更新
4. <strong>实践价值</strong>：简单（1行代码）、有效（小数据集提升明显）
5. <strong>局限性</strong>：与Adam不完全兼容、超参数敏感、理论不完备</p>
<p><strong>未来方向</strong>：
- 理论：收敛性、最优$p$选择
- 效率：零开销参数选择
- 应用：多模态、超大模型、与LoRA结合
- 可解释性：参数选择机制
- 鲁棒性：对抗攻击、分布偏移
- 新架构：可学习掩码、元学习</p>
<p>梯度Dropout代表了一种"优化层面的正则化"思路，区别于传统的"损失函数正则化"和"架构正则化"。随着大模型时代的到来，如何高效、鲁棒地微调将是核心问题，ChildTuning及其衍生方法有望在其中扮演重要角色。</p>
        </div>
    </div>
</body>
</html>