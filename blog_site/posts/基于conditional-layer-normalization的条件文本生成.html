<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>基于Conditional Layer Normalization的条件文本生成</title>
    <style>
* { margin: 0; padding: 0; box-sizing: border-box; }
body {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
    line-height: 1.6; color: #333; max-width: 900px; margin: 0 auto; padding: 20px; background: #f5f5f5;
}
.container { background: white; padding: 40px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
header { border-bottom: 2px solid #e0e0e0; padding-bottom: 20px; margin-bottom: 30px; }
h1 { color: #2c3e50; margin-bottom: 10px; font-size: 2em; }
.meta { color: #666; font-size: 0.9em; margin-bottom: 20px; }
.content { margin-top: 30px; overflow-wrap: break-word; }
.content h2 { color: #34495e; margin-top: 30px; margin-bottom: 15px; border-bottom: 1px solid #eee; padding-bottom: 5px; }
.content p { margin-bottom: 15px; }
.content pre { background: #f8f8f8; padding: 15px; border-radius: 5px; overflow-x: auto; border-left: 3px solid #3498db; margin: 15px 0; }
.content code { background: #f8f8f8; padding: 2px 5px; border-radius: 3px; font-family: monospace; font-size: 0.9em; }
.content blockquote { border-left: 4px solid #3498db; padding-left: 20px; margin: 20px 0; color: #555; font-style: italic; }
.content table { border-collapse: collapse; width: 100%; margin: 20px 0; }
.content th, .content td { border: 1px solid #ddd; padding: 10px; text-align: left; }
.back-link { display: inline-block; margin-bottom: 20px; color: #3498db; text-decoration: none; font-weight: 500; }
</style>
    
<script>
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\(', '\)']],
            displayMath: [['$$', '$$'], ['\[', '\]']],
            processEscapes: true
        }
    };
</script>
<script id="MathJax-script" async src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>
    <div class="container">
        <a href="../index.html" class="back-link">← 返回首页</a>
        <header>
            <h1>基于Conditional Layer Normalization的条件文本生成</h1>
            <div class="meta">📅 最后更新: 2025-12-31 | 📄 大小: 12.0 KB</div>
        </header>
        <div class="content">
            <p><strong>原文链接</strong>: <a href="https://spaces.ac.cn/archives/7124">https://spaces.ac.cn/archives/7124</a></p>
<p><strong>发布日期</strong>: </p>
<hr />
<p>从文章<a href="/archives/6933">《从语言模型到Seq2Seq：Transformer如戏，全靠Mask》</a>中我们可以知道，只要配合适当的Attention Mask，Bert（或者其他Transformer模型）就可以用来做无条件生成（Language Model）和序列翻译（Seq2Seq）任务。</p>
<p>可如果是有条件生成呢？比如控制文本的类别，按类别随机生成文本，也就是Conditional Language Model；又比如传入一副图像，来生成一段相关的文本描述，也就是Image Caption。</p>
<h2 id="_1">相关工作</h2>
<p>八月份的论文<a href="https://papers.cool/arxiv/1908.06938">《Encoder-Agnostic Adaptation for Conditional Language Generation》</a>比较系统地分析了利用预训练模型做条件生成的几种方案；九月份有一篇论文<a href="https://papers.cool/arxiv/1909.05858">《CTRL: A Conditional Transformer Language Model for Controllable Generation》</a>提供了一个基于条件生成来预训练的模型，不过这本质还是跟GPT一样的语言模型，只能以文字输入为条件；而最近的论文<a href="https://papers.cool/arxiv/1912.02164">《Plug and Play Language Models: a Simple Approach to Controlled Text Generation》</a>将$p(x|y)$转化为$p(x)p(y|x)$来探究基于预训练模型的条件生成。</p>
<p>不过这些经典工作都不是本文要介绍的。本文关注的是以一个固定长度的向量作为条件的文本生成的场景，而方法是<strong>Conditional Layer Normalization</strong> ——把条件融合到Layer Normalization的$\beta$和$\gamma$中去。</p>
<h2 id="_2">思路细节</h2>
<p>Conditional Layer Normalization的想法来源于图像中流行的条件GAN的思路——条件BN（Conditional Batch Normalization），相关内容可以参考<a href="/archives/6549">《从DCGAN到SELF-MOD：GAN的模型架构发展一览》</a>。条件BN还有一个变种，称之为AdaIN（Adaptive Instance Normalization）。条件BN、AdaIN都是将已有的Normalization方法中的$\beta$和$\gamma$变成输入条件的函数，从而可以通过条件来控制生成的行为。</p>
<p>在Bert等Transformer模型中，主要的Normalization方法是Layer Normalization，所以很自然就能想到将对应的$\beta$和$\gamma$变成输入条件的函数，来控制Transformer模型的生成行为，这就是Conditional Layer Normalization的线索思路。（但目前还没有看到同样思路的工作出现，所以这算是笔者闭门造车出来的新鲜玩意了。）</p>
<p><a href="/usr/uploads/2019/12/2102002684.png" title="点击查看原图"><img alt="条件Normalization示意图" src="/usr/uploads/2019/12/2102002684.png" /></a></p>
<p>条件Normalization示意图</p>
<p>对于已经预训练好的模型来说，已经有现成的、无条件的$\beta$和$\gamma$了，它们都是长度固定的向量。我们可以通过两个不同的变换矩阵，将输入条件变换到跟$\beta,\gamma$一样的维度，然后将两个变换结果分别加到$\beta$和$\gamma$上去。为了防止扰乱原来的预训练权重，两个变换矩阵可以全零初始化（单层神经网络可以用全零初始化，连续的多层神经网络才不应当用全零初始化），这样在初始状态，模型依然保持跟原来的预训练模型一致。</p>
<h2 id="_3">代码实现</h2>
<p>直觉上，这种以文本生成为目的的finetune应该要用GPT等自回归预训练模型才能提升效果，但事实上，之前的文章<a href="/archives/6933">《从语言模型到Seq2Seq：Transformer如戏，全靠Mask》</a>已经表明，哪怕你加载Bert的预训练权重来做生成任务，表现依然良好。所以不管哪种Transformer-based的预训练模型，都可以考虑用来finetune做文本生成模型来。而本文还是以预训练Bert为基础模型进行实验。</p>
<p>至于代码，本文所描述的Conditional Layer Normalization技巧，也已经被集成到笔者所开发的<a href="https://github.com/bojone/bert4keras">bert4keras</a>中了，现在基础函数<code>build_transformer_model</code>新增了如下参数：</p>
<blockquote>
<p>1、layer_norm_cond：如果该参数非None，则意味着它是一个张量，shape=[batch_size, cond_size]，用来作为Layer Normalization的条件；</p>
<p>2、layer_norm_cond_size：如果该参数非None且layer_norm_cond为None，则意味着它是一个整数，自行构建一个shape=[batch_size, layer_norm_cond_size]的输入层作为Layer Normalization的条件；</p>
<p>3、layer_norm_cond_hidden_size：如果该参数非None，则意味着它是一个整数，用于先将输入条件投影到更低维空间，这是因为输入的条件可能维度很高，直接投影到hidden_size（比如768）的话，参数可能过多，所以可以先投影到更低维空间，然后升维；</p>
<p>4、layer_norm_cond_hidden_act：投影到更低维空间时的激活函数，如果为None，则不加激活函数（线性激活）；</p>
<p>5、additional_input_layers：额外的输入层，如果外部传入了张量作为条件，则需要把条件张量所依赖的所有输入层都添加进来，作为输入层，才能构建最终的模型。</p>
</blockquote>
<h2 id="_4">实验效果</h2>
<p>介绍再多，其实还不如看例子来得实际。笔者做了两个实验来验证Conditional Layer Normalization的效果。一个是通过情感极性来控制文本生成，也就是情感分类的反问题，这直接通过类的Embedding来作为Layer Normalization的条件；另一个是图像描述生成（Image Caption），通过预训练的imagenet模型将图片编码为一个固定长度的向量作为Layer Normalization的条件。</p>
<p>这两个代码分别放在<a href="https://github.com/bojone/bert4keras/blob/master/examples/task_conditional_language_model.py">task_conditional_language_model.py</a>和<a href="https://github.com/bojone/bert4keras/blob/master/examples/task_image_caption.py">task_image_caption.py</a>中。</p>
<h3 id="_5">情感文本生成</h3>
<p>情感文本生成就是用的训练集是笔者之前收集整理的<a href="https://github.com/bojone/bert4keras/blob/master/examples/datasets/sentiment.zip">情感分类语料</a>，将输入文本和标签反过来用即可。最后生成的时候按概率随机采样，从而能生成不同的文本。</p>
<p>部分输出：</p>
<blockquote>
<p><strong>正面采样:</strong><br />
 [u'外观时尚、漂亮、性价比高。', u'外观漂亮，配置均衡，比较满意，性价比高，外观漂亮，性能较高。', u'我是在大学的时候看到这本书的，所以一直在买。书中的作者是林静蕾，她用自己的口吻写出了一个孩子成长中的心路历程，让我看到了她们成长中的不同之处，以及她们成长过程中的不同境界。让我很欣赏！', u'我想这是一本能够告诉读者什么是坏的，而不是教你怎样说话，告诉我什么是错。这里我推荐了《我要讲故事》，这本书是我很喜欢的一本书，我认为它的理由很多，但是，我相信我。如果你从中得到一些改进，或者你已经有了一个明智的决定。', u'我们一家五口住的是标间，大床房，大床的床很舒服；而我们在携程网上订了两套大床房，这个酒店的价格还是比较合理的；但是房间的隔音效果不太理想，有点响的声音；酒店门口的地铁在施工中，不方便；但是酒店的门口的出租车不知道是哪个车的，打车不是很方便；酒店外面的停']</p>
<p><strong>负面采样:</strong><br />
 [u'不知道是不是因为电池不太好，不是我不喜欢。', u'看了评论才买的. 结果发现不是那么便宜, 价格也不便宜.', u'1、外壳不容易沾手印，不容易洗洗2、屏幕有点旧，不能下载铃声', u'我是7月6日订购了《杜拉拉升职记》并已通过银行付款，为什么订单下了两周多至今还未到货？是收货时间太快了，可能就这么过去了吧？', u'这本书我是在网上先看了一遍，后来我再看了一遍。感觉作者的文笔实在太烂了，特别是在写他的博客时特别别扭，写得很不专业，特别是他写股票时那个情绪调节的小男孩，简直就是自作聪明的样子，简直就是自作聪明的一种表现！']</p>
</blockquote>
<h3 id="image-caption">Image Caption</h3>
<p>Image Caption以<a href="http://cocodataset.org/#download">COCO数据集</a>为例，这个数据集的图片场景比较丰富一些。另外2017年的challenger.ai也举办过一个<a href="https://challenger.ai/dataset/caption?lan=zh">图像中文描述生成竞赛</a>，里边也包含了一个不错的数据集（读者自己自行想办法收集），不过图片的场景相对来说单调一些。</p>
<p>部分输出：  </p>
<p><a href="/usr/uploads/2019/12/3163471200.jpg" title="点击查看原图"><img alt="模型预测: a baseball game in progress with the batter up to plate." src="/usr/uploads/2019/12/3163471200.jpg" /></a></p>
<p>模型预测: a baseball game in progress with the batter up to plate.</p>
<p><a href="/usr/uploads/2019/12/3673525199.jpg" title="点击查看原图"><img alt="模型预测: a train that is sitting on the tracks." src="/usr/uploads/2019/12/3673525199.jpg" /></a></p>
<p>模型预测: a train that is sitting on the tracks.</p>
<blockquote>
<p><strong>image_id:</strong> COCO_val2014_000000524611.jpg<br />
<strong>url:</strong> <a href="http://images.cocodataset.org/val2014/COCO_val2014_000000524611.jpg">http://images.cocodataset.org/val2014/COCO_val2014_000000524611.jpg</a><br />
<strong>predict:</strong> a train that is sitting on the tracks.<br />
<strong>references:</strong> [u'A train carrying chemical tanks traveling past a water tower.', u'Dual train tracks with a train on one of them and a water tower in the background.', u'a train some trees and a water tower ', u'Train on tracks with water tower for Davis Junction in the rear.', u'A train on a train track going through a bunch of trees.']</p>
<p><strong>image_id:</strong> COCO_val2014_000000202923.jpg<br />
<strong>url:</strong> <a href="http://images.cocodataset.org/val2014/COCO_val2014_000000202923.jpg">http://images.cocodataset.org/val2014/COCO_val2014_000000202923.jpg</a><br />
<strong>predict:</strong> a baseball game in progress with the batter up to plate.<br />
<strong>references:</strong> [u'Batter, catcher, and umpire anticipating the next pitch.', u'A baseball player holding a baseball bat in the game.', u'A baseball player stands ready at the plate.', u'Baseball players on the field ready for the pitch.', u'A view from behind a mesh fence of a baseball game.']</p>
</blockquote>
<h2 id="_6">文章小结</h2>
<p>提出了利用Conditional Layer Normalization来将外部条件融入到预训练模型中的思路，其直接应用就是条件文本生成，但其实也不单单可以用于生成模型，也可以用于分类模型等场景（外部条件可能是其他模态的信息，来辅助分类）。最后基于bert4keras给出了代码实现以及两个例子。</p>
<p><em><strong>转载到请包括本文地址：</strong><a href="https://spaces.ac.cn/archives/7124">https://spaces.ac.cn/archives/7124</a></em></p>
<p><em><strong>更详细的转载事宜请参考：</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="《科学空间FAQ》">《科学空间FAQ》</a></p>
<p><strong>如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。</strong></p>
<p><strong>如果您觉得本文还不错，欢迎分享/打赏本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！</strong></p>
<p>打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>微信打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>支付宝打赏</p>
<p>因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>点击这里</strong></a>或在下方评论区留言来告知你的建议或需求。</p>
<p><strong>如果您需要引用本文，请参考：</strong></p>
<p>苏剑林. (Dec. 14, 2019). 《基于Conditional Layer Normalization的条件文本生成 》[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/7124">https://spaces.ac.cn/archives/7124</a></p>
<p>@online{kexuefm-7124,<br />
title={基于Conditional Layer Normalization的条件文本生成},<br />
author={苏剑林},<br />
year={2019},<br />
month={Dec},<br />
url={\url{https://spaces.ac.cn/archives/7124}},<br />
} </p>
<hr />
<h2 id="_7">公式推导与注释</h2>
<p>TODO: 添加详细的数学公式推导和注释</p>
        </div>
    </div>
</body>
</html>