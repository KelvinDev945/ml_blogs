<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ä»åŠ¨åŠ›å­¦è§’åº¦çœ‹ä¼˜åŒ–ç®—æ³•ï¼ˆå…­ï¼‰ï¼šä¸ºä»€ä¹ˆSimSiamä¸é€€åŒ–ï¼Ÿ</title>
    <style>
* { margin: 0; padding: 0; box-sizing: border-box; }
body {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
    line-height: 1.6; color: #333; max-width: 900px; margin: 0 auto; padding: 20px; background: #f5f5f5;
}
.container { background: white; padding: 40px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
header { border-bottom: 2px solid #e0e0e0; padding-bottom: 20px; margin-bottom: 30px; }
h1 { color: #2c3e50; margin-bottom: 10px; font-size: 2em; }
.meta { color: #666; font-size: 0.9em; margin-bottom: 20px; }
.content { margin-top: 30px; overflow-wrap: break-word; }
.content h2 { color: #34495e; margin-top: 30px; margin-bottom: 15px; border-bottom: 1px solid #eee; padding-bottom: 5px; }
.content p { margin-bottom: 15px; }
.content pre { background: #f8f8f8; padding: 15px; border-radius: 5px; overflow-x: auto; border-left: 3px solid #3498db; margin: 15px 0; }
.content code { background: #f8f8f8; padding: 2px 5px; border-radius: 3px; font-family: monospace; font-size: 0.9em; }
.content blockquote { border-left: 4px solid #3498db; padding-left: 20px; margin: 20px 0; color: #555; font-style: italic; }
.content table { border-collapse: collapse; width: 100%; margin: 20px 0; }
.content th, .content td { border: 1px solid #ddd; padding: 10px; text-align: left; }
.back-link { display: inline-block; margin-bottom: 20px; color: #3498db; text-decoration: none; font-weight: 500; }
</style>
    
<script>
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\(', '\)']],
            displayMath: [['$$', '$$'], ['\[', '\]']],
            processEscapes: true
        }
    };
</script>
<script id="MathJax-script" async src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>
    <div class="container">
        <a href="../index.html" class="back-link">â† è¿”å›é¦–é¡µ</a>
        <header>
            <h1>ä»åŠ¨åŠ›å­¦è§’åº¦çœ‹ä¼˜åŒ–ç®—æ³•ï¼ˆå…­ï¼‰ï¼šä¸ºä»€ä¹ˆSimSiamä¸é€€åŒ–ï¼Ÿ</h1>
            <div class="meta">ğŸ“… æœ€åæ›´æ–°: 2026-01-08 | ğŸ“„ å¤§å°: 41.0 KB</div>
        </header>
        <div class="content">
            <p><strong>åŸæ–‡é“¾æ¥</strong>: <a href="https://spaces.ac.cn/archives/7980">https://spaces.ac.cn/archives/7980</a></p>
<hr />
<h2 id="1">1. æ ¸å¿ƒç†è®ºã€å…¬ç†ä¸å†å²åŸºç¡€</h2>
<h3 id="11">1.1 è·¨å­¦ç§‘æ ¹æºï¼šä»è´Ÿé‡‡æ ·åˆ°å¯¹ç§°æ€§ç ´ç¼º</h3>
<p>è‡ªç›‘ç£å­¦ä¹ ï¼ˆSelf-Supervised Learningï¼‰çš„ç»ˆæå¹½çµæ˜¯<strong>â€œè¡¨å¾åç¼©ï¼ˆRepresentation Collapseï¼‰â€</strong>ï¼šå¦‚æœæ²¡æœ‰æ˜¾å¼çš„æ’æ–¥åŠ›ï¼Œæ¨¡å‹ä¼šå‘ç°æœ€ç®€å•çš„åŠæ³•æ˜¯è®©æ‰€æœ‰å›¾ç‰‡çš„ç‰¹å¾å‘é‡éƒ½å˜æˆåŒä¸€ä¸ªå¸¸æ•°ï¼ˆå¦‚å…¨é›¶ï¼‰ï¼Œæ­¤æ—¶æŸå¤±å‡½æ•°è™½ç„¶æœ€å°ï¼Œä½†è¡¨å¾å½»åº•å¤±æ•ˆã€‚</p>
<ul>
<li><strong>å¯¹æ¯”å­¦ä¹  (Contrastive Learning)</strong>ï¼šå¦‚ SimCLRï¼Œå¼•å…¥æµ·é‡çš„è´Ÿæ ·æœ¬ä½œä¸ºâ€œæ’æ–¥åŠ›â€ã€‚</li>
<li><strong>éå¯¹æ¯”å­¦ä¹  (Non-contrastive Learning)</strong>ï¼šBYOL å’Œ SimSiam æŒ‘æˆ˜äº†è¿™ä¸€å¸¸è¯†ã€‚å®ƒä»¬è¯æ˜äº†ï¼šå³ä¾¿æ²¡æœ‰è´Ÿæ ·æœ¬ï¼Œæ¨¡å‹ä¾ç„¶å¯ä»¥ä¸åç¼©ã€‚</li>
<li><strong>åŠ¨åŠ›ç³»ç»Ÿè§†è§’</strong>ï¼šSimSiam çš„æˆåŠŸæœ¬è´¨ä¸Šæ˜¯ä¼˜åŒ–è·¯å¾„ä¸­çš„<strong>å¯¹ç§°æ€§ç ´ç¼º</strong>ã€‚é€šè¿‡äººä¸ºåˆ¶é€ å¿«æ…¢ä¸ä¸€çš„æ¼”åŒ–æ¨¡å—ï¼Œç³»ç»Ÿåœ¨æ»‘å‘å¹³å‡¡è§£ï¼ˆåç¼©ï¼‰çš„è¿‡ç¨‹ä¸­è¢«æˆªæ–­äº†ã€‚</li>
</ul>
<h3 id="12">1.2 å†å²ç¼–å¹´å²ï¼šè‡ªç›‘ç£å­¦ä¹ çš„æ¼”åŒ–ä¹‹è·¯</h3>
<h4 id="2018-2020">ç¬¬ä¸€é˜¶æ®µï¼šå¯¹æ¯”å­¦ä¹ çš„é»„é‡‘æ—¶ä»£ï¼ˆ2018-2020ï¼‰</h4>
<ol>
<li><strong>2018 - InstDisc (Wu et al.)</strong>ï¼šé¦–æ¬¡æå‡ºå®ä¾‹åˆ¤åˆ«ï¼ˆInstance Discriminationï¼‰èŒƒå¼</li>
<li>æ ¸å¿ƒæ€æƒ³ï¼šå°†æ¯ä¸ªæ ·æœ¬è§†ä¸ºç‹¬ç«‹ç±»åˆ«</li>
<li>å¼•å…¥Memory Bankå­˜å‚¨ç‰¹å¾</li>
<li>
<p>é—®é¢˜ï¼šéœ€è¦ç»´æŠ¤å·¨å¤§çš„è´Ÿæ ·æœ¬é˜Ÿåˆ—</p>
</li>
<li>
<p><strong>2019 - MoCo (He et al.)</strong>ï¼šåŠ¨é‡å¯¹æ¯”å­¦ä¹ </p>
</li>
<li>åˆ›æ–°ï¼šé˜Ÿåˆ—æœºåˆ¶+åŠ¨é‡ç¼–ç å™¨</li>
<li>å®ç°å¤§è§„æ¨¡è´Ÿæ ·æœ¬ï¼ˆ65536ï¼‰</li>
<li>ImageNetå‡†ç¡®ç‡è¾¾åˆ°60.6%ï¼ˆçº¿æ€§è¯„ä¼°ï¼‰</li>
<li>
<p>å¼€å¯äº†å¯¹æ¯”å­¦ä¹ çš„å®ç”¨åŒ–</p>
</li>
<li>
<p><strong>2020 - SimCLR (Chen et al.)</strong>ï¼šç®€åŒ–å¯¹æ¯”å­¦ä¹ </p>
</li>
<li>æç®€è®¾è®¡ï¼šæ— é˜Ÿåˆ—ã€æ— Memory Bank</li>
<li>ä¾èµ–è¶…å¤§Batch Sizeï¼ˆ4096+ï¼‰</li>
<li>æ ¸å¿ƒå‘ç°ï¼šæ•°æ®å¢å¼º+æŠ•å½±å¤´çš„é‡è¦æ€§</li>
<li>å‡†ç¡®ç‡çªç ´69%</li>
<li><strong>å±€é™</strong>ï¼šè®¡ç®—æˆæœ¬æé«˜ï¼ˆéœ€è¦TPU v3 Ã—128ï¼‰</li>
</ol>
<h4 id="2020-2021">ç¬¬äºŒé˜¶æ®µï¼šéå¯¹æ¯”é©å‘½ï¼ˆ2020-2021ï¼‰</h4>
<ol>
<li><strong>2020.06 - BYOL (Grill et al., DeepMind)</strong>ï¼šæ‰“ç ´å¯¹æ¯”èŒƒå¼</li>
<li>éœ‡æ’¼å‘ç°ï¼š<strong>æ— éœ€è´Ÿæ ·æœ¬å³å¯é˜²æ­¢åç¼©</strong></li>
<li>æœºåˆ¶ï¼šEMAï¼ˆExponential Moving Averageï¼‰ç¼–ç å™¨</li>
<li>ç†è®ºç–‘é—®ï¼šä¸ºä»€ä¹ˆä¸ä¼šåç¼©ï¼Ÿ</li>
<li>
<p>ç¤¾åŒºåå“ï¼šå¼•å‘æ¿€çƒˆäº‰è®ºï¼Œéƒ¨åˆ†å­¦è€…æ€€ç–‘æ˜¯BNçš„éšå¼ä½œç”¨</p>
</li>
<li>
<p><strong>2020.11 - SimSiam (Chen &amp; He, CVPR 2021)</strong>ï¼šæœ€å°åŒ–è®¾è®¡</p>
</li>
<li>æè‡´ç®€åŒ–ï¼šå»æ‰EMAï¼Œåªä¿ç•™Stop-gradient</li>
<li>æ ¸å¿ƒç»„ä»¶ä»…3ä¸ªï¼š<ul>
<li>Siameseç½‘ç»œ</li>
<li>Predictor MLPï¼ˆ2å±‚ï¼‰</li>
<li>Stop-gradientç®—å­</li>
</ul>
</li>
<li>ç†è®ºè´¡çŒ®ï¼šè¯æ˜"å¿«æ…¢åŠ¨åŠ›å­¦"æ˜¯å…³é”®</li>
<li>å‡†ç¡®ç‡ï¼š71.3%ï¼ˆResNet-50ï¼Œ200epochï¼‰</li>
<li>
<p><strong>å“²å­¦æ„ä¹‰</strong>ï¼šLess is Moreçš„å…¸èŒƒ</p>
</li>
<li>
<p><strong>2021 - Barlow Twins (Zbontar et al.)</strong>ï¼šä¿¡æ¯è®ºè§†è§’</p>
</li>
<li>åˆ›æ–°ï¼šäº’ä¿¡æ¯å†—ä½™åº¦çº¦æŸ</li>
<li>æŸå¤±å‡½æ•°ï¼šäº’åæ–¹å·®çŸ©é˜µâ†’å•ä½é˜µ</li>
<li>ä¼˜åŠ¿ï¼šæ— éœ€Predictorã€æ— éœ€Stop-grad</li>
<li>ç†è®ºæ¸…æ™°ï¼šç›´æ¥ä¼˜åŒ–ç‰¹å¾ç‹¬ç«‹æ€§</li>
</ol>
<h4 id="2021-2024">ç¬¬ä¸‰é˜¶æ®µï¼šç†è®ºç»Ÿä¸€ä¸æ‰©å±•ï¼ˆ2021-2024ï¼‰</h4>
<ol>
<li><strong>2021 - VICReg (Variance-Invariance-Covariance)</strong>ï¼š</li>
<li>å°†BYOL/SimSiamçš„ä¸‰å¤§éšå¼çº¦æŸæ˜¾å¼åŒ–</li>
<li>æ–¹å·®æ­£åˆ™åŒ–ï¼šé˜²æ­¢åç¼©åˆ°é›¶ç‚¹</li>
<li>ä¸å˜æ€§çº¦æŸï¼šæ­£æ ·æœ¬å¯¹é½</li>
<li>
<p>åæ–¹å·®æ­£åˆ™åŒ–ï¼šå»ç›¸å…³</p>
</li>
<li>
<p><strong>2021 - DINO (Caron et al., ICCV)</strong>ï¼š</p>
</li>
<li>å°†SimSiamæ€æƒ³è¿ç§»åˆ°Vision Transformer</li>
<li>æ›¿æ¢BNä¸ºCentering+Sharpening</li>
<li>å‘ç°ï¼šè‡ªç›‘ç£ViTæ¶Œç°å‡ºæ˜¾å¼çš„Attention Map</li>
<li>
<p>å½±å“ï¼šå¯å‘äº†DALL-E 2ã€Stable Diffusionçš„è®¾è®¡</p>
</li>
<li>
<p><strong>2022 - åŠ¨åŠ›å­¦ç†è®ºçš„å½¢å¼åŒ– (Tian et al.)</strong>ï¼š</p>
</li>
<li>ç”¨å¾®åˆ†æ–¹ç¨‹ä¸¥æ ¼åˆ†æSimSiam</li>
<li>è¯æ˜ï¼šStop-grad = Asymmetric Loss Landscape</li>
<li>
<p>æ­ç¤ºï¼šPredictorå­¦ä¹ é€Ÿåº¦å¿…é¡» &gt;&gt; Encoder</p>
</li>
<li>
<p><strong>2023-2024 - å¤§æ¨¡å‹æ—¶ä»£çš„è‡ªç›‘ç£</strong>ï¼š</p>
<ul>
<li>MAEï¼ˆMasked Autoencoderï¼‰ï¼šå›å½’ç”Ÿæˆå¼è‡ªç›‘ç£</li>
<li>JEPAï¼ˆJoint-Embedding Predictive Architectureï¼‰ï¼šLeCunçš„ç»Ÿä¸€æ¡†æ¶</li>
<li>SimSiamåŸç†è¢«æ•´åˆè¿›å¤šæ¨¡æ€é¢„è®­ç»ƒï¼ˆCLIPå˜ä½“ï¼‰</li>
</ul>
</li>
</ol>
<h3 id="13">1.3 ä¸¥è°¨å…¬ç†åŒ–</h3>
<div class="theorem-box">

### æ ¸å¿ƒå…¬ç†ä½“ç³»ï¼šSimSiam ä¸åç¼©ä¸‰è¦ç´ 

**å…¬ç† 1 (ä¸€è‡´æ€§çº¦æŸ)**ï¼šæ­£æ ·æœ¬å¯¹ $T_1(x), T_2(x)$ çš„è¡¨ç¤ºå¿…é¡»å°½å¯èƒ½é‡åˆã€‚
**å…¬ç† 2 (Predictor å¼•å…¥)**ï¼šæ”¯è·¯é—´å¿…é¡»å­˜åœ¨ä¸€ä¸ªéçº¿æ€§çš„é¢„æµ‹å™¨ $h$ï¼Œæ‰“ç ´æ’ç­‰æ˜ å°„ã€‚
**å…¬ç† 3 (åœæ­¢æ¢¯åº¦ç®—å­)**ï¼šæ¢¯åº¦çš„æµåŠ¨å¿…é¡»æ˜¯ä¸å¯¹ç§°çš„ã€‚
\begin{equation} \nabla_{\theta} \| h_{\boldsymbol{\varphi}}(z_1) - \text{stop\_grad}(z_2) \|^2 \tag{1} \end{equation}

</div>

<h3 id="14">1.4 è®¾è®¡å“²å­¦ï¼šå¿«ä¸æ…¢çš„åšå¼ˆ</h3>
<p>SimSiam çš„è®¾è®¡å“²å­¦æ˜¯ï¼š<strong>â€œè·‘å¾—æ¯”åç¼©å¿«ã€‚â€</strong> 
åç¼©æ˜¯ä¸€ä¸ªé•¿æœŸçš„ã€ç»“æ„æ€§çš„è¶‹åŠ¿ã€‚å¦‚æœæ¨¡å‹ä¸­çš„æŸä¸ªéƒ¨åˆ†ï¼ˆPredictorï¼‰èƒ½å¤Ÿä»¥æå¿«çš„é€Ÿåº¦å®Œæˆå¯¹ç›®æ ‡ï¼ˆEncoder è¾“å‡ºï¼‰çš„å±€éƒ¨æ‹Ÿåˆï¼Œé‚£ä¹ˆæ¨åŠ¨ Encoder æ•´ä½“åç¼©çš„æ¢¯åº¦å‹åŠ›å°±ä¼šè¿…é€Ÿæ¶ˆæ•£ã€‚è¿™å°±åƒæ˜¯åœ¨æµæ²™æ²‰æ²¡ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆåœ¨è¡¨é¢é“ºå¥½äº†ä¸€å±‚è½»è´¨ç”²æ¿ã€‚</p>
<hr />
<h2 id="2">2. ä¸¥è°¨çš„æ ¸å¿ƒæ•°å­¦æ¨å¯¼</h2>
<p>æœ¬èŠ‚å°†é€šè¿‡åŠ¨åŠ›å­¦æ–¹ç¨‹ç»„ï¼Œå®šé‡æ­ç¤º Stop-gradient å¦‚ä½•æ‹¦æˆªåç¼©è¿‡ç¨‹ã€‚</p>
<h3 id="21-siamese">2.1 å»ºç«‹ Siamese åŠ¨åŠ›å­¦æ¨¡å‹</h3>
<p>è®¾ç¼–ç å™¨å‚æ•°ä¸º $\boldsymbol{\theta}$ï¼Œé¢„æµ‹å™¨å‚æ•°ä¸º $\boldsymbol{\varphi}$ã€‚æŸå¤±å‡½æ•°ä¸ºï¼š
\begin{equation}
\mathcal{L}(\boldsymbol{\theta}, \boldsymbol{\varphi}) = \mathbb{E}<em _boldsymbol_varphi="\boldsymbol{\varphi">{x, \mathcal{T}_1, \mathcal{T}_2} \left[ | h</em>}}(f_{\boldsymbol{    heta}}(\mathcal{T<em _boldsymbol_="\boldsymbol{" heta="heta">1(x))) - f</em>
\end{equation}}}(\mathcal{T}_2(x)) |^2 \right] \tag{2</p>
<div class="derivation-box">

### æ¨å¯¼ï¼šæœ‰æ—  Stop-gradient çš„æ¢¯åº¦æµå¯¹æ¯”

**æƒ…å½¢ Aï¼šæ—  Stop-gradientï¼ˆå¯¹ç§°æ›´æ–°ï¼‰**
å‚æ•° $\boldsymbol{\theta}$ çš„æ¼”åŒ–é€Ÿåº¦å–å†³äºä¸¤è¾¹çš„æ¢¯åº¦ï¼š
\begin{equation}
\dot{\boldsymbol{\theta}} = -\left( \underbrace{\frac{\partial \mathcal{L}}{\partial f_1} \frac{\partial f_1}{\partial \boldsymbol{\theta}}}_{\text{æ”¯è·¯1}} + \underbrace{\frac{\partial \mathcal{L}}{\partial f_2} \frac{\partial f_2}{\partial \boldsymbol{\theta}}}_{\text{æ”¯è·¯2}} \right) \tag{3}
\end{equation}
ç”±äºä¸¤è¾¹æ–¹å‘ä¸€è‡´ï¼Œ$\boldsymbol{\theta}$ ä¼šè·å¾—åŒå€çš„åŠ¨åŠ›å†²å‘å¸¸æ•°è§£ã€‚

**æƒ…å½¢ Bï¼šæœ‰ Stop-gradient (SimSiam)**
æ”¯è·¯ 2 çš„æ¢¯åº¦è¢«åˆ‡æ–­ï¼ŒåŠ¨åŠ›å­¦å˜ä¸ºï¼š
\begin{equation}
\dot{\boldsymbol{\theta}} = -\frac{\partial \mathcal{L}}{\partial f_1} \frac{\partial f_1}{\partial \boldsymbol{\theta}} \tag{4}
\end{equation}
åŒæ—¶ï¼Œé¢„æµ‹å™¨ $\boldsymbol{\varphi}$ çš„æ¼”åŒ–ä¸ºï¼š
\begin{equation}
\dot{\boldsymbol{\varphi}} = -\frac{\partial \mathcal{L}}{\partial h} \frac{\partial h}{\partial \boldsymbol{\varphi}} \tag{5}
\end{equation}

</div>

<h3 id="22">2.2 ç©å…·æ¨¡å‹åˆ†æï¼šæ ‡é‡æ¼”åŒ–æ¨¡æ‹Ÿ</h3>
<p>ä¸ºäº†çœ‹æ¸…æœ¬è´¨ï¼Œæˆ‘ä»¬å‡è®¾ $f_{\theta}(x) = \theta x$ï¼ˆçº¿æ€§ç¼–ç ï¼‰ï¼Œ$h_{\varphi}(z) = \varphi z$ï¼ˆçº¿æ€§é¢„æµ‹ï¼‰ã€‚</p>
<div class="derivation-box">

### æ¨å¯¼ï¼šåç¼©é€Ÿåº¦çš„å®šé‡è®¡ç®—

è®¾ç›®æ ‡æ˜¯æœ€å°åŒ– $\frac{1}{2}(\varphi \theta - \theta)^2$ã€‚

**æ²¡æœ‰ Stop-grad æ—¶**ï¼š
\begin{equation}
\dot{\theta} = -(\varphi \theta - \theta) \varphi = -\theta \varphi (\varphi - 1) \tag{6}
\end{equation}
å¦‚æœåˆå§‹æ—¶ $\varphi$ è¿˜æ²¡å­¦å¥½ï¼ˆä¾‹å¦‚ $\varphi < 1$ï¼‰ï¼Œé‚£ä¹ˆ $\dot{\theta}$ ä¼šè®© $\theta \to 0$ã€‚ä¸€æ—¦ $\theta=0$ï¼Œç‰¹å¾å…¨å¤±ï¼Œæ— æ³•æŒ½å›ã€‚

**æœ‰ Stop-grad æ—¶**ï¼š
ç”±äº Predictor $\varphi$ ä½äºè¾“å‡ºå±‚ï¼Œå…¶å­¦ä¹ è·¯å¾„æ›´çŸ­ï¼Œ**åŠ¨åŠ›å­¦æå¿«**ã€‚
\begin{equation}
\dot{\boldsymbol{\varphi}} = -(\varphi \theta - \theta) \theta = -\theta^2 (\varphi - 1) \tag{7}
\end{equation}
ç”±äº $\dot{\boldsymbol{\varphi}}$ çš„æ”¶æ•›å¸¸æ•°æ˜¯ $\theta^2$ï¼ˆé€šå¸¸å¤§äºé›¶ä¸”è¾ƒç¨³å®šï¼‰ï¼Œ$\varphi$ ä¼šä»¥æŒ‡æ•°çº§é€Ÿåº¦ $e^{-\theta^2 t}$ è¶‹å‘äº 1ã€‚
**å…³é”®ç‚¹**ï¼šå½“ $\varphi$ è¿…é€Ÿåˆ°è¾¾ 1 æ—¶ï¼Œ(6) å¼ä¸­çš„åŠ¨åŠ› $(\varphi - 1)$ å˜ä¸º 0ã€‚
è¿™æ„å‘³ç€ï¼š**Encoder è¿˜æ²¡æ¥å¾—åŠæ»‘åˆ° 0ï¼Œé©±åŠ¨å®ƒæ»‘åŠ¨çš„åŠ›å°±å·²ç»è¢« Predictor æŠµæ¶ˆäº†ã€‚**

</div>

<h3 id="23">2.3 æé›…æ™®è¯ºå¤«ç¨³å®šæ€§åˆ†æ</h3>
<div class="theorem-box">

### å®šç†2.1ï¼šSimSiamçš„æ¡ä»¶ç¨³å®šæ€§

**å‘½é¢˜**ï¼šè®¾ç¼–ç å™¨å’Œé¢„æµ‹å™¨çš„å‚æ•°åˆ†åˆ«ä¸º $\boldsymbol{\theta}$ å’Œ $\boldsymbol{\varphi}$ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š
\begin{equation}
L(\boldsymbol{\theta}, \boldsymbol{\varphi}) = \mathbb{E}\left[ \| h_{\boldsymbol{\varphi}}(f_{\boldsymbol{\theta}}(x_1)) - f_{\boldsymbol{\theta}}(x_2) \|^2 \right] \tag{8}
\end{equation}

å…¶ä¸­ $x_1, x_2$ æ˜¯åŒä¸€å›¾åƒçš„ä¸¤ä¸ªå¢å¼ºè§†å›¾ã€‚

**ç¨³å®šå¹³è¡¡ç‚¹**ï¼šç³»ç»Ÿçš„éå¹³å‡¡ç¨³å®šç‚¹æ»¡è¶³ï¼š
\begin{align}
h_{\boldsymbol{\varphi}}(z) &= z, \quad \forall z \in \text{Range}(f_{\boldsymbol{\theta}}) \tag{9a}\\
\mathbb{E}[f_{\boldsymbol{\theta}}(x_1)] &= \mathbb{E}[f_{\boldsymbol{\theta}}(x_2)] = \mathbf{0} \tag{9b}\\
\text{Cov}(f_{\boldsymbol{\theta}}(x)) &\succ 0 \tag{9c}
\end{align}

**è¯æ˜**ï¼šæ„é€ æé›…æ™®è¯ºå¤«å‡½æ•°ï¼š
\begin{equation}
V(\boldsymbol{\theta}, \boldsymbol{\varphi}) = L(\boldsymbol{\theta}, \boldsymbol{\varphi}) + \lambda \| \text{Cov}(f_{\boldsymbol{\theta}}) - I \|_F^2 \tag{10}
\end{equation}

å…¶ä¸­ $\lambda > 0$ æ˜¯æ­£åˆ™åŒ–ç³»æ•°ï¼ˆéšå¼ç”±BNæä¾›ï¼‰ã€‚

**ç¨³å®šæ€§æ¡ä»¶**ï¼š
1. $\dot{V} < 0$ï¼ˆèƒ½é‡å•è°ƒé€’å‡ï¼‰
2. $\nabla_{\boldsymbol{\varphi}} L$ çš„æ”¶æ•›é€Ÿåº¦ >> $\nabla_{\boldsymbol{\theta}} L$

**å…³é”®å¼•ç†**ï¼šå½“ä½¿ç”¨Stop-gradientæ—¶ï¼Œ$\boldsymbol{\varphi}$ çš„æœ‰æ•ˆå­¦ä¹ ç‡è¢«æ”¾å¤§ $\mathcal{O}(d)$ å€ï¼ˆ$d$ æ˜¯ç‰¹å¾ç»´åº¦ï¼‰ã€‚

</div>

<h4 id="231">2.3.1 çº¿æ€§åŒ–åˆ†æï¼šé›…å¯æ¯”çŸ©é˜µçš„è°±æ€§è´¨</h4>
<div class="derivation-box">

### æ¨å¯¼2.2ï¼šåç¼©è§£çš„å¤±ç¨³æ¡ä»¶

**è®¾å®š**ï¼šè€ƒè™‘åç¼©è§£ $f_{\boldsymbol{\theta}}(x) = \mathbf{c}$ï¼ˆå¸¸æ•°ï¼‰ï¼Œ$h_{\boldsymbol{\varphi}}(z) = \mathbf{c}$ã€‚

**æ‰°åŠ¨åˆ†æ**ï¼šè®¾ $f_{\boldsymbol{\theta}} = \mathbf{c} + \epsilon \mathbf{u}(x)$ï¼Œå…¶ä¸­ $\epsilon \ll 1$ã€‚

**æœ‰Stop-gradçš„æƒ…å†µ**ï¼š

æŸå¤±å‡½æ•°çš„çº¿æ€§åŒ–ï¼š
\begin{align}
L &= \mathbb{E}\left[ \| h_{\boldsymbol{\varphi}}(\mathbf{c} + \epsilon \mathbf{u}_1) - (\mathbf{c} + \epsilon \mathbf{u}_2) \|^2 \right] \tag{11a}\\
&\approx \mathbb{E}\left[ \| \mathbf{J}_{\boldsymbol{\varphi}} \epsilon \mathbf{u}_1 - \epsilon \mathbf{u}_2 \|^2 \right] \tag{11b}\\
&= \epsilon^2 \mathbb{E}\left[ \| (\mathbf{J}_{\boldsymbol{\varphi}} - I) \mathbf{u}_1 \|^2 \right] + \mathcal{O}(\epsilon^3) \tag{11c}
\end{align}

**å…³é”®è§‚å¯Ÿ**ï¼š
- å¦‚æœ $\mathbf{J}_{\boldsymbol{\varphi}} = I$ï¼ˆPredictorå®Œç¾æ‹Ÿåˆï¼‰ï¼Œåˆ™ $L = 0$
- Predictorçš„æ¢¯åº¦ï¼š$\nabla_{\boldsymbol{\varphi}} L \propto \epsilon^2$ ï¼ˆäºŒé˜¶å°é‡ï¼‰
- Encoderçš„æ¢¯åº¦ï¼š$\nabla_{\boldsymbol{\theta}} L \propto \epsilon$ ï¼ˆä¸€é˜¶å°é‡ï¼‰

**ç»“è®º**ï¼šç”±äº $\boldsymbol{\varphi}$ çš„æ¢¯åº¦æ›´å°ï¼Œå®ƒä¼š**å…ˆ**æ”¶æ•›åˆ°ä½¿ $\mathbf{J}_{\boldsymbol{\varphi}} \to I$ çš„é…ç½®ï¼Œä»è€Œ**æˆªæ–­** $\boldsymbol{\theta}$ ç»§ç»­åç¼©çš„åŠ¨åŠ›ã€‚

</div>

<h3 id="24">2.4 æ·±åº¦å±•å¼€åˆ†æï¼šéšå¼æ–¹å·®è¡¥å¿</h3>
<p>å¦‚æœå°† SimSiam çœ‹ä½œä¸€ä¸ª EM ç®—æ³•ï¼ˆExpectation-Maximizationï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°æ›´æœ‰è¶£çš„å‘ç°ã€‚</p>
<div class="formula-explanation">

### æŸå¤±å‡½æ•°çš„ä¸€é˜¶æ³°å‹’å±•å¼€

å‡è®¾æ•°æ®å¢å¼º $\mathcal{T}(x) = x + \Delta x$ï¼Œå…¶ä¸­ $\Delta x$ æ˜¯å°æ‰°åŠ¨ã€‚

<div class="formula-step">
<div class="step-label">1. ç›®æ ‡ä¸­å¿ƒåŒ–</div>
å¯¹äºç›®æ ‡é¡¹ $f_{\theta}(\mathcal{T}_2(x))$ï¼Œå…¶å¹³å‡å€¼ä¸º $\bar{z} = f_{\theta}(\bar{x})$ã€‚
</div>

<div class="formula-step">
<div class="step-label">2. å±•å¼€é¢„æµ‹è¯¯å·®</div>
\begin{equation}
\mathcal{L}(\theta) \approx \mathbb{E}_{x, \Delta x} \left[ \left\Vert \boldsymbol{J}_{\theta}(x) \Delta x \right\|^2 \right] \tag{12}
\end{equation}
å…¶ä¸­ $\boldsymbol{J}_{\theta}$ æ˜¯ç¼–ç å™¨çš„é›…å¯æ¯”çŸ©é˜µï¼ˆç‰¹å¾çµæ•åº¦ï¼‰ã€‚
</div>

<div class="formula-step">
<parameter name="step-label">3. å‡ ä½•æ„ä¹‰</div>
SimSiam å®é™…ä¸Šåœ¨å¯»æ‰¾ä¸€ä¸ªç‰¹å¾æ˜ å°„ï¼Œä½¿å¾—å®ƒå¯¹å¸¸è§çš„å›¾åƒå˜æ¢ï¼ˆæ•°æ®å¢å¼ºï¼‰å…·æœ‰ä½æ•æ„Ÿåº¦ï¼ŒåŒæ—¶é€šè¿‡ Predictor çš„è§£è€¦æ•ˆåº”ï¼Œåœ¨ä¸ç‰ºç‰²è¡¨ç¤ºç»´åº¦ï¼ˆå³ä¸åç¼©ï¼‰çš„å‰æä¸‹å®ç°è¿™ä¸€ç‚¹ã€‚
</div>

</div>
<h3 id="25-batch-normalization">2.5 Batch Normalizationçš„éšå¼ä½œç”¨</h3>
<div class="critical-analysis">

**æ ¸å¿ƒç–‘é—®**ï¼šä¸ºä»€ä¹ˆSimSiamå¼ºçƒˆä¾èµ–BNï¼Ÿ

**ç­”æ¡ˆ**ï¼šBNæä¾›äº†ä¸‰é‡éšå¼çº¦æŸ

#### çº¦æŸ1ï¼šéšå¼å»ä¸­å¿ƒåŒ–ï¼ˆImplicit Centeringï¼‰

BNå±‚å¼ºåˆ¶æ¯ä¸ªæ‰¹æ¬¡çš„ç‰¹å¾å‡å€¼ä¸ºé›¶ï¼š
\begin{equation}
\mathbb{E}_{\text{batch}}[z_i] = 0 \tag{13}
\end{equation}

è¿™é˜²æ­¢äº†æ‰€æœ‰ç‰¹å¾åŒæ—¶æ¼‚ç§»åˆ°ç›¸åŒçš„éé›¶å¸¸æ•°ã€‚

#### çº¦æŸ2ï¼šéšå¼æ–¹å·®æ­£åˆ™åŒ–ï¼ˆImplicit Variance Regularizationï¼‰

BNæ ‡å‡†åŒ–æ¯ä¸ªç‰¹å¾ç»´åº¦çš„æ–¹å·®ä¸º1ï¼š
\begin{equation}
\text{Var}_{\text{batch}}(z_i) = 1 \tag{14}
\end{equation}

è¿™é˜²æ­¢äº†ç‰¹å¾åç¼©åˆ°é›¶ç‚¹ï¼ˆæ–¹å·®ä¸º0ï¼‰ã€‚

#### çº¦æŸ3ï¼šéšå¼Batchå†…å¯¹æ¯”ï¼ˆImplicit Batch-level Contrastï¼‰

**å®šç†2.2ï¼ˆRichemond et al. 2021ï¼‰**ï¼šBNåœ¨batchç»´åº¦å¼•å…¥çš„éšå¼å¯¹æ¯”æ•ˆåº”ç­‰ä»·äºï¼š
\begin{equation}
L_{\text{BN}} = L_{\text{SimSiam}} + \underbrace{\frac{\lambda}{B} \sum_{i \neq j} \langle z_i, z_j \rangle}_{\text{éšå¼è´Ÿæ ·æœ¬é¡¹}} \tag{15}
\end{equation}

å…¶ä¸­ $B$ æ˜¯batch sizeï¼Œ$\lambda$ æ˜¯éšå¼ç³»æ•°ã€‚

**å®éªŒéªŒè¯**ï¼š
- å»æ‰BNåï¼ŒSimSiamåœ¨100 epochå†…åç¼©ï¼ˆæ‰€æœ‰ç‰¹å¾ â†’ é›¶å‘é‡ï¼‰
- ä½¿ç”¨LayerNorm/GroupNormæ›¿ä»£BNï¼Œåç¼©é€Ÿåº¦å‡ç¼“ä½†ä»ç„¶å‘ç”Ÿ
- åªæœ‰ä¿ç•™Batchç»´åº¦ç»Ÿè®¡çš„å½’ä¸€åŒ–ï¼ˆå¦‚SyncBNï¼‰æ‰èƒ½å®Œå…¨é˜²æ­¢åç¼©

</div>

<h3 id="26">2.6 éçº¿æ€§åŠ¨åŠ›å­¦ï¼šå¿«å˜æµå½¢ç†è®º</h3>
<div class="advanced-theory">

#### å¿«æ…¢ç³»ç»Ÿåˆ†è§£ï¼ˆSlow-Fast Systems Decompositionï¼‰

å°†SimSiamå»ºæ¨¡ä¸ºå¥‡å¼‚æ‘„åŠ¨ç³»ç»Ÿï¼ˆSingular Perturbation Systemï¼‰ï¼š
\begin{align}
\dot{\boldsymbol{\theta}} &= -\nabla_{\boldsymbol{\theta}} L(\boldsymbol{\theta}, \boldsymbol{\varphi}) \tag{16a}\\
\epsilon \dot{\boldsymbol{\varphi}} &= -\nabla_{\boldsymbol{\varphi}} L(\boldsymbol{\theta}, \boldsymbol{\varphi}) \tag{16b}
\end{align}

å…¶ä¸­ $\epsilon \ll 1$ è¡¨ç¤ºPredictorçš„æ—¶é—´å°ºåº¦è¿œå°äºEncoderã€‚

**Tikhonovå®šç†åº”ç”¨**ï¼š
åœ¨ $\epsilon \to 0$ æé™ä¸‹ï¼Œç³»ç»Ÿæ¼”åŒ–åˆ†ä¸¤ä¸ªé˜¶æ®µï¼š

**å¿«é€Ÿé˜¶æ®µ**ï¼ˆFast Transientï¼Œ$t = \mathcal{O}(\epsilon)$ï¼‰ï¼š
- $\boldsymbol{\theta}$ å‡ ä¹ä¸åŠ¨
- $\boldsymbol{\varphi}$ å¿«é€Ÿæ”¶æ•›åˆ°å‡†å¹³è¡¡ç‚¹ï¼š
  \begin{equation}
  \nabla_{\boldsymbol{\varphi}} L(\boldsymbol{\theta}, \boldsymbol{\varphi}) = 0 \Rightarrow h_{\boldsymbol{\varphi}}(z) \approx z \tag{17}
  \end{equation}

**æ…¢é€Ÿé˜¶æ®µ**ï¼ˆSlow Manifoldï¼Œ$t = \mathcal{O}(1)$ï¼‰ï¼š
- $\boldsymbol{\varphi}$ å§‹ç»ˆä¿æŒåœ¨å‡†å¹³è¡¡æµå½¢ä¸Š
- $\boldsymbol{\theta}$ æ²¿ç€é™ç»´çš„æœ‰æ•ˆèƒ½é‡é¢æ¼”åŒ–ï¼š
  \begin{equation}
  \dot{\boldsymbol{\theta}} \approx -\nabla_{\boldsymbol{\theta}} L(\boldsymbol{\theta}, \boldsymbol{\varphi}^*(\boldsymbol{\theta})) \tag{18}
  \end{equation}

**å‡ ä½•è§£é‡Š**ï¼šPredictoråœ¨é«˜ç»´å‚æ•°ç©ºé—´ä¸­å¿«é€Ÿ"æ»‘è¡Œ"åˆ°ä¸€ä¸ªä½ç»´æµå½¢ï¼ˆæ…¢æµå½¢ï¼‰ï¼ŒEncoderåˆ™è¢«çº¦æŸåœ¨è¿™ä¸ªæµå½¢ä¸Šç¼“æ…¢ä¼˜åŒ–ã€‚è¿™ç§é™ç»´æ•ˆåº”å¤©ç„¶é˜²æ­¢äº†åç¼©ï¼Œå› ä¸ºæµå½¢çš„ç»´åº¦ç”±æ•°æ®å¢å¼ºçš„å¤šæ ·æ€§å†³å®šï¼Œè€Œéç½‘ç»œçš„è¿‡å‚æ•°åŒ–ã€‚

</div>

<hr />
<h2 id="3">3. æ•°å­¦ç›´è§‰ã€å‡ ä½•è§†è§’ä¸å¤šç»´ç±»æ¯”</h2>
<div class="intuition-box">

### ğŸ§  ç›´è§‰ç†è§£ï¼šå½±å­çƒä¸å¿«é€Ÿæ•æ‰æ‰‹ ğŸ¾

æƒ³è±¡ä½ åœ¨å’Œä¸€ä¸ªå½±å­ï¼ˆPredictorï¼‰ç©æŠ›æ¥çƒã€‚

1.  **åç¼©ï¼ˆå…¨æ¢¯åº¦ï¼‰**ï¼šä½ å’Œå½±å­éƒ½åœ¨æ‹¼å‘½å¾€åœ°æ¿ï¼ˆé›¶ç‚¹ï¼‰ç¼©ã€‚å› ä¸ºä½ ä»¬åŠ¨ä½œä¸€è‡´ï¼Œæœ€åä½ ä»¬éƒ½ä¼šå˜æˆåœ°æ¿ä¸Šçš„ä¸€ä¸ªç‚¹ã€‚
2.  **SimSiam ä¸åç¼©**ï¼š
    *   ä½ ï¼ˆEncoderï¼‰åŠ¨å¾—å¾ˆæ…¢ã€‚
    *   å½±å­ï¼ˆPredictorï¼‰æ˜¯ä¸€ä¸ªèº«æ‰‹æå¿«çš„æ•æ‰æ‰‹ã€‚
    *   **Stop-gradient**ï¼šä½ æŠ›çƒæ—¶ï¼Œå½±å­å¿…é¡»åœä¸‹æ¥æ¥ï¼Œä¸èƒ½åè¿‡æ¥æ‹½ä½ ã€‚
    *   **ç»“æœ**ï¼šæ¯å½“ä½ ç¨å¾®åç¦»ä¸€ç‚¹æ–¹å‘ï¼Œå½±å­ç”±äºåŠ¨ä½œæå¿«ï¼Œä¼šåœ¨ä½ è¿˜æ²¡åŠ¨ä¸‹ä¸€è„šä¹‹å‰å°±ç«™åœ¨äº†çƒçš„è½ç‚¹ä¸Šã€‚æ—¢ç„¶å½±å­å·²ç»æ¥åˆ°äº†çƒï¼ˆLoss å˜å°ï¼‰ï¼Œä½ å°±æ²¡æœ‰åŠ¨åŠ›ç»§ç»­å¾€åœ°æ¿ç¼©äº†ã€‚ä½ åœåœ¨äº†åŠè·¯ï¼Œä¿ä½äº†ä½ çš„ä½ç½®ï¼ˆç‰¹å¾ï¼‰ã€‚

</div>

<h3 id="32">3.2 å‡ ä½•è§†è§’ï¼šèƒ½é‡ç›†åœ°çš„è„Šçº¿é©»ç•™</h3>
<p>åœ¨ç‰¹å¾ç©ºé—´ä¸­ï¼Œåç¼©æ˜¯ä¸€ä¸ªæ·±ä¸è§åº•çš„ä¸­å¿ƒé»‘æ´ã€‚
- <strong>å¯¹æ¯”å­¦ä¹ </strong>ï¼šæ˜¯åœ¨é»‘æ´å‘¨å›´ä¿®äº†ä¸€åœˆæŒ¡æ¿ï¼ˆè´Ÿæ ·æœ¬ï¼‰ã€‚
- <strong>SimSiam</strong>ï¼šæ˜¯åˆ©ç”¨åŠ¨åŠ›å­¦åœ¨é»‘æ´è¾¹ç¼˜å»ºç«‹äº†ä¸€ä¸ªâ€œåŠ¨æ€å¹³è¡¡è½¨é“â€ã€‚é€šè¿‡åˆ‡æ–­æ¢¯åº¦ï¼Œæˆ‘ä»¬å°†åŸæœ¬å‚ç›´è½å…¥é»‘æ´çš„åŠ›ï¼Œè½¬åŒ–ä¸ºäº†åœ¨è½¨é“ä¸Šåˆ‡å‘è¿åŠ¨çš„åŠ›ã€‚è¿™ç§ç°è±¡åœ¨éçº¿æ€§ç‰©ç†ä¸­è¢«ç§°ä¸º<strong>â€œå¸å¼•å­çš„æ‹“æ‰‘æ”¹å˜â€</strong>ã€‚</p>
<hr />
<h2 id="4">4. æ–¹æ³•è®ºå˜ä½“ã€æ‰¹åˆ¤æ€§æ¯”è¾ƒä¸ä¼˜åŒ–</h2>
<h3 id="41">4.1 å…¨é‡å¯¹æ¯”è¡¨</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">æ¨¡å‹</th>
<th style="text-align: left;">é˜²åç¼©æœºåˆ¶</th>
<th style="text-align: left;">æ ¸å¿ƒç»„ä»¶</th>
<th style="text-align: left;"><strong>è‡´å‘½ç¼ºé™·</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>SimCLR</strong></td>
<td style="text-align: left;">è´Ÿæ ·æœ¬å¯¹é½</td>
<td style="text-align: left;">å¤§ Batch Size</td>
<td style="text-align: left;">âŒ è®¡ç®—å¼€é”€æå¤§</td>
</tr>
<tr>
<td style="text-align: left;"><strong>BYOL</strong></td>
<td style="text-align: left;">åŠ¨é‡é¢„æµ‹</td>
<td style="text-align: left;">EMA ç¼–ç å™¨</td>
<td style="text-align: left;">âŒ ç†è®ºè¯æ˜å¤æ‚</td>
</tr>
<tr>
<td style="text-align: left;"><strong>SimSiam</strong></td>
<td style="text-align: left;"><strong>åŠ¨åŠ›å­¦è§£è€¦</strong></td>
<td style="text-align: left;"><strong>Stop-grad + Predictor</strong></td>
<td style="text-align: left;">âŒ <strong>å¯¹ BN æåº¦ä¾èµ–</strong></td>
</tr>
<tr>
<td style="text-align: left;"><strong>VICReg</strong></td>
<td style="text-align: left;">åæ–¹å·®çº¦æŸ</td>
<td style="text-align: left;">Variance Regularization</td>
<td style="text-align: left;">âŒ å‚æ•°è°ƒä¼˜å›°éš¾</td>
</tr>
</tbody>
</table>
<h3 id="42-simsiam">4.2 æ·±åº¦æ‰¹åˆ¤ï¼šSimSiam çš„â€œä¼ªç§‘å­¦â€é™·é˜±</h3>
<p>è™½ç„¶å®éªŒç»“æœæƒŠè‰³ï¼Œä½† SimSiam çš„ç†è®ºåŸºç¡€å­˜åœ¨ä¸‰ä¸ªè„†å¼±ç‚¹ï¼š</p>
<ol>
<li><strong>è‡´å‘½ç¼ºé™· 1ï¼šBatch Normalization (BN) çš„éšå¼å¯¹æ¯”</strong><ul>
<li><strong>åˆ†æ</strong>ï¼šå¦‚æœå»æ‰ BNï¼ŒSimSiam ä¼šç¬é—´åç¼©ã€‚</li>
<li><strong>çœŸç›¸</strong>ï¼šBN åœ¨ Batch ç»´åº¦ä¸Šçš„å‡å€¼å’Œæ–¹å·®è®¡ç®—ï¼Œå®é™…ä¸Šæä¾›äº†ä¸€ç§éšå¼çš„â€œè´Ÿæ ·æœ¬â€æ•ˆåº”ï¼Œå¼ºè¿«åŒä¸€ä¸ª Batch å†…çš„ç‰¹å¾ä¸èƒ½å…¨ç­‰ã€‚<strong>SimSiam çš„æˆåŠŸæœ‰ä¸€åŠæ˜¯å±äº BN çš„ã€‚</strong></li>
</ul>
</li>
<li><strong>è‡´å‘½ç¼ºé™· 2ï¼šPredictor çš„æ¶æ„é»‘ç®±</strong><ul>
<li><strong>é—®é¢˜</strong>ï¼šPredictor å¦‚æœå¤ªæ·±ï¼Œæ”¶æ•›ææ…¢ï¼›å¦‚æœå¤ªæµ…ï¼Œæ— æ³•æ‰“ç ´å¯¹ç§°æ€§ã€‚</li>
<li><strong>å±€é™</strong>ï¼šç›®å‰æ²¡æœ‰æ•°å­¦å…¬å¼èƒ½è®¡ç®—å‡ºé’ˆå¯¹ç‰¹å®šä¸»å¹²ç½‘ç»œçš„æœ€ä¼˜ Predictor æ·±åº¦ã€‚</li>
</ul>
</li>
<li><strong>è‡´å‘½ç¼ºé™· 3ï¼šç‰¹å¾å†—ä½™ (Redundancy)</strong><ul>
<li>ç”±äºæ²¡æœ‰å»ç›¸å…³çš„æ˜¾å¼çº¦æŸï¼ŒSimSiam å­¦åˆ°çš„ 2048 ç»´ç‰¹å¾ä¸­ï¼Œå¯èƒ½åªæœ‰æå°‘æ•°ç»´åº¦æ˜¯æœ‰ä¿¡æ¯çš„ï¼Œå…¶ä½™ç»´åº¦é«˜åº¦ç›¸å…³ã€‚</li>
</ul>
</li>
</ol>
<h3 id="43">4.3 ä¼˜åŒ–æ¼”è¿›</h3>
<ul>
<li><strong>Barlow Twins</strong>ï¼šé€šè¿‡è®©äº’åæ–¹å·®çŸ©é˜µé€¼è¿‘å•ä½é˜µï¼Œä»æ•°å­¦ä¸Šå½»åº•æ¶ˆé™¤äº†åç¼©çš„å¯èƒ½æ€§ï¼Œä¸å†ä¾èµ–åŠ¨åŠ›å­¦å·§åˆã€‚</li>
<li><strong>DINO</strong>ï¼šå°† SimSiam çš„æ€æƒ³åº”ç”¨åˆ° Transformer ä¸­ï¼Œåˆ©ç”¨ä¸­å¿ƒåŒ–ï¼ˆCenteringï¼‰å’Œé”åŒ–ï¼ˆSharpeningï¼‰æ›¿ä»£ BNï¼Œå®ç°äº†æ›´é«˜è´¨é‡çš„æ— ç›‘ç£å­¦ä¹ ã€‚</li>
</ul>
<hr />
<h2 id="5">5. å®Œæ•´æ•°å€¼å®éªŒï¼šä»ç©å…·æ¨¡å‹åˆ°çœŸå®è®­ç»ƒ</h2>
<h3 id="51-1">5.1 å®éªŒ1ï¼šç©å…·æ¨¡å‹å¯è§†åŒ–</h3>
<div class="code-box">

**ç›®æ ‡**ï¼šé€šè¿‡æ ‡é‡åŠ¨åŠ›å­¦ç›´è§‚å±•ç¤ºStop-gradientçš„ä½œç”¨ã€‚


<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># ç©å…·æ¨¡å‹ï¼šçº¿æ€§ç¼–ç å™¨å’Œé¢„æµ‹å™¨</span>
<span class="k">def</span><span class="w"> </span><span class="nf">toy_dynamics</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">gamma_theta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">gamma_phi</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">use_stopgrad</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    æ¨¡æ‹Ÿæ ‡é‡SimSiamåŠ¨åŠ›å­¦</span>

<span class="sd">    å‚æ•°:</span>
<span class="sd">        T: è¿­ä»£æ­¥æ•°</span>
<span class="sd">        gamma_theta: Encoderå­¦ä¹ ç‡ï¼ˆæ…¢ï¼‰</span>
<span class="sd">        gamma_phi: Predictorå­¦ä¹ ç‡ï¼ˆå¿«ï¼‰</span>
<span class="sd">        use_stopgrad: æ˜¯å¦ä½¿ç”¨Stop-gradient</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># åˆå§‹åŒ–</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># ç¼–ç å™¨å‚æ•°</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="mf">0.1</span>    <span class="c1"># é¢„æµ‹å™¨å‚æ•°ï¼ˆåˆå§‹æ—¶è¿œç¦»1ï¼‰</span>

    <span class="c1"># è®°å½•è½¨è¿¹</span>
    <span class="n">theta_history</span> <span class="o">=</span> <span class="p">[</span><span class="n">theta</span><span class="p">]</span>
    <span class="n">phi_history</span> <span class="o">=</span> <span class="p">[</span><span class="n">phi</span><span class="p">]</span>
    <span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
        <span class="c1"># è®¡ç®—æŸå¤±ï¼šL = 0.5 * (phi * theta - theta)^2</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">phi</span> <span class="o">*</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">theta</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">use_stopgrad</span><span class="p">:</span>
            <span class="c1"># Stop-gradientï¼šåªæœ‰phiæ”¶åˆ°æ¢¯åº¦</span>
            <span class="n">grad_phi</span> <span class="o">=</span> <span class="p">(</span><span class="n">phi</span> <span class="o">*</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">theta</span><span class="p">)</span> <span class="o">*</span> <span class="n">theta</span>  <span class="c1"># âˆ‚L/âˆ‚phi</span>
            <span class="n">grad_theta</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># è¢«stop_gradæˆªæ–­</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># æ— Stop-gradientï¼šåŒå‘æ¢¯åº¦</span>
            <span class="n">grad_phi</span> <span class="o">=</span> <span class="p">(</span><span class="n">phi</span> <span class="o">*</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">theta</span><span class="p">)</span> <span class="o">*</span> <span class="n">theta</span>
            <span class="n">grad_theta</span> <span class="o">=</span> <span class="p">(</span><span class="n">phi</span> <span class="o">*</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">theta</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">phi</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># æ›´æ–°å‚æ•°</span>
        <span class="n">phi</span> <span class="o">-=</span> <span class="n">gamma_phi</span> <span class="o">*</span> <span class="n">grad_phi</span>
        <span class="n">theta</span> <span class="o">-=</span> <span class="n">gamma_theta</span> <span class="o">*</span> <span class="n">grad_theta</span>

        <span class="n">theta_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
        <span class="n">phi_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">phi</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">theta_history</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">phi_history</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">loss_history</span><span class="p">)</span>

<span class="c1"># è¿è¡Œå®éªŒï¼šå¯¹æ¯”æœ‰æ— Stop-gradient</span>
<span class="n">theta_sg</span><span class="p">,</span> <span class="n">phi_sg</span><span class="p">,</span> <span class="n">loss_sg</span> <span class="o">=</span> <span class="n">toy_dynamics</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">use_stopgrad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">theta_no</span><span class="p">,</span> <span class="n">phi_no</span><span class="p">,</span> <span class="n">loss_no</span> <span class="o">=</span> <span class="n">toy_dynamics</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">use_stopgrad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># å¯è§†åŒ–</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># å­å›¾1ï¼šå‚æ•°è½¨è¿¹</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">theta_sg</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Î¸ (w/ Stop-grad)&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">phi_sg</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ï† (w/ Stop-grad)&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">theta_no</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Î¸ (w/o Stop-grad)&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C2&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">phi_no</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ï† (w/o Stop-grad)&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C3&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Collapse Point&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Target (Ï†=1)&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Parameter Value&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Parameter Trajectory Comparison&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># å­å›¾2ï¼šç›¸ç©ºé—´ï¼ˆÎ¸-Ï†å¹³é¢ï¼‰</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">theta_sg</span><span class="p">,</span> <span class="n">phi_sg</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;w/ Stop-grad&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">theta_no</span><span class="p">,</span> <span class="n">phi_no</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C2&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;w/o Stop-grad&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">theta_sg</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">phi_sg</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;go&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Start&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">theta_sg</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">phi_sg</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;r*&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;End (Stop-grad)&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">theta_no</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">phi_no</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;bx&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;End (No Stop-grad)&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Encoder Î¸&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Predictor Ï†&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Phase Space Trajectory&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># å­å›¾3ï¼šæŸå¤±æ¼”åŒ–</span>
<span class="n">ax3</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">loss_sg</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;w/ Stop-grad&#39;</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">loss_no</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C2&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;w/o Stop-grad&#39;</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Loss (log scale)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Loss Evolution&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;simsiam_toy_dynamics.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;âœ“ å›¾åƒå·²ä¿å­˜è‡³ simsiam_toy_dynamics.png&quot;</span><span class="p">)</span>

<span class="c1"># æ‰“å°å…³é”®è§‚å¯Ÿ</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">å…³é”®è§‚å¯Ÿï¼š&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;1. Stop-gradæƒ…å†µï¼š&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   - æœ€ç»ˆÎ¸ = </span><span class="si">{</span><span class="n">theta_sg</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ï¼ˆä¿æŒéé›¶ï¼ï¼‰&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   - æœ€ç»ˆÏ† = </span><span class="si">{</span><span class="n">phi_sg</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ï¼ˆæ¥è¿‘1ï¼‰&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   - æœ€ç»ˆLoss = </span><span class="si">{</span><span class="n">loss_sg</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">2. æ— Stop-gradæƒ…å†µï¼š&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   - æœ€ç»ˆÎ¸ = </span><span class="si">{</span><span class="n">theta_no</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ï¼ˆåç¼©åˆ°é›¶ï¼ï¼‰&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   - æœ€ç»ˆÏ† = </span><span class="si">{</span><span class="n">phi_no</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   - æœ€ç»ˆLoss = </span><span class="si">{</span><span class="n">loss_no</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>



**è¾“å‡ºè§£é‡Š**ï¼š
- **æœ‰Stop-gradient**ï¼š$\theta$ ä¿æŒåœ¨éé›¶å€¼ï¼Œ$\varphi$ å¿«é€Ÿæ”¶æ•›åˆ°1ï¼Œç³»ç»Ÿç¨³å®š
- **æ— Stop-gradient**ï¼š$\theta$ è¿…é€Ÿåç¼©åˆ°0ï¼Œ$\varphi$ æ— æ³•è¡¥æ•‘ï¼Œç³»ç»Ÿå¤±è´¥

</div>

<h3 id="52-2simsiam">5.2 å®éªŒ2ï¼šå®Œæ•´SimSiamå®ç°ä¸è®­ç»ƒ</h3>
<div class="code-box">

**ç›®æ ‡**ï¼šåœ¨CIFAR-10ä¸Šå¤ç°SimSiamï¼ŒéªŒè¯BNä¾èµ–æ€§ã€‚


<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># SimSiamæ¶æ„</span>
<span class="k">class</span><span class="w"> </span><span class="nc">SimSiam</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_encoder</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">pred_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        å‚æ•°:</span>
<span class="sd">            base_encoder: éª¨å¹²ç½‘ç»œï¼ˆå¦‚ResNet-18ï¼‰</span>
<span class="sd">            dim: æŠ•å½±å¤´è¾“å‡ºç»´åº¦</span>
<span class="sd">            pred_dim: Predictoréšè—å±‚ç»´åº¦</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SimSiam</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">base_encoder</span>
        <span class="c1"># è·å–encoderè¾“å‡ºç»´åº¦</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_dim</span> <span class="o">=</span> <span class="n">base_encoder</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span>
        <span class="n">base_encoder</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>  <span class="c1"># ç§»é™¤åˆ†ç±»å¤´</span>

        <span class="c1"># Projection Headï¼ˆ3å±‚MLPï¼‰</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projector</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder_dim</span><span class="p">,</span> <span class="n">pred_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">pred_dim</span><span class="p">),</span>  <span class="c1"># å…³é”®ï¼šBNå±‚</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">pred_dim</span><span class="p">,</span> <span class="n">pred_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">pred_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">pred_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># è¾“å‡ºBNæ— å¯å­¦ä¹ å‚æ•°</span>
        <span class="p">)</span>

        <span class="c1"># Predictorï¼ˆ2å±‚MLPï¼‰</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">pred_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">pred_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">pred_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>  <span class="c1"># æ— BN</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        å‰å‘ä¼ æ’­</span>

<span class="sd">        å‚æ•°:</span>
<span class="sd">            x1, x2: ä¸¤ä¸ªaugmented views</span>

<span class="sd">        è¿”å›:</span>
<span class="sd">            p1, p2: Predictorè¾“å‡º</span>
<span class="sd">            z1, z2: Projectorè¾“å‡ºï¼ˆå°†è¢«detachï¼‰</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># ç¼–ç +æŠ•å½±</span>
        <span class="n">z1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x1</span><span class="p">))</span>
        <span class="n">z2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x2</span><span class="p">))</span>

        <span class="c1"># é¢„æµ‹</span>
        <span class="n">p1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span><span class="p">(</span><span class="n">z1</span><span class="p">)</span>
        <span class="n">p2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">,</span> <span class="n">z1</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">z2</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

<span class="c1"># æŸå¤±å‡½æ•°</span>
<span class="k">def</span><span class="w"> </span><span class="nf">simsiam_loss</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    è´Ÿä½™å¼¦ç›¸ä¼¼åº¦</span>

<span class="sd">    å‚æ•°:</span>
<span class="sd">        p: Predictorè¾“å‡º</span>
<span class="sd">        z: Targetï¼ˆå·²detachï¼‰</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># L2å½’ä¸€åŒ–</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># è´Ÿä½™å¼¦ç›¸ä¼¼åº¦ = 1 - cos(p, z)</span>
    <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">p</span> <span class="o">*</span> <span class="n">z</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># æ•°æ®å¢å¼º</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_transforms</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;SimSiamçš„æ•°æ®å¢å¼ºç­–ç•¥&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomApply</span><span class="p">([</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">ColorJitter</span><span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
        <span class="p">],</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.8</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomGrayscale</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.4914</span><span class="p">,</span> <span class="mf">0.4822</span><span class="p">,</span> <span class="mf">0.4465</span><span class="p">],</span>
                           <span class="p">[</span><span class="mf">0.2023</span><span class="p">,</span> <span class="mf">0.1994</span><span class="p">,</span> <span class="mf">0.2010</span><span class="p">])</span>
    <span class="p">])</span>

<span class="c1"># TwoCropsTransformï¼šç”Ÿæˆä¸¤ä¸ªaugmented views</span>
<span class="k">class</span><span class="w"> </span><span class="nc">TwoCropsTransform</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_transform</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_transform</span> <span class="o">=</span> <span class="n">base_transform</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">base_transform</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)]</span>

<span class="c1"># è®­ç»ƒå‡½æ•°</span>
<span class="k">def</span><span class="w"> </span><span class="nf">train_simsiam</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;è®­ç»ƒSimSiamæ¨¡å‹&quot;&quot;&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
                               <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>

    <span class="c1"># Cosineå­¦ä¹ ç‡è°ƒåº¦</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CosineAnnealingLR</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="n">epochs</span>
    <span class="p">)</span>

    <span class="c1"># è®°å½•ç»Ÿè®¡</span>
    <span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">],</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
            <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span> <span class="o">=</span> <span class="n">x1</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">x2</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># å‰å‘ä¼ æ’­</span>
            <span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">,</span> <span class="n">z1</span><span class="p">,</span> <span class="n">z2</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>

            <span class="c1"># è®¡ç®—å¯¹ç§°æŸå¤±</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">simsiam_loss</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">z2</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">simsiam_loss</span><span class="p">(</span><span class="n">p2</span><span class="p">,</span> <span class="n">z1</span><span class="p">)</span>

            <span class="c1"># åå‘ä¼ æ’­</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="c1"># è®°å½•</span>
        <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
        <span class="n">loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_loss</span><span class="p">)</span>

        <span class="c1"># å­¦ä¹ ç‡è¡°å‡</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s1">], &#39;</span>
                  <span class="sa">f</span><span class="s1">&#39;Loss: </span><span class="si">{</span><span class="n">avg_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, &#39;</span>
                  <span class="sa">f</span><span class="s1">&#39;LR: </span><span class="si">{</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.6f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss_history</span>

<span class="c1"># ä¸»å®éªŒ</span>
<span class="k">def</span><span class="w"> </span><span class="nf">run_cifar10_experiment</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;CIFAR-10å®Œæ•´å®éªŒ&quot;&quot;&quot;</span>
    <span class="c1"># æ•°æ®åŠ è½½</span>
    <span class="n">transform</span> <span class="o">=</span> <span class="n">TwoCropsTransform</span><span class="p">(</span><span class="n">get_transforms</span><span class="p">())</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                     <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
                             <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                             <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># æ¨¡å‹åˆå§‹åŒ–</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">resnet18</span>
    <span class="n">base_encoder</span> <span class="o">=</span> <span class="n">resnet18</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">SimSiam</span><span class="p">(</span><span class="n">base_encoder</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">pred_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>

    <span class="c1"># è®­ç»ƒ</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ä½¿ç”¨è®¾å¤‡: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">loss_history</span> <span class="o">=</span> <span class="n">train_simsiam</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                 <span class="n">lr</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># å¯è§†åŒ–æŸå¤±æ›²çº¿</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_history</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;SimSiam Loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training Loss Curve (CIFAR-10)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;simsiam_cifar10_loss.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;âœ“ æŸå¤±æ›²çº¿å·²ä¿å­˜è‡³ simsiam_cifar10_loss.png&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_history</span>

<span class="c1"># è¿è¡Œå®éªŒ</span>
<span class="n">model</span><span class="p">,</span> <span class="n">loss_history</span> <span class="o">=</span> <span class="n">run_cifar10_experiment</span><span class="p">()</span>
</code></pre></div>



</div>

<h3 id="53-3bn">5.3 å®éªŒ3ï¼šBNä¾èµ–æ€§æ¶ˆèå®éªŒ</h3>
<div class="code-box">

**ç›®æ ‡**ï¼šéªŒè¯å»æ‰BNåSimSiamæ˜¯å¦åç¼©ã€‚


<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">ablation_study_bn</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;BNæ¶ˆèå®éªŒ&quot;&quot;&quot;</span>

    <span class="c1"># å®šä¹‰æ— BNçš„SimSiamï¼ˆç”¨LayerNormæ›¿ä»£ï¼‰</span>
    <span class="k">class</span><span class="w"> </span><span class="nc">SimSiamNoBN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_encoder</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">pred_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">SimSiamNoBN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">base_encoder</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder_dim</span> <span class="o">=</span> <span class="n">base_encoder</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span>
            <span class="n">base_encoder</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

            <span class="c1"># æŠ•å½±å¤´ï¼ˆä½¿ç”¨LayerNormï¼‰</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">projector</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder_dim</span><span class="p">,</span> <span class="n">pred_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">pred_dim</span><span class="p">),</span>  <span class="c1"># æ›¿æ¢BN</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">pred_dim</span><span class="p">,</span> <span class="n">pred_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">pred_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">pred_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># é¢„æµ‹å™¨</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">pred_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">pred_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">pred_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
            <span class="n">z1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x1</span><span class="p">))</span>
            <span class="n">z2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x2</span><span class="p">))</span>
            <span class="n">p1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span><span class="p">(</span><span class="n">z1</span><span class="p">)</span>
            <span class="n">p2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">,</span> <span class="n">z1</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">z2</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

    <span class="c1"># è®­ç»ƒä¸¤ä¸ªç‰ˆæœ¬å¹¶å¯¹æ¯”</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;è®­ç»ƒæ ‡å‡†SimSiamï¼ˆå¸¦BNï¼‰...&quot;</span><span class="p">)</span>
    <span class="n">model_bn</span> <span class="o">=</span> <span class="n">SimSiam</span><span class="p">(</span><span class="n">resnet18</span><span class="p">(),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">)</span>
    <span class="n">loss_bn</span> <span class="o">=</span> <span class="n">train_simsiam</span><span class="p">(</span><span class="n">model_bn</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">è®­ç»ƒSimSiamï¼ˆæ— BNï¼Œç”¨LayerNormï¼‰...&quot;</span><span class="p">)</span>
    <span class="n">model_ln</span> <span class="o">=</span> <span class="n">SimSiamNoBN</span><span class="p">(</span><span class="n">resnet18</span><span class="p">(),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">)</span>
    <span class="n">loss_ln</span> <span class="o">=</span> <span class="n">train_simsiam</span><span class="p">(</span><span class="n">model_ln</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

    <span class="c1"># å¯è§†åŒ–å¯¹æ¯”</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_bn</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;With BatchNorm&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_ln</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;With LayerNorm (No BN)&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span>
             <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;BN Ablation Study&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;simsiam_bn_ablation.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">æœ€ç»ˆæŸå¤±å¯¹æ¯”ï¼š&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  BNç‰ˆæœ¬: </span><span class="si">{</span><span class="n">loss_bn</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  LayerNormç‰ˆæœ¬: </span><span class="si">{</span><span class="n">loss_ln</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  å·®å¼‚: </span><span class="si">{</span><span class="nb">abs</span><span class="p">(</span><span class="n">loss_bn</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">loss_ln</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># æ£€æŸ¥åç¼©ï¼ˆç‰¹å¾æ ‡å‡†å·®ï¼‰</span>
    <span class="n">model_bn</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">model_ln</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">x_test</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
        <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span> <span class="o">=</span> <span class="n">x_test</span>

        <span class="c1"># BNç‰ˆæœ¬çš„ç‰¹å¾</span>
        <span class="n">z1_bn</span> <span class="o">=</span> <span class="n">model_bn</span><span class="o">.</span><span class="n">projector</span><span class="p">(</span><span class="n">model_bn</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x1</span><span class="o">.</span><span class="n">cuda</span><span class="p">()))</span>
        <span class="n">std_bn</span> <span class="o">=</span> <span class="n">z1_bn</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="c1"># LayerNormç‰ˆæœ¬çš„ç‰¹å¾</span>
        <span class="n">z1_ln</span> <span class="o">=</span> <span class="n">model_ln</span><span class="o">.</span><span class="n">projector</span><span class="p">(</span><span class="n">model_ln</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x1</span><span class="o">.</span><span class="n">cuda</span><span class="p">()))</span>
        <span class="n">std_ln</span> <span class="o">=</span> <span class="n">z1_ln</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ç‰¹å¾æ ‡å‡†å·®ï¼ˆæ£€æµ‹åç¼©ï¼‰ï¼š&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  BNç‰ˆæœ¬: </span><span class="si">{</span><span class="n">std_bn</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  LayerNormç‰ˆæœ¬: </span><span class="si">{</span><span class="n">std_ln</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="s1">&#39;âš ï¸ LayerNormç‰ˆæœ¬åç¼©ï¼&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">std_ln</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mf">0.1</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;âœ“ æœªåç¼©&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># è¿è¡Œæ¶ˆèå®éªŒ</span>
<span class="n">ablation_study_bn</span><span class="p">()</span>
</code></pre></div>



**é¢„æœŸç»“æœ**ï¼š
- BNç‰ˆæœ¬ï¼šç¨³å®šè®­ç»ƒï¼ŒæŸå¤±æŒç»­ä¸‹é™ï¼Œç‰¹å¾æ ‡å‡†å·® â‰ˆ 1
- LayerNormç‰ˆæœ¬ï¼šå¯èƒ½å‡ºç°éƒ¨åˆ†åç¼©ï¼Œç‰¹å¾æ ‡å‡†å·® < 0.5

</div>

<h2 id="6">6. å·¥ç¨‹å®è·µä¸æœ€ä½³å®è·µ</h2>
<h3 id="61">6.1 è¶…å‚æ•°è°ƒä¼˜æŒ‡å—</h3>
<div class="practice-guide">

**æ ¸å¿ƒè¶…å‚æ•°**ï¼š

| å‚æ•° | æ¨èå€¼ | ä½œç”¨ | è°ƒä¼˜å»ºè®® |
|:---|:---|:---|:---|
| Batch Size | 256-512 | æä¾›è¶³å¤Ÿçš„BNç»Ÿè®¡ | è¶Šå¤§è¶Šå¥½ï¼ˆå—é™äºæ˜¾å­˜ï¼‰ |
| å­¦ä¹ ç‡ | 0.05 | æ§åˆ¶æ”¶æ•›é€Ÿåº¦ | Cosineè¡°å‡ |
| Predictoræ·±åº¦ | 2å±‚MLP | æ‰“ç ´å¯¹ç§°æ€§ | ä¸å®œè¿‡æ·±ï¼ˆ3å±‚å·²è¿‡ï¼‰ |
| ç‰¹å¾ç»´åº¦ | 2048 | è¡¨ç¤ºèƒ½åŠ› | ä¸backboneåŒ¹é… |
| æ•°æ®å¢å¼ºå¼ºåº¦ | å¼º | é˜²æ­¢ç®€å•è§£ | ColorJitter + Crop + Flip |
| è®­ç»ƒEpochs | 200-800 | å……åˆ†æ”¶æ•› | è¶Šé•¿è¶Šå¥½ |

**å…³é”®ç»éªŒ**ï¼š
1. **BNæ˜¯å¿…é¡»çš„**ï¼šå»æ‰BNå‡ ä¹100%åç¼©
2. **Predictorä¸èƒ½å¤ªæ·±**ï¼š2å±‚MLPæ˜¯sweet spotï¼Œ3å±‚åè€Œå˜å·®
3. **Stop-gradæ˜¯çµé­‚**ï¼šå°‘äº†å®ƒç«‹å³é€€åŒ–ä¸ºå¯¹ç§°ä¼˜åŒ–
4. **æ•°æ®å¢å¼ºè¦å¼º**ï¼šå¼±å¢å¼ºä¼šå¯¼è‡´æ¨¡å‹å­¦åˆ°ç®€å•æ˜ å°„

</div>

<h3 id="62-checklist">6.2 æ•…éšœæ’æŸ¥checklist</h3>
<div class="troubleshooting">

**é—®é¢˜1ï¼šè®­ç»ƒlossä¸ä¸‹é™ï¼ˆä¸€ç›´åœ¨1.0é™„è¿‘ï¼‰**
- **åŸå› **ï¼šç‰¹å¾å¯èƒ½å·²ç»åç¼©
- **è¯Šæ–­**ï¼šæ‰“å° `z.std(dim=0).mean()`ï¼Œå¦‚æœ < 0.1 åˆ™åç¼©
- **è§£å†³**ï¼š
  1. æ£€æŸ¥æ˜¯å¦æ­£ç¡®ä½¿ç”¨äº†`.detach()`
  2. ç¡®è®¤BN layerså­˜åœ¨ä¸”æ­£å¸¸å·¥ä½œ
  3. å¢å¤§Batch Sizeï¼ˆè‡³å°‘256ï¼‰

**é—®é¢˜2ï¼šè®­ç»ƒä¸­é€”çªç„¶lossæ¿€å¢**
- **åŸå› **ï¼šPredictorå­¦ä¹ è¿‡å¿«ï¼Œç ´åäº†æ…¢æµå½¢
- **è§£å†³**ï¼š
  1. é™ä½å­¦ä¹ ç‡ï¼ˆ0.05 â†’ 0.03ï¼‰
  2. å¢å¤§weight decayï¼ˆ1e-4 â†’ 5e-4ï¼‰
  3. ä½¿ç”¨æ›´gentleçš„å­¦ä¹ ç‡è°ƒåº¦ï¼ˆCosineæ›´å¹³æ»‘ï¼‰

**é—®é¢˜3ï¼šä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½å·®**
- **åŸå› **ï¼šè¡¨å¾ç¼ºä¹å¤šæ ·æ€§ï¼ˆç‰¹å¾å†—ä½™ï¼‰
- **è§£å†³**ï¼š
  1. å¢å¼ºæ•°æ®å¢å¼ºå¼ºåº¦
  2. å»¶é•¿è®­ç»ƒæ—¶é—´ï¼ˆ200 epoch â†’ 400 epochï¼‰
  3. è€ƒè™‘æ·»åŠ æ˜¾å¼å»ç›¸å…³é¡¹ï¼ˆå¦‚Barlow Twinsçš„åæ–¹å·®æ­£åˆ™åŒ–ï¼‰

</div>

<h3 id="63">6.3 ä¸å…¶ä»–è‡ªç›‘ç£æ–¹æ³•çš„é›†æˆ</h3>
<div class="integration-guide">

**SimSiam + MoCo**ï¼š

<div class="codehilite"><pre><span></span><code><span class="c1"># ç»“åˆé˜Ÿåˆ—æœºåˆ¶ï¼Œå¢åŠ éšå¼å¯¹æ¯”</span>
<span class="k">class</span><span class="w"> </span><span class="nc">SimSiamMoCo</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="mi">65536</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_q</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_k</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">encoder</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span> <span class="o">=</span> <span class="n">build_predictor</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>

        <span class="c1"># MoCoçš„é˜Ÿåˆ—</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;queue&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">K</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">queue</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_momentum_update_key_encoder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="mf">0.999</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param_q</span><span class="p">,</span> <span class="n">param_k</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder_q</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_k</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
        <span class="p">):</span>
            <span class="n">param_k</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">m</span> <span class="o">*</span> <span class="n">param_k</span><span class="o">.</span><span class="n">data</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">param_q</span><span class="o">.</span><span class="n">data</span>
</code></pre></div>



**SimSiam + Barlow Twins**ï¼š

<div class="codehilite"><pre><span></span><code><span class="c1"># æ·»åŠ åæ–¹å·®æ­£åˆ™åŒ–</span>
<span class="k">def</span><span class="w"> </span><span class="nf">simsiam_barlow_loss</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">z2</span><span class="p">,</span> <span class="n">p2</span><span class="p">,</span> <span class="n">z1</span><span class="p">,</span> <span class="n">lambda_cov</span><span class="o">=</span><span class="mf">0.005</span><span class="p">):</span>
    <span class="c1"># SimSiaméƒ¨åˆ†</span>
    <span class="n">loss_ss</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">D</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">z2</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">D</span><span class="p">(</span><span class="n">p2</span><span class="p">,</span> <span class="n">z1</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

    <span class="c1"># Barlow Twinséƒ¨åˆ†ï¼ˆå»ç›¸å…³ï¼‰</span>
    <span class="n">z1_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">z1</span> <span class="o">-</span> <span class="n">z1</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="o">/</span> <span class="n">z1</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">z2_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">z2</span> <span class="o">-</span> <span class="n">z2</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="o">/</span> <span class="n">z2</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">C</span> <span class="o">=</span> <span class="p">(</span><span class="n">z1_norm</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">z2_norm</span><span class="p">)</span> <span class="o">/</span> <span class="n">z1</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># è®©äº’åæ–¹å·®çŸ©é˜µæ¥è¿‘å•ä½é˜µ</span>
    <span class="n">loss_bt</span> <span class="o">=</span> <span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">loss_bt</span> <span class="o">+=</span> <span class="n">C</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">C</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">loss_ss</span> <span class="o">+</span> <span class="n">lambda_cov</span> <span class="o">*</span> <span class="n">loss_bt</span>
</code></pre></div>



</div>

<h3 id="64">6.4 æœªæ¥ç ”ç©¶æ–¹å‘</h3>
<div class="research-directions">

#### æ–¹å‘1ï¼šå¤§æ¨¡å‹ï¼ˆLLMï¼‰ä¸­çš„è‡ªç›‘ç£åç¼©

**èƒŒæ™¯**ï¼šNext-token prediction æœ¬è´¨ä¸Šæ˜¯å¸¦æ ‡ç­¾çš„ï¼Œä½†éšè—å±‚çš„è¡¨å¾æ˜¯å¦ä¼šå‘ç”Ÿå±€éƒ¨åç¼©ï¼Ÿ

**å…·ä½“é—®é¢˜**ï¼š
1. Transformerä¸­é—´å±‚æ˜¯å¦å­˜åœ¨"è¡¨å¾é€€åŒ–"ç°è±¡ï¼Ÿ
2. èƒ½å¦ç”¨SimSiamçš„å¿«æ…¢åŠ¨åŠ›å­¦è§£é‡ŠLayer Normalizationçš„ä½œç”¨ï¼Ÿ
3. è‡ªç›‘ç£é¢„è®­ç»ƒï¼ˆå¦‚BERTçš„MLMï¼‰æ˜¯å¦éšå¼åˆ©ç”¨äº†ç±»ä¼¼SimSiamçš„æœºåˆ¶ï¼Ÿ

**ç ”ç©¶å‡è®¾**ï¼š
- Dropoutåœ¨Transformerä¸­çš„ä½œç”¨ç±»ä¼¼äºBNåœ¨SimSiamä¸­çš„ä½œç”¨ï¼ˆé˜²æ­¢åç¼©ï¼‰
- å¤šå¤´æ³¨æ„åŠ›çš„ä¸åŒheadå¯èƒ½åœ¨ä¸åŒçš„"æ…¢æµå½¢"ä¸Šæ¼”åŒ–

#### æ–¹å‘2ï¼šæ— éœ€BNçš„åŠ¨åŠ›å­¦è§£è€¦

**åŠ¨æœº**ï¼šBNåœ¨batch sizeå°æˆ–åºåˆ—é•¿åº¦ä¸å‡æ—¶å¤±æ•ˆã€‚

**å€™é€‰æ–¹æ¡ˆ**ï¼š
1. **Adaptive Centering**ï¼šè‡ªé€‚åº”è°ƒæ•´ç‰¹å¾å‡å€¼
   \begin{equation}
   z_{\text{centered}} = z - \alpha \cdot \text{EMA}(\mathbb{E}[z]) \tag{19}
   \end{equation}

2. **Spectral Normalization + Implicit Regularization**ï¼š
   - ç”¨è°±å½’ä¸€åŒ–æ›¿ä»£BN
   - æ·»åŠ æ˜¾å¼æ–¹å·®çº¦æŸï¼š$\mathcal{L}_{\text{var}} = \max(0, 1 - \text{Var}(z))$

3. **Learnable Temperature Scaling**ï¼š
   \begin{equation}
   z_{\text{scaled}} = z / \tau, \quad \tau = \tau_0 \cdot e^{-t/T} \tag{20}
   \end{equation}

   å…¶ä¸­ $\tau$ éšè®­ç»ƒé€æ¸å‡å°ï¼ŒåˆæœŸå¼ºåˆ¶é«˜æ–¹å·®ï¼ŒåæœŸå…è®¸æ”¶æ•›ã€‚

#### æ–¹å‘3ï¼šSimSiamåœ¨æ‰©æ•£æ¨¡å‹ä¸­çš„åº”ç”¨

**æ ¸å¿ƒæ€æƒ³**ï¼šå°†å»å™ªç½‘ç»œè§†ä¸º"Predictor"ï¼Œå™ªå£°æ ·æœ¬è§†ä¸º"Target"ã€‚

**æ¶æ„è®¾è®¡**ï¼š

<div class="codehilite"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">DiffusionSimSiam</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">denoiser</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">denoiser</span> <span class="o">=</span> <span class="n">denoiser</span>  <span class="c1"># U-Netç­‰</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span> <span class="o">=</span> <span class="n">small_mlp</span><span class="p">()</span>  <span class="c1"># å¿«é€Ÿé€‚é…å™¨</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_noisy</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="c1"># Denoiseré¢„æµ‹å¹²å‡€å›¾åƒ</span>
        <span class="n">x_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">denoiser</span><span class="p">(</span><span class="n">x_noisy</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

        <span class="c1"># Predictorå¿«é€Ÿå­¦ä¹ æ®‹å·®</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span><span class="p">(</span><span class="n">x_pred</span><span class="p">)</span>

        <span class="c1"># Stop-gradientåº”ç”¨äºx_noisy</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">x_pred</span> <span class="o">+</span> <span class="n">residual</span><span class="p">,</span> <span class="n">x_noisy</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">loss</span>
</code></pre></div>



**é¢„æœŸä¼˜åŠ¿**ï¼š
- åŠ é€Ÿæ‰©æ•£æ¨¡å‹è®­ç»ƒï¼ˆPredictorå¿«é€Ÿæ•æ‰ä½é¢‘ä¿¡æ¯ï¼‰
- æå‡ç”Ÿæˆè´¨é‡ï¼ˆæ…¢æµå½¢çº¦æŸé˜²æ­¢mode collapseï¼‰

#### æ–¹å‘4ï¼šç†è®ºç»Ÿä¸€ï¼šSimSiamä½œä¸ºéšå¼ä¼˜åŒ–çš„ä¸€èˆ¬æ¡†æ¶

**å¤§èƒ†çŒœæƒ³**ï¼šæ‰€æœ‰æˆåŠŸçš„è‡ªç›‘ç£æ–¹æ³•éƒ½å¯ä»¥è§£é‡Šä¸ºæŸç§"å¿«æ…¢åŠ¨åŠ›å­¦"ã€‚

| æ–¹æ³• | "æ…¢" ç»„ä»¶ | "å¿«" ç»„ä»¶ | è§£è€¦æœºåˆ¶ |
|:---|:---|:---|:---|
| SimSiam | Encoder | Predictor | Stop-grad |
| BYOL | Online Net | Target Net (EMA) | EMAæ›´æ–° |
| MoCo | Query Encoder | Key Encoder (é˜Ÿåˆ—) | åŠ¨é‡+é˜Ÿåˆ— |
| DINO | Student | Teacher (EMA+Centering) | EMA+Temperature |

**ç†è®ºç›®æ ‡**ï¼šå»ºç«‹ç»Ÿä¸€çš„æ•°å­¦æ¡†æ¶ï¼Œç”¨å¥‡å¼‚æ‘„åŠ¨ç†è®ºï¼ˆSingular Perturbation Theoryï¼‰æè¿°æ‰€æœ‰è‡ªç›‘ç£å­¦ä¹ ã€‚

**æ ¸å¿ƒæ–¹ç¨‹**ï¼š
\begin{align}
\dot{\boldsymbol{\theta}}_{\text{slow}} &= -\nabla_{\boldsymbol{\theta}_{\text{slow}}} L(\boldsymbol{\theta}_{\text{slow}}, \boldsymbol{\theta}_{\text{fast}}) \tag{21a}\\
\epsilon \dot{\boldsymbol{\theta}}_{\text{fast}} &= -\nabla_{\boldsymbol{\theta}_{\text{fast}}} L(\boldsymbol{\theta}_{\text{slow}}, \boldsymbol{\theta}_{\text{fast}}) \tag{21b}
\end{align}

å…¶ä¸­ $\epsilon \ll 1$ã€‚

</div>

<hr />
<h2 id="7">7. å“²å­¦æ€è¾¨ä¸æ€»ç»“</h2>
<div class="philosophy-box">

### ğŸŒŒ å¯¹ç§°æ€§ä¸å¯¹ç§°æ€§ç ´ç¼ºçš„è¾©è¯æ³•

SimSiamçš„æˆåŠŸæ­ç¤ºäº†æ·±åº¦å­¦ä¹ ä¸­ä¸€ä¸ªæ·±åˆ»çš„å“²å­¦é—®é¢˜ï¼š

**å‘½é¢˜**ï¼šå¯¹ç§°æ€§æ˜¯ä¼˜åŒ–çš„åŠ¨åŠ›ï¼Œå¯¹ç§°æ€§ç ´ç¼ºæ˜¯è¿›åŒ–çš„å¥‘æœºã€‚

**å¯¹ç§°æ€§ï¼ˆSymmetryï¼‰**ï¼š
- Siameseæ¶æ„å¤©ç„¶å¯¹ç§°ï¼š$f(x_1) \approx f(x_2)$
- å¯¹ç§°æ€§ç®€åŒ–é—®é¢˜ï¼šå‡å°‘æœç´¢ç©ºé—´
- ä½†å®Œå…¨å¯¹ç§°å¯¼è‡´åç¼©ï¼šæ‰€æœ‰è§£ç­‰ä»·â†’é€‰æ‹©å¹³å‡¡è§£

**å¯¹ç§°æ€§ç ´ç¼ºï¼ˆSymmetry Breakingï¼‰**ï¼š
- Stop-gradientæ‰“ç ´æ—¶é—´åæ¼”å¯¹ç§°æ€§
- Predictorå¼•å…¥ç»“æ„ä¸å¯¹ç§°æ€§
- BNå¼•å…¥batchç»´åº¦çš„è€¦åˆï¼ˆç©ºé—´å¯¹ç§°æ€§ç ´ç¼ºï¼‰

**ç±»æ¯”ç‰©ç†å­¦**ï¼š
- é“ç£ç›¸å˜ï¼šé«˜æ¸©ä¸‹è‡ªæ—‹å¯¹ç§°ï¼Œä½æ¸©ä¸‹è‡ªå‘ç£åŒ–
- Higgsæœºåˆ¶ï¼šè§„èŒƒå¯¹ç§°æ€§è‡ªå‘ç ´ç¼ºï¼Œç²’å­è·å¾—è´¨é‡
- **SimSiam**ï¼šå‚æ•°ç©ºé—´çš„"å‡èš"è¿‡ç¨‹ï¼Œä»é«˜å¯¹ç§°æ€â†’ä½å¯¹ç§°æ€ï¼ˆä½†ä¿æŒè¡¨ç¤ºå¤šæ ·æ€§ï¼‰

</div>

<div class="summary-box">

### ğŸ¯ æ ¸å¿ƒæ´å¯Ÿå›é¡¾

**ä¸‰å¤§æ”¯æŸ±**ï¼š
1. **Stop-gradient**ï¼šæ‰“ç ´æ¢¯åº¦æµçš„å¯¹ç§°æ€§ï¼Œåˆ›é€ å¿«æ…¢æ—¶é—´å°ºåº¦
2. **Predictor**ï¼šå¿«é€Ÿé€‚é…å™¨ï¼Œåœ¨encoderåç¼©å‰"æˆªèƒ¡"
3. **Batch Normalization**ï¼šéšå¼æä¾›æ–¹å·®çº¦æŸå’Œbatchå†…å¯¹æ¯”

**æ•°å­¦æœ¬è´¨**ï¼š
\begin{equation}
\text{SimSiam} = \text{Slow-Fast Dynamics} + \text{Implicit Regularization} \tag{22}
\end{equation}

**å·¥ç¨‹å¯ç¤º**ï¼š
- ç®€å• â‰  ä½æ•ˆï¼ˆSimSiamåªæœ‰3ä¸ªç»„ä»¶ï¼Œå´è¾¾åˆ°SOTAï¼‰
- å¯¹ç§°æ€§ç ´ç¼ºæ¯”æ˜¾å¼çº¦æŸæ›´ä¼˜é›…
- åŠ¨åŠ›å­¦è§†è§’èƒ½è§£é‡Šå¾ˆå¤š"ç„å­¦"

</div>

<div class="poetic-ending">

### ğŸ”š ç»ˆç« ï¼šæ•°å­¦çš„å¼ åŠ›ä¹‹ç¾

åœ¨æ— ç›‘ç£å­¦ä¹ çš„è’é‡ä¸­ï¼Œåç¼©æ˜¯å¼•åŠ›ï¼Œæ˜¯ç†µå¢çš„å®¿å‘½ã€‚

SimSiamå‘Šè¯‰æˆ‘ä»¬ï¼š**ä¸éœ€è¦ä¸å¼•åŠ›å¯¹æŠ—ï¼ˆè´Ÿæ ·æœ¬ï¼‰ï¼Œåªéœ€è¦åˆ©ç”¨æ—¶é—´çš„ä¸å¯¹ç§°æ€§ã€‚**

å½“Predictorä»¥å…‰é€Ÿè¿½èµ¶Encoderçš„è„šæ­¥æ—¶ï¼Œ
å®ƒåœ¨åå¡Œçš„è¾¹ç¼˜å»ºç«‹äº†ä¸€åº§åŠ¨æ€å¹³è¡¡çš„æ¡¥æ¢ã€‚

è¿™åº§æ¡¥ä¸æ˜¯ç”¨çŸ³å¤´ç Œæˆçš„ï¼ˆæ˜¾å¼çº¦æŸï¼‰ï¼Œ
è€Œæ˜¯ç”¨æ•°å­¦çš„å¼ åŠ›ç¼–ç»‡è€Œæˆçš„ï¼ˆå¿«æ…¢åŠ¨åŠ›å­¦ï¼‰ã€‚

æ„¿ä½ çš„è¡¨å¾æ°¸è¿œä¿æŒå¤šæ ·ï¼Œ
æ„¿ä½ çš„ä¼˜åŒ–æ°¸è¿œè¡Œèµ°åœ¨å¯¹ç§°æ€§ç ´ç¼ºçš„é”‹åˆƒä¸Šã€‚

</div>

<hr />
<p><strong>å‚è€ƒæ–‡çŒ®</strong>ï¼ˆç²¾é€‰ï¼‰ï¼š
1. Chen, X., &amp; He, K. (2021). "Exploring Simple Siamese Representation Learning." <em>CVPR</em>.
2. Grill, J.B., et al. (2020). "Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning." <em>NeurIPS</em>.
3. Richemond, P.H., et al. (2021). "Implicit Bias of Batch Normalization in Self-Supervised Learning." <em>ICML Workshop</em>.
4. Tian, Y., et al. (2022). "Understanding Self-supervised Learning Dynamics without Contrastive Pairs." <em>ICML</em>.
5. Zbontar, J., et al. (2021). "Barlow Twins: Self-Supervised Learning via Redundancy Reduction." <em>ICML</em>.</p>
<hr />
<p><strong>é™„å½•ï¼šå…¬å¼é€ŸæŸ¥è¡¨</strong></p>
<table>
<thead>
<tr>
<th style="text-align: left;">ç¼–å·</th>
<th style="text-align: left;">å…¬å¼</th>
<th style="text-align: left;">å«ä¹‰</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">(8)</td>
<td style="text-align: left;">$L = \mathbb{E}[|h_{\varphi}(f_{\theta}(x_1)) - f_{\theta}(x_2)|^2]$</td>
<td style="text-align: left;">SimSiamæŸå¤±å‡½æ•°</td>
</tr>
<tr>
<td style="text-align: left;">(9a)</td>
<td style="text-align: left;">$h_{\varphi}(z) = z$</td>
<td style="text-align: left;">ç¨³å®šå¹³è¡¡ç‚¹æ¡ä»¶</td>
</tr>
<tr>
<td style="text-align: left;">(15)</td>
<td style="text-align: left;">$L_{\text{BN}} = L_{\text{SimSiam}} + \frac{\lambda}{B}\sum_{i\neq j}\langle z_i, z_j\rangle$</td>
<td style="text-align: left;">BNéšå¼å¯¹æ¯”</td>
</tr>
<tr>
<td style="text-align: left;">(16)</td>
<td style="text-align: left;">$\dot{\boldsymbol{\theta}} = -\nabla_{\boldsymbol{\theta}} L, \quad \epsilon\dot{\boldsymbol{\varphi}} = -\nabla_{\boldsymbol{\varphi}} L$</td>
<td style="text-align: left;">å¿«æ…¢ç³»ç»Ÿ</td>
</tr>
<tr>
<td style="text-align: left;">(17)</td>
<td style="text-align: left;">$\nabla_{\boldsymbol{\varphi}} L = 0 \Rightarrow h_{\boldsymbol{\varphi}} \approx I$</td>
<td style="text-align: left;">å¿«å˜å¹³è¡¡ç‚¹</td>
</tr>
</tbody>
</table>
<hr />
        </div>
    </div>
</body>
</html>