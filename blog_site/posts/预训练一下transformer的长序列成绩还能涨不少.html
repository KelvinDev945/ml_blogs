<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>é¢„è®­ç»ƒä¸€ä¸‹ï¼ŒTransformerçš„é•¿åºåˆ—æˆç»©è¿˜èƒ½æ¶¨ä¸å°‘ï¼</title>
    <style>
* { margin: 0; padding: 0; box-sizing: border-box; }
body {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
    line-height: 1.6; color: #333; max-width: 900px; margin: 0 auto; padding: 20px; background: #f5f5f5;
}
.container { background: white; padding: 40px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
header { border-bottom: 2px solid #e0e0e0; padding-bottom: 20px; margin-bottom: 30px; }
h1 { color: #2c3e50; margin-bottom: 10px; font-size: 2em; }
.meta { color: #666; font-size: 0.9em; margin-bottom: 20px; }
.content { margin-top: 30px; overflow-wrap: break-word; }
.content h2 { color: #34495e; margin-top: 30px; margin-bottom: 15px; border-bottom: 1px solid #eee; padding-bottom: 5px; }
.content p { margin-bottom: 15px; }
.content pre { background: #f8f8f8; padding: 15px; border-radius: 5px; overflow-x: auto; border-left: 3px solid #3498db; margin: 15px 0; }
.content code { background: #f8f8f8; padding: 2px 5px; border-radius: 3px; font-family: monospace; font-size: 0.9em; }
.content blockquote { border-left: 4px solid #3498db; padding-left: 20px; margin: 20px 0; color: #555; font-style: italic; }
.content table { border-collapse: collapse; width: 100%; margin: 20px 0; }
.content th, .content td { border: 1px solid #ddd; padding: 10px; text-align: left; }
.back-link { display: inline-block; margin-bottom: 20px; color: #3498db; text-decoration: none; font-weight: 500; }
</style>
    
<script>
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\(', '\)']],
            displayMath: [['$$', '$$'], ['\[', '\]']],
            processEscapes: true
        }
    };
</script>
<script id="MathJax-script" async src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>
    <div class="container">
        <a href="../index.html" class="back-link">â† è¿”å›é¦–é¡µ</a>
        <header>
            <h1>é¢„è®­ç»ƒä¸€ä¸‹ï¼ŒTransformerçš„é•¿åºåˆ—æˆç»©è¿˜èƒ½æ¶¨ä¸å°‘ï¼</h1>
            <div class="meta">ğŸ“… æœ€åæ›´æ–°: 2025-11-26 | ğŸ“„ å¤§å°: 23.2 KB</div>
        </header>
        <div class="content">
            <p><strong>åŸæ–‡é“¾æ¥</strong>: <a href="https://spaces.ac.cn/archives/9787">https://spaces.ac.cn/archives/9787</a></p>
<p><strong>å‘å¸ƒæ—¥æœŸ</strong>: </p>
<hr />
<p>ä½œä¸ºLLMçš„ä¸»æµæ¨¡å‹æ¶æ„ï¼ŒTransformeråœ¨å„ç±»ä»»åŠ¡ä¸Šçš„æ€»ä½“è¡¨ç°éƒ½å‡ºè‰²ï¼Œå¤§å¤šæ•°æƒ…å†µä¸‹ï¼ŒTransformerçš„æ§½ç‚¹åªæ˜¯å®ƒçš„å¹³æ–¹å¤æ‚åº¦ï¼Œè€Œä¸æ˜¯æ•ˆæœâ€”â€”é™¤äº†ä¸€ä¸ªåä¸ºLong Range Arenaï¼ˆä¸‹é¢ç®€ç§°LRAï¼‰çš„Benchmarkã€‚ä¸€ç›´ä»¥æ¥ï¼ŒLRAä¸€ç›´æ˜¯çº¿æ€§RNNç±»æ¨¡å‹çš„â€œä¸»åœºâ€ï¼Œä¸ä¹‹ç›¸æ¯”Transformeråœ¨ä¸Šé¢æœ‰æ˜æ˜¾çš„å·®è·ï¼Œä»¥è‡³äºè®©äººæ€€ç–‘è¿™æ˜¯å¦å°±æ˜¯Transformerçš„å›ºæœ‰ç¼ºé™·ã€‚</p>
<p>ä¸è¿‡ï¼Œè¿‘æ—¥è®ºæ–‡<a href="https://papers.cool/arxiv/2310.02980">ã€ŠNever Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priorsã€‹</a>å°†è¿™â€œç¼ºå¤±çš„ä¸€ç¯â€ç»™è¡¥é½äº†ã€‚è®ºæ–‡æŒ‡å‡ºï¼Œç¼ºä¹é¢„è®­ç»ƒæ˜¯Transformeråœ¨LRAä¸Šæ•ˆæœè¾ƒå·®çš„ä¸»è¦åŸå› ï¼Œè€Œæ‰€æœ‰æ¶æ„éƒ½å¯ä»¥é€šè¿‡é¢„è®­ç»ƒè·å¾—ä¸€å®šçš„æå‡ï¼ŒTransformerçš„æå‡åˆ™æ›´ä¸ºæ˜æ˜¾ã€‚</p>
<h2 id="_1">æ—§èƒŒæ™¯</h2>
<p>Long Range Arenaï¼ˆLRAï¼‰æ˜¯é•¿åºåˆ—å»ºæ¨¡çš„ä¸€ä¸ªBenchmarkï¼Œæå‡ºè‡ªè®ºæ–‡<a href="https://papers.cool/arxiv/2011.04006">ã€ŠLong Range Arena: A Benchmark for Efficient Transformersã€‹</a>ï¼Œä»è®ºæ–‡æ ‡é¢˜å°±å¯ä»¥çœ‹å‡ºï¼ŒLRAæ˜¯ä¸ºäº†æµ‹è¯•å„ç§Efficientç‰ˆçš„Transformerè€Œæ„å»ºçš„ï¼Œé‡Œè¾¹åŒ…å«äº†å¤šç§ç±»å‹çš„æ•°æ®ï¼Œåºåˆ—é•¿åº¦ä»1kåˆ°16kä¸ç­‰ï¼Œæ­¤å‰ä¸å°‘Efficient Transformerçš„å·¥ä½œä¹Ÿéƒ½åœ¨LRAè¿›è¡Œäº†æµ‹è¯•ã€‚è™½ç„¶åœ¨ä»£è¡¨æ€§æ–¹é¢æœ‰äº›äº‰è®®ï¼Œä½†LRAä¾ç„¶ä¸å¤±ä¸ºä¸€ä¸ªæµ‹è¯•Efficient Transformerçš„é•¿åºåˆ—èƒ½åŠ›çš„ç»å…¸Benchmarkã€‚</p>
<p><a href="/usr/uploads/2023/10/3692059662.png" title="ç‚¹å‡»æŸ¥çœ‹åŸå›¾"><img alt="MEGAè®ºæ–‡ä¸­çš„LRAç»“æœ" src="/usr/uploads/2023/10/3692059662.png" /></a></p>
<p>MEGAè®ºæ–‡ä¸­çš„LRAç»“æœ</p>
<p>å¯èƒ½ä¼šè®©éƒ¨åˆ†è¯»è€…æ„å¤–çš„æ˜¯ï¼Œæ ‡å‡†çš„Transformerï¼ˆXFMï¼‰åœ¨è¿™ä¸ªBenchmarkä¸Šçš„æˆç»©å¹¶ä¸å‡ºè‰²ï¼Œæ˜æ˜¾è½åäºä¸€ç³»åˆ—çº¿æ€§RNNç±»æ¨¡å‹ï¼Œæ¯”å¦‚ç»å…¸çš„SSMï¼ˆ<a href="https://papers.cool/arxiv/2111.00396">S4</a>ã€<a href="https://papers.cool/arxiv/2203.14343">S4D</a>ã€<a href="https://papers.cool/arxiv/2208.04933">S5</a>ï¼‰æˆ–è€…æ­¤å‰æˆ‘ä»¬ä»‹ç»è¿‡çš„<a href="/archives/9554">LRU</a>ï¼Œç”šè‡³äºæ­¤å‰çš„SOTAæ¨¡å‹<a href="https://papers.cool/arxiv/2209.10655">MEGA</a>ï¼Œä¹Ÿéœ€è¦åœ¨<a href="/archives/8934">GAU</a>çš„åŸºç¡€ä¸Šè£…å¤‡çº¿æ€§RNNæ¨¡å—ï¼ˆè®ºæ–‡é‡Œè¾¹ç§°ä¸ºEMAï¼‰ã€‚æ€»è€Œè¨€ä¹‹ï¼Œæ­¤å‰LRAä¸Šçš„æ¨¡å‹æ’è¡Œæƒ…å†µï¼Œå¼ºçƒˆåœ°é€éœ²ç€â€œAttentionå¯ä»¥æœ‰ï¼Œä½†RNNå¿…ä¸å¯å°‘â€çš„ä¿¡å·ã€‚</p>
<p><strong>ï¼ˆæ³¨ï¼šLRAçš„å®Œæ•´æˆç»©æ’è¡Œå¯ä»¥åœ¨<a href="https://paperswithcode.com/sota/long-range-modeling-on-lra">https://paperswithcode.com/sota/long-range-modeling-on-lra</a> æŸ¥é˜…ã€‚ï¼‰</strong></p>
<h2 id="_2">æ–°ç»“è®º</h2>
<p>å¾ˆæ˜æ˜¾ï¼Œ<a href="https://papers.cool/arxiv/2310.02980">ã€ŠNever Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priorsã€‹</a>çš„å‡ºç°æ‰“ç ´äº†è¿™ä¸€å°è±¡ï¼Œå®ƒæŒ‡å‡ºç”¨è®­ç»ƒé›†é¢„è®­ç»ƒå°±å¯ä»¥å¤§å¤§ç¼©å°ä¸¤è€…çš„å·®è·ï¼Œå¹¶è¿›ä¸€æ­¥æå‡ºâ€œæ— é¢„è®­ç»ƒï¼Œä¸å…¬å¹³â€çš„è§‚ç‚¹ã€‚</p>
<p><a href="/usr/uploads/2023/10/1358414937.png" title="ç‚¹å‡»æŸ¥çœ‹åŸå›¾"><img alt="â€œTransformer+é¢„è®­ç»ƒâ€ç›¸æ¯”äºTransformeråŠå„ç§Effectiveç‰ˆçš„æå‡" src="/usr/uploads/2023/10/1358414937.png" /></a></p>
<p>â€œTransformer+é¢„è®­ç»ƒâ€ç›¸æ¯”äºTransformeråŠå„ç§Effectiveç‰ˆçš„æå‡</p>
<p>é¢„è®­ç»ƒçš„åšæ³•å¾ˆç®€å•ï¼Œä»»åŠ¡é€‰æ‹©MLMæˆ–è€…GPTéƒ½å¯ä»¥ï¼Œæ•°æ®é›†åˆ™è¿˜æ˜¯åŸæœ¬çš„è®­ç»ƒé›†ï¼Œè¿™æ ·ä¸€æ¥é™¤äº†å¢åŠ äº†ç®—åŠ›æ¶ˆè€—å¤–ï¼Œå¹¶æ²¡æœ‰å¼•å…¥é¢å¤–çš„çŸ¥è¯†æ¥æºï¼Œæ‰€ä»¥æ¯”è¾ƒæ˜¯å…¬å¹³çš„ã€‚äº‹å®ä¸Šï¼Œä¸ç®¡æ˜¯Transformerè¿˜æ˜¯RNNï¼Œç»è¿‡é¢„è®­ç»ƒä¹‹åéƒ½èƒ½è·å¾—æ˜æ˜¾çš„æå‡ï¼Œåªä¸è¿‡Transformerçš„æå‡æ›´åŠ æ˜æ˜¾ï¼š  </p>
<p><a href="/usr/uploads/2023/10/546916399.png" title="ç‚¹å‡»æŸ¥çœ‹åŸå›¾"><img alt="â€œTransformer+é¢„è®­ç»ƒâ€ä¸â€œS4+é¢„è®­ç»ƒâ€" src="/usr/uploads/2023/10/546916399.png" /></a></p>
<p>â€œTransformer+é¢„è®­ç»ƒâ€ä¸â€œS4+é¢„è®­ç»ƒâ€</p>
<p><a href="/usr/uploads/2023/10/476588374.png" title="ç‚¹å‡»æŸ¥çœ‹åŸå›¾"><img alt="ä¸SOTAæ¨¡å‹çš„å¯¹æ¯”" src="/usr/uploads/2023/10/476588374.png" /></a></p>
<p>ä¸SOTAæ¨¡å‹çš„å¯¹æ¯”</p>
<p>äº‹åæ¥çœ‹ï¼Œè®ºæ–‡çš„ç»“è®ºå¹¶ä¸è®©äººæ„å¤–ï¼Œç”šè‡³æœ‰ç‚¹â€œæ˜¾ç„¶æˆç«‹â€çš„æ„Ÿè§‰ï¼Œä½†æ­¤å‰å¤§å®¶ä¼¼ä¹éƒ½æ²¡å¾€è¿™ä¸ªæ–¹å‘å»æƒ³ï¼ˆæˆ–è€…æ˜¯æƒ³åˆ°äº†ä½†è§‰å¾—ä¸æ˜¯å…³é”®ï¼Ÿï¼‰ï¼Œæ‰€ä»¥ä½œè€…ä»¬é¦–å…ˆæ„è¯†åˆ°å¹¶è¯æ˜é¢„è®­ç»ƒåœ¨LRAçš„é‡è¦æ€§ï¼Œä¾ç„¶æ˜¯éå¸¸å€¼å¾—ç§°èµçš„ã€‚</p>
<p>é¢„è®­ç»ƒçš„é‡è¦æ€§å®é™…ä¸Šè¡¨æ˜äº†Inductive Biasåœ¨LRAä¸Šçš„é‡è¦æ€§ï¼Œå› ä¸ºLRAä¸ºäº†ä½¿å¾—åºåˆ—è¶³å¤ŸLongï¼Œå®ƒçš„tokené¢—ç²’åº¦æ˜¯éå¸¸ç»†çš„ï¼Œæ¯”å¦‚æ–‡æœ¬ä»»åŠ¡æ˜¯ä»¥å­—æ¯ä¸ºtokençš„ï¼Œå›¾åƒä»»åŠ¡æ˜¯ä»¥åƒç´ ä¸ºtokenå¹¶ç›´æ¥å°†äºŒç»´å›¾åƒå±•å¹³ä¸ºä¸€ç»´åºåˆ—çš„ï¼Œå¾ˆæ˜æ˜¾è¿™äº›ä»»åŠ¡æ—¢éœ€è¦è¿œç¨‹ä¾èµ–ï¼Œåˆæœ‰æ˜æ˜¾çš„å±€åŸŸæ€§ï¼Œçº¿æ€§RNNæ­£å¥½éå¸¸è´´åˆå®ƒçš„ç‰¹æ€§ã€‚è€ŒTransformerç›¸å¯¹æ¥è¯´æ²¡æœ‰é‚£ä¹ˆæ˜æ˜¾çš„Inductive Biasï¼Œå®ƒè¿˜éœ€è¦é¢å¤–åŠ ä½ç½®ç¼–ç æ‰æœ‰ä½ç½®ä¿¡æ¯ï¼Œè€Œå³ä¾¿åŠ äº†ä¹Ÿæ²¡æœ‰æ˜¾è‘—çš„å±€åŸŸæ€§ï¼Œå› æ­¤æ›´éœ€è¦é¢„è®­ç»ƒæ¥é€‚åº”æ•°æ®ç‰¹æ€§ï¼Œæˆ–è€…è¯´ï¼Œé€šè¿‡é¢„è®­ç»ƒæ¥è¡¥å……Inductive Biasã€‚</p>
<h2 id="_3">å…¨å‰§ç»ˆ</h2>
<p>æœ¬æ–‡è·Ÿå¤§å®¶å¿«é€Ÿåˆ†äº«äº†ä¸€ä¸ªè¾ƒæ–°çš„å®éªŒç»“è®ºï¼Œå³é¢„è®­ç»ƒèƒ½æœ‰æ•ˆæé«˜å„ç§æ¨¡å‹åœ¨LRAä¸Šçš„æˆç»©ï¼Œå°¤å…¶æ˜¯Transformerç»è¿‡é¢„è®­ç»ƒä¹‹åï¼Œæ•ˆæœåŸºæœ¬ä¸Šä¹Ÿèƒ½æ¥è¿‘SOTAæ¢¯é˜Ÿï¼Œè¿™æ‰“ç ´äº†ç¬”è€…ä¸€ç›´ä»¥æ¥LRAå¿…é¡»è¦åŠ çº¿æ€§RNNçš„å°è±¡ã€‚</p>
<p><em><strong>è½¬è½½åˆ°è¯·åŒ…æ‹¬æœ¬æ–‡åœ°å€ï¼š</strong><a href="https://spaces.ac.cn/archives/9787">https://spaces.ac.cn/archives/9787</a></em></p>
<p><em><strong>æ›´è¯¦ç»†çš„è½¬è½½äº‹å®œè¯·å‚è€ƒï¼š</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="ã€Šç§‘å­¦ç©ºé—´FAQã€‹">ã€Šç§‘å­¦ç©ºé—´FAQã€‹</a></p>
<p><strong>å¦‚æœæ‚¨è¿˜æœ‰ä»€ä¹ˆç–‘æƒ‘æˆ–å»ºè®®ï¼Œæ¬¢è¿åœ¨ä¸‹æ–¹è¯„è®ºåŒºç»§ç»­è®¨è®ºã€‚</strong></p>
<p><strong>å¦‚æœæ‚¨è§‰å¾—æœ¬æ–‡è¿˜ä¸é”™ï¼Œæ¬¢è¿åˆ†äº«/æ‰“èµæœ¬æ–‡ã€‚æ‰“èµå¹¶éè¦ä»ä¸­è·å¾—æ”¶ç›Šï¼Œè€Œæ˜¯å¸Œæœ›çŸ¥é“ç§‘å­¦ç©ºé—´è·å¾—äº†å¤šå°‘è¯»è€…çš„çœŸå¿ƒå…³æ³¨ã€‚å½“ç„¶ï¼Œå¦‚æœä½ æ— è§†å®ƒï¼Œä¹Ÿä¸ä¼šå½±å“ä½ çš„é˜…è¯»ã€‚å†æ¬¡è¡¨ç¤ºæ¬¢è¿å’Œæ„Ÿè°¢ï¼</strong></p>
<p>æ‰“èµ</p>
<p><img alt="ç§‘å­¦ç©ºé—´" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>å¾®ä¿¡æ‰“èµ</p>
<p><img alt="ç§‘å­¦ç©ºé—´" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>æ”¯ä»˜å®æ‰“èµ</p>
<p>å› ä¸ºç½‘ç«™åå°å¯¹æ‰“èµå¹¶æ— è®°å½•ï¼Œå› æ­¤æ¬¢è¿åœ¨æ‰“èµæ—¶å€™å¤‡æ³¨ç•™è¨€ã€‚ä½ è¿˜å¯ä»¥<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>ç‚¹å‡»è¿™é‡Œ</strong></a>æˆ–åœ¨ä¸‹æ–¹è¯„è®ºåŒºç•™è¨€æ¥å‘ŠçŸ¥ä½ çš„å»ºè®®æˆ–éœ€æ±‚ã€‚</p>
<p><strong>å¦‚æœæ‚¨éœ€è¦å¼•ç”¨æœ¬æ–‡ï¼Œè¯·å‚è€ƒï¼š</strong></p>
<p>è‹å‰‘æ—. (Oct. 08, 2023). ã€Šé¢„è®­ç»ƒä¸€ä¸‹ï¼ŒTransformerçš„é•¿åºåˆ—æˆç»©è¿˜èƒ½æ¶¨ä¸å°‘ï¼ ã€‹[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/9787">https://spaces.ac.cn/archives/9787</a></p>
<p>@online{kexuefm-9787,<br />
title={é¢„è®­ç»ƒä¸€ä¸‹ï¼ŒTransformerçš„é•¿åºåˆ—æˆç»©è¿˜èƒ½æ¶¨ä¸å°‘ï¼},<br />
author={è‹å‰‘æ—},<br />
year={2023},<br />
month={Oct},<br />
url={\url{https://spaces.ac.cn/archives/9787}},<br />
} </p>
<hr />
<h2 id="_4">å…¬å¼æ¨å¯¼ä¸æ³¨é‡Š</h2>
<h3 id="transformer">ä¸€ã€Transformeré•¿åºåˆ—å»ºæ¨¡çš„æ•°å­¦åŸºç¡€</h3>
<h4 id="11">1.1 é•¿åºåˆ—çš„å¤æ‚åº¦é—®é¢˜</h4>
<p>æ ‡å‡†Transformerçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„æ—¶é—´å’Œç©ºé—´å¤æ‚åº¦ä¸ºï¼š</p>
<p>\begin{equation}
\text{Time}(\text{Attention}) = \mathcal{O}(L^2 d)
\tag{1}
\end{equation}</p>
<p>\begin{equation}
\text{Space}(\text{Attention}) = \mathcal{O}(L^2)
\tag{2}
\end{equation}</p>
<p>å…¶ä¸­ $L$ æ˜¯åºåˆ—é•¿åº¦ï¼Œ$d$ æ˜¯æ¨¡å‹ç»´åº¦ã€‚</p>
<p><strong>ç“¶é¢ˆåˆ†æ</strong>: å½“ $L$ ä»2Kå¢åŠ åˆ°16Kæ—¶ï¼š</p>
<p>\begin{equation}
\frac{\text{Cost}<em L="2K">{L=16K}}{\text{Cost}</em>\right)^2 = 64
\tag{3}
\end{equation}}} = \left(\frac{16K}{2K</p>
<p>è®¡ç®—å’Œå†…å­˜å¼€é”€å¢åŠ 64å€ï¼</p>
<h4 id="12">1.2 é•¿åºåˆ—çš„ä½ç½®ç¼–ç æŒ‘æˆ˜</h4>
<p><strong>é—®é¢˜1: å¤–æ¨å¤±è´¥</strong> - è®­ç»ƒé•¿åº¦ $L_{\text{train}}$ï¼Œæµ‹è¯•é•¿åº¦ $L_{\text{test}} &gt; L_{\text{train}}$ï¼š</p>
<p>å¯¹äºç»å¯¹ä½ç½®ç¼–ç ï¼š</p>
<p>\begin{equation}
\boldsymbol{x}_i' = \boldsymbol{x}_i + \boldsymbol{PE}(i)
\tag{4}
\end{equation}</p>
<p>å½“ $i &gt; L_{\text{train}}$ æ—¶ï¼Œ$\boldsymbol{PE}(i)$ æ˜¯æ¨¡å‹ä»æœªè§è¿‡çš„ï¼Œå¯¼è‡´æ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚</p>
<p><strong>é—®é¢˜2: è¿œç¨‹ä¾èµ–è¡°å‡</strong> - Softmaxçš„å½’ä¸€åŒ–æ•ˆåº”ï¼š</p>
<p>\begin{equation}
\alpha_{i,j} = \frac{\exp(s_{i,j})}{\sum_{k=1}^{L} \exp(s_{i,k})}
\tag{5}
\end{equation}</p>
<p>å½“ $L$ å¾ˆå¤§æ—¶ï¼Œæ¯ä¸ªä½ç½®åˆ†é…åˆ°çš„æ³¨æ„åŠ›æƒé‡è¢«ç¨€é‡Šï¼š</p>
<p>\begin{equation}
\mathbb{E}[\alpha_{i,j}] = \frac{1}{L}
\tag{6}
\end{equation}</p>
<p><strong>æ•°å€¼ç¤ºä¾‹</strong>: $L=2048$ vs $L=16384$:</p>
<p>\begin{equation}
\frac{\mathbb{E}[\alpha_{i,j}]<em i_j="i,j">{L=16K}}{\mathbb{E}[\alpha</em>
\tag{7}
\end{equation}}]_{L=2K}} = \frac{1/16384}{1/2048} = \frac{1}{8</p>
<p>æ¯ä¸ªtokençš„æ³¨æ„åŠ›é™ä½åˆ°åŸæ¥çš„1/8ã€‚</p>
<h3 id="_5">äºŒã€é¢„è®­ç»ƒå¯¹é•¿åºåˆ—çš„æ•°å­¦ä½œç”¨</h3>
<h4 id="21-inductive-bias">2.1 Inductive Biasçš„æ•°å­¦å®šä¹‰</h4>
<p><strong>å®šä¹‰</strong>: Inductive Biasæ˜¯æ¨¡å‹å‡è®¾ç©ºé—´çš„å…ˆéªŒçº¦æŸã€‚</p>
<p>å¯¹äºå‡½æ•°ç©ºé—´ $\mathcal{F}$ï¼ŒInductive Bias $\mathcal{B}$ é™åˆ¶äº†å¯å­¦ä¹ çš„å‡½æ•°ï¼š</p>
<p>\begin{equation}
f \in \mathcal{F}_{\mathcal{B}} \subset \mathcal{F}
\tag{8}
\end{equation}</p>
<h4 id="22-inductive-bias">2.2 é¢„è®­ç»ƒä½œä¸ºInductive Biasæ³¨å…¥</h4>
<p><strong>æ— é¢„è®­ç»ƒ</strong>: æ¨¡å‹ä»éšæœºåˆå§‹åŒ–å¼€å§‹ï¼Œ$\mathcal{F}_{\text{random}}$ å¾ˆå¤§ã€‚</p>
<p><strong>æœ‰é¢„è®­ç»ƒ</strong>: æ¨¡å‹ä»é¢„è®­ç»ƒæƒé‡å¼€å§‹ï¼Œ$\mathcal{F}_{\text{pretrain}}$ æ›´èšç„¦ã€‚</p>
<p>\begin{equation}
\mathcal{F}<em _text_random="\text{random">{\text{pretrain}} \subset \mathcal{F}</em>
\tag{9}
\end{equation}}</p>
<p><strong>æ•°å­¦ç›´è§‰</strong>: é¢„è®­ç»ƒåœ¨æ•°æ®çš„ç‰¹å®šæµå½¢ä¸Š"é›•åˆ»"å‡ºäº†æ¨¡å‹ï¼Œå‡å°‘äº†ä¼˜åŒ–éš¾åº¦ã€‚</p>
<h4 id="23">2.3 é•¿åºåˆ—é¢„è®­ç»ƒçš„ä¼˜åŒ–è§†è§’</h4>
<p>è€ƒè™‘æŸå¤±å‡½æ•° $\mathcal{L}(\boldsymbol{\theta}; L)$ï¼Œå…¶ä¸­ $L$ æ˜¯åºåˆ—é•¿åº¦ã€‚</p>
<p><strong>æ³›åŒ–ç•Œ</strong>: æ ¹æ®PACå­¦ä¹ ç†è®ºï¼Œæ³›åŒ–è¯¯å·®æ»¡è¶³ï¼š</p>
<p>\begin{equation}
\mathcal{L}<em _text_train="\text{train">{\text{test}} \leq \mathcal{L}</em>\right)
\tag{10}
\end{equation}}} + \mathcal{O}\left(\sqrt{\frac{d \log L}{n}</p>
<p>å…¶ä¸­ $n$ æ˜¯è®­ç»ƒæ ·æœ¬æ•°ï¼Œ$d$ æ˜¯æ¨¡å‹å¤æ‚åº¦ã€‚</p>
<p><strong>å…³é”®æ´å¯Ÿ</strong>: åœ¨é•¿åºåˆ— $L$ ä¸Šé¢„è®­ç»ƒï¼Œå¯ä»¥ç›´æ¥å‡å°ç¬¬äºŒé¡¹ï¼ˆæ³›åŒ–gapï¼‰ï¼</p>
<h4 id="24">2.4 ä½ç½®ç¼–ç çš„åˆ†å¸ƒé€‚åº”</h4>
<p><strong>åŸå§‹åˆ†å¸ƒ</strong>: è®­ç»ƒé›†ä½ç½®ç¼–ç åˆ†å¸ƒ $P_{\text{train}}(i)$ï¼Œ$i \in [1, L_{\text{train}}]$</p>
<p><strong>ç›®æ ‡åˆ†å¸ƒ</strong>: æµ‹è¯•é›†ä½ç½®ç¼–ç åˆ†å¸ƒ $P_{\text{test}}(i)$ï¼Œ$i \in [1, L_{\text{test}}]$</p>
<p>é¢„è®­ç»ƒä½¿å¾—ï¼š</p>
<p>\begin{equation}
D_{\text{KL}}(P_{\text{test}} | P_{\text{model}}) &lt; D_{\text{KL}}(P_{\text{test}} | P_{\text{random}})
\tag{11}
\end{equation}</p>
<p>å…¶ä¸­ $D_{\text{KL}}$ æ˜¯KLæ•£åº¦ã€‚</p>
<h3 id="long-range-arena-lra">ä¸‰ã€Long Range Arena (LRA) åŸºå‡†çš„æ•°å­¦åˆ†æ</h3>
<h4 id="31-lra">3.1 LRAä»»åŠ¡çš„ç‰¹å¾</h4>
<p>LRAåŒ…å«å¤šä¸ªé•¿åºåˆ—ä»»åŠ¡ï¼š
- ListOps: åºåˆ—é•¿åº¦ ~2K
- Text: å­—ç¬¦çº§æ–‡æœ¬ï¼Œé•¿åº¦ ~4K
- Retrieval: æ–‡æ¡£æ£€ç´¢ï¼Œé•¿åº¦ ~4K
- Image: åƒç´ çº§å›¾åƒï¼Œé•¿åº¦ ~1K (32Ã—32)
- PathFinder: è§†è§‰è·¯å¾„ï¼Œé•¿åº¦ ~1K
- Path-X: æ‰©å±•è·¯å¾„ï¼Œé•¿åº¦ ~16K</p>
<p><strong>å…±åŒç‰¹ç‚¹</strong>: Tokenç²’åº¦ç»†ï¼ˆå­—ç¬¦çº§ã€åƒç´ çº§ï¼‰ï¼Œéœ€è¦æ•æ‰é•¿ç¨‹ä¾èµ–ã€‚</p>
<h4 id="32">3.2 å±€åŸŸæ€§çš„æ•°å­¦åˆ»ç”»</h4>
<p><strong>å®šä¹‰</strong>: å±€åŸŸæ€§æŒ‡ç›¸é‚»ä½ç½®çš„ç›¸å…³æ€§å¼ºäºè¿œè·ç¦»ä½ç½®ã€‚</p>
<p>\begin{equation}
\text{Corr}(\boldsymbol{x}_i, \boldsymbol{x}_j) = f(|i - j|)
\tag{12}
\end{equation}</p>
<p>å…¶ä¸­ $f$ æ˜¯å•è°ƒé€’å‡å‡½æ•°ã€‚</p>
<p>å¯¹äºå­—ç¬¦çº§æ–‡æœ¬ï¼š</p>
<p>\begin{equation}
f(d) \approx \exp(-\lambda d), \quad \lambda &gt; 0
\tag{13}
\end{equation}</p>
<p><strong>æ•°å€¼ç¤ºä¾‹</strong>: ç›¸é‚»å­—ç¬¦ç›¸å…³æ€§çº¦0.8ï¼Œé—´éš”10ä¸ªå­—ç¬¦é™åˆ°0.1ã€‚</p>
<h4 id="33-rnn">3.3 çº¿æ€§RNNçš„å±€åŸŸæ€§ä¼˜åŠ¿</h4>
<p>çº¿æ€§RNN (å¦‚SSM) çš„æ›´æ–°å…¬å¼ï¼š</p>
<p>\begin{equation}
\boldsymbol{h}<em t-1="t-1">t = \boldsymbol{A} \boldsymbol{h}</em>_t
\tag{14}
\end{equation}} + \boldsymbol{B} \boldsymbol{x</p>
<p><strong>éšå¼å±€åŸŸæ€§</strong>: å½“ $\boldsymbol{A}$ çš„è°±åŠå¾„ $\rho(\boldsymbol{A}) &lt; 1$ æ—¶ï¼š</p>
<p>\begin{equation}
|\boldsymbol{h}<em k="0">t| \leq |\boldsymbol{A}|^t |\boldsymbol{h}_0| + \sum</em>|
\tag{15}
\end{equation}}^{t-1} |\boldsymbol{A}|^k |\boldsymbol{B}| |\boldsymbol{x}_{t-k</p>
<p>è¿œè·ç¦»çš„ $\boldsymbol{x}_{t-k}$ è´¡çŒ®æŒ‰ $|\boldsymbol{A}|^k$ æŒ‡æ•°è¡°å‡ï¼</p>
<h4 id="34-transformer">3.4 Transformerçš„å…¨å±€æ³¨æ„åŠ›å›°å¢ƒ</h4>
<p>Transformerçš„æ³¨æ„åŠ›æ˜¯å…¨å±€çš„ï¼Œæ²¡æœ‰å…ˆéªŒçš„å±€åŸŸæ€§åç½®ï¼š</p>
<p>\begin{equation}
\boldsymbol{o}<em j="1">i = \sum</em>_j
\tag{16}
\end{equation}}^{L} \alpha_{i,j} \boldsymbol{v</p>
<p>$\alpha_{i,j}$ åœ¨åˆå§‹åŒ–æ—¶å¯¹æ‰€æœ‰ $j$ å‡ ä¹å‡åŒ€åˆ†å¸ƒã€‚</p>
<p><strong>éœ€è¦å­¦ä¹ </strong>: æ¨¡å‹éœ€è¦ä»æ•°æ®ä¸­å­¦ä¹ å±€åŸŸæ€§æ¨¡å¼ï¼Œè€Œé¢„è®­ç»ƒæ­£æ˜¯æä¾›è¿™ç§å­¦ä¹ çš„æœºä¼šï¼</p>
<h3 id="_6">å››ã€ä½ç½®æ’å€¼çš„æ·±å…¥æ•°å­¦æ¨å¯¼</h3>
<h4 id="41">4.1 æœ´ç´ å¤–æ¨çš„å¤±è´¥åˆ†æ</h4>
<p>å¯¹äºRoPEï¼Œä½ç½® $n$ çš„ç¼–ç ï¼š</p>
<p>\begin{equation}
\boldsymbol{\mathcal{R}}<em d_2-1="d/2-1">n = \text{diag}(\boldsymbol{R}(n\theta_0), \ldots, \boldsymbol{R}(n\theta</em>))
\tag{17}
\end{equation}</p>
<p><strong>è®­ç»ƒèŒƒå›´</strong>: $n \in [0, L_{\text{train}}-1]$ï¼Œè§’åº¦èŒƒå›´ $\theta_i n \in [0, (L_{\text{train}}-1)\theta_i]$</p>
<p><strong>æµ‹è¯•èŒƒå›´</strong>: $n \in [0, L_{\text{test}}-1]$ï¼Œè§’åº¦èŒƒå›´æ‰©å¤§åˆ° $[0, (L_{\text{test}}-1)\theta_i]$</p>
<p><strong>é—®é¢˜</strong>: å¯¹äºå°çš„ $\theta_i$ (é«˜é¢‘)ï¼Œè§’åº¦è¶…å‡ºè®­ç»ƒèŒƒå›´å¯¼è‡´å¤–æ¨å¤±è´¥ã€‚</p>
<p><strong>æ•°å€¼ç¤ºä¾‹</strong>: $L_{\text{train}}=2048, L_{\text{test}}=8192, \theta_0=1$:</p>
<p>\begin{equation}
\theta_0 \cdot 8191 = 8191 \gg \theta_0 \cdot 2047 = 2047
\tag{18}
\end{equation}</p>
<p>è§’åº¦å¢åŠ äº†4å€ï¼Œå®Œå…¨è¶…å‡ºè®­ç»ƒèŒƒå›´ï¼</p>
<h4 id="42-pi">4.2 ä½ç½®æ’å€¼ (PI) çš„æ•°å­¦åŸç†</h4>
<p><strong>æ ¸å¿ƒæ€æƒ³</strong>: å°†æµ‹è¯•ä½ç½®ç¼©æ”¾åˆ°è®­ç»ƒèŒƒå›´å†…ã€‚</p>
<p>\begin{equation}
n_{\text{scaled}} = n \cdot \frac{L_{\text{train}}}{L_{\text{test}}}
\tag{19}
\end{equation}</p>
<p><strong>ç›¸å¯¹è·ç¦»ä¿æŒ</strong>: å¯¹äºä½ç½® $m, n$:</p>
<p>\begin{equation}
\frac{n_{\text{scaled}} - m_{\text{scaled}}}{L_{\text{test}}} = \frac{n - m}{L_{\text{train}}}
\tag{20}
\end{equation}</p>
<p>ç›¸å¯¹è·ç¦»çš„æ¯”ä¾‹ä¸å˜ï¼</p>
<h4 id="43-pi">4.3 PIçš„é¢‘ç‡åˆ†æ</h4>
<p>PIç­‰æ•ˆäºé™ä½æ‰€æœ‰é¢‘ç‡ï¼š</p>
<p>\begin{equation}
\theta_i \cdot n_{\text{scaled}} = \theta_i \cdot n \cdot \frac{L_{\text{train}}}{L_{\text{test}}} = \left(\theta_i \cdot \frac{L_{\text{train}}}{L_{\text{test}}}\right) \cdot n
\tag{21}
\end{equation}</p>
<p>ç­‰ä»·äºé¢‘ç‡ä» $\theta_i$ å˜ä¸º $\theta_i' = \theta_i \cdot s$ï¼Œå…¶ä¸­ $s = L_{\text{train}} / L_{\text{test}} &lt; 1$ã€‚</p>
<p><strong>ä¿¡æ¯æŸå¤±</strong>: æ‰€æœ‰é¢‘ç‡ç»Ÿä¸€é™ä½ï¼Œé«˜é¢‘ä¿¡æ¯è¢«å‹ç¼©ã€‚</p>
<h4 id="44-pi">4.4 PIçš„ç†è®ºä¿è¯</h4>
<p><strong>å®šç†</strong>: å¦‚æœè®­ç»ƒæ—¶æ¨¡å‹å­¦ä¹ åˆ°äº†ç›¸å¯¹ä½ç½®æ¨¡å¼ï¼ŒPIä¿æŒè¿™äº›æ¨¡å¼ã€‚</p>
<p><strong>è¯æ˜</strong>: RoPEçš„å†…ç§¯å½¢å¼ï¼š</p>
<p>\begin{equation}
(\boldsymbol{\mathcal{R}}<em n-m="n-m">m \boldsymbol{q})^\top (\boldsymbol{\mathcal{R}}_n \boldsymbol{k}) = \boldsymbol{q}^\top \boldsymbol{\mathcal{R}}</em>
\tag{22}
\end{equation}} \boldsymbol{k</p>
<p>PIåï¼š</p>
<p>\begin{equation}
(\boldsymbol{\mathcal{R}}<em ns="ns">{ms} \boldsymbol{q})^\top (\boldsymbol{\mathcal{R}}</em>
\tag{23}
\end{equation}} \boldsymbol{k}) = \boldsymbol{q}^\top \boldsymbol{\mathcal{R}}_{(n-m)s} \boldsymbol{k</p>
<p>ç›¸å¯¹ä½ç½® $(n-m)$ ç¼©æ”¾äº†ç›¸åŒå› å­ $s$ï¼Œæ¨¡å¼ä¿æŒï¼â–¡</p>
<h3 id="_7">äº”ã€æ³¨æ„åŠ›ç¨€ç–åŒ–çš„æ•°å­¦ç­–ç•¥</h3>
<h4 id="51">5.1 æ»‘åŠ¨çª—å£æ³¨æ„åŠ›</h4>
<p><strong>å®šä¹‰</strong>: æ¯ä¸ªä½ç½®åªå…³æ³¨å±€éƒ¨çª—å£å†…çš„tokenã€‚</p>
<p>\begin{equation}
\alpha_{i,j} = \begin{cases}
\frac{\exp(s_{i,j})}{\sum_{k \in W_i} \exp(s_{i,k})}, &amp; j \in W_i \
0, &amp; \text{otherwise}
\end{cases}
\tag{24}
\end{equation}</p>
<p>å…¶ä¸­çª—å£ $W_i = {j : |i - j| \leq w}$ï¼Œ$w$ æ˜¯çª—å£å¤§å°ã€‚</p>
<p><strong>å¤æ‚åº¦é™ä½</strong>:</p>
<p>\begin{equation}
\text{Time} = \mathcal{O}(Lwd) = \mathcal{O}(Ld) \quad (w \ll L)
\tag{25}
\end{equation}</p>
<p>ä» $\mathcal{O}(L^2d)$ é™ä¸º $\mathcal{O}(Ld)$ï¼Œçº¿æ€§å¤æ‚åº¦ï¼</p>
<h4 id="52-longformer">5.2 Longformerçš„è†¨èƒ€çª—å£</h4>
<p><strong>ç»„åˆç­–ç•¥</strong>: å±€éƒ¨çª—å£ + å…¨å±€token + è†¨èƒ€æ³¨æ„åŠ›</p>
<p>\begin{equation}
\text{Attention Pattern} = W_{\text{local}} \cup G_{\text{global}} \cup W_{\text{dilated}}
\tag{26}
\end{equation}</p>
<p>å…¶ä¸­ï¼š
- $W_{\text{local}}$: æ»‘åŠ¨çª—å£ï¼Œ$|W_{\text{local}}| = 2w$
- $G_{\text{global}}$: å…¨å±€token (å¦‚[CLS])ï¼Œ$|G_{\text{global}}| = g$
- $W_{\text{dilated}}$: è†¨èƒ€çª—å£ï¼Œé—´éš” $r$ é‡‡æ ·</p>
<p><strong>æœ‰æ•ˆæ„Ÿå—é‡</strong>: ç»è¿‡ $L_{\text{layer}}$ å±‚åï¼š</p>
<p>\begin{equation}
\text{Receptive Field} = w \times L_{\text{layer}} + g \times L + r \times \lfloor w/r \rfloor
\tag{27}
\end{equation}</p>
<h4 id="53-bigbird">5.3 BigBirdçš„éšæœºæ³¨æ„åŠ›</h4>
<p><strong>ä¸‰ç§æ³¨æ„åŠ›æ¨¡å¼</strong>:
1. å…¨å±€æ³¨æ„åŠ›: $g$ ä¸ªéšæœºé€‰æ‹©çš„tokenå¯¹æ‰€æœ‰ä½ç½®
2. çª—å£æ³¨æ„åŠ›: çª—å£å¤§å° $w$
3. éšæœºæ³¨æ„åŠ›: æ¯ä¸ªä½ç½®éšæœºå…³æ³¨ $r$ ä¸ªtoken</p>
<p><strong>å¤æ‚åº¦</strong>:</p>
<p>\begin{equation}
\text{Time} = \mathcal{O}((g + w + r) \cdot L \cdot d)
\tag{28}
\end{equation}</p>
<p><strong>ç†è®ºä¿è¯</strong>: éšæœºå›¾çš„è¿é€šæ€§ç†è®ºä¿è¯ï¼Œ$r = \mathcal{O}(\log L)$ å³å¯ä¿è¯å›¾è¿é€šï¼Œå®ç°å…¨å±€ä¿¡æ¯ä¼ æ’­ã€‚</p>
<h3 id="_8">å…­ã€é¢„è®­ç»ƒç­–ç•¥çš„æ•°å­¦è®¾è®¡</h3>
<h4 id="61-mlm">6.1 æ©ç è¯­è¨€æ¨¡å‹ (MLM) çš„é•¿åºåˆ—æ‰©å±•</h4>
<p>æ ‡å‡†MLMï¼š</p>
<p>\begin{equation}
\mathcal{L}<em _in="\in" _mathcal_M="\mathcal{M" i="i">{\text{MLM}} = -\sum</em>}} \log P(\boldsymbol{x<em _mathcal_M="\mathcal{M" _setminus="\setminus">i | \boldsymbol{x}</em>)
\tag{29}
\end{equation}}</p>
<p>å…¶ä¸­ $\mathcal{M}$ æ˜¯è¢«æ©ç çš„ä½ç½®é›†åˆã€‚</p>
<p><strong>é•¿åºåˆ—æŒ‘æˆ˜</strong>: $|\boldsymbol{x}|$ å¾ˆå¤§æ—¶ï¼Œä¸Šä¸‹æ–‡è¿‡é•¿å¯èƒ½å¯¼è‡´ï¼š
1. è¿‡æ‹Ÿåˆå±€éƒ¨æ¨¡å¼
2. å…¨å±€ä¿¡æ¯è¢«ç¨€é‡Š</p>
<p><strong>æ”¹è¿›: è·¨åº¦æ©ç </strong>:</p>
<p>\begin{equation}
\mathcal{M} = \bigcup_{k=1}^{K} [s_k, s_k + l_k)
\tag{30}
\end{equation}</p>
<p>è¿ç»­æ©ç å¤šä¸ªtokenï¼Œè¿«ä½¿æ¨¡å‹å­¦ä¹ æ›´é•¿ç¨‹çš„ä¾èµ–ã€‚</p>
<h4 id="62-gpt-style">6.2 è‡ªå›å½’é¢„è®­ç»ƒ (GPT-style)</h4>
<p>\begin{equation}
\mathcal{L}<em i="1">{\text{AR}} = -\sum</em>}^{L} \log P(\boldsymbol{x<em _i="&lt;i">i | \boldsymbol{x}</em>)
\tag{31}
\end{equation}</p>
<p><strong>é•¿åºåˆ—ä¼˜åŠ¿</strong>: æ¯ä¸ªtokenéƒ½ä½œä¸ºé¢„æµ‹ç›®æ ‡ï¼Œå……åˆ†åˆ©ç”¨é•¿åºåˆ—æ•°æ®ã€‚</p>
<p><strong>å›°éš¾</strong>: æ—©æœŸä½ç½®çš„é¢„æµ‹ä¾èµ–çš„ä¸Šä¸‹æ–‡å°‘ï¼Œæ™šæœŸä½ç½®çš„ä¸Šä¸‹æ–‡è¿‡é•¿ã€‚</p>
<p><strong>è§£å†³: æ–‡æ¡£çº§é¢„è®­ç»ƒ</strong>: å°†å¤šä¸ªæ–‡æ¡£æ‹¼æ¥ï¼Œå­¦ä¹ è·¨æ–‡æ¡£çš„é•¿ç¨‹æ¨¡å¼ã€‚</p>
<h4 id="63">6.3 å¯¹æ¯”å­¦ä¹ çš„é•¿åºåˆ—è§†è§’</h4>
<p><strong>SimCLR for Sequences</strong>:</p>
<p>\begin{equation}
\mathcal{L}<em j="1">{\text{contrastive}} = -\log \frac{\exp(\text{sim}(\boldsymbol{h}_i, \boldsymbol{h}_i^+) / \tau)}{\sum</em>
\tag{32}
\end{equation}}^{B} \exp(\text{sim}(\boldsymbol{h}_i, \boldsymbol{h}_j) / \tau)</p>
<p>å…¶ä¸­ $\boldsymbol{h}_i^+$ æ˜¯æ­£æ ·æœ¬ï¼ˆåŒä¸€åºåˆ—çš„ä¸åŒè§†è§’ï¼‰ï¼Œ$\boldsymbol{h}_j$ æ˜¯è´Ÿæ ·æœ¬ã€‚</p>
<p><strong>é•¿åºåˆ—çš„å¢å¼ºç­–ç•¥</strong>:
1. éšæœºè£å‰ªä¸åŒé•¿åº¦ç‰‡æ®µ
2. æ—¶é—´æ‰­æ›² (temporal warping)
3. ä½ç½®æ‰“ä¹±</p>
<h3 id="_9">ä¸ƒã€é•¿åºåˆ—çš„è®¡ç®—ä¼˜åŒ–</h3>
<h4 id="71-flashattention">7.1 FlashAttentionçš„æ•°å­¦åŸç†</h4>
<p><strong>æ ¸å¿ƒæ€æƒ³</strong>: å‡å°‘HBM (é«˜å¸¦å®½å†…å­˜) è®¿é—®ï¼Œåˆ©ç”¨SRAM (ç‰‡ä¸Šå†…å­˜)ã€‚</p>
<p><strong>æ ‡å‡†Attentionçš„å†…å­˜è®¿é—®</strong>:
1. ä»HBMè¯»å–Q, K, V: $\mathcal{O}(Ld)$
2. è®¡ç®— $\boldsymbol{S} = \boldsymbol{Q}\boldsymbol{K}^\top$ï¼Œå†™å…¥HBM: $\mathcal{O}(L^2)$
3. è®¡ç®— $\boldsymbol{P} = \text{softmax}(\boldsymbol{S})$ï¼Œå†™å…¥HBM: $\mathcal{O}(L^2)$
4. è®¡ç®— $\boldsymbol{O} = \boldsymbol{P}\boldsymbol{V}$: $\mathcal{O}(L^2d)$</p>
<p>æ€»HBMè®¿é—®: $\mathcal{O}(L^2 + Ld)$</p>
<p><strong>FlashAttentionçš„åˆ†å—ç­–ç•¥</strong>:</p>
<p>å°†Q, K, Våˆ†æˆå¤§å°ä¸º $B$ çš„å—ï¼Œåœ¨SRAMä¸­å®Œæˆè®¡ç®—ï¼š</p>
<p>\begin{equation}
\boldsymbol{O}<em j="j">{[i]} = \sum</em>} \text{softmax}\left(\frac{\boldsymbol{Q<em _j_="[j]">{[i]} \boldsymbol{K}</em>
\tag{33}
\end{equation}}^\top}{\sqrt{d}}\right) \boldsymbol{V}_{[j]</p>
<p><strong>HBMè®¿é—®é™ä½</strong>: $\mathcal{O}(L^2 / B + Ld)$ï¼Œå½“ $B \sim \sqrt{L}$ æ—¶æ¥è¿‘çº¿æ€§ï¼</p>
<h4 id="72-flash-decoupled-attention">7.2 Flash-Decoupled Attention</h4>
<p><strong>åˆ†ç¦»QKå’ŒVçš„è®¡ç®—</strong>:</p>
<p>\begin{equation}
\boldsymbol{A} = \text{softmax}\left(\frac{\boldsymbol{Q}\boldsymbol{K}^\top}{\sqrt{d}}\right)
\tag{34}
\end{equation}</p>
<p>\begin{equation}
\boldsymbol{O} = \boldsymbol{A} \boldsymbol{V}
\tag{35}
\end{equation}</p>
<p><strong>ä¼˜åŒ–</strong>: å¯ä»¥å…ˆè®¡ç®—ç¨€ç–çš„ $\boldsymbol{A}$ (åªä¿ç•™top-k)ï¼Œå†ä¹˜ $\boldsymbol{V}$ã€‚</p>
<p>\begin{equation}
\text{Sparse}(\boldsymbol{A})<em i_j="i,j">{i,j} = \begin{cases}
A</em>) \
0, &amp; \text{otherwise}
\end{cases}
\tag{36}
\end{equation}}, &amp; j \in \text{top-k}(A_{i,:</p>
<p><strong>å¤æ‚åº¦</strong>: $\mathcal{O}(Lkd)$ vs $\mathcal{O}(L^2d)$ï¼Œå½“ $k \ll L$ æ—¶æ˜¾è‘—é™ä½ã€‚</p>
<h4 id="73-gradient-checkpointing">7.3 æ¢¯åº¦æ£€æŸ¥ç‚¹ (Gradient Checkpointing)</h4>
<p><strong>æ ‡å‡†åå‘ä¼ æ’­</strong>: éœ€è¦å­˜å‚¨æ‰€æœ‰ä¸­é—´æ¿€æ´»ï¼Œå†…å­˜ $\mathcal{O}(N \times L \times d)$</p>
<p><strong>æ¢¯åº¦æ£€æŸ¥ç‚¹</strong>: åªå­˜å‚¨éƒ¨åˆ†æ¿€æ´»ï¼Œéœ€è¦æ—¶é‡æ–°è®¡ç®—ã€‚</p>
<p>åˆ† $C$ ä¸ªæ£€æŸ¥ç‚¹ï¼š</p>
<p>\begin{equation}
\text{Memory} = \mathcal{O}(C \times L \times d)
\tag{37}
\end{equation}</p>
<p>\begin{equation}
\text{Computation} = \mathcal{O}(N \times L \times d) \times \left(1 + \frac{N}{C}\right)
\tag{38}
\end{equation}</p>
<p><strong>æœ€ä¼˜ç­–ç•¥</strong>: $C = \sqrt{N}$ï¼Œå†…å­˜é™ä½ $\sqrt{N}$ å€ï¼Œè®¡ç®—å¢åŠ å¸¸æ•°å€ã€‚</p>
<h3 id="_10">å…«ã€å®éªŒç»“æœçš„æ•°å­¦è§£é‡Š</h3>
<h4 id="81-lra">8.1 LRAæ€§èƒ½æå‡çš„åˆ†è§£</h4>
<p>é¢„è®­ç»ƒåçš„æ€§èƒ½æå‡å¯ä»¥åˆ†è§£ä¸ºï¼š</p>
<p>\begin{equation}
\Delta_{\text{Acc}} = \Delta_{\text{pos}} + \Delta_{\text{local}} + \Delta_{\text{global}}
\tag{39}
\end{equation}</p>
<p>å…¶ä¸­ï¼š
- $\Delta_{\text{pos}}$: ä½ç½®ç¼–ç é€‚åº”
- $\Delta_{\text{local}}$: å±€éƒ¨æ¨¡å¼å­¦ä¹ 
- $\Delta_{\text{global}}$: å…¨å±€ä¾èµ–å»ºæ¨¡</p>
<p><strong>Transformerçš„ä¼˜åŠ¿</strong>: $\Delta_{\text{global}}$ æ›´å¤§ï¼Œå› ä¸ºå…¨å±€æ³¨æ„åŠ›æœºåˆ¶ã€‚</p>
<p><strong>æ•°å€¼ç¤ºä¾‹</strong>: åœ¨ListOpsä»»åŠ¡ä¸Šï¼š
- æ— é¢„è®­ç»ƒ: 36.4%
- æœ‰é¢„è®­ç»ƒ: 38.6%
- $\Delta_{\text{pos}} \approx 1.0\%$
- $\Delta_{\text{local}} \approx 0.5\%$
- $\Delta_{\text{global}} \approx 0.7\%$</p>
<h4 id="82-transformer-vs-ssm">8.2 Transformer vs SSMçš„å¯¹æ¯”</h4>
<p><strong>SSMçš„ä¼˜åŠ¿</strong>: å¤©ç„¶çš„å±€åŸŸæ€§åç½®</p>
<p>\begin{equation}
\text{Score}_{\text{SSM}} = \alpha \cdot \text{Local} + \beta \cdot \text{Global}
\tag{40}
\end{equation}</p>
<p>å…¶ä¸­ $\alpha &gt; \beta$ï¼ˆå±€éƒ¨æƒé‡æ›´å¤§ï¼‰ã€‚</p>
<p><strong>Transformer + é¢„è®­ç»ƒ</strong>: å­¦ä¼šäº†å±€åŸŸæ€§ï¼ŒåŒæ—¶ä¿ç•™å…¨å±€èƒ½åŠ›</p>
<p>\begin{equation}
\text{Score}_{\text{TF+PT}} = \alpha' \cdot \text{Local} + \beta' \cdot \text{Global}
\tag{41}
\end{equation}</p>
<p>å…¶ä¸­ $\alpha' \approx \alpha, \beta' &gt; \beta$ã€‚</p>
<p><strong>å…³é”®</strong>: é¢„è®­ç»ƒè®©Transformerå­¦ä¼šäº†SSMçš„ä¼˜åŠ¿ï¼ŒåŒæ—¶ä¿æŒäº†è‡ªå·±çš„ä¼˜åŠ¿ï¼</p>
<h3 id="_11">ä¹ã€ç†è®ºåˆ†æä¸å®è·µå»ºè®®</h3>
<h4 id="91">9.1 é¢„è®­ç»ƒé•¿åº¦çš„é€‰æ‹©</h4>
<p><strong>ç›®æ ‡é•¿åº¦</strong> $L_{\text{target}}$ï¼Œ<strong>é¢„è®­ç»ƒé•¿åº¦</strong> $L_{\text{pretrain}}$ çš„é€‰æ‹©ï¼š</p>
<p><strong>ç»éªŒå…¬å¼</strong>:</p>
<p>\begin{equation}
L_{\text{pretrain}} = \min(L_{\text{target}}, \alpha \cdot L_{\text{train}})
\tag{42}
\end{equation}</p>
<p>å…¶ä¸­ $L_{\text{train}}$ æ˜¯åŸè®­ç»ƒé•¿åº¦ï¼Œ$\alpha \in [2, 4]$ã€‚</p>
<p><strong>æ•°å€¼ç¤ºä¾‹</strong>: åŸè®­ç»ƒ2Kï¼Œç›®æ ‡16K:
- ç›´æ¥å¾®è°ƒ: å¤±è´¥
- é¢„è®­ç»ƒ4K â†’ å¾®è°ƒ16K: æˆåŠŸ
- é¢„è®­ç»ƒ8K â†’ å¾®è°ƒ16K: æ›´å¥½</p>
<h4 id="92">9.2 é¢„è®­ç»ƒæ•°æ®é‡çš„ä¼°è®¡</h4>
<p><strong>PACç•Œ</strong>: éœ€è¦çš„æ ·æœ¬æ•°ä¸åºåˆ—é•¿åº¦ç›¸å…³ï¼š</p>
<p>\begin{equation}
n \geq \frac{c}{\epsilon^2} (d \log L + \log(1/\delta))
\tag{43}
\end{equation}</p>
<p>å…¶ä¸­ $\epsilon$ æ˜¯ç›®æ ‡è¯¯å·®ï¼Œ$\delta$ æ˜¯å¤±è´¥æ¦‚ç‡ã€‚</p>
<p><strong>å…³é”®</strong>: æ•°æ®éœ€æ±‚éš $\log L$ å¢é•¿ï¼Œè€Œéçº¿æ€§å¢é•¿ï¼</p>
<p><strong>æ•°å€¼ç¤ºä¾‹</strong>: $L$ ä»2Kå¢åŠ åˆ°16K ($\times 8$)ï¼Œæ•°æ®éœ€æ±‚å¢åŠ  $\log_2 8 = 3$ å€ã€‚</p>
<h4 id="93">9.3 ä½ç½®ç¼–ç æ–¹æ¡ˆçš„é€‰æ‹©</h4>
<table>
<thead>
<tr>
<th>åºåˆ—é•¿åº¦</th>
<th>æ¨èæ–¹æ¡ˆ</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td>â‰¤ 2K</td>
<td>æ ‡å‡†RoPE</td>
<td>æ— éœ€ç‰¹æ®Šå¤„ç†</td>
</tr>
<tr>
<td>2K-8K</td>
<td>PI</td>
<td>ç®€å•æœ‰æ•ˆ</td>
</tr>
<tr>
<td>8K-32K</td>
<td>NTK-Aware PI</td>
<td>ä¿ç•™é«˜é¢‘ä¿¡æ¯</td>
</tr>
<tr>
<td>&gt; 32K</td>
<td>ALiBiæˆ–é¢„è®­ç»ƒ</td>
<td>å¤–æ¨æ€§æ›´å¥½</td>
</tr>
</tbody>
</table>
<h4 id="94">9.4 æ³¨æ„åŠ›æ¨¡å¼çš„é…ç½®</h4>
<p><strong>æ¨èé…ç½®</strong>: Longformer-style</p>
<div class="codehilite"><pre><span></span><code>çª—å£å¤§å° w = min(512, L/4)
å…¨å±€tokenæ•° g = ceil(log_2(L))
è†¨èƒ€ç‡ r = 2 (å¶æ•°å±‚) / 4 (å¥‡æ•°å±‚)
</code></pre></div>

<p><strong>å¤æ‚åº¦</strong>:</p>
<p>\begin{equation}
\text{Total} = \mathcal{O}((w + g + w/r) \times L \times d) \approx \mathcal{O}(wLd)
\tag{44}
\end{equation}</p>
<h3 id="_12">åã€æ€»ç»“</h3>
<p>æœ¬èŠ‚è¯¦ç»†æ¨å¯¼äº†é•¿åºåˆ—Transformerçš„æ•°å­¦åŸç†ï¼š</p>
<p><strong>æ ¸å¿ƒå‘ç°</strong>:
1. <strong>é¢„è®­ç»ƒçš„ä½œç”¨</strong>: æ³¨å…¥Inductive Biasï¼Œé€‚åº”ä½ç½®åˆ†å¸ƒ
2. <strong>ä½ç½®æ’å€¼</strong>: ä¿æŒç›¸å¯¹ä½ç½®æ¨¡å¼ï¼Œå®ç°é•¿åº¦å¤–æ¨
3. <strong>ç¨€ç–æ³¨æ„åŠ›</strong>: é™ä½å¤æ‚åº¦ï¼Œä¿ç•™å…³é”®ä¾èµ–</p>
<p><strong>å…³é”®å…¬å¼</strong>:</p>
<p><strong>ä½ç½®æ’å€¼</strong>:
\begin{equation}
n_{\text{scaled}} = n \cdot \frac{L_{\text{train}}}{L_{\text{test}}}
\tag{45}
\end{equation}</p>
<p><strong>ç¨€ç–æ³¨æ„åŠ›å¤æ‚åº¦</strong>:
\begin{equation}
\mathcal{O}(L^2d) \to \mathcal{O}((w + g + r) Ld)
\tag{46}
\end{equation}</p>
<p><strong>é¢„è®­ç»ƒæ ·æœ¬éœ€æ±‚</strong>:
\begin{equation}
n \geq \mathcal{O}(d \log L)
\tag{47}
\end{equation}</p>
<p><strong>å®è·µå¯ç¤º</strong>:
1. é•¿åºåˆ—ä»»åŠ¡å¿…é¡»é¢„è®­ç»ƒï¼ˆå°¤å…¶æ˜¯ç»†ç²’åº¦tokenï¼‰
2. ä½ç½®ç¼–ç é€‰æ‹©éœ€è¦è€ƒè™‘å¤–æ¨æ€§
3. ç¨€ç–æ³¨æ„åŠ›å¯ä»¥æœ‰æ•ˆé™ä½å¤æ‚åº¦
4. Transformerçš„å…¨å±€èƒ½åŠ›åœ¨é¢„è®­ç»ƒåå¾—ä»¥å……åˆ†å‘æŒ¥</p>
<p>é€šè¿‡é¢„è®­ç»ƒï¼ŒTransformeråœ¨é•¿åºåˆ—å»ºæ¨¡ä¸Šä¸å†é€Šè‰²äºçº¿æ€§RNNï¼Œç”šè‡³åœ¨æŸäº›ä»»åŠ¡ä¸Šè¡¨ç°æ›´ä¼˜ï¼Œè¿™ä¸ºé•¿åºåˆ—å¤„ç†æä¾›äº†æ–°çš„èŒƒå¼ã€‚</p>
        </div>
    </div>
</body>
</html>