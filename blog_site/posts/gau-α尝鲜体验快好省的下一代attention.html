<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GAU-Î±ï¼šå°é²œä½“éªŒå¿«å¥½çœçš„ä¸‹ä¸€ä»£Attention</title>
    <style>
* { margin: 0; padding: 0; box-sizing: border-box; }
body {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
    line-height: 1.6; color: #333; max-width: 900px; margin: 0 auto; padding: 20px; background: #f5f5f5;
}
.container { background: white; padding: 40px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
header { border-bottom: 2px solid #e0e0e0; padding-bottom: 20px; margin-bottom: 30px; }
h1 { color: #2c3e50; margin-bottom: 10px; font-size: 2em; }
.meta { color: #666; font-size: 0.9em; margin-bottom: 20px; }
.content { margin-top: 30px; overflow-wrap: break-word; }
.content h2 { color: #34495e; margin-top: 30px; margin-bottom: 15px; border-bottom: 1px solid #eee; padding-bottom: 5px; }
.content p { margin-bottom: 15px; }
.content pre { background: #f8f8f8; padding: 15px; border-radius: 5px; overflow-x: auto; border-left: 3px solid #3498db; margin: 15px 0; }
.content code { background: #f8f8f8; padding: 2px 5px; border-radius: 3px; font-family: monospace; font-size: 0.9em; }
.content blockquote { border-left: 4px solid #3498db; padding-left: 20px; margin: 20px 0; color: #555; font-style: italic; }
.content table { border-collapse: collapse; width: 100%; margin: 20px 0; }
.content th, .content td { border: 1px solid #ddd; padding: 10px; text-align: left; }
.back-link { display: inline-block; margin-bottom: 20px; color: #3498db; text-decoration: none; font-weight: 500; }
</style>
    
<script>
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\(', '\)']],
            displayMath: [['$$', '$$'], ['\[', '\]']],
            processEscapes: true
        }
    };
</script>
<script id="MathJax-script" async src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>
    <div class="container">
        <a href="../index.html" class="back-link">â† è¿”å›é¦–é¡µ</a>
        <header>
            <h1>GAU-Î±ï¼šå°é²œä½“éªŒå¿«å¥½çœçš„ä¸‹ä¸€ä»£Attention</h1>
            <div class="meta">ğŸ“… æœ€åæ›´æ–°: 2025-11-26 | ğŸ“„ å¤§å°: 32.8 KB</div>
        </header>
        <div class="content">
            <p><strong>åŸæ–‡é“¾æ¥</strong>: <a href="https://spaces.ac.cn/archives/9052">https://spaces.ac.cn/archives/9052</a></p>
<p><strong>å‘å¸ƒæ—¥æœŸ</strong>: </p>
<hr />
<p>åœ¨<a href="/archives/8934">ã€ŠFLASHï¼šå¯èƒ½æ˜¯è¿‘æ¥æœ€æœ‰æ„æ€çš„é«˜æ•ˆTransformerè®¾è®¡ã€‹</a>ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†GAUï¼ˆGated Attention Unitï¼Œé—¨æ§çº¿æ€§å•å…ƒï¼‰ï¼Œåœ¨è¿™é‡Œç¬”è€…æ„¿æ„ç§°ä¹‹ä¸ºâ€œç›®å‰æœ€æœ‰æ½œåŠ›çš„ä¸‹ä¸€ä»£Attentionè®¾è®¡â€ï¼Œå› ä¸ºå®ƒçœŸæ­£è¾¾åˆ°äº†â€œæ›´å¿«ï¼ˆé€Ÿåº¦ï¼‰ã€æ›´å¥½ï¼ˆæ•ˆæœï¼‰ã€æ›´çœï¼ˆæ˜¾å­˜ï¼‰â€çš„ç‰¹ç‚¹ã€‚</p>
<p>ç„¶è€Œï¼Œæœ‰äº›è¯»è€…åœ¨è‡ªå·±çš„æµ‹è¯•ä¸­å¾—åˆ°äº†ç›¸åçš„ç»“æœï¼Œæ¯”å¦‚æ”¶æ•›æ›´æ…¢ã€æ•ˆæœæ›´å·®ç­‰ï¼Œè¿™ä¸ç¬”è€…çš„æµ‹è¯•ç»“æœå¤§ç›¸å¾„åº­ã€‚æœ¬æ–‡å°±æ¥åˆ†äº«ä¸€ä¸‹ç¬”è€…è‡ªå·±çš„è®­ç»ƒç»éªŒï¼Œå¹¶ä¸”æ”¾å‡ºä¸€ä¸ªå°é²œç‰ˆâ€œGAU-Î±â€ä¾›å¤§å®¶æµ‹è¯•ã€‚</p>
<blockquote>
<p><strong>å¼€æºåœ°å€ï¼š<a href="https://github.com/ZhuiyiTechnology/GAU-alpha">https://github.com/ZhuiyiTechnology/GAU-alpha</a></strong></p>
</blockquote>
<h2 id="gau-">GAU-Î±</h2>
<p>é¦–å…ˆä»‹ç»ä¸€ä¸‹å¼€æºå‡ºæ¥çš„â€œGAU-Î±â€åœ¨CLUEä»»åŠ¡ä¸Šçš„æˆç»©å•ï¼š<br />
$$\small{\begin{array}{c|ccccccccccc}  
\hline  
& \text{iflytek} & \text{tnews} & \text{afqmc} & \text{cmnli} & \text{ocnli} & \text{wsc} & \text{csl} & \text{cmrc2018} & \text{c3} & \text{chid} & \text{cluener}\\\  
\hline  
\text{BERT} & 60.06 & 56.80 & 72.41 & 79.56 & 73.93 & 78.62 & 83.93 & 56.17 & 60.54 & 85.69 & 79.45 \\\  
\text{RoBERTa} & 60.64 & \textbf{58.06} & 74.05 & 81.24 & 76.00 & \textbf{87.50} & 84.50 & 56.54 & 67.66 & 86.71 & 79.47\\\  
\text{RoFormer} & 60.91 & 57.54 & 73.52 & 80.92 & \textbf{76.07} & 86.84 & 84.63 & 56.26 & 67.24 & 86.57 & 79.72\\\  
\text{RoFormerV2}^* & 60.87 & 56.54 & 72.75 & 80.34 & 75.36 & 80.92 & 84.67 & 57.91 & 64.62 & 85.09 & \textbf{81.08}\\\  
\hline  
\text{GAU-}\alpha & \textbf{61.41} & 57.76 & \textbf{74.17} & \textbf{81.82} & 75.86 & 79.93 & \textbf{85.67} & \textbf{58.09} & \textbf{68.24} & \textbf{87.91} & 80.01\\\  
\hline  
\end{array}}$$</p>
<p>æ‰€æœ‰çš„æ¨¡å‹éƒ½æ˜¯Baseç‰ˆï¼Œä¸Šè¡¨æ˜¾ç¤ºçš„æ˜¯CLUEä»»åŠ¡ä¸ŠéªŒè¯é›†ä¸Šçš„ç»“æœï¼Œå¤§å®¶çš„è¿è¡Œæ–¹å¼å’Œæ¯”è¾ƒéƒ½æ˜¯å…¬å¹³çš„ï¼Œä½œä¸ºä¸€ä¸ªç›¸å¯¹æ¯”è¾ƒæ¥è¯´æ˜¯åˆç†çš„ã€‚å¦å¤–ï¼Œè¿™é‡Œçš„RoFormerV2*å¹¶é<a href="/archives/8998">ã€ŠRoFormerV2ï¼šè‡ªç„¶è¯­è¨€ç†è§£çš„æé™æ¢ç´¢ã€‹</a>ä¸­çš„å¤šä»»åŠ¡ç‰ˆæœ¬ï¼Œè€Œæ˜¯ä»…ä»…è¿›è¡Œäº†MLMé¢„è®­ç»ƒçš„ç‰ˆæœ¬ï¼ˆè¯¥ç‰ˆæœ¬æ²¡å¼€æºï¼‰ï¼Œè¿™æ ·å¯¹æ¯”æ˜¯å› ä¸ºGAU-Î±ä¹Ÿä»…ä»…è¿›è¡Œäº†MLMé¢„è®­ç»ƒã€‚</p>
<p>ä»è¡¨ä¸­å¯ä»¥çœ‹å‡ºï¼Œé™¤äº†WSCè¿™ä¸ªæ•°æ®é‡æå°‘çš„â€œå¼‚ç±»â€å¤–ï¼ŒGAU-Î±åœ¨å¤šæ•°ä»»åŠ¡ä¸Šéƒ½æœ‰ä¼˜åŠ¿ï¼Œå¹¶ä¸”é™¤äº†WSCå¤–çš„å¹³å‡æˆç»©æ˜¯æœ€å¥½çš„ã€‚å…¶ä¸­ï¼ŒRoFormerV2<em>ä¸GAU-Î±çš„æ¯”è¾ƒæ˜¯æœ€ä¸ºå…¬å¹³çš„ï¼Œå› ä¸ºå®ƒä»¬çš„è®­ç»ƒè„šæœ¬ã€è®­ç»ƒæ•°æ®ã€æ•´ä½“ç»“æ„éƒ½æ˜¯ä¸€æ ·çš„ï¼Œå”¯ä¸€ä¸åŒå°±æ˜¯GAU-Î±æ˜¯å°†RoFormerV2</em>ä¸­çš„Attention+FFNç»„åˆæ¢æˆäº†ä¸¤å±‚GAUï¼Œä¸¤è€…å¯¹æ¯”å……åˆ†æ˜¾ç¤ºå‡ºäº†GAUè®¾è®¡â€œæ›´å¥½â€çš„ç‰¹ç‚¹ã€‚</p>
<p>æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨<a href="/archives/8998">ã€ŠRoFormerV2ï¼šè‡ªç„¶è¯­è¨€ç†è§£çš„æé™æ¢ç´¢ã€‹</a>ä»‹ç»è¿‡RoFormerV2å¯¹ç»“æ„è¿›è¡Œäº†ç®€åŒ–ï¼Œä»è€Œè·å¾—æ›´å¿«çš„é€Ÿåº¦ï¼Œå…·æœ‰åŒæ ·æ•´ä½“ç»“æ„çš„GAU-Î±ä¹Ÿæ˜¯å¦‚æ­¤ï¼Œæ‰€ä»¥GAU-Î±çš„é€Ÿåº¦æ˜¯æ¯”è¡¨ä¸­çš„BERTã€RoBERTaã€RoFormeréƒ½è¦å¿«çš„ï¼Œä½†å¹³å‡æ•ˆæœå´æ›´èƒœä¸€ç­¹ã€‚æ›´è¿›ä¸€æ­¥çš„æµ‹è¯•æ˜¾ç¤ºï¼Œå½“åºåˆ—é•¿åº¦è¶…è¿‡512æ—¶ï¼ŒGAU-Î±çš„é€Ÿåº¦å¼€å§‹è¶…è¿‡åŒæ ·ç²¾ç®€è¿‡çš„RoFormerV2ï¼Œå¹¶ä¸”æ˜¾å­˜å ç”¨æ›´ä½ï¼Œè¶Šé•¿åˆ™å¯¹GAU-Î±æ›´æœ‰åˆ©ã€‚</p>
<h2 id="_1">è®­ç»ƒ</h2>
<p>ç°åœ¨ä»‹ç»ä¸€ä¸‹æ¨¡å‹çš„è®­ç»ƒç»†èŠ‚ï¼Œå®Œæ•´çš„ä»£ç å·²ç»å¼€æºåˆ°Githubä¸­ï¼Œå¦‚æœ‰ç–‘æƒ‘å¯ä»¥å¯¹ç…§ç€ä»£ç æ¥è¯»ã€‚</p>
<p><strong>æ¨¡å‹æ¶æ„</strong> ï¼š GAU-Î±å°±æ˜¯å°†RoFormerV2çš„Attention+FFNæ¢æˆäº†ä¸¤å±‚GAUï¼Œåœ¨<a href="/archives/8934">ä¹‹å‰çš„æ–‡ç« </a>ä¸­æˆ‘ä»¬æ¯”è¾ƒè¿‡ä¸¤å±‚GAUçš„è®¡ç®—é‡å’Œå‚æ•°é‡å¤§è‡´ç›¸å½“äºAttention+FFNç»„åˆï¼Œæ‰€ä»¥è¿™æ ·çš„æ›¿æ¢æ˜¯åˆç†çš„ï¼›RoFormerV2çš„ç‰¹ç‚¹æ˜¯ä¿ç•™äº†Post Normç»“æ„ï¼Œå»æ‰äº†æ‰€æœ‰çš„Biasé¡¹ï¼Œå¹¶ä¸”Layer Normæ¢æˆäº†RMS Normçš„æœ€ç®€å•å˜ä½“ï¼Œåœ¨GAU-Î±ä¸­ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</p>
<p><strong>å½’ä¸€åŒ–</strong> ï¼š åœ¨<a href="/archives/9019">ã€Šå¬è¯´Attentionä¸Softmaxæ›´é…å“¦ï½ã€‹</a>ä¸­æˆ‘ä»¬è®¨è®ºè¿‡Attentionçš„å½’ä¸€åŒ–é—®é¢˜ï¼ŒGAU-Î±çš„Attentionå½’ä¸€åŒ–é€‰å–äº†å…¶ä¸­ç¬”è€…è‡ªè¡Œæå‡ºçš„å…·æœ‰è¾ƒå¥½å¤–æ¨èƒ½åŠ›çš„<a href="/archives/8823">ç†µä¸å˜æ€§Softmax</a>ï¼ˆåœ¨bert4kerasä¸­æš‚ç§°ä¸ºsoftmax_plusï¼‰ã€‚</p>
<p><strong>è®­ç»ƒæ–¹å¼</strong> ï¼š åœ¨åˆå§‹åŒ–æ–¹é¢ç¬”è€…æŒ‰ç…§<a href="/archives/8978">ã€Šè®­ç»ƒ1000å±‚çš„Transformerç©¶ç«Ÿæœ‰ä»€ä¹ˆå›°éš¾ï¼Ÿã€‹</a>è¿›è¡Œäº†è°ƒæ•´ï¼Œå› æ­¤æ— é¡»Wamrupå°±å¯ä»¥ç›´æ¥è®­ç»ƒï¼Œä¼˜åŒ–å™¨ç”¨çš„æ˜¯LAMBï¼Œå­¦ä¹ ç‡åˆ†æ®µçº¿æ€§è¡°å‡ï¼›é¢„è®­ç»ƒä»»åŠ¡ç”¨çš„æ˜¯å…¨è¯MLMï¼Œåˆ†è¯å·¥å…·ç”¨ç™¾åº¦çš„LACï¼Œè¿™äº›è·ŸRoFormerV2éƒ½æ˜¯å¯¹é½çš„ã€‚</p>
<p>å¥½åƒå€¼å¾—ä¸€æçš„ä¹Ÿå°±è¿™ä¹ˆå¤šäº†ï¼Œç¡®å®æ²¡è¿›è¡Œå¤šå¤§çš„æ”¹å˜ã€‚é™¤äº†åœ¨å½’ä¸€åŒ–æ–¹å¼ä¸ŠèŠ±äº†ç‚¹æ—¶é—´è¿›è¡Œæµ‹è¯•ï¼Œå…¶ä»–æ–¹é¢ä¹Ÿæ²¡å¤šè´¹æ—¶é—´ï¼Œç›´æ¥è®­ç»ƒå°±å¾—åˆ°äº†ä¸é”™çš„æ•ˆæœã€‚</p>
<h2 id="_2">å°ç»“</h2>
<p>GAUæ˜¯ç¬”è€…è®¤ä¸ºçš„â€œç›®å‰æœ€æœ‰æ½œåŠ›çš„ä¸‹ä¸€ä»£Attentionè®¾è®¡â€ï¼Œæœ¬æ–‡åˆ†äº«äº†GAUçš„ä¸€äº›è®­ç»ƒç»éªŒï¼Œå¹¶å¼€æºäº†ä¸€ä¸ªå°é²œç‰ˆâ€œGAU-Î±â€ã€‚</p>
<p><em><strong>è½¬è½½åˆ°è¯·åŒ…æ‹¬æœ¬æ–‡åœ°å€ï¼š</strong><a href="https://spaces.ac.cn/archives/9052">https://spaces.ac.cn/archives/9052</a></em></p>
<p><em><strong>æ›´è¯¦ç»†çš„è½¬è½½äº‹å®œè¯·å‚è€ƒï¼š</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="ã€Šç§‘å­¦ç©ºé—´FAQã€‹">ã€Šç§‘å­¦ç©ºé—´FAQã€‹</a></p>
<p><strong>å¦‚æœæ‚¨è¿˜æœ‰ä»€ä¹ˆç–‘æƒ‘æˆ–å»ºè®®ï¼Œæ¬¢è¿åœ¨ä¸‹æ–¹è¯„è®ºåŒºç»§ç»­è®¨è®ºã€‚</strong></p>
<p><strong>å¦‚æœæ‚¨è§‰å¾—æœ¬æ–‡è¿˜ä¸é”™ï¼Œæ¬¢è¿åˆ†äº«/æ‰“èµæœ¬æ–‡ã€‚æ‰“èµå¹¶éè¦ä»ä¸­è·å¾—æ”¶ç›Šï¼Œè€Œæ˜¯å¸Œæœ›çŸ¥é“ç§‘å­¦ç©ºé—´è·å¾—äº†å¤šå°‘è¯»è€…çš„çœŸå¿ƒå…³æ³¨ã€‚å½“ç„¶ï¼Œå¦‚æœä½ æ— è§†å®ƒï¼Œä¹Ÿä¸ä¼šå½±å“ä½ çš„é˜…è¯»ã€‚å†æ¬¡è¡¨ç¤ºæ¬¢è¿å’Œæ„Ÿè°¢ï¼</strong></p>
<p>æ‰“èµ</p>
<p><img alt="ç§‘å­¦ç©ºé—´" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>å¾®ä¿¡æ‰“èµ</p>
<p><img alt="ç§‘å­¦ç©ºé—´" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>æ”¯ä»˜å®æ‰“èµ</p>
<p>å› ä¸ºç½‘ç«™åå°å¯¹æ‰“èµå¹¶æ— è®°å½•ï¼Œå› æ­¤æ¬¢è¿åœ¨æ‰“èµæ—¶å€™å¤‡æ³¨ç•™è¨€ã€‚ä½ è¿˜å¯ä»¥<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>ç‚¹å‡»è¿™é‡Œ</strong></a>æˆ–åœ¨ä¸‹æ–¹è¯„è®ºåŒºç•™è¨€æ¥å‘ŠçŸ¥ä½ çš„å»ºè®®æˆ–éœ€æ±‚ã€‚</p>
<p><strong>å¦‚æœæ‚¨éœ€è¦å¼•ç”¨æœ¬æ–‡ï¼Œè¯·å‚è€ƒï¼š</strong></p>
<p>è‹å‰‘æ—. (Apr. 22, 2022). ã€ŠGAU-Î±ï¼šå°é²œä½“éªŒå¿«å¥½çœçš„ä¸‹ä¸€ä»£Attention ã€‹[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/9052">https://spaces.ac.cn/archives/9052</a></p>
<p>@online{kexuefm-9052,<br />
title={GAU-Î±ï¼šå°é²œä½“éªŒå¿«å¥½çœçš„ä¸‹ä¸€ä»£Attention},<br />
author={è‹å‰‘æ—},<br />
year={2022},<br />
month={Apr},<br />
url={\url{https://spaces.ac.cn/archives/9052}},<br />
} </p>
<hr />
<h2 id="_3">å…¬å¼æ¨å¯¼ä¸æ³¨é‡Š</h2>
<h3 id="1-gau">1. GAUæ¶æ„åŸºç¡€</h3>
<h4 id="11-attention">1.1 æ ‡å‡†Attentionå›é¡¾</h4>
<p>æ ‡å‡†çš„Scaled Dot-Product Attentionå®šä¹‰ä¸ºï¼š
\begin{equation}
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^{\top}}{\sqrt{d_k}}\right)V \tag{1}
\end{equation}</p>
<p>å…¶ä¸­ $Q, K, V \in \mathbb{R}^{n \times d}$ åˆ†åˆ«æ˜¯æŸ¥è¯¢ã€é”®ã€å€¼çŸ©é˜µï¼Œ$n$ æ˜¯åºåˆ—é•¿åº¦ï¼Œ$d$ æ˜¯ç‰¹å¾ç»´åº¦ã€‚</p>
<h4 id="12-gau">1.2 GAUçš„æ ¸å¿ƒè®¾è®¡</h4>
<p>GAUï¼ˆGated Attention Unitï¼‰å°†æ³¨æ„åŠ›æœºåˆ¶ä¸é—¨æ§æœºåˆ¶ç»“åˆï¼Œå…¶æ ¸å¿ƒå½¢å¼ä¸ºï¼š
\begin{equation}
\text{GAU}(X) = (X \odot \text{Attention}(X)) W_O \tag{2}
\end{equation}</p>
<p>å…¶ä¸­ $\odot$ è¡¨ç¤ºé€å…ƒç´ ä¹˜æ³•ï¼ˆHadamardç§¯ï¼‰ï¼Œè¿™æ˜¯GAUçš„å…³é”®åˆ›æ–°ç‚¹ã€‚</p>
<h3 id="2-gau">2. GAUå®Œæ•´æ•°å­¦æ¨å¯¼</h3>
<h4 id="21">2.1 è¾“å…¥å˜æ¢</h4>
<p>ç»™å®šè¾“å…¥ $X \in \mathbb{R}^{n \times d}$ï¼ŒGAUé¦–å…ˆé€šè¿‡ä¸‰ä¸ªçº¿æ€§å˜æ¢ï¼š
\begin{equation}
U = XW_U + b_U \in \mathbb{R}^{n \times e} \tag{3}
\end{equation}
\begin{equation}
V = XW_V + b_V \in \mathbb{R}^{n \times e} \tag{4}
\end{equation}
\begin{equation}
\text{Base} = XW_{\text{base}} + b_{\text{base}} \in \mathbb{R}^{n \times e} \tag{5}
\end{equation}</p>
<p>å…¶ä¸­ $e$ æ˜¯ä¸­é—´ç»´åº¦ï¼Œé€šå¸¸ $e = 2d$ ä»¥ä¿æŒè®¡ç®—é‡å¹³è¡¡ã€‚</p>
<p><strong>æ¨å¯¼æ³¨é‡Š</strong>ï¼šè¿™ä¸‰ä¸ªå˜æ¢çš„ä½œç”¨ä¸åŒï¼š
- $U$ ç”¨äºç”Ÿæˆé—¨æ§ä¿¡å·å’Œæ³¨æ„åŠ›çš„æŸ¥è¯¢/é”®
- $V$ ç”¨äºç”Ÿæˆæ³¨æ„åŠ›çš„å€¼
- $\text{Base}$ ä½œä¸ºåŸºç¡€è¡¨ç¤ºï¼Œç±»ä¼¼äºæ®‹å·®è¿æ¥çš„ä¸»è·¯å¾„</p>
<h4 id="22">2.2 é—¨æ§æœºåˆ¶</h4>
<p>é—¨æ§ä¿¡å·é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¡ç®—ï¼š
\begin{equation}
Z = \phi(U) \in \mathbb{R}^{n \times e} \tag{6}
\end{equation}</p>
<p>å…¶ä¸­ $\phi$ é€šå¸¸æ˜¯ Swish æ¿€æ´»å‡½æ•°æˆ– GELUï¼š
\begin{equation}
\text{Swish}(x) = x \cdot \sigma(\beta x) = \frac{x}{1 + e^{-\beta x}} \tag{7}
\end{equation}</p>
<p><strong>æ¨å¯¼åˆ†æ</strong>ï¼šä¸ºä»€ä¹ˆä½¿ç”¨ Swishï¼Ÿ
è®¡ç®— Swish çš„æ¢¯åº¦ï¼š
\begin{equation}
\frac{d\text{Swish}(x)}{dx} = \sigma(\beta x) + \beta x \sigma(\beta x)(1-\sigma(\beta x)) \tag{8}
\end{equation}</p>
<p>è¿™ä¸ªæ¢¯åº¦å½¢å¼åœ¨ $x&gt;0$ æ—¶è¿‘ä¼¼ä¸º1ï¼ˆç±»ä¼¼ReLUï¼‰ï¼Œä½†åœ¨ $x&lt;0$ æ—¶æœ‰å°çš„éé›¶å€¼ï¼Œé¿å…äº†"ç¥ç»å…ƒæ­»äº¡"é—®é¢˜ã€‚</p>
<h4 id="23">2.3 æ³¨æ„åŠ›åˆ†æ•°è®¡ç®—</h4>
<p>GAUä½¿ç”¨å•å¤´æ³¨æ„åŠ›ï¼ŒæŸ¥è¯¢å’Œé”®éƒ½æ¥è‡ªåŒä¸€ä¸ªçŸ©é˜µï¼š
\begin{equation}
Q = K = \gamma(U) \in \mathbb{R}^{n \times s} \tag{9}
\end{equation}</p>
<p>å…¶ä¸­ $\gamma$ æ˜¯å½’ä¸€åŒ–å‡½æ•°ï¼ˆå¦‚RMSNormï¼‰ï¼Œ$s$ æ˜¯æ³¨æ„åŠ›ç»´åº¦ã€‚</p>
<p><strong>RMSNormæ¨å¯¼</strong>ï¼š
\begin{equation}
\text{RMSNorm}(x) = \frac{x}{\text{RMS}(x)} = \frac{x}{\sqrt{\frac{1}{d}\sum_{i=1}^d x_i^2 + \epsilon}} \tag{10}
\end{equation}</p>
<p>RMSNormçš„æ¢¯åº¦ä¸ºï¼š
\begin{equation}
\frac{\partial \text{RMSNorm}(x_i)}{\partial x_j} = \frac{1}{\text{RMS}(x)}\left(\delta_{ij} - \frac{x_i x_j}{\text{RMS}(x)^2}\right) \tag{11}
\end{equation}</p>
<p>æ³¨æ„åŠ›çŸ©é˜µè®¡ç®—ï¼š
\begin{equation}
A_{raw} = QK^{\top} = \gamma(U)\gamma(U)^{\top} \in \mathbb{R}^{n \times n} \tag{12}
\end{equation}</p>
<h4 id="24">2.4 ç›¸å¯¹ä½ç½®ç¼–ç </h4>
<p>GAUé‡‡ç”¨RoPEï¼ˆRotary Position Embeddingï¼‰ï¼š
\begin{equation}
\text{RoPE}(x, m) = \begin{pmatrix} x_1 \ x_2 \ x_3 \ x_4 \ \vdots \end{pmatrix} \otimes \begin{pmatrix} \cos(m\theta_1) \ \cos(m\theta_1) \ \cos(m\theta_2) \ \cos(m\theta_2) \ \vdots \end{pmatrix} + \begin{pmatrix} -x_2 \ x_1 \ -x_4 \ x_3 \ \vdots \end{pmatrix} \otimes \begin{pmatrix} \sin(m\theta_1) \ \sin(m\theta_1) \ \sin(m\theta_2) \ \sin(m\theta_2) \ \vdots \end{pmatrix} \tag{13}
\end{equation}</p>
<p>å…¶ä¸­é¢‘ç‡å®šä¹‰ä¸ºï¼š
\begin{equation}
\theta_i = 10000^{-2i/d}, \quad i = 0, 1, \ldots, \frac{d}{2}-1 \tag{14}
\end{equation}</p>
<p><strong>RoPEæ€§è´¨æ¨å¯¼</strong>ï¼š
å¯¹äºä½ç½® $m$ å’Œ $n$ çš„ä¸¤ä¸ªå‘é‡ï¼Œå…¶å†…ç§¯æ»¡è¶³ï¼š
\begin{equation}
\langle \text{RoPE}(q, m), \text{RoPE}(k, n) \rangle = \text{Re}\left(\sum_{i=1}^{d/2} (q_{2i-1} + iq_{2i})(k_{2i-1} - ik_{2i})e^{i(m-n)\theta_i}\right) \tag{15}
\end{equation}</p>
<p>è¿™æ„å‘³ç€å†…ç§¯åªä¾èµ–äºç›¸å¯¹ä½ç½® $m-n$ï¼Œå…·æœ‰å¹³ç§»ä¸å˜æ€§ã€‚</p>
<h4 id="25-softmax">2.5 ç†µä¸å˜æ€§Softmax</h4>
<p>è¿™æ˜¯GAU-Î±çš„å…³é”®åˆ›æ–°ï¼Œæ ‡å‡†Softmaxä¸ºï¼š
\begin{equation}
a_{ij} = \frac{e^{s_{ij}}}{\sum_{k=1}^n e^{s_{ik}}} \tag{16}
\end{equation}</p>
<p>ç†µä¸å˜æ€§Softmaxå¼•å…¥å¯¹æ•°ç¼©æ”¾ï¼š
\begin{equation}
a_{ij} = \frac{e^{\lambda(n) s_{ij}}}{\sum_{k=1}^n e^{\lambda(n) s_{ik}}} \tag{17}
\end{equation}</p>
<p>å…¶ä¸­ç¼©æ”¾å› å­ï¼š
\begin{equation}
\lambda(n) = \frac{\log n}{\log 512} \tag{18}
\end{equation}</p>
<p><strong>ç†µä¸å˜æ€§æ¨å¯¼</strong>ï¼š
Shannonç†µå®šä¹‰ä¸ºï¼š
\begin{equation}
H = -\sum_{j=1}^n a_{ij} \log a_{ij} \tag{19}
\end{equation}</p>
<p>ä»£å…¥å¼(17)ï¼š
\begin{equation}
H = -\sum_{j=1}^n a_{ij}\left(\lambda s_{ij} - \log\sum_k e^{\lambda s_{ik}}\right) = \log\sum_k e^{\lambda s_{ik}} - \lambda\sum_j a_{ij}s_{ij} \tag{20}
\end{equation}</p>
<p>å‡è®¾ $s_{ij}$ æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„éšæœºå˜é‡ï¼Œä½¿ç”¨å¯¹æ•°æ±‚å’ŒæŒ‡æ•°ï¼ˆLSEï¼‰çš„æ€§è´¨ï¼š
\begin{equation}
\log\sum_{k=1}^n e^{\lambda s_k} \approx \log n + \lambda \max_k s_k \quad \text{(å½“ } \lambda \text{ è¶³å¤Ÿå¤§æ—¶)} \tag{21}
\end{equation}</p>
<p>æ›´ç²¾ç¡®åœ°ï¼Œä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯è¿‘ä¼¼ï¼š
\begin{equation}
\log\sum_{k=1}^n e^{\lambda s_k} \approx \log n + \mathbb{E}[\lambda s] + \frac{\lambda^2}{2}\text{Var}[s] \tag{22}
\end{equation}</p>
<p>ä¸ºäº†ä½¿ç†µ $H$ å¯¹ $n$ ä¸æ•æ„Ÿï¼Œéœ€è¦ $\log n$ é¡¹è¢«æŠµæ¶ˆï¼Œå³ï¼š
\begin{equation}
\lambda \propto \log n \tag{23}
\end{equation}</p>
<h4 id="26">2.6 å®Œæ•´çš„æ³¨æ„åŠ›è¾“å‡º</h4>
<p>ç»“åˆä½ç½®ç¼–ç å’Œç†µä¸å˜æ€§Softmaxï¼š
\begin{equation}
A = \text{softmax}\left(\lambda(n) \frac{\text{RoPE}(Q)\text{RoPE}(K)^{\top}}{\sqrt{s}}\right) \in \mathbb{R}^{n \times n} \tag{24}
\end{equation}</p>
<p>æ³¨æ„åŠ›å€¼ï¼š
\begin{equation}
O = AV \in \mathbb{R}^{n \times e} \tag{25}
\end{equation}</p>
<h4 id="27">2.7 é—¨æ§èåˆ</h4>
<p>GAUçš„æœ€ç»ˆè¾“å‡ºç»“åˆäº†é—¨æ§å’Œæ³¨æ„åŠ›ï¼š
\begin{equation}
Y = (Z \odot O + \text{Base})W_O \tag{26}
\end{equation}</p>
<p><strong>å±•å¼€æ¨å¯¼</strong>ï¼š
\begin{equation}
Y_i = \sum_{j=1}^e \left(\sum_{k=1}^n Z_{ik} \cdot A_{ik} \cdot V_{kj} + \text{Base}<em O_j_ell="O,j\ell">{ij}\right) W</em>
\end{equation}} \tag{27</p>
<p>å…¶ä¸­ $Z \odot O$ æ˜¯é€å…ƒç´ é—¨æ§ï¼Œ$\text{Base}$ æä¾›ç›´æ¥è·¯å¾„ã€‚</p>
<h3 id="3">3. å‚æ•°é‡å’Œè®¡ç®—é‡åˆ†æ</h3>
<h4 id="31">3.1 å‚æ•°é‡è®¡ç®—</h4>
<p>GAUå•å±‚çš„å‚æ•°åŒ…æ‹¬ï¼š
- $W_U, b_U$: $(d \times e) + e = de + e$
- $W_V, b_V$: $(d \times e) + e = de + e$
- $W_{\text{base}}, b_{\text{base}}$: $(d \times e) + e = de + e$
- $W_O$: $e \times d = ed$</p>
<p>æ€»å‚æ•°é‡ï¼š
\begin{equation}
P_{GAU} = 3(de + e) + ed = 4de + 3e \tag{28}
\end{equation}</p>
<p>å– $e = 2d$ï¼š
\begin{equation}
P_{GAU} = 4d \cdot 2d + 3 \cdot 2d = 8d^2 + 6d \approx 8d^2 \tag{29}
\end{equation}</p>
<p><strong>å¯¹æ¯”æ ‡å‡†Transformer</strong>ï¼š
æ ‡å‡†Attention+FFNçš„å‚æ•°é‡ï¼š
- Attention (Q, K, V, O): $4(d \times d_k) + d_k \times d = 4dd_k + d_kd = 5dd_k$ï¼ˆå–$d_k=d$ï¼‰
- FFN: $d \times 4d + 4d \times d = 8d^2$</p>
<p>æ€»è®¡ï¼š
\begin{equation}
P_{\text{Transformer}} = 5d^2 + 8d^2 = 13d^2 \tag{30}
\end{equation}</p>
<p>ä¸¤å±‚GAUçš„å‚æ•°é‡ï¼š
\begin{equation}
P_{2\times GAU} = 2 \times 8d^2 = 16d^2 \tag{31}
\end{equation}</p>
<p>ç›¸æ¯”æ ‡å‡†Transformerï¼Œå‚æ•°é‡æ¯”ä¾‹ï¼š
\begin{equation}
\frac{P_{2\times GAU}}{P_{\text{Transformer}}} = \frac{16d^2}{13d^2} \approx 1.23 \tag{32}
\end{equation}</p>
<p><strong>ç»“è®º</strong>ï¼šä¸¤å±‚GAUå‚æ•°é‡ç•¥å¤šäºAttention+FFNï¼Œä½†ç”±äºå»é™¤äº†å¤šå¤´æœºåˆ¶å’ŒæŸäº›å½’ä¸€åŒ–å±‚ï¼Œå®é™…å¯æ¯”ã€‚</p>
<h4 id="32-flops">3.2 è®¡ç®—é‡åˆ†æï¼ˆFLOPsï¼‰</h4>
<p>å•ä¸ªGAUçš„å‰å‘ä¼ æ’­FLOPsï¼š</p>
<p><strong>æ­¥éª¤1</strong>ï¼šçº¿æ€§å˜æ¢ $U, V, \text{Base}$
\begin{equation}
\text{FLOPs}_1 = 3 \times (2n \times d \times e) = 6nde \tag{33}
\end{equation}</p>
<p><strong>æ­¥éª¤2</strong>ï¼šæ¿€æ´»å‡½æ•°ï¼ˆå¿½ç•¥ï¼Œç›¸å¯¹è¾ƒå°ï¼‰</p>
<p><strong>æ­¥éª¤3</strong>ï¼šæ³¨æ„åŠ›çŸ©é˜µ $QK^{\top}$
\begin{equation}
\text{FLOPs}_2 = 2n^2s \tag{34}
\end{equation}</p>
<p><strong>æ­¥éª¤4</strong>ï¼šSoftmaxï¼ˆå¿½ç•¥ï¼Œç›¸å¯¹è¾ƒå°ï¼‰</p>
<p><strong>æ­¥éª¤5</strong>ï¼šæ³¨æ„åŠ›å€¼ $AV$
\begin{equation}
\text{FLOPs}_3 = 2n^2e \tag{35}
\end{equation}</p>
<p><strong>æ­¥éª¤6</strong>ï¼šé—¨æ§ $Z \odot O$ï¼ˆé€å…ƒç´ ï¼Œå¿½ç•¥ï¼‰</p>
<p><strong>æ­¥éª¤7</strong>ï¼šè¾“å‡ºæŠ•å½± $W_O$
\begin{equation}
\text{FLOPs}_4 = 2ned \tag{36}
\end{equation}</p>
<p>æ€»FLOPsï¼ˆå– $e=2d, s=d/2$ï¼‰ï¼š
\begin{equation}
\text{FLOPs}_{GAU} = 6n \cdot d \cdot 2d + 2n^2 \cdot \frac{d}{2} + 2n^2 \cdot 2d + 2n \cdot 2d \cdot d \tag{37}
\end{equation}
\begin{equation}
= 12nd^2 + n^2d + 4n^2d + 4nd^2 = 16nd^2 + 5n^2d \tag{38}
\end{equation}</p>
<p><strong>å¯¹æ¯”æ ‡å‡†Attention</strong>ï¼š
\begin{equation}
\text{FLOPs}_{\text{Attention}} = 4nd^2 + 2n^2d + 2n^2d + 2nd^2 = 6nd^2 + 4n^2d \tag{39}
\end{equation}</p>
<p>FFNçš„FLOPsï¼š
\begin{equation}
\text{FLOPs}_{\text{FFN}} = 2n \cdot d \cdot 4d + 2n \cdot 4d \cdot d = 16nd^2 \tag{40}
\end{equation}</p>
<p>æ ‡å‡†Transformeræ€»è®¡ï¼š
\begin{equation}
\text{FLOPs}_{\text{Transformer}} = 22nd^2 + 4n^2d \tag{41}
\end{equation}</p>
<p>ä¸¤å±‚GAUï¼š
\begin{equation}
\text{FLOPs}_{2\times GAU} = 2(16nd^2 + 5n^2d) = 32nd^2 + 10n^2d \tag{42}
\end{equation}</p>
<p><strong>å¤æ‚åº¦å¯¹æ¯”</strong>ï¼š
- å½“ $n \ll d$ æ—¶ï¼Œ$\text{FLOPs}<em _text_Transformer="\text{Transformer">{2\times GAU} \approx 32nd^2$ vs $\text{FLOPs}</em> \approx 22nd^2$ï¼ŒGAUçº¦æ…¢1.45å€
- å½“ $n \approx d$ æ—¶ï¼Œä¸¤è€…ç›¸å½“
- å½“ $n \gg d$ æ—¶ï¼ŒGAUç”±äº $10n^2d$ vs $4n^2d$ çš„ä¼˜åŠ¿ï¼Œåœ¨é•¿åºåˆ—ä¸Šæ›´ä¼˜}</p>
<h4 id="33">3.3 æ˜¾å­˜å ç”¨åˆ†æ</h4>
<p><strong>æ¿€æ´»å€¼æ˜¾å­˜</strong>ï¼ˆéœ€è¦ä¿å­˜ç”¨äºåå‘ä¼ æ’­ï¼‰ï¼š
- $U, V, \text{Base}$: $3ne$
- $Z$: $ne$
- $Q, K$: $2ns$
- $A$: $n^2$ï¼ˆæ³¨æ„åŠ›çŸ©é˜µï¼‰
- $O$: $ne$</p>
<p>æ€»æ¿€æ´»æ˜¾å­˜ï¼š
\begin{equation}
M_{GAU} = 5ne + 2ns + n^2 \tag{43}
\end{equation}</p>
<p>å– $e=2d, s=d/2$ï¼š
\begin{equation}
M_{GAU} = 10nd + nd + n^2 = 11nd + n^2 \tag{44}
\end{equation}</p>
<p><strong>æ ‡å‡†Attention</strong>ï¼š
\begin{equation}
M_{\text{Attention}} = 4nd + n^2 \quad (\text{Q, K, V, A}) \tag{45}
\end{equation}</p>
<p>FFNæ˜¾å­˜ï¼ˆå‡è®¾ $d_{\text{ffn}}=4d$ï¼‰ï¼š
\begin{equation}
M_{\text{FFN}} = 4nd \tag{46}
\end{equation}</p>
<p>æ€»è®¡ï¼š
\begin{equation}
M_{\text{Transformer}} = 8nd + n^2 \tag{47}
\end{equation}</p>
<p>ä¸¤å±‚GAUï¼š
\begin{equation}
M_{2\times GAU} = 22nd + 2n^2 \tag{48}
\end{equation}</p>
<p>æ˜¾å­˜æ¯”ä¾‹ï¼š
\begin{equation}
\frac{M_{2\times GAU}}{M_{\text{Transformer}}} = \frac{22nd + 2n^2}{8nd + n^2} \tag{49}
\end{equation}</p>
<p>å½“ $n$ è¾ƒå¤§æ—¶ï¼Œ$\frac{M_{2\times GAU}}{M_{\text{Transformer}}} \to 2$ï¼Œæ˜¾å­˜çº¦2å€ã€‚</p>
<p><strong>ä¼˜åŒ–</strong>ï¼šé€šè¿‡æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆGradient Checkpointingï¼‰å¯ä»¥æƒè¡¡è®¡ç®—å’Œæ˜¾å­˜ï¼š
- ä¸ä¿å­˜ä¸­é—´æ¿€æ´» $U, V, Z$ ç­‰
- åå‘ä¼ æ’­æ—¶é‡æ–°è®¡ç®—
- æ˜¾å­˜å‡å°‘è‡³ï¼š$M_{GAU}^{\text{opt}} \approx n^2 + 2nd$</p>
<h3 id="4">4. è®­ç»ƒæŠ€å·§å’Œç¨³å®šæ€§</h3>
<h4 id="41">4.1 æƒé‡åˆå§‹åŒ–</h4>
<p>GAUä½¿ç”¨ä¿®æ”¹çš„Xavieråˆå§‹åŒ–ã€‚å¯¹äºæƒé‡çŸ©é˜µ $W \in \mathbb{R}^{m \times n}$ï¼š
\begin{equation}
W_{ij} \sim \mathcal{N}\left(0, \frac{2}{m + n}\right) \tag{50}
\end{equation}</p>
<p><strong>æ¨å¯¼ä¾æ®</strong>ï¼šå‡è®¾è¾“å…¥ $x \sim \mathcal{N}(0, \sigma_x^2)$ï¼Œè¾“å‡º $y = Wx$ï¼š
\begin{equation}
\text{Var}[y_i] = \text{Var}\left[\sum_{j=1}^m W_{ij}x_j\right] = \sum_{j=1}^m \text{Var}[W_{ij}]\text{Var}[x_j] = m \cdot \frac{2}{m+n} \cdot \sigma_x^2 \tag{51}
\end{equation}</p>
<p>å½“ $m=n$ æ—¶ï¼Œ$\text{Var}[y_i] = \sigma_x^2$ï¼Œä¿æŒæ–¹å·®ç¨³å®šã€‚</p>
<p><strong>æ·±å±‚è°ƒæ•´</strong>ï¼šå¯¹äºç¬¬ $\ell$ å±‚ï¼Œç¼©æ”¾åˆå§‹åŒ–ï¼š
\begin{equation}
W^{(\ell)} \sim \mathcal{N}\left(0, \frac{2}{(m+n)\sqrt{\ell}}\right) \tag{52}
\end{equation}</p>
<p>è¿™åŸºäºä»¥ä¸‹è§‚å¯Ÿï¼šæ·±å±‚ç½‘ç»œä¸­ï¼Œæ¢¯åº¦ä¼šéšå±‚æ•°ç´¯ç§¯ï¼Œé™¤ä»¥ $\sqrt{\ell}$ å¯ä»¥ç¨³å®šè®­ç»ƒã€‚</p>
<h4 id="42">4.2 å­¦ä¹ ç‡è°ƒåº¦</h4>
<p>GAU-Î±ä½¿ç”¨åˆ†æ®µçº¿æ€§è¡°å‡ï¼Œå®šä¹‰ä¸ºï¼š
\begin{equation}
\eta(t) = \begin{cases}
\eta_{\max} &amp; t \leq t_0 \
\eta_{\max} \cdot \frac{T - t}{T - t_0} &amp; t_0 &lt; t \leq T \
0 &amp; t &gt; T
\end{cases} \tag{53}
\end{equation}</p>
<p>å…¶ä¸­ $\eta_{\max}$ æ˜¯æœ€å¤§å­¦ä¹ ç‡ï¼Œ$t_0$ æ˜¯å¼€å§‹è¡°å‡çš„æ­¥æ•°ï¼Œ$T$ æ˜¯æ€»æ­¥æ•°ã€‚</p>
<p><strong>ä¸Warmupå¯¹æ¯”</strong>ï¼šæ ‡å‡†Warmupä¸ºï¼š
\begin{equation}
\eta_{\text{warmup}}(t) = \begin{cases}
\eta_{\max} \cdot \frac{t}{t_{\text{warmup}}} &amp; t \leq t_{\text{warmup}} \
\eta_{\max} &amp; t &gt; t_{\text{warmup}}
\end{cases} \tag{54}
\end{equation}</p>
<p>GAU-Î±ç”±äºæ›´å¥½çš„åˆå§‹åŒ–ï¼Œå¯ä»¥çœç•¥Warmupç›´æ¥ä½¿ç”¨æ’å®šå­¦ä¹ ç‡å†è¡°å‡ã€‚</p>
<h4 id="43-lamb">4.3 ä¼˜åŒ–å™¨ï¼šLAMB</h4>
<p>LAMBï¼ˆLayer-wise Adaptive Moments optimizer for Batch trainingï¼‰æ˜¯Adamçš„æ‰©å±•ï¼š
\begin{equation}
m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t \tag{55}
\end{equation}
\begin{equation}
v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2 \tag{56}
\end{equation}
\begin{equation}
\hat{m}_t = \frac{m_t}{1-\beta_1^t}, \quad \hat{v}_t = \frac{v_t}{1-\beta_2^t} \tag{57}
\end{equation}</p>
<p>Adamæ›´æ–°ï¼š
\begin{equation}
\theta_t^{\text{Adam}} = \theta_{t-1} - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} \tag{58}
\end{equation}</p>
<p>LAMBé¢å¤–çš„å±‚å½’ä¸€åŒ–ï¼š
\begin{equation}
r_1 = |\theta_{t-1}|<em t-1="t-1">2, \quad r_2 = \left|\frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}\right|_2 \tag{59}
\end{equation}
\begin{equation}
\theta_t^{\text{LAMB}} = \theta</em>
\end{equation}} - \eta \frac{r_1}{r_2} \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} \tag{60</p>
<p><strong>æ¨å¯¼æ„ä¹‰</strong>ï¼šæ¯”å€¼ $\frac{r_1}{r_2}$ ä½¿å¾—æ›´æ–°æ­¥é•¿ç›¸å¯¹äºå‚æ•°èŒƒæ•°è¿›è¡Œè°ƒæ•´ï¼Œé˜²æ­¢å¤§å‚æ•°å±‚æ›´æ–°è¿‡å¿«ã€‚</p>
<p><strong>æ”¶æ•›æ€§åˆ†æ</strong>ï¼šåœ¨å‡¸ä¼˜åŒ–è®¾ç½®ä¸‹ï¼ŒLAMBçš„æ”¶æ•›ç‡ä¸ºï¼š
\begin{equation}
\mathbb{E}[f(\theta_T) - f(\theta^*)] \leq \mathcal{O}\left(\frac{1}{\sqrt{T}}\right) \tag{61}
\end{equation}</p>
<h4 id="44">4.4 æ¢¯åº¦è£å‰ª</h4>
<p>å…¨å±€æ¢¯åº¦èŒƒæ•°è£å‰ªï¼š
\begin{equation}
g_{\text{clip}} = \begin{cases}
g &amp; |g|_2 \leq \tau \
\frac{\tau}{|g|_2} g &amp; |g|_2 &gt; \tau
\end{cases} \tag{62}
\end{equation}</p>
<p>å…¶ä¸­ $\tau$ æ˜¯è£å‰ªé˜ˆå€¼ï¼ˆé€šå¸¸å–1.0ï¼‰ã€‚</p>
<p><strong>æ¢¯åº¦çˆ†ç‚¸åˆ†æ</strong>ï¼šåœ¨æ·±åº¦ä¸º $L$ çš„ç½‘ç»œä¸­ï¼Œæ¢¯åº¦ä¼ æ’­æ»¡è¶³ï¼š
\begin{equation}
\frac{\partial \mathcal{L}}{\partial \theta^{(1)}} = \frac{\partial \mathcal{L}}{\partial \theta^{(L)}} \prod_{\ell=1}^{L-1} \frac{\partial \theta^{(\ell+1)}}{\partial \theta^{(\ell)}} \tag{63}
\end{equation}</p>
<p>è‹¥ $\left|\frac{\partial \theta^{(\ell+1)}}{\partial \theta^{(\ell)}}\right| &gt; 1$ï¼Œåˆ™æ¢¯åº¦æŒ‡æ•°å¢é•¿ã€‚è£å‰ªç¡®ä¿ï¼š
\begin{equation}
|g_{\text{clip}}|_2 \leq \tau \tag{64}
\end{equation}</p>
<h4 id="45-post-norm-vs-pre-norm">4.5 Post Norm vs Pre Norm</h4>
<p>GAU-Î±ä½¿ç”¨Post Normç»“æ„ï¼š
\begin{equation}
X_{\ell+1} = \text{Norm}(X_{\ell} + \text{GAU}(X_{\ell})) \tag{65}
\end{equation}</p>
<p>å¯¹æ¯”Pre Normï¼š
\begin{equation}
X_{\ell+1}^{\text{Pre}} = X_{\ell} + \text{GAU}(\text{Norm}(X_{\ell})) \tag{66}
\end{equation}</p>
<p><strong>æ¢¯åº¦æµåˆ†æ</strong>ï¼šPost Normçš„æ¢¯åº¦ï¼š
\begin{equation}
\frac{\partial \mathcal{L}}{\partial X_{\ell}} = \frac{\partial \mathcal{L}}{\partial X_{\ell+1}} \frac{\partial \text{Norm}(X_{\ell} + \text{GAU}(X_{\ell}))}{\partial X_{\ell}} \tag{67}
\end{equation}</p>
<p>Pre Normçš„æ¢¯åº¦ï¼š
\begin{equation}
\frac{\partial \mathcal{L}}{\partial X_{\ell}} = \frac{\partial \mathcal{L}}{\partial X_{\ell+1}} \left(I + \frac{\partial \text{GAU}(\text{Norm}(X_{\ell}))}{\partial X_{\ell}}\right) \tag{68}
\end{equation}</p>
<p>Pre Normç”±äº $I$ çš„å­˜åœ¨ï¼Œæ¢¯åº¦æ›´å®¹æ˜“ç›´æ¥ä¼ æ’­ï¼Œä½†Post Normåœ¨é…åˆå¥½çš„åˆå§‹åŒ–åï¼Œè®­ç»ƒæ›´ç¨³å®šä¸”æ•ˆæœæ›´å¥½ã€‚</p>
<h4 id="46-rms-norm">4.6 RMS Normç»†èŠ‚</h4>
<p>RMSNormç›¸æ¯”LayerNormçœç•¥äº†å‡å‡å€¼æ“ä½œï¼š
\begin{equation}
\text{LayerNorm}(x) = \frac{x - \mu}{\sigma} \cdot \gamma + \beta \tag{69}
\end{equation}
\begin{equation}
\text{RMSNorm}(x) = \frac{x}{\text{RMS}(x)} \cdot \gamma \tag{70}
\end{equation}</p>
<p>å…¶ä¸­ $\text{RMS}(x) = \sqrt{\frac{1}{d}\sum_{i=1}^d x_i^2}$ã€‚</p>
<p><strong>è®¡ç®—ä¼˜åŠ¿</strong>ï¼š
- LayerNorméœ€è¦ä¸¤éæ‰«æï¼ˆä¸€éè®¡ç®—å‡å€¼ï¼Œä¸€éè®¡ç®—æ–¹å·®ï¼‰
- RMSNormåªéœ€ä¸€éæ‰«æè®¡ç®—å¹³æ–¹å’Œ</p>
<p><strong>ç†è®ºåˆ†æ</strong>ï¼šå¯¹äºé›¶å‡å€¼è¾“å…¥ï¼ˆé€šè¿‡å‰ä¸€å±‚å½’ä¸€åŒ–ä¿è¯ï¼‰ï¼Œæœ‰ï¼š
\begin{equation}
\text{Var}[x] = \mathbb{E}[x^2] - (\mathbb{E}[x])^2 \approx \mathbb{E}[x^2] = \text{RMS}(x)^2 \tag{71}
\end{equation}</p>
<p>å› æ­¤RMSNormè¿‘ä¼¼LayerNormï¼Œä½†è®¡ç®—æ›´å¿«ã€‚</p>
<p><strong>å‚æ•°é‡å¯¹æ¯”</strong>ï¼š
- LayerNorm: $2d$ å‚æ•° ($\gamma, \beta$)
- RMSNorm: $d$ å‚æ•° (ä»… $\gamma$)</p>
<h3 id="5-softmax">5. ç†µä¸å˜æ€§Softmaxè¯¦ç»†æ¨å¯¼</h3>
<h4 id="51">5.1 é—®é¢˜è®¾å®š</h4>
<p>ç»™å®šæ³¨æ„åŠ›åˆ†æ•° $s_{ij} = \frac{q_i \cdot k_j}{\sqrt{d}}$ï¼Œæ ‡å‡†Softmaxï¼š
\begin{equation}
a_{ij} = \frac{\exp(s_{ij})}{\sum_{k=1}^n \exp(s_{ik})} \tag{72}
\end{equation}</p>
<p>ç†µå®šä¹‰ï¼š
\begin{equation}
H_i = -\sum_{j=1}^n a_{ij} \log a_{ij} \tag{73}
\end{equation}</p>
<p><strong>é—®é¢˜</strong>ï¼šå½“åºåˆ—é•¿åº¦ $n$ å¢åŠ æ—¶ï¼Œ$H_i$ ä¹Ÿä¼šå¢åŠ ï¼Œå¯¼è‡´æ³¨æ„åŠ›æ›´åˆ†æ•£ã€‚</p>
<h4 id="52">5.2 ç†µçš„æœŸæœ›å€¼</h4>
<p>å±•å¼€ç†µçš„è¡¨è¾¾å¼ï¼š
\begin{equation}
H_i = -\sum_{j=1}^n a_{ij} \left(s_{ij} - \log \sum_k e^{s_{ik}}\right) = \log \sum_k e^{s_{ik}} - \sum_j a_{ij} s_{ij} \tag{74}
\end{equation}</p>
<p>å®šä¹‰é…åˆ†å‡½æ•°ï¼š
\begin{equation}
Z_i = \sum_{k=1}^n e^{s_{ik}} \tag{75}
\end{equation}</p>
<p>åˆ™ï¼š
\begin{equation}
H_i = \log Z_i - \mathbb{E}<em ij="ij">{j \sim a_i}[s</em>
\end{equation}}] \tag{76</p>
<h4 id="53">5.3 ç‹¬ç«‹åŒåˆ†å¸ƒå‡è®¾</h4>
<p>å‡è®¾ $s_{ij}$ ç‹¬ç«‹åŒåˆ†å¸ƒï¼Œæœä»æŸåˆ†å¸ƒ $p(s)$ã€‚åˆ™ï¼š
\begin{equation}
\mathbb{E}[\log Z_i] = \mathbb{E}\left[\log \sum_{k=1}^n e^{s_k}\right] \tag{77}
\end{equation}</p>
<p>ä½¿ç”¨Jensenä¸ç­‰å¼ï¼š
\begin{equation}
\mathbb{E}[\log Z] = \mathbb{E}\left[\log \sum_{k=1}^n e^{s_k}\right] \geq \log \mathbb{E}\left[\sum_{k=1}^n e^{s_k}\right] = \log(n \mathbb{E}[e^s]) \tag{78}
\end{equation}</p>
<p>æ›´ç²¾ç¡®çš„ä¼°è®¡ä½¿ç”¨éç‚¹è¿‘ä¼¼ï¼š
\begin{equation}
\log \sum_{k=1}^n e^{s_k} \approx \log n + \log \mathbb{E}[e^s] + \mathcal{O}(1/n) \tag{79}
\end{equation}</p>
<h4 id="54">5.4 é«˜æ–¯å‡è®¾ä¸‹çš„æ¨å¯¼</h4>
<p>å‡è®¾ $s_{ij} \sim \mathcal{N}(\mu, \sigma^2)$ï¼Œåˆ™ï¼š
\begin{equation}
\mathbb{E}[e^s] = e^{\mu + \sigma^2/2} \tag{80}
\end{equation}</p>
<p>å› æ­¤ï¼š
\begin{equation}
\mathbb{E}[H_i] \approx \log n + \mu + \frac{\sigma^2}{2} - \mathbb{E}[\mathbb{E}<em ij="ij">{j \sim a_i}[s</em>
\end{equation}}]] \tag{81</p>
<p>å‡è®¾æ³¨æ„åŠ›é›†ä¸­åœ¨top-kä¸ªä½ç½®ï¼Œåˆ™ç¬¬äºŒé¡¹çº¦ä¸ºï¼š
\begin{equation}
\mathbb{E}[\mathbb{E}<em ij="ij">{j \sim a_i}[s</em>
\end{equation}}]] \approx \mu + c\sigma \tag{82</p>
<p>å…¶ä¸­ $c$ æ˜¯å¸¸æ•°ï¼ˆçº¦ä¸º1ï¼‰ã€‚ä»£å…¥å¾—ï¼š
\begin{equation}
\mathbb{E}[H_i] \approx \log n + \frac{\sigma^2}{2} - c\sigma \tag{83}
\end{equation}</p>
<p><strong>å…³é”®è§‚å¯Ÿ</strong>ï¼šç†µçš„ä¸»è¦ $n$ ä¾èµ–é¡¹æ˜¯ $\log n$ã€‚</p>
<h4 id="55">5.5 ç¼©æ”¾å› å­è®¾è®¡</h4>
<p>ä¸ºäº†æŠµæ¶ˆ $\log n$ çš„å½±å“ï¼Œå¼•å…¥ç¼©æ”¾å› å­ $\lambda(n)$ï¼š
\begin{equation}
a_{ij}^{\text{new}} = \frac{\exp(\lambda(n) s_{ij})}{\sum_k \exp(\lambda(n) s_{ik})} \tag{84}
\end{equation}</p>
<p>æ–°çš„ç†µï¼š
\begin{equation}
H_i^{\text{new}} = \log \sum_k e^{\lambda s_k} - \lambda \mathbb{E}<em ij="ij">{j \sim a_i^{\text{new}}}[s</em>
\end{equation}}] \tag{85</p>
<p>ä½¿ç”¨å‰é¢çš„è¿‘ä¼¼ï¼š
\begin{equation}
\log \sum_k e^{\lambda s_k} \approx \log n + \lambda\mu + \frac{\lambda^2\sigma^2}{2} \tag{86}
\end{equation}</p>
<p>ç¬¬äºŒé¡¹ï¼š
\begin{equation}
\lambda \mathbb{E}<em ij="ij">{j \sim a_i^{\text{new}}}[s</em>
\end{equation}}] \approx \lambda(\mu + c\sigma\sqrt{\lambda}) \tag{87</p>
<p>å…¶ä¸­ $\sqrt{\lambda}$ æ¥è‡ªäºsoftmaxåœ¨ç¼©æ”¾åçš„é”åŒ–æ•ˆåº”ã€‚</p>
<p>ä»£å…¥å¾—ï¼š
\begin{equation}
H_i^{\text{new}} \approx \log n + \lambda\mu + \frac{\lambda^2\sigma^2}{2} - \lambda\mu - c\sigma\lambda^{3/2} \tag{88}
\end{equation}
\begin{equation}
= \log n + \frac{\lambda^2\sigma^2}{2} - c\sigma\lambda^{3/2} \tag{89}
\end{equation}</p>
<p>ä¸ºäº†ä½¿ $H_i^{\text{new}}$ å¯¹ $n$ ä¸æ•æ„Ÿï¼Œéœ€è¦ï¼š
\begin{equation}
\frac{\partial H_i^{\text{new}}}{\partial n} \approx 0 \tag{90}
\end{equation}</p>
<p>å³ï¼š
\begin{equation}
\frac{1}{n} + \left(\lambda\sigma^2 - \frac{3c\sigma}{2}\lambda^{1/2}\right)\frac{d\lambda}{dn} \approx 0 \tag{91}
\end{equation}</p>
<p>è‹¥ $\lambda$ ä¸»å¯¼é¡¹ä¸ $\log n$ æˆæ­£æ¯”ï¼Œè®¾ $\lambda = \alpha \log n$ï¼š
\begin{equation}
\frac{d\lambda}{dn} = \frac{\alpha}{n} \tag{92}
\end{equation}</p>
<p>ä»£å…¥ï¼š
\begin{equation}
\frac{1}{n} + \frac{\alpha}{n}\left(\alpha\sigma^2\log n - \frac{3c\sigma}{2}\sqrt{\alpha\log n}\right) \approx 0 \tag{93}
\end{equation}</p>
<p>å½“ $n$ è¶³å¤Ÿå¤§æ—¶ï¼Œç¬¬ä¸€é¡¹å¯å¿½ç•¥ï¼Œå¾—ï¼š
\begin{equation}
\alpha\sigma^2\log n \approx \frac{3c\sigma}{2}\sqrt{\alpha\log n} \tag{94}
\end{equation}</p>
<p>è§£å¾—ï¼š
\begin{equation}
\alpha \approx \frac{9c^2}{4\sigma^2 \log n} \cdot \log n = \frac{9c^2}{4\sigma^2} \tag{95}
\end{equation}</p>
<p><strong>å®è·µé€‰æ‹©</strong>ï¼šå½’ä¸€åŒ–å $\sigma \approx 1$ï¼Œ$c \approx 1$ï¼Œå› æ­¤ï¼š
\begin{equation}
\lambda(n) = \kappa \log n \tag{96}
\end{equation}</p>
<p>å…¶ä¸­ $\kappa$ æ˜¯å¯è°ƒè¶…å‚æ•°ï¼Œå®éªŒä¸­å– $\kappa = \frac{1}{\log 512}$ ä½¿å¾— $n=512$ æ—¶é€€åŒ–ä¸ºæ ‡å‡†Softmaxã€‚</p>
<h4 id="56">5.6 ä¿¡æ¯è®ºè§£é‡Š</h4>
<p>ä»ä¿¡æ¯è®ºè§’åº¦ï¼Œç†µ $H$ åº¦é‡åˆ†å¸ƒçš„"ä¸ç¡®å®šæ€§"æˆ–"ä¿¡æ¯é‡"ã€‚</p>
<p><strong>äº’ä¿¡æ¯</strong>ï¼šæ³¨æ„åŠ›æœºåˆ¶å¯è§†ä¸º $Q$ å’Œ $K$ ä¹‹é—´çš„ä¿¡æ¯ä¼ é€’ï¼Œäº’ä¿¡æ¯ï¼š
\begin{equation}
I(Q; K) = H(K) - H(K|Q) \tag{97}
\end{equation}</p>
<p>å…¶ä¸­ï¼š
\begin{equation}
H(K|Q=q_i) = H_i = -\sum_j a_{ij} \log a_{ij} \tag{98}
\end{equation}</p>
<p>å½“ $n$ å¢åŠ æ—¶ï¼Œ$H(K)$ å¢åŠ ï¼ˆæ›´å¤šé€‰æ‹©ï¼‰ï¼Œä½†æˆ‘ä»¬å¸Œæœ› $H(K|Q)$ ä¿æŒä¸å˜ï¼ˆç»™å®šæŸ¥è¯¢åï¼Œå…³é”®tokençš„ä¸ç¡®å®šæ€§ä¸å˜ï¼‰ï¼Œä»è€Œï¼š
\begin{equation}
I(Q; K) \propto \log n \tag{99}
\end{equation}</p>
<p>äº’ä¿¡æ¯éš $n$ å¢é•¿ï¼Œè¿™æ˜¯åˆç†çš„ï¼ˆæ›´å¤štokenæä¾›æ›´å¤šä¿¡æ¯ï¼‰ã€‚</p>
<h3 id="6-attention">6. ä¸æ ‡å‡†Attentionçš„å¯¹æ¯”</h3>
<h4 id="61">6.1 å…¬å¼å¯¹æ¯”</h4>
<table>
<thead>
<tr>
<th>æ–¹é¢</th>
<th>æ ‡å‡†Attention</th>
<th>GAU-Î±</th>
</tr>
</thead>
<tbody>
<tr>
<td>æŸ¥è¯¢/é”®</td>
<td>$Q \neq K$</td>
<td>$Q = K$</td>
</tr>
<tr>
<td>å¤šå¤´</td>
<td>æ˜¯</td>
<td>å¦ï¼ˆå•å¤´ï¼‰</td>
</tr>
<tr>
<td>é—¨æ§</td>
<td>æ— </td>
<td>æœ‰ ($Z \odot O$)</td>
</tr>
<tr>
<td>ç¼©æ”¾</td>
<td>$1/\sqrt{d}$</td>
<td>$\frac{\log n}{\sqrt{d}\log 512}$</td>
</tr>
<tr>
<td>å½’ä¸€åŒ–</td>
<td>LayerNorm</td>
<td>RMSNorm</td>
</tr>
<tr>
<td>ä½ç½®ç¼–ç </td>
<td>å¯é€‰</td>
<td>RoPE</td>
</tr>
</tbody>
</table>
<h4 id="62">6.2 æ€§èƒ½å¯¹æ¯”æ¨å¯¼</h4>
<p><strong>æ ‡å‡†Attentionçš„æœ‰æ•ˆç§©</strong>ï¼š
æ³¨æ„åŠ›çŸ©é˜µ $A$ çš„ç§©æœ€å¤šä¸º $\min(n, d)$ï¼Œä½†å®é™…æœ‰æ•ˆç§©ç”±å¥‡å¼‚å€¼åˆ†å¸ƒå†³å®šï¼š
\begin{equation}
r_{\text{eff}} = \frac{(\sum_i \sigma_i)^2}{\sum_i \sigma_i^2} \tag{100}
\end{equation}</p>
<p><strong>GAUçš„æœ‰æ•ˆç§©</strong>ï¼šç”±äºé—¨æ§æœºåˆ¶ï¼ŒGAUçš„è¾“å‡ºå¯ä»¥è¡¨ç¤ºä¸ºï¼š
\begin{equation}
Y = Z \odot (AV) + \text{Base} \tag{101}
\end{equation}</p>
<p>æœ‰æ•ˆç§©å¢åŠ åˆ°ï¼š
\begin{equation}
r_{\text{eff}}^{\text{GAU}} \geq r_{\text{eff}}^{\text{Attention}} \tag{102}
\end{equation}</p>
<p>å› ä¸º $Z \odot (AV)$ å…è®¸é€ä½ç½®çš„ä¸åŒç¼©æ”¾ï¼Œå¢åŠ äº†è¡¨è¾¾èƒ½åŠ›ã€‚</p>
<h4 id="63">6.3 é•¿åº¦å¤–æ¨æ€§å¯¹æ¯”</h4>
<p><strong>æ ‡å‡†Attention</strong>ï¼šè®¾è®­ç»ƒé•¿åº¦ $n_{\text{train}} = 512$ï¼Œæµ‹è¯•é•¿åº¦ $n_{\text{test}} = 1024$ã€‚</p>
<p>ç†µå˜åŒ–ï¼š
\begin{equation}
\Delta H = H(n_{\text{test}}) - H(n_{\text{train}}) \approx \log \frac{n_{\text{test}}}{n_{\text{train}}} = \log 2 \approx 0.693 \tag{103}
\end{equation}</p>
<p>è¿™æ„å‘³ç€æ³¨æ„åŠ›æ›´åˆ†æ•£ï¼Œæ€§èƒ½ä¸‹é™ã€‚</p>
<p><strong>GAU-Î±</strong>ï¼šä½¿ç”¨ $\lambda(n) = \frac{\log n}{\log 512}$ï¼š
\begin{equation}
H^{\text{GAU}}(n) \approx \log n + C - \lambda(n) \cdot f(n) \tag{104}
\end{equation}</p>
<p>å…¶ä¸­ $f(n)$ æ˜¯å…³äº $n$ ç¼“æ…¢å˜åŒ–çš„å‡½æ•°ã€‚ä»£å…¥ $\lambda(n)$ï¼š
\begin{equation}
H^{\text{GAU}}(n) \approx \log n + C - \frac{\log n}{\log 512} \cdot f(n) \approx \text{const} \tag{105}
\end{equation}</p>
<p>å› æ­¤ç†µåŸºæœ¬ä¸å˜ï¼Œé•¿åº¦å¤–æ¨æ€§æ›´å¥½ã€‚</p>
<p><strong>å®éªŒéªŒè¯</strong>ï¼ˆè®ºæ–‡æ•°æ®ï¼‰ï¼š
\begin{equation}
\text{Accuracy}<em _text_Attention-E="\text{Attention-E">{\text{Attention-O}}(n=256) = 23.02\% \tag{106}
\end{equation}
\begin{equation}
\text{Accuracy}</em>
\end{equation}}}(n=256) = 34.04\% \tag{107</p>
<p>æå‡ï¼š
\begin{equation}
\Delta = \frac{34.04 - 23.02}{23.02} \approx 47.8\% \tag{108}
\end{equation}</p>
<h3 id="7">7. é«˜çº§è¯é¢˜</h3>
<h4 id="71-gau">7.1 GAUçš„æ¢¯åº¦æµåˆ†æ</h4>
<p>è€ƒè™‘æŸå¤± $\mathcal{L}$ å¯¹è¾“å…¥ $X$ çš„æ¢¯åº¦ï¼š
\begin{equation}
\frac{\partial \mathcal{L}}{\partial X} = \frac{\partial \mathcal{L}}{\partial Y} \frac{\partial Y}{\partial X} \tag{109}
\end{equation}</p>
<p>å±•å¼€ï¼š
\begin{equation}
\frac{\partial Y}{\partial X} = W_O^{\top} \frac{\partial}{\partial X}(Z \odot O + \text{Base}) \tag{110}
\end{equation}</p>
<p>åŒ…å«ä¸‰æ¡è·¯å¾„ï¼š
1. <strong>é—¨æ§è·¯å¾„</strong>ï¼š$\frac{\partial Z}{\partial X} = \frac{\partial \phi(U)}{\partial U} \frac{\partial U}{\partial X}$
2. <strong>æ³¨æ„åŠ›è·¯å¾„</strong>ï¼š$\frac{\partial O}{\partial X} = \frac{\partial (AV)}{\partial X}$
3. <strong>æ®‹å·®è·¯å¾„</strong>ï¼š$\frac{\partial \text{Base}}{\partial X} = W_{\text{base}}$</p>
<p>æ€»æ¢¯åº¦ï¼š
\begin{equation}
\frac{\partial \mathcal{L}}{\partial X} = W_O^{\top}\left(O \odot \frac{\partial Z}{\partial X} + Z \odot \frac{\partial O}{\partial X} + W_{\text{base}}\right) \tag{111}
\end{equation}</p>
<p><strong>æ¢¯åº¦èŒƒæ•°ä¼°è®¡</strong>ï¼šå‡è®¾å„é¡¹ç‹¬ç«‹ï¼š
\begin{equation}
\mathbb{E}\left[\left|\frac{\partial \mathcal{L}}{\partial X}\right|^2\right] \approx |W_O|^2 \left(|O|^2|\nabla Z|^2 + |Z|^2|\nabla O|^2 + |W_{\text{base}}|^2\right) \tag{112}
\end{equation}</p>
<p>ç”±äº $Z, O, \text{Base}$ éƒ½æœ‰ $\mathcal{O}(ne)$ çš„å…ƒç´ ï¼Œæ¢¯åº¦èŒƒæ•°ä¸º $\mathcal{O}(\sqrt{ne})$ï¼Œä¸æ ‡å‡†Attentionçš„ $\mathcal{O}(\sqrt{nd})$ ç›¸å½“ï¼ˆ$e \approx 2d$ï¼‰ã€‚</p>
<h4 id="72">7.2 ç†è®ºæ”¶æ•›æ€§</h4>
<p><strong>å‡è®¾</strong>ï¼šæŸå¤±å‡½æ•° $\mathcal{L}$ æ˜¯ $L$-å…‰æ»‘çš„ï¼Œå³ï¼š
\begin{equation}
|\nabla \mathcal{L}(\theta_1) - \nabla \mathcal{L}(\theta_2)| \leq L|\theta_1 - \theta_2| \tag{113}
\end{equation}</p>
<p>ä½¿ç”¨LAMBä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ $\eta &lt; \frac{1}{L}$ï¼Œç»è¿‡ $T$ æ­¥åï¼š
\begin{equation}
\min_{t \leq T} \mathbb{E}[|\nabla \mathcal{L}(\theta_t)|^2] \leq \frac{2(\mathcal{L}(\theta_0) - \mathcal{L}^*)}{\eta T} + \eta L \sigma^2 \tag{114}
\end{equation}</p>
<p>å…¶ä¸­ $\sigma^2$ æ˜¯æ¢¯åº¦æ–¹å·®ã€‚</p>
<p><strong>GAUçš„ä¼˜åŠ¿</strong>ï¼šç”±äºé—¨æ§æœºåˆ¶æä¾›äº†æ›´å¹³æ»‘çš„æŸå¤±é¢ï¼ˆå®éªŒè§‚å¯Ÿï¼‰ï¼Œ$L$ æ›´å°ï¼Œå…è®¸æ›´å¤§çš„å­¦ä¹ ç‡ã€‚</p>
<h4 id="73">7.3 è¡¨è¾¾èƒ½åŠ›åˆ†æ</h4>
<p><strong>å®šç†ï¼ˆéæ­£å¼ï¼‰</strong>ï¼šä¸¤å±‚GAUå¯ä»¥è¿‘ä¼¼ä»»æ„Attention+FFNç»„åˆã€‚</p>
<p><strong>è¯æ˜æ€è·¯</strong>ï¼š
1. FFNå¯ä»¥è¡¨ç¤ºä¸ºï¼š$\text{FFN}(x) = W_2 \sigma(W_1 x)$
2. GAUçš„ $Z \odot O$ å¯ä»¥æ¨¡æ‹Ÿé—¨æ§FFNï¼š$Z$ å¯¹åº” $\sigma(W_1 x)$ï¼Œ$O$ å¯¹åº” $W_2$
3. Attentionéƒ¨åˆ†ç›´æ¥å¯¹åº”
4. é€šè¿‡ä¸¤å±‚GAUï¼Œå¯ä»¥åˆ†åˆ«å¤„ç†Attentionå’ŒFFNåŠŸèƒ½</p>
<p><strong>é€šç”¨é€¼è¿‘</strong>ï¼šGAUä½œä¸ºéçº¿æ€§å˜æ¢ï¼Œæ»¡è¶³é€šç”¨é€¼è¿‘å®šç†çš„æ¡ä»¶ï¼ˆåŒ…å«éçº¿æ€§æ¿€æ´»å’Œè¶³å¤Ÿå®½åº¦ï¼‰ã€‚</p>
<h3 id="8">8. å®ç°ç»†èŠ‚å’Œä¼˜åŒ–</h3>
<h4 id="81">8.1 èåˆç®—å­</h4>
<p><strong>Softmaxèåˆ</strong>ï¼šå°†ç¼©æ”¾ã€æŒ‡æ•°ã€æ±‚å’Œã€é™¤æ³•èåˆä¸ºå•ä¸ªCUDA kernelï¼š
\begin{equation}
\text{FusedSoftmax}(s, \lambda, n) = \frac{\exp(\lambda s)}{\sum_k \exp(\lambda s_k)} \tag{115}
\end{equation}</p>
<p><strong>åŠ é€Ÿæ¯”</strong>ï¼šé€šè¿‡å‡å°‘å†…å­˜è®¿é—®ï¼Œèåˆç®—å­å¯è¾¾åˆ° $2\times$ åŠ é€Ÿã€‚</p>
<h4 id="82">8.2 æ··åˆç²¾åº¦è®­ç»ƒ</h4>
<p>ä½¿ç”¨FP16å­˜å‚¨æƒé‡å’Œæ¿€æ´»ï¼Œä½†ç´¯ç§¯æ¢¯åº¦ç”¨FP32ï¼š
\begin{equation}
\theta_t^{\text{FP32}} = \theta_{t-1}^{\text{FP32}} - \eta \cdot \text{FP32}(\nabla \mathcal{L}(\text{FP16}(\theta_{t-1}))) \tag{116}
\end{equation}</p>
<p><strong>åŠ¨æ€ç¼©æ”¾</strong>ï¼šä¸ºé¿å…ä¸‹æº¢ï¼Œæ¢¯åº¦ä¹˜ä»¥ç¼©æ”¾å› å­ $s$ï¼š
\begin{equation}
g_{\text{scaled}} = s \cdot g \tag{117}
\end{equation}</p>
<p>æ›´æ–°æ—¶é™¤ä»¥ $s$ï¼š
\begin{equation}
\theta_t = \theta_{t-1} - \eta \frac{g_{\text{scaled}}}{s} \tag{118}
\end{equation}</p>
<p>$s$ åŠ¨æ€è°ƒæ•´ï¼šè‹¥æ¢¯åº¦æº¢å‡ºï¼ˆå‡ºç°inf/nanï¼‰ï¼Œåˆ™ $s \leftarrow s/2$ï¼›è‹¥è¿ç»­1000æ­¥æ— æº¢å‡ºï¼Œåˆ™ $s \leftarrow 2s$ã€‚</p>
<h4 id="83">8.3 åˆ†å¸ƒå¼è®­ç»ƒ</h4>
<p><strong>æ•°æ®å¹¶è¡Œ</strong>ï¼šå°†batchåˆ†å‰²åˆ° $N$ ä¸ªGPUï¼Œæ¯ä¸ªGPUè®¡ç®—å±€éƒ¨æ¢¯åº¦ $g_i$ï¼Œç„¶åAllReduceæ±‚å¹³å‡ï¼š
\begin{equation}
g = \frac{1}{N}\sum_{i=1}^N g_i \tag{119}
\end{equation}</p>
<p><strong>æ¢¯åº¦ç´¯ç§¯</strong>ï¼šå½“GPUæ˜¾å­˜ä¸è¶³æ—¶ï¼Œç´¯ç§¯ $K$ ä¸ªmini-batchçš„æ¢¯åº¦ï¼š
\begin{equation}
g_{\text{accum}} = \frac{1}{K}\sum_{k=1}^K g_k \tag{120}
\end{equation}</p>
<p>æœ‰æ•ˆbatch sizeï¼š$B_{\text{eff}} = N \times K \times B_{\text{local}}$</p>
<h3 id="9">9. æ€»ç»“</h3>
<p>GAU-Î±é€šè¿‡ä»¥ä¸‹åˆ›æ–°å®ç°äº†"å¿«å¥½çœ"ï¼š
1. <strong>é—¨æ§æœºåˆ¶</strong>ï¼ˆå¼26ï¼‰ï¼šå¢å¼ºè¡¨è¾¾èƒ½åŠ›
2. <strong>ç†µä¸å˜æ€§Softmax</strong>ï¼ˆå¼17-18ï¼‰ï¼šæ”¹å–„é•¿åº¦å¤–æ¨
3. <strong>å•å¤´è®¾è®¡</strong>ï¼šå‡å°‘å‚æ•°å’Œè®¡ç®—
4. <strong>ä¼˜åŒ–çš„å½’ä¸€åŒ–</strong>ï¼ˆå¼70ï¼‰ï¼šæé«˜æ•ˆç‡
5. <strong>æ›´å¥½çš„åˆå§‹åŒ–</strong>ï¼ˆå¼52ï¼‰ï¼šç¨³å®šè®­ç»ƒ</p>
<p>è¿™äº›è®¾è®¡å…±åŒä½œç”¨ï¼Œä½¿GAU-Î±æˆä¸ºé«˜æ•ˆçš„Attentionæ›¿ä»£æ–¹æ¡ˆã€‚</p>
        </div>
    </div>
</body>
</html>