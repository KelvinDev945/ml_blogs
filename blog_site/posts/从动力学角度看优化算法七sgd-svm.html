<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ä»åŠ¨åŠ›å­¦è§’åº¦çœ‹ä¼˜åŒ–ç®—æ³•ï¼ˆä¸ƒï¼‰ï¼šSGD â‰ˆ SVM</title>
    <style>
* { margin: 0; padding: 0; box-sizing: border-box; }
body {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
    line-height: 1.6; color: #333; max-width: 900px; margin: 0 auto; padding: 20px; background: #f5f5f5;
}
.container { background: white; padding: 40px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
header { border-bottom: 2px solid #e0e0e0; padding-bottom: 20px; margin-bottom: 30px; }
h1 { color: #2c3e50; margin-bottom: 10px; font-size: 2em; }
.meta { color: #666; font-size: 0.9em; margin-bottom: 20px; }
.content { margin-top: 30px; overflow-wrap: break-word; }
.content h2 { color: #34495e; margin-top: 30px; margin-bottom: 15px; border-bottom: 1px solid #eee; padding-bottom: 5px; }
.content p { margin-bottom: 15px; }
.content pre { background: #f8f8f8; padding: 15px; border-radius: 5px; overflow-x: auto; border-left: 3px solid #3498db; margin: 15px 0; }
.content code { background: #f8f8f8; padding: 2px 5px; border-radius: 3px; font-family: monospace; font-size: 0.9em; }
.content blockquote { border-left: 4px solid #3498db; padding-left: 20px; margin: 20px 0; color: #555; font-style: italic; }
.content table { border-collapse: collapse; width: 100%; margin: 20px 0; }
.content th, .content td { border: 1px solid #ddd; padding: 10px; text-align: left; }
.back-link { display: inline-block; margin-bottom: 20px; color: #3498db; text-decoration: none; font-weight: 500; }
</style>
    
<script>
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\(', '\)']],
            displayMath: [['$$', '$$'], ['\[', '\]']],
            processEscapes: true
        }
    };
</script>
<script id="MathJax-script" async src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>
    <div class="container">
        <a href="../index.html" class="back-link">â† è¿”å›é¦–é¡µ</a>
        <header>
            <h1>ä»åŠ¨åŠ›å­¦è§’åº¦çœ‹ä¼˜åŒ–ç®—æ³•ï¼ˆä¸ƒï¼‰ï¼šSGD â‰ˆ SVM</h1>
            <div class="meta">ğŸ“… æœ€åæ›´æ–°: 2026-01-08 | ğŸ“„ å¤§å°: 45.3 KB</div>
        </header>
        <div class="content">
            <p><strong>åŸæ–‡é“¾æ¥</strong>: <a href="https://spaces.ac.cn/archives/8314">https://spaces.ac.cn/archives/8314</a></p>
<hr />
<h2 id="1">1. æ ¸å¿ƒç†è®ºã€å…¬ç†ä¸å†å²åŸºç¡€</h2>
<h3 id="11">1.1 è·¨å­¦ç§‘æ ¹æºï¼šä»ç¡¬é—´éš”åˆ°åŠ¨åŠ›å­¦æ”¶æ•›</h3>
<p>æ·±åº¦å­¦ä¹ çš„ä¸€ä¸ªæ ¸å¿ƒè°œé¢˜æ˜¯ï¼š<strong>ä¸ºä»€ä¹ˆè¿‡å‚æ•°åŒ–çš„æ¨¡å‹ï¼ˆå‚æ•°é‡è¿œå¤§äºæ ·æœ¬é‡ï¼‰èƒ½å¤Ÿæ³›åŒ–ï¼Ÿ</strong>
æŒ‰ç…§ä¼ ç»Ÿçš„ VC ç»´ç†è®ºï¼Œå‚æ•°è¶Šå¤šï¼Œæ¨¡å‹å¤æ‚åº¦è¶Šé«˜ï¼Œè¶Šå®¹æ˜“è¿‡æ‹Ÿåˆã€‚ä½†åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬å³ä½¿ä¸åŠ ä»»ä½•æ˜¾å¼çš„æ­£åˆ™åŒ–é¡¹ï¼ˆå¦‚ L2 Regularizationï¼‰ï¼ŒSGD è®­ç»ƒå‡ºçš„ç¥ç»ç½‘ç»œä¾ç„¶å…·æœ‰æä½³çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p>è¿™ä¸ªè°œé¢˜çš„ç­”æ¡ˆéšè—åœ¨ä¸¤ä¸ªçœ‹ä¼¼æ— å…³é¢†åŸŸçš„äº¤å‰ç‚¹ä¸Šï¼š
- <strong>ç»Ÿè®¡å­¦ä¹ ç†è®º (Statistical Learning Theory)</strong>ï¼š1990s Vapnik æå‡ºçš„æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰ç†è®ºè®¤ä¸ºï¼Œåˆ†ç±»å™¨çš„æ³›åŒ–è¯¯å·®ç•Œä¸â€œåˆ†ç±»é—´éš”ï¼ˆMarginï¼‰â€æˆåæ¯”ã€‚æœ€å¤§åŒ–é—´éš”æ˜¯æå‡æ³›åŒ–èƒ½åŠ›çš„æœ€å¼ºæ‰‹æ®µã€‚
- <strong>éçº¿æ€§åŠ¨åŠ›å­¦ (Nonlinear Dynamics)</strong>ï¼šSoudry ç­‰äººåœ¨ 2018 å¹´çš„å¼€åˆ›æ€§å·¥ä½œè¯æ˜ï¼Œåœ¨ä½¿ç”¨ Logistic Lossï¼ˆæˆ– Cross Entropyï¼‰è®­ç»ƒçº¿æ€§åˆ†ç±»å™¨æ—¶ï¼Œæ¢¯åº¦ä¸‹é™çš„åŠ¨åŠ›å­¦è½¨è¿¹ä¼šè‡ªåŠ¨æ”¶æ•›åˆ°æœ€å¤§é—´éš”æ–¹å‘ã€‚</p>
<p>è¿™æ„å‘³ç€ï¼š<strong>SGD è¿™ä¸€ä¼˜åŒ–ç®—æ³•æœ¬èº«ï¼Œå°±å†…åµŒäº†ä¸€ä¸ªéšå¼çš„ SVM æ±‚è§£å™¨ã€‚</strong></p>
<h3 id="12">1.2 å†å²ç¼–å¹´å²ï¼šä»ç¡¬é—´éš”åˆ°éšå¼åç½®</h3>
<ol>
<li><strong>1960s - æ„ŸçŸ¥æœºç®—æ³•</strong>ï¼šRosenblatt æå‡ºäº†æ„ŸçŸ¥æœºï¼Œä½†å®ƒåªèƒ½æ‰¾åˆ°ä»»æ„ä¸€ä¸ªè§£ï¼Œæ²¡æœ‰ä»»ä½•å…³äºâ€œæœ€ä¼˜è§£â€çš„ä¿è¯ã€‚</li>
<li><strong>1995 - SVM çš„é»„é‡‘æ—¶ä»£</strong>ï¼šVapnik æå‡ºäº†æœ€å¤§é—´éš”åˆ†ç±»å™¨ã€‚ä¸ºäº†æ±‚è§£å®ƒï¼Œæˆ‘ä»¬éœ€è¦å¼•å…¥æ‹‰æ ¼æœ—æ—¥å¯¹å¶å˜é‡ï¼Œå¹¶è§£å†³ä¸€ä¸ªå¤æ‚çš„äºŒæ¬¡è§„åˆ’ï¼ˆQPï¼‰é—®é¢˜ã€‚</li>
<li><strong>2017 - æ³›åŒ–ä¹‹è°œçš„çˆ†å‘</strong>ï¼šZhang ç­‰äººåœ¨ ICLR å‘è¡¨ã€ŠUnderstanding deep learning requires rethinking generalizationã€‹ï¼ŒæŒ‡å‡ºæ·±åº¦ç½‘ç»œå¯ä»¥è½»æ˜“è®°ä½éšæœºæ ‡ç­¾ï¼Œè¿™å½»åº•å‡»ç¢äº†åŸºäºæ¨¡å‹å®¹é‡çš„ä¼ ç»Ÿæ³›åŒ–ç†è®ºã€‚</li>
<li><strong>2018 - éšå¼åç½® (Implicit Bias) çš„å‘ç°</strong>ï¼šSoudry ç­‰äººåœ¨ <em>The Implicit Bias of Gradient Descent on Separable Data</em> ä¸­è¯æ˜ï¼Œåœ¨æ•°æ®çº¿æ€§å¯åˆ†çš„æƒ…å†µä¸‹ï¼ŒSGD è®­ç»ƒå‡ºçš„æƒé‡æ–¹å‘ $\boldsymbol{w}/|\boldsymbol{w}|$ ä¼šæ¸è¿‘æ”¶æ•›åˆ° SVM çš„è§£ã€‚</li>
<li><strong>2020s - æ·±åº¦ç½‘ç»œçš„æ¨å¹¿</strong>ï¼šGunasekarã€Lyu å’Œ Li ç­‰äººå°†è¿™ä¸€ç»“è®ºæ¨å¹¿åˆ°äº†æ·±åº¦çº¿æ€§ç½‘ç»œå’Œå¯¹è§’çº¿æ€§ç½‘ç»œï¼Œç”šè‡³å‘ç°äº†åœ¨çŸ©é˜µåˆ†è§£ä»»åŠ¡ä¸­ SGD ä¼šå¯»æ‰¾æœ€å°æ ¸èŒƒæ•°ï¼ˆNuclear Normï¼‰è§£ã€‚</li>
</ol>
<h3 id="13">1.3 ä¸¥è°¨å…¬ç†åŒ–ï¼šéšå¼ä¼˜åŒ–çš„æ•°å­¦åŸºçŸ³</h3>
<p>ä¸ºäº†ä¸¥æ ¼è¯æ˜ SGD â‰ˆ SVMï¼Œæˆ‘ä»¬éœ€è¦ä»¥ä¸‹å…¬ç†ä½“ç³»ï¼š</p>
<div class="theorem-box">

### æ ¸å¿ƒå…¬ç† 1ï¼šçº¿æ€§å¯åˆ†æ€§ (Linear Separability)
å‡è®¾æ•°æ®é›† $\mathcal{D} = \{(\boldsymbol{x}_i, y_i)\}_{i=1}^n$ æ˜¯çº¿æ€§å¯åˆ†çš„ã€‚å³å­˜åœ¨è‡³å°‘ä¸€ä¸ªå•ä½å‘é‡ $\boldsymbol{u}^*$ï¼Œä½¿å¾—å¯¹äºæ‰€æœ‰ $i$ï¼š
\begin{equation} y_i \langle \boldsymbol{u}^*, \boldsymbol{x}_i \rangle \geq \gamma > 0 \tag{1} \end{equation}
è¿™ä¿è¯äº†æŸå¤±å‡½æ•°å¯ä»¥è¢«ä¼˜åŒ–åˆ° 0ï¼Œä¸”å‚æ•°æ¨¡é•¿ä¼šè¶‹äºæ— ç©·å¤§ã€‚

### æ ¸å¿ƒå…¬ç† 2ï¼šæŒ‡æ•°å°¾éƒ¨æŸå¤± (Exponential Tail Loss)
æŸå¤±å‡½æ•° $\ell(z)$ å¿…é¡»å…·æœ‰æŒ‡æ•°è¡°å‡çš„å°¾éƒ¨ç‰¹æ€§ï¼Œä¾‹å¦‚ Logistic Loss $\ell(z) = \log(1+e^{-z})$ æˆ–æŒ‡æ•°æŸå¤± $e^{-z}$ã€‚
\begin{equation} \lim_{z \to \infty} \ell(z) e^{\alpha z} = C \tag{2} \end{equation}
è¿™æ„å‘³ç€å½“åˆ†ç±»ç½®ä¿¡åº¦æé«˜æ—¶ï¼Œæ¢¯åº¦è™½ç„¶å¾®å°ï¼Œä½†æ°¸è¿œä¸ä¼šæ¶ˆå¤±ã€‚æ­£æ˜¯è¿™å¾®å¼±çš„â€œå°¾éƒ¨æ¢¯åº¦â€ï¼Œåœ¨æ¼«é•¿çš„è®­ç»ƒå²æœˆä¸­å¡‘é€ äº†å‚æ•°çš„æ–¹å‘ã€‚

### æ ¸å¿ƒå…¬ç† 3ï¼šæ¢¯åº¦æµè¿‘ä¼¼ (Gradient Flow Approximation)
æˆ‘ä»¬ä¸»è¦ç ”ç©¶è¿ç»­æ—¶é—´çš„æ¢¯åº¦æµåŠ¨åŠ›å­¦ï¼š
\begin{equation} \dot{\boldsymbol{\theta}}(t) = -\nabla L(\boldsymbol{\theta}(t)) \tag{3} \end{equation}
è™½ç„¶ç¦»æ•£çš„ SGD ä¼šå¼•å…¥å™ªå£°ï¼Œä½†å¤§é‡ç ”ç©¶è¡¨æ˜ï¼Œåªè¦å­¦ä¹ ç‡è¶³å¤Ÿå°ï¼Œç¦»æ•£è½¨è¿¹çš„æ¸è¿‘è¡Œä¸ºä¸è¿ç»­æµæ˜¯ä¸€è‡´çš„ã€‚

</div>

<h3 id="14">1.4 è®¾è®¡å“²å­¦ï¼šæ— ä¸ºè€Œæ²»çš„æ­£åˆ™åŒ–</h3>
<p>SGD â‰ˆ SVM çš„è®¾è®¡å“²å­¦æ˜¯ï¼š<strong>â€œä¸éœ€è¦æ˜¾å¼çš„çº¦æŸï¼Œæ¼”åŒ–æœ¬èº«å°±æ˜¯ä¸€ç§é€‰æ‹©ã€‚â€</strong>
ä¼ ç»Ÿçš„ SVM éœ€è¦æˆ‘ä»¬æ‰‹åŠ¨å†™ä¸‹ $\min |\boldsymbol{w}|^2$ çš„ç›®æ ‡å‡½æ•°ã€‚è€Œ SGD å‘Šè¯‰æˆ‘ä»¬ï¼Œä½ ä¸éœ€è¦å‘Šè¯‰æ¨¡å‹å»â€œæœ€å°åŒ–èŒƒæ•°â€æˆ–â€œæœ€å¤§åŒ–é—´éš”â€ï¼Œä½ åªéœ€è¦ç»™å®ƒä¸€ä¸ªæŒ‡æ•°å‹çš„æŸå¤±å‡½æ•°ï¼Œç„¶åè®©å®ƒä¸€ç›´è·‘ä¸‹å»ã€‚
éšç€å‚æ•°æ¨¡é•¿ $|\boldsymbol{\theta}| \to \infty$ï¼ŒæŸå¤±å‡½æ•°çš„å‡ ä½•æ€§è´¨ä¼šè‡ªåŠ¨â€œæŒ¤å‹â€å‚æ•°çš„æ–¹å‘ï¼Œè¿«ä½¿å®ƒå¯¹é½åˆ°é‚£ä¸ªæœ€å®½ã€æœ€ç¨³å¥çš„åˆ†ç±»ç•Œé¢ä¸Šã€‚è¿™æ˜¯ä¸€ç§<strong>â€œé€šè¿‡è¿‡ç¨‹å®šä¹‰ç»“æœâ€</strong>çš„æ·±åˆ»å“²å­¦ã€‚</p>
<hr />
<h2 id="2">2. ä¸¥è°¨çš„æ ¸å¿ƒæ•°å­¦æ¨å¯¼</h2>
<p>æœ¬èŠ‚å°†é€šè¿‡è¯¦å°½çš„æé™åˆ†æï¼Œä»åŠ¨åŠ›å­¦æ–¹ç¨‹æ¨å¯¼å‡º KKT æ¡ä»¶çš„æ¶Œç°ã€‚è¿™æ˜¯ä¸€åœºä»å¾®ç§¯åˆ†åˆ°å‡¸ä¼˜åŒ–çš„åä¸½å†’é™©ã€‚</p>
<h3 id="21">2.1 é—®é¢˜çš„åŠ¨åŠ›å­¦å»ºæ¨¡</h3>
<p>è®¾äºŒåˆ†ç±»æ•°æ®é›†ä¸º ${(\boldsymbol{x}<em i="1">i, y_i)}</em>}^n$ã€‚ä¸ºäº†ç®€åŒ–ç¬¦å·ï¼Œæˆ‘ä»¬å°† $y_i$ å¸æ”¶è¿› $\boldsymbol{x<em i="1">i$ ä¸­ï¼Œå³å‡è®¾å¯¹äºæ‰€æœ‰æ ·æœ¬ï¼Œç›®æ ‡æ˜¯ $\langle \boldsymbol{\theta}, \boldsymbol{x}_i \rangle &gt; 0$ã€‚
æŸå¤±å‡½æ•°ä¸º Logistic Lossï¼š
\begin{equation} L(\boldsymbol{\theta}) = \sum</em>}^n \ell(\langle \boldsymbol{\theta}, \boldsymbol{x<em i="1">i \rangle) = \sum</em>}^n \log(1 + e^{-\langle \boldsymbol{\theta}, \boldsymbol{x}_i \rangle}) \tag{4} \end{equation</p>
<div class="derivation-box">

### æ¨å¯¼ 7.1ï¼šæ¢¯åº¦çš„æ¸è¿‘å±•å¼€ä¸æ¨¡é•¿å‘æ•£

**æ­¥éª¤ 1ï¼šè®¡ç®—æ¢¯åº¦è¡¨è¾¾å¼**
å¯¹ $\boldsymbol{\theta}$ æ±‚å¯¼ï¼š
\begin{equation} \nabla L(\boldsymbol{\theta}) = \sum_{i=1}^n \ell'(\langle \boldsymbol{\theta}, \boldsymbol{x}_i \rangle) \boldsymbol{x}_i = \sum_{i=1}^n \frac{-e^{-\langle \boldsymbol{\theta}, \boldsymbol{x}_i \rangle}}{1 + e^{-\langle \boldsymbol{\theta}, \boldsymbol{x}_i \rangle}} \boldsymbol{x}_i \tag{5} \end{equation}

**æ­¥éª¤ 2ï¼šè€ƒè™‘è®­ç»ƒåæœŸçš„æ¸è¿‘è¡Œä¸º**
ç”±äºæ•°æ®å¯åˆ†ï¼Œéšç€è®­ç»ƒè¿›è¡Œï¼Œ$L \to 0$ï¼Œè¿™æ„å‘³ç€å¯¹äºæ‰€æœ‰ $i$ï¼Œ$\langle \boldsymbol{\theta}, \boldsymbol{x}_i \rangle \to +\infty$ã€‚
åœ¨ $z \to \infty$ æ—¶ï¼Œåˆ†æ¯ $1 + e^{-z} \to 1$ã€‚å› æ­¤æ¢¯åº¦å¯ä»¥è¿‘ä¼¼ä¸ºï¼š
\begin{equation} \nabla L(\boldsymbol{\theta}) \approx -\sum_{i=1}^n e^{-\langle \boldsymbol{\theta}, \boldsymbol{x}_i \rangle} \boldsymbol{x}_i \tag{6} \end{equation}

**æ­¥éª¤ 3ï¼šå‚æ•°æ¨¡é•¿çš„å¢é•¿è§„å¾‹**
è€ƒè™‘æ¨¡é•¿å¹³æ–¹ $\|\boldsymbol{\theta}\|^2$ çš„å˜åŒ–ç‡ï¼š
\begin{equation} \frac{d}{dt} \|\boldsymbol{\theta}\|^2 = 2 \langle \boldsymbol{\theta}, \dot{\boldsymbol{\theta}} \rangle = -2 \langle \boldsymbol{\theta}, \nabla L \rangle \tag{7} \end{equation}
ä»£å…¥ (6) çš„è¿‘ä¼¼ï¼š
\begin{equation} \frac{d}{dt} \|\boldsymbol{\theta}\|^2 \approx 2 \sum_{i=1}^n \langle \boldsymbol{\theta}, \boldsymbol{x}_i \rangle e^{-\langle \boldsymbol{\theta}, \boldsymbol{x}_i \rangle} \tag{8} \end{equation}
ç”±äºå‡½æ•° $f(u) = u e^{-u}$ åœ¨ $u \to \infty$ æ—¶è¶‹äº 0ï¼Œè¿™æ„å‘³ç€æ¨¡é•¿çš„å¢é•¿é€Ÿåº¦ $\frac{d}{dt} \|\boldsymbol{\theta}\|^2$ ä¼šéšæ—¶é—´è¡°å‡ã€‚
ä¸¥æ ¼çš„æ¨å¯¼è¡¨æ˜ï¼Œ$\|\boldsymbol{\theta}(t)\| \sim \ln t$ã€‚è¿™æ˜¯ä¸€ä¸ªææ…¢çš„å¢é•¿é€Ÿåº¦ï¼Œä½†å®ƒç¡®å®å‘æ•£ã€‚

</div>

<h3 id="22">2.2 æ ¸å¿ƒå¼•ç†ï¼šæ”¯æŒå‘é‡çš„ä¸»å¯¼åœ°ä½</h3>
<p>å½“æ¨¡é•¿è¶‹äºæ— ç©·æ—¶ï¼Œè™½ç„¶æ‰€æœ‰æ ·æœ¬çš„æ¢¯åº¦è´¡çŒ®éƒ½åœ¨å‡å°ï¼Œä½†å®ƒä»¬å‡å°çš„<strong>é€Ÿåº¦</strong>æˆªç„¶ä¸åŒã€‚</p>
<div class="derivation-box">

### æ¨å¯¼ 7.2ï¼šè°ä¸»å¯¼äº†æ–¹å‘ï¼Ÿ

**æ­¥éª¤ 1ï¼šåˆ†è§£æ¨¡é•¿ä¸æ–¹å‘**
ä»¤ $\boldsymbol{\theta}(t) = \rho(t) \boldsymbol{u}(t)$ï¼Œå…¶ä¸­ $\rho(t) = \|\boldsymbol{\theta}(t)\|$ æ˜¯æ¨¡é•¿ï¼Œ$\boldsymbol{u}(t)$ æ˜¯å•ä½æ–¹å‘å‘é‡ã€‚
æˆ‘ä»¬å°†å…³æ³¨ $\boldsymbol{u}(t)$ åœ¨ $t \to \infty$ æ—¶çš„æé™ã€‚

**æ­¥éª¤ 2ï¼šè¯†åˆ«â€œæœ€æ…¢è¡°å‡é¡¹â€**
è§‚å¯Ÿæ¢¯åº¦è¿‘ä¼¼å…¬å¼ (6)ï¼š$-\nabla L \approx \sum_{i=1}^n e^{-\rho \langle \boldsymbol{u}, \boldsymbol{x}_i \rangle} \boldsymbol{x}_i$ã€‚
å®šä¹‰ç¬¬ $i$ ä¸ªæ ·æœ¬çš„å‡ ä½•é—´éš”ä¸º $\gamma_i = \langle \boldsymbol{u}, \boldsymbol{x}_i \rangle$ã€‚
æ¢¯åº¦çš„æ–¹å‘ç”±æŒ‡æ•°é¡¹ $e^{-\rho \gamma_i}$ å†³å®šã€‚
æ˜¾ç„¶ï¼Œ**æ‹¥æœ‰æœ€å°é—´éš” $\gamma_{\min}$ çš„æ ·æœ¬ï¼ˆå³æ”¯æŒå‘é‡ï¼‰**ï¼Œå…¶æŒ‡æ•°è¡°å‡æœ€æ…¢ï¼Œåœ¨æ¢¯åº¦å’Œä¸­å æ¯”æœ€å¤§ã€‚

**æ­¥éª¤ 3ï¼šæé™æ–¹å‘çš„çº¿æ€§ç»„åˆ**
ä»¤ $\mathcal{S}$ ä¸ºå…·æœ‰æœ€å°é—´éš”çš„æ ·æœ¬é›†åˆï¼ˆæ”¯æŒå‘é‡é›†ï¼‰ã€‚å½“ $\rho \to \infty$ æ—¶ï¼š
\begin{equation} -\nabla L(\boldsymbol{\theta}) \propto \sum_{i \in \mathcal{S}} e^{-\rho \gamma_{\min}} \boldsymbol{x}_i + \sum_{j \notin \mathcal{S}} o(e^{-\rho \gamma_{\min}}) \boldsymbol{x}_j \tag{9} \end{equation}
è¿™æ„å‘³ç€ï¼Œæ¢¯åº¦çš„æ–¹å‘æ¸æ¸æ”¶æ•›åˆ°æ”¯æŒå‘é‡çš„éè´Ÿçº¿æ€§ç»„åˆï¼š
\begin{equation} \boldsymbol{d}_{\infty} = \lim_{t \to \infty} \frac{-\nabla L}{\|-\nabla L\|} \in \text{Cone}(\lbrace\boldsymbol{x}_i\rbrace_{i \in \mathcal{S}}) \tag{10} \end{equation}

</div>

<h3 id="23-svm-kkt">2.3 å¯¹å¶åŸç†ï¼šSVM çš„ KKT æ¡ä»¶å†ç°</h3>
<p>ä¸ºä»€ä¹ˆæ¢¯åº¦æ–¹å‘çš„æé™ä¸€å®šæ˜¯ SVM çš„è§£ï¼Ÿè®©æˆ‘ä»¬çœ‹çœ‹ SVM çš„å¯¹å¶é—®é¢˜ã€‚</p>
<div class="formula-explanation">

### SVM å¯¹å¶æ€§ä¸æ¢¯åº¦æµçš„æ•°å­¦åŒæ„

**1. ç¡¬é—´éš” SVM çš„åŸé—®é¢˜**ï¼š
\begin{equation} \min_{\boldsymbol{w}} \|\boldsymbol{w}\|^2 \quad \text{s.t.} \quad \langle \boldsymbol{w}, \boldsymbol{x}_i \rangle \geq 1, \forall i \tag{11} \end{equation}

**2. KKT æ¡ä»¶**ï¼š
æœ€ä¼˜è§£ $\boldsymbol{w}^*$ å¿…é¡»æ»¡è¶³ï¼š
- **å¹³ç¨³æ€§**ï¼š$\boldsymbol{w}^* = \sum_{i=1}^n \alpha_i \boldsymbol{x}_i$ï¼Œå…¶ä¸­ $\alpha_i \geq 0$ã€‚
- **äº’è¡¥æ¾å¼›**ï¼š$\alpha_i (\langle \boldsymbol{w}^*, \boldsymbol{x}_i \rangle - 1) = 0$ã€‚å³åªæœ‰æ”¯æŒå‘é‡ï¼ˆ$\langle \boldsymbol{w}^*, \boldsymbol{x}_i \rangle = 1$ï¼‰çš„ $\alpha_i > 0$ã€‚

**3. æ¢¯åº¦æµçš„éšå¼ KKT**ï¼š
å›åˆ° (9) å¼ï¼Œæˆ‘ä»¬å‘ç°æ¢¯åº¦æµçš„æ–¹å‘ $\boldsymbol{u}(t)$ æ­£æ˜¯è¢«æ”¯æŒå‘é‡é›†åˆ $\mathcal{S}$ çš„çº¿æ€§ç»„åˆæ‰€é©±åŠ¨ã€‚
åœ¨åŠ¨åŠ›å­¦çš„å¹³è¡¡æ€ï¼Œæ–¹å‘å‘é‡ $\boldsymbol{u}$ çš„å˜åŒ–ç‡ä¸º 0ï¼Œè¿™æ„å‘³ç€ $\boldsymbol{u}$ å¿…é¡»ä¸ç´¯ç§¯æ¢¯åº¦çš„æ–¹å‘ä¸€è‡´ã€‚
Soudry (2018) ä¸¥æ ¼è¯æ˜äº†ï¼š
\begin{equation} \lim_{t \to \infty} \frac{\boldsymbol{\theta}(t)}{\|\boldsymbol{\theta}(t)\|} = \frac{\boldsymbol{w}_{\text{SVM}}}{\|\boldsymbol{w}_{\text{SVM}}\|} \tag{12} \end{equation}
è¿™å°±æ˜¯è‘—åçš„ **Directional Convergence Theorem**ã€‚

</div>

<h3 id="24">2.4 æ–¹å‘åŠ¨åŠ›å­¦æ–¹ç¨‹çš„æ¨å¯¼</h3>
<p>æˆ‘ä»¬å¯ä»¥ç›´æ¥å†™å‡ºæ–¹å‘å‘é‡ $\boldsymbol{u}(t)$ çš„å¾®åˆ†æ–¹ç¨‹ï¼Œä»è€Œæ›´ç›´è§‚åœ°çœ‹åˆ°å®ƒå¦‚ä½•å¯»æ‰¾æœ€å¤§é—´éš”ã€‚</p>
<div class="derivation-box">

### æ¨å¯¼ 7.3ï¼šæ–¹å‘æ¼”åŒ–çš„å¾®åˆ†æ–¹ç¨‹

**æ­¥éª¤ 1ï¼šåˆ©ç”¨å•†æ³•åˆ™æ±‚å¯¼**
\begin{equation} \dot{\boldsymbol{u}} = \frac{d}{dt} \left( \frac{\boldsymbol{\theta}}{\|\boldsymbol{\theta}\|} \right) = \frac{\dot{\boldsymbol{\theta}} \|\boldsymbol{\theta}\| - \boldsymbol{\theta} \frac{d}{dt}\|\boldsymbol{\theta}\|}{\|\boldsymbol{\theta}\|^2} \tag{13} \end{equation}
æ³¨æ„ $\frac{d}{dt}\|\boldsymbol{\theta}\| = \langle \boldsymbol{u}, \dot{\boldsymbol{\theta}} \rangle$ã€‚

**æ­¥éª¤ 2ï¼šä»£å…¥æ¢¯åº¦æµ $\dot{\boldsymbol{\theta}} = -\nabla L$**
\begin{equation} \dot{\boldsymbol{u}} = \frac{1}{\rho} \left( -\nabla L - \boldsymbol{u} \langle \boldsymbol{u}, -\nabla L \rangle \right) \tag{14} \end{equation}
è¿™å¯ä»¥ç®€å†™ä¸ºæ¢¯åº¦çš„æŠ•å½±å½¢å¼ï¼š
\begin{equation} \dot{\boldsymbol{u}} = -\frac{1}{\rho} (I - \boldsymbol{u}\boldsymbol{u}^T) \nabla L \tag{15} \end{equation}
å…¶ä¸­ $I - \boldsymbol{u}\boldsymbol{u}^T$ æ˜¯å‘åˆ‡å¹³é¢ï¼ˆå‚ç›´äº $\boldsymbol{u}$ çš„å¹³é¢ï¼‰çš„æŠ•å½±çŸ©é˜µã€‚

**æ­¥éª¤ 3ï¼šç‰©ç†æ„ä¹‰**
æ–¹ç¨‹ (15) è¯´æ˜ï¼Œæ–¹å‘ $\boldsymbol{u}$ çš„å˜åŒ–ç”±**æŸå¤±å‡½æ•°çš„æ¢¯åº¦åœ¨åˆ‡å‘ä¸Šçš„åˆ†é‡**é©±åŠ¨ã€‚
å½“ $\boldsymbol{u}$ è°ƒæ•´åˆ°ä½¿å¾—æ‰€æœ‰æ”¯æŒå‘é‡çš„æ¢¯åº¦åˆæˆåŠ›å‚ç›´äºçƒé¢æ—¶ï¼ˆå³æ— æ³•å†åœ¨çƒé¢ä¸Šæ‰¾åˆ°ä¸‹é™æ–¹å‘ï¼‰ï¼Œ$\dot{\boldsymbol{u}}$ å˜ä¸º 0ï¼Œæ­¤æ—¶å³è¾¾åˆ°æœ€å¤§é—´éš”è§£ã€‚

</div>

<h3 id="25">2.5 æ¸è¿‘æ”¶æ•›é€Ÿç‡çš„ç²¾ç¡®åˆ†æ</h3>
<p>ä¸ä»…è¦è¯æ˜æ”¶æ•›ï¼Œè¿˜è¦çŸ¥é“æ”¶æ•›æœ‰å¤šæ…¢ã€‚</p>
<div class="step-by-step">

<div class="step">
**æŸå¤±è¡°å‡é€Ÿç‡**ï¼š
å·²çŸ¥ $\rho(t) \sim \ln t$ã€‚ç”±äº $L \approx e^{-\rho \gamma}$ï¼Œæ‰€ä»¥ $L(t) \approx 1/t$ã€‚
</div>

<div class="step">
**é—´éš”æ”¶æ•›é€Ÿç‡**ï¼š
è®¾æœ€ä¼˜é—´éš”ä¸º $\gamma^*$ï¼Œå½“å‰é—´éš”ä¸º $\gamma(t)$ã€‚
Nacson (2019) è¯æ˜äº†ï¼š
\begin{equation} \gamma^* - \gamma(t) \leq \mathcal{O}\left( \frac{1}{\ln t} \right) \tag{16} \end{equation}
</div>

<div class="step">
**ä»¤äººç»æœ›çš„æ…¢**ï¼š
$1/\ln t$ çš„æ”¶æ•›é€Ÿåº¦æ„å‘³ç€ï¼šå¦‚æœä½ æƒ³è®©é—´éš”è¯¯å·®å‡åŠï¼Œä½ éœ€è¦è®­ç»ƒçš„æ—¶é—´æ˜¯åŸæ¥çš„å¹³æ–¹å€ï¼ˆä¾‹å¦‚ä» $10^4$ æ­¥å¢åŠ åˆ° $10^8$ æ­¥ï¼‰ï¼
è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ·±åº¦å­¦ä¹ æ¨¡å‹è™½ç„¶èƒ½å­¦åˆ°æœ€å¤§é—´éš”ï¼Œä½†éœ€è¦æé•¿çš„è®­ç»ƒæ—¶é—´æ¥"ç²¾ä¿®"è¾¹ç•Œã€‚
</div>

</div>

<h3 id="26-softmax">2.6 å¤šç±»åˆ†ç±»çš„æ¨å¹¿ï¼šä»äºŒåˆ†ç±»åˆ° Softmax</h3>
<p>ä»¥ä¸Šåˆ†æä¸»è¦é’ˆå¯¹äºŒåˆ†ç±»ã€‚é‚£ä¹ˆå¤šç±»åˆ†ç±»ï¼ˆ$K &gt; 2$ï¼‰çš„æƒ…å†µå‘¢ï¼Ÿ</p>
<div class="derivation-box">

### æ¨å¯¼ 7.6ï¼šå¤šç±» Logistic å›å½’çš„éšå¼åç½®

**æ­¥éª¤ 1ï¼šSoftmax æŸå¤±çš„æ•°å­¦å½¢å¼**
å¯¹äº $K$ ç±»åˆ†ç±»ï¼Œæ¨¡å‹ä¸º $\boldsymbol{W} \in \mathbb{R}^{K \times d}$ï¼Œæ¯ä¸€è¡Œ $\boldsymbol{w}_k$ å¯¹åº”ç¬¬ $k$ ç±»çš„æƒé‡ã€‚
ç»™å®šæ ·æœ¬ $(\boldsymbol{x}_i, y_i)$ï¼Œå…¶ä¸­ $y_i \in \{1, \dots, K\}$ï¼Œäº¤å‰ç†µæŸå¤±ä¸ºï¼š
\begin{equation} \ell_i(\boldsymbol{W}) = -\log \frac{e^{\langle \boldsymbol{w}_{y_i}, \boldsymbol{x}_i \rangle}}{\sum_{k=1}^K e^{\langle \boldsymbol{w}_k, \boldsymbol{x}_i \rangle}} \tag{17} \end{equation}

**æ­¥éª¤ 2ï¼šæ¸è¿‘è¡Œä¸ºåˆ†æ**
è®¾æ‰€æœ‰ç±»åˆ«çš„å¾—åˆ†ä¸º $s_k = \langle \boldsymbol{w}_k, \boldsymbol{x}_i \rangle$ã€‚å‡è®¾çœŸå®ç±» $y_i = 1$ã€‚
å½“è®­ç»ƒåæœŸ $s_1 \gg s_k$ ï¼ˆ$k \neq 1$ï¼‰æ—¶ï¼š
\begin{equation} \ell_i \approx -s_1 + \log\left( e^{s_1} + \sum_{k=2}^K e^{s_k} \right) \approx \log\left( 1 + \sum_{k=2}^K e^{s_k - s_1} \right) \tag{18} \end{equation}

**æ­¥éª¤ 3ï¼šé—´éš”çš„å®šä¹‰**
åœ¨å¤šç±»æƒ…å†µä¸‹ï¼Œé—´éš”å®šä¹‰ä¸ºçœŸå®ç±»å¾—åˆ†ä¸æ¬¡ä¼˜ç±»å¾—åˆ†ä¹‹å·®ï¼š
\begin{equation} \gamma_i = \langle \boldsymbol{w}_{y_i} - \boldsymbol{w}_{y_i^*}, \boldsymbol{x}_i \rangle \tag{19} \end{equation}
å…¶ä¸­ $y_i^* = \arg\max_{k \neq y_i} \langle \boldsymbol{w}_k, \boldsymbol{x}_i \rangle$ æ˜¯æ··æ·†ç±»ï¼ˆæœ€æ˜“æ··æ·†çš„é”™è¯¯ç±»ï¼‰ã€‚

**æ­¥éª¤ 4ï¼šæ”¶æ•›åˆ°å¤šç±» SVM**
Ji å’Œ Telgarsky (2019) è¯æ˜ï¼Œåœ¨å¤šç±»å¯åˆ†æ•°æ®ä¸Šï¼ŒSoftmax æŸå¤±çš„æ¢¯åº¦æµä¼šæ”¶æ•›åˆ°ä»¥ä¸‹ä¼˜åŒ–é—®é¢˜çš„è§£ï¼š
\begin{equation} \min_{\boldsymbol{W}} \sum_{k=1}^K \|\boldsymbol{w}_k\|^2 \quad \text{s.t.} \quad \forall i, k \neq y_i : \langle \boldsymbol{w}_{y_i} - \boldsymbol{w}_k, \boldsymbol{x}_i \rangle \geq 1 \tag{20} \end{equation}
è¿™æ­£æ˜¯å¤šç±» SVMï¼ˆä¸€å¯¹å¤šå½¢å¼ï¼‰ï¼

**æ­¥éª¤ 5ï¼šå®è·µä¸­çš„è•´å«**
- å¯¹äºå›°éš¾æ ·æœ¬ï¼ˆæ¥è¿‘å†³ç­–è¾¹ç•Œï¼‰ï¼Œä¸»å¯¼æ¢¯åº¦çš„æ˜¯**æ··æ·†å¯¹**ï¼ˆçœŸå®ç±» vs æ¬¡ä¼˜ç±»ï¼‰
- è¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆ Hard Example Mining åœ¨å¤šç±»åˆ†ç±»ä¸­ç‰¹åˆ«æœ‰æ•ˆ
- ä¹Ÿæ­ç¤ºäº†ä¸ºä»€ä¹ˆ Label Smoothing èƒ½æ”¹å–„æ³›åŒ–ï¼šå®ƒè½¯åŒ–äº†ç¡¬é—´éš”çº¦æŸ

</div>

<h3 id="27-vs">2.7 æ­£åˆ™åŒ–è·¯å¾„ï¼šæ˜¾å¼ vs éšå¼çš„è¿ç»­ç»Ÿ</h3>
<p>æˆ‘ä»¬å¯ä»¥å°† SGD çš„éšå¼åç½®çœ‹ä½œæ­£åˆ™åŒ–å¼ºåº¦ $\lambda \to 0$ çš„æé™ã€‚</p>
<div class="formula-explanation">

### æ­£åˆ™åŒ–è·¯å¾„çš„æ•°å­¦ç»Ÿä¸€

è€ƒè™‘ä¸€ç³»åˆ—å¸¦æ˜¾å¼æ­£åˆ™åŒ–çš„é—®é¢˜ï¼š
\begin{equation} \min_{\boldsymbol{\theta}} L(\boldsymbol{\theta}) + \lambda R(\boldsymbol{\theta}) \tag{21} \end{equation}
å…¶ä¸­ $R(\boldsymbol{\theta})$ æ˜¯æ­£åˆ™é¡¹ï¼ˆå¦‚ $\|\boldsymbol{\theta}\|^2$ï¼‰ã€‚

**å…³é”®å®šç†ï¼ˆRosset et al. 2004ï¼‰**ï¼š
å½“ $\lambda \to 0$ æ—¶ï¼Œæ­£åˆ™åŒ–è·¯å¾„çš„æé™ç‚¹æ°å¥½æ˜¯æœªæ­£åˆ™åŒ–é—®é¢˜åœ¨éšå¼åç½®ä¸‹çš„è§£ã€‚
å½¢å¼åŒ–åœ°ï¼š
\begin{equation} \lim_{\lambda \to 0^+} \boldsymbol{\theta}^*(\lambda) = \boldsymbol{\theta}_{\text{SGD}}^{\infty} \tag{22} \end{equation}

**è¯æ˜æ€è·¯**ï¼š
1. å›ºå®š $\lambda > 0$ æ—¶ï¼ŒKKT æ¡ä»¶ä¸ºï¼š
   \begin{equation} \nabla L(\boldsymbol{\theta}^*) + \lambda \nabla R(\boldsymbol{\theta}^*) = 0 \tag{23} \end{equation}
2. å½“æŸå¤± $L \to 0$ æ—¶ï¼Œ$\nabla L$ æå°ï¼Œä¸»å¯¼é¡¹å˜ä¸º $\lambda \nabla R$
3. ä½†åŒæ—¶ $\lambda \to 0$ï¼Œä¸¤è€…çš„å¹³è¡¡ç‚¹æ­£æ˜¯ SGD é•¿æ—¶é—´æ¼”åŒ–çš„æ–¹å‘

**å‡ ä½•æ„è±¡**ï¼š
æƒ³è±¡æ­£åˆ™åŒ–å‚æ•° $\lambda$ æ§åˆ¶ç€ä¸€ä¸ª"å¼¹ç°§"çš„å¼ºåº¦ï¼Œæ‹‰ç€å‚æ•°è¿œç¦»åŸç‚¹ã€‚
å½“ $\lambda$ å¾ˆå¤§æ—¶ï¼Œå¼¹ç°§åŠ›å¼ºï¼Œå‚æ•°è¢«ç‰¢ç‰¢çº¦æŸåœ¨åŸç‚¹é™„è¿‘ã€‚
å½“ $\lambda \to 0$ æ—¶ï¼Œå¼¹ç°§åŠ›æ¶ˆå¤±ï¼Œä½†å‚æ•°å·²ç»"è®°ä½"äº†å¼¹ç°§æ›¾ç»çš„æ–¹å‘â€”â€”è¿™å°±æ˜¯éšå¼åç½®ã€‚

</div>

<hr />
<h2 id="3">3. ä»çº¿æ€§åˆ°éçº¿æ€§ï¼šæ·±åº¦ç½‘ç»œä¸­çš„éšå¼åç½®</h2>
<p>çº¿æ€§åˆ†ç±»å™¨çš„ç»“è®ºå·²è¶³å¤Ÿéœ‡æ’¼ã€‚ä½†æ·±åº¦å­¦ä¹ çš„çœŸæ­£èˆå°æ˜¯å¤šå±‚éçº¿æ€§ç½‘ç»œã€‚é‚£ä¹ˆ SGD â‰ˆ SVM çš„é­”æ³•æ˜¯å¦ä¼šåœ¨æ·±å±‚ä¸­å¤±æ•ˆï¼Ÿ</p>
<h3 id="31">3.1 æ·±åº¦çº¿æ€§ç½‘ç»œï¼šçŸ©é˜µåˆ†è§£çš„éšå¼æ­£åˆ™åŒ–</h3>
<p>è™½ç„¶ç¥ç»ç½‘ç»œé€šå¸¸æ˜¯éçº¿æ€§çš„ï¼Œä½†ä¸€ä¸ªé‡è¦çš„ä¸­é—´ç†è®ºå¯¹è±¡æ˜¯<strong>æ·±åº¦çº¿æ€§ç½‘ç»œ</strong>ï¼š
\begin{equation} f(\boldsymbol{x}; \boldsymbol{W}<em L-1="L-1">1, \dots, \boldsymbol{W}_L) = \boldsymbol{W}_L \boldsymbol{W}</em>
è™½ç„¶ä»åŠŸèƒ½ä¸Šç­‰ä»·äºä¸€ä¸ªå•å±‚çº¿æ€§æ˜ å°„ $\boldsymbol{W} = \boldsymbol{W}_L \cdots \boldsymbol{W}_1$ï¼Œä½†å…¶} \cdots \boldsymbol{W}_1 \boldsymbol{x} \tag{17} \end{equation<strong>å‚æ•°åŒ–æ–¹å¼</strong>å¯¼è‡´äº†å®Œå…¨ä¸åŒçš„ä¼˜åŒ–è½¨è¿¹ã€‚</p>
<div class="derivation-box">

### æ¨å¯¼ 7.4ï¼šæ·±åº¦çº¿æ€§ç½‘ç»œçš„éšå¼æ ¸èŒƒæ•°æœ€å°åŒ–

**é—®é¢˜è®¾å®š**ï¼š
è€ƒè™‘çŸ©é˜µåˆ†è§£ä»»åŠ¡ï¼Œç›®æ ‡æ˜¯æ‹Ÿåˆ $\boldsymbol{Y} \in \mathbb{R}^{m \times n}$ï¼š
\begin{equation} \min_{\boldsymbol{W}_1, \boldsymbol{W}_2} L = \|\boldsymbol{Y} - \boldsymbol{W}_2 \boldsymbol{W}_1\|_F^2 \tag{18} \end{equation}

**æ­¥éª¤ 1ï¼šè¯†åˆ«è¿‡å‚æ•°åŒ–çš„å†—ä½™æ€§**
å¦‚æœå†…éƒ¨ç»´åº¦ $d > \text{rank}(\boldsymbol{Y})$ï¼Œåˆ™è¯¥é—®é¢˜æœ‰æ— ç©·å¤šä¸ªå…¨å±€æœ€ä¼˜è§£ï¼ˆæ‰€æœ‰æ»¡è¶³ $\boldsymbol{W}_2 \boldsymbol{W}_1 = \boldsymbol{Y}$ çš„åˆ†è§£ï¼‰ã€‚
ä½† SGD ä¼šé€‰æ‹©å“ªä¸€ä¸ªï¼Ÿ

**æ­¥éª¤ 2ï¼šæ¢¯åº¦æµçš„åŠ¨åŠ›å­¦æ–¹ç¨‹**
\begin{align}
\dot{\boldsymbol{W}}_1 &= \boldsymbol{W}_2^T (\boldsymbol{Y} - \boldsymbol{W}_2 \boldsymbol{W}_1) \tag{19} \\
\dot{\boldsymbol{W}}_2 &= (\boldsymbol{Y} - \boldsymbol{W}_2 \boldsymbol{W}_1) \boldsymbol{W}_1^T \tag{20}
\end{align}

**æ­¥éª¤ 3ï¼šæ ¸èŒƒæ•°çš„æ¼”åŒ–é€Ÿç‡**
å®šä¹‰æ ¸èŒƒæ•°ï¼ˆçŸ©é˜µçš„æ‰€æœ‰å¥‡å¼‚å€¼ä¹‹å’Œï¼‰ï¼š
\begin{equation} \|\boldsymbol{W}\|_* = \sum_{i=1}^r \sigma_i(\boldsymbol{W}) \tag{21} \end{equation}
Gunasekar ç­‰äºº (2017) è¯æ˜ï¼Œå½“æŸå¤±è¶‹äº 0 æ—¶ï¼Œ$\boldsymbol{W}_2 \boldsymbol{W}_1$ çš„æ ¸èŒƒæ•°æ¼”åŒ–æ»¡è¶³ï¼š
\begin{equation} \frac{d}{dt} \|\boldsymbol{W}_2 \boldsymbol{W}_1\|_* \to 0^+ \tag{22} \end{equation}
è¿™æ„å‘³ç€ SGD éšå¼åœ°æœ€å°åŒ–äº†çŸ©é˜µçš„æ ¸èŒƒæ•°ï¼Œä»è€Œé€‰æ‹©äº†æœ€"ç®€å•"çš„ä½ç§©è§£ã€‚

**æ­¥éª¤ 4ï¼šä¸çŸ©é˜µå®Œæˆçš„è”ç³»**
æ ¸èŒƒæ•°æœ€å°åŒ–æ˜¯çŸ©é˜µå®Œæˆï¼ˆMatrix Completionï¼‰å’Œæ¨èç³»ç»Ÿä¸­çš„æ ¸å¿ƒæŠ€æœ¯ã€‚
ä¼ ç»Ÿæ–¹æ³•éœ€è¦æ˜¾å¼æ±‚è§£ï¼š
\begin{equation} \min_{\boldsymbol{W}} \|\boldsymbol{W}\|_* \quad \text{s.t.} \quad \mathcal{P}_\Omega(\boldsymbol{W}) = \mathcal{P}_\Omega(\boldsymbol{Y}) \tag{23} \end{equation}
å…¶ä¸­ $\mathcal{P}_\Omega$ æ˜¯è§‚æµ‹é›†åˆçš„æŠ•å½±ç®—å­ã€‚è¿™æ˜¯ä¸€ä¸ªå‡¸ä¼˜åŒ–é—®é¢˜ï¼Œä½†éœ€è¦æ˜‚è´µçš„å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰ã€‚
è€Œæ·±åº¦çº¿æ€§ç½‘ç»œé€šè¿‡ SGD éšå¼åœ°å®ç°äº†åŒæ ·çš„æ•ˆæœï¼Œä¸”è®¡ç®—æˆæœ¬è¿œä½äº SVDã€‚

**æ­¥éª¤ 5ï¼šæ·±åº¦çš„å¿…è¦æ€§**
æœ‰è¶£çš„æ˜¯ï¼Œå¦‚æœç›´æ¥ä¼˜åŒ–å•å±‚ $\boldsymbol{W}$ï¼ˆå³ $L=1$ï¼‰ï¼ŒSGD ä¼šæ”¶æ•›åˆ° Frobenius èŒƒæ•°æœ€å°åŒ–ï¼Œè€Œéæ ¸èŒƒæ•°ã€‚
åªæœ‰åœ¨å¤šå±‚åˆ†è§£ $\boldsymbol{W} = \boldsymbol{W}_L \cdots \boldsymbol{W}_1$ æ—¶ï¼Œæ ¸èŒƒæ•°çš„åç½®æ‰ä¼šæ¶Œç°ã€‚
è¿™æ­ç¤ºäº†**æ·±åº¦æœ¬èº«æ˜¯ä¸€ç§æ­£åˆ™åŒ–æœºåˆ¶**ã€‚

</div>

<h3 id="32-relu">3.2 å¯¹è§’çº¿æ€§ç½‘ç»œï¼šReLU ç½‘ç»œçš„ç®€åŒ–æ¨¡å‹</h3>
<p>å¯¹è§’çº¿æ€§ç½‘ç»œæ˜¯ä»‹äºçº¯çº¿æ€§å’Œå…¨éçº¿æ€§ä¹‹é—´çš„æ¨¡å‹ï¼š
\begin{equation} f(\boldsymbol{x}; \boldsymbol{w}_1, \boldsymbol{w}_2) = \boldsymbol{w}_2 \odot (\boldsymbol{w}_1 \odot \boldsymbol{x}) \tag{24} \end{equation}
å…¶ä¸­ $\odot$ è¡¨ç¤ºé€å…ƒç´ ä¹˜æ³•ï¼ˆHadamard ç§¯ï¼‰ã€‚</p>
<p>è¿™å¯ä»¥çœ‹ä½œæ˜¯å¸¦æœ‰å›ºå®šæ¿€æ´»æ¨¡å¼çš„ ReLU ç½‘ç»œçš„é€€åŒ–ç‰ˆæœ¬ã€‚</p>
<div class="formula-explanation">

### å¯¹è§’ç½‘ç»œä¸­çš„ $\ell_1$ éšå¼åç½®

Lyu å’Œ Li (2020) è¯æ˜ï¼Œåœ¨å¯¹è§’çº¿æ€§ç½‘ç»œä¸­ï¼ŒSGD ä¼šéšå¼åœ°æœ€å°åŒ–å‚æ•°çš„ $\ell_1$ èŒƒæ•°ï¼š
\begin{equation} \boldsymbol{w}^*_{\text{SGD}} = \arg\min \|\boldsymbol{w}\|_1 \quad \text{s.t.} \quad \boldsymbol{w} \odot \boldsymbol{x}_i = y_i, \forall i \tag{25} \end{equation}

è¿™ä¸å‹ç¼©æ„ŸçŸ¥ï¼ˆCompressed Sensingï¼‰ä¸­çš„ LASSO æ­£åˆ™åŒ–å®Œå…¨ä¸€è‡´ï¼
$\ell_1$ èŒƒæ•°çš„ç¨€ç–æ€§è¯±å¯¼ç‰¹æ€§æ„å‘³ç€ï¼ŒSGD ä¼šè‡ªåŠ¨é€‰æ‹©æœ€ç¨€ç–çš„è§£ï¼Œå³åªæ¿€æ´»æœ€å°‘æ•°é‡çš„ç‰¹å¾ã€‚

**å‡ ä½•ç›´è§‰**ï¼š
åœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œ$\ell_1$ çƒæ˜¯ä¸€ä¸ª"è±å½¢"ï¼Œå…¶é¡¶ç‚¹ä½äºåæ ‡è½´ä¸Šã€‚å½“ä¼˜åŒ–è½¨è¿¹æ’ä¸Šè¿™ä¸ªè±å½¢æ—¶,å¤§æ¦‚ç‡ä¼šæ’åœ¨æŸä¸ªé¡¶ç‚¹ä¸Šï¼Œä»è€Œå¯¼è‡´å¤§é‡åæ ‡ä¸º 0ã€‚

</div>

<h3 id="33-relu">3.3 ReLU ç½‘ç»œçš„æœ€å¤§é—´éš”ï¼šç¥ç»æ­£åˆ‡æ ¸è§†è§’</h3>
<p>å¯¹äºçœŸæ­£çš„æ·±åº¦ ReLU ç½‘ç»œï¼Œä¸¥æ ¼çš„ç†è®ºåˆ†æå˜å¾—æä¸ºå›°éš¾ã€‚ä½†åœ¨<strong>ç¥ç»æ­£åˆ‡æ ¸ï¼ˆNeural Tangent Kernel, NTKï¼‰</strong>æ¡†æ¶ä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥è·å¾—æ¸è¿‘çš„ç†è§£ã€‚</p>
<div class="step-by-step">

<div class="step">
**NTK æé™**ï¼š
å½“ç½‘ç»œå®½åº¦ $m \to \infty$ æ—¶ï¼Œè®­ç»ƒåŠ¨æ€çº¿æ€§åŒ–ï¼Œç½‘ç»œè¡Œä¸ºç­‰ä»·äºä¸€ä¸ªå›ºå®šçš„æ ¸å›å½’å™¨ï¼š
\begin{equation} f_{\boldsymbol{\theta}}(\boldsymbol{x}) \approx f_{\boldsymbol{\theta}_0}(\boldsymbol{x}) + \langle \nabla_{\boldsymbol{\theta}} f_{\boldsymbol{\theta}_0}(\boldsymbol{x}), \boldsymbol{\theta} - \boldsymbol{\theta}_0 \rangle \tag{26} \end{equation}
å®šä¹‰æ ¸å‡½æ•°ï¼š
\begin{equation} K(\boldsymbol{x}, \boldsymbol{x}') = \mathbb{E}_{\boldsymbol{\theta}_0}[\langle \nabla_{\boldsymbol{\theta}} f_{\boldsymbol{\theta}_0}(\boldsymbol{x}), \nabla_{\boldsymbol{\theta}} f_{\boldsymbol{\theta}_0}(\boldsymbol{x}') \rangle] \tag{27} \end{equation}
</div>

<div class="step">
**æ ¸ç©ºé—´ä¸­çš„ SVM**ï¼š
Chizat ç­‰äºº (2020) è¯æ˜ï¼Œåœ¨ NTK æé™ä¸‹ï¼ŒSGD åœ¨æ ¸ç‰¹å¾ç©ºé—´ $\mathcal{H}_K$ ä¸­å¯»æ‰¾æœ€å¤§é—´éš”è§£ï¼š
\begin{equation} \boldsymbol{\alpha}^* = \arg\min_{\boldsymbol{\alpha}} \|\sum_{i=1}^n \alpha_i K(\cdot, \boldsymbol{x}_i)\|_{\mathcal{H}_K}^2 \quad \text{s.t.} \quad y_i f(\boldsymbol{x}_i) \geq 1 \tag{28} \end{equation}
è¿™æ­£æ˜¯æ ¸ SVMï¼
</div>

<div class="step">
**ç‰¹å¾å­¦ä¹ ä¸æ ¸çš„æ¼”åŒ–**ï¼š
ä½†ç°å®ä¸­çš„ç½‘ç»œå¹¶éæ— é™å®½ã€‚åœ¨æœ‰é™å®½åº¦ä¸‹ï¼Œç½‘ç»œä¼šè¿›è¡Œ**ç‰¹å¾å­¦ä¹ ï¼ˆFeature Learningï¼‰**ï¼Œå³æ ¸å‡½æ•°æœ¬èº«ä¹Ÿåœ¨è®­ç»ƒä¸­æ”¹å˜ã€‚
è¿™æ—¶ï¼Œéšå¼åç½®å˜å¾—æ›´åŠ å¾®å¦™â€”â€”SGD ä¸ä»…åœ¨å½“å‰ç‰¹å¾ç©ºé—´ä¸­å¯»æ‰¾æœ€å¤§é—´éš”,è¿˜ä¼šè°ƒæ•´ç‰¹å¾ç©ºé—´æœ¬èº«,ä½¿å¾—æ•°æ®åœ¨æ–°ç©ºé—´ä¸­æ›´å®¹æ˜“åˆ†ç¦»ã€‚
</div>

</div>

<h3 id="34-batchnorm">3.4 å½’ä¸€åŒ–å±‚çš„å½±å“ï¼šBatchNorm ä¸éšå¼åç½®çš„ç›¸äº’ä½œç”¨</h3>
<p>ç°ä»£ç¥ç»ç½‘ç»œä¸­å¹¿æ³›ä½¿ç”¨çš„ Batch Normalization (BN) ä¼šå¦‚ä½•å½±å“éšå¼åç½®ï¼Ÿ</p>
<div class="derivation-box">

### æ¨å¯¼ 7.5ï¼šBatchNorm ä¸‹çš„å°ºåº¦ä¸å˜æ€§

**æ­¥éª¤ 1ï¼šBatchNorm çš„æ•°å­¦å®šä¹‰**
å¯¹äºå±‚çš„è¾“å‡º $\boldsymbol{z}$ï¼ŒBN æ‰§è¡Œï¼š
\begin{equation} \text{BN}(\boldsymbol{z}) = \boldsymbol{\gamma} \odot \frac{\boldsymbol{z} - \mu}{\sqrt{\sigma^2 + \epsilon}} + \boldsymbol{\beta} \tag{29} \end{equation}
å…¶ä¸­ $\mu, \sigma^2$ æ˜¯ batch å†…çš„å‡å€¼å’Œæ–¹å·®ã€‚

**æ­¥éª¤ 2ï¼šå°ºåº¦ç­‰å˜æ€§è´¨**
å…³é”®è§‚å¯Ÿï¼šå¦‚æœæˆ‘ä»¬å°†æƒé‡ $\boldsymbol{W}$ ç¼©æ”¾ä¸º $\alpha \boldsymbol{W}$ï¼ŒBN çš„è¾“å‡ºä¿æŒä¸å˜ï¼ˆé€šè¿‡ç›¸åº”è°ƒæ•´ $\boldsymbol{\gamma}$ï¼‰ã€‚
è¿™æ„å‘³ç€æŸå¤±å‡½æ•°å…³äºæƒé‡çš„æ¨¡é•¿æ˜¯**å¹³å¦çš„ï¼ˆflatï¼‰**ã€‚

**æ­¥éª¤ 3ï¼šéšå¼åç½®çš„å‡å¼±**
ç”±äº BN æ¶ˆé™¤äº†æ¨¡é•¿ä¿¡æ¯ï¼ŒSGD çš„éšå¼ $\ell_2$ åç½®ä¼šè¢«å‰Šå¼±ã€‚
van Laarhoven (2017) è¯æ˜ï¼ŒBN ä¼šå¯¼è‡´ SGD åå‘äºæœ€å°åŒ–æƒé‡çš„**æœ‰æ•ˆèŒƒæ•°ï¼ˆEffective Normï¼‰**ï¼š
\begin{equation} \|\boldsymbol{W}\|_{\text{eff}}^2 = \sum_l \frac{\|\boldsymbol{W}_l\|_F^2}{\|\boldsymbol{\gamma}_l\|^2} \tag{30} \end{equation}
è¿™æ˜¯ä¸€ç§**å±‚å½’ä¸€åŒ–çš„èŒƒæ•°**ï¼Œé¼“åŠ±ä¸åŒå±‚ä¹‹é—´çš„"å¹³è¡¡"å¢é•¿ã€‚

**æ­¥éª¤ 4ï¼šæœ€å¤§é—´éš”çš„ä¿æŒ**
å°½ç®¡ BN æ”¹å˜äº†èŒƒæ•°å½¢å¼ï¼Œä½†æœ€å¤§é—´éš”çš„æ€§è´¨ä¾ç„¶ä¿ç•™ã€‚
Wei å’Œ Ma (2019) è¯æ˜ï¼Œåœ¨åˆ†ç±»ä»»åŠ¡ä¸­ï¼ŒBN ç½‘ç»œçš„ SGD ä»ç„¶æ”¶æ•›åˆ°ä¸€ä¸ª**å¹¿ä¹‰æœ€å¤§é—´éš”è§£**ï¼Œä½†é—´éš”çš„åº¦é‡æ–¹å¼ç”±æœ‰æ•ˆèŒƒæ•°å®šä¹‰ã€‚

</div>

<hr />
<h2 id="4">4. æ•°å€¼å®éªŒï¼šçœ¼è§ä¸ºå®çš„åŠ¨åŠ›å­¦æ¼”åŒ–</h2>
<p>ç†è®ºæ˜¯ç¾çš„ï¼Œä½†å®éªŒæ˜¯å¿…é¡»çš„ã€‚è®©æˆ‘ä»¬é€šè¿‡ä¸€ç³»åˆ—ç²¾å¿ƒè®¾è®¡çš„å®éªŒï¼Œç›´è§‚åœ°çœ‹åˆ° SGD å¦‚ä½•"å¯»æ‰¾"SVM è§£ã€‚</p>
<h3 id="41-1">4.1 å®éªŒ 1ï¼šäºŒç»´çº¿æ€§åˆ†ç±»çš„è½¨è¿¹å¯è§†åŒ–</h3>
<p><strong>å®éªŒè®¾ç½®</strong>ï¼š
- æ•°æ®ï¼š100 ä¸ªäºŒç»´ç‚¹ï¼Œåˆ†ä¸ºä¸¤ç±»ï¼Œçº¿æ€§å¯åˆ†
- æ¨¡å‹ï¼šå•å±‚çº¿æ€§åˆ†ç±»å™¨ $f(\boldsymbol{x}) = \langle \boldsymbol{w}, \boldsymbol{x} \rangle + b$
- æŸå¤±ï¼šLogistic Loss
- ä¼˜åŒ–å™¨ï¼šGDï¼ˆå­¦ä¹ ç‡ 0.1ï¼‰</p>
<div class="code-box">


<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.svm</span><span class="w"> </span><span class="kn">import</span> <span class="n">SVC</span>

<span class="c1"># ç”Ÿæˆçº¿æ€§å¯åˆ†æ•°æ®</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">X_neg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">])</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">X_pos</span><span class="p">,</span> <span class="n">X_neg</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">50</span> <span class="o">+</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># Logistic Loss æ¢¯åº¦</span>
<span class="k">def</span><span class="w"> </span><span class="nf">grad_logistic</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">w</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">)))</span>

<span class="c1"># æ¢¯åº¦ä¸‹é™</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
<span class="n">trajectory</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">copy</span><span class="p">()]</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5000</span><span class="p">):</span>
    <span class="n">w</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">grad_logistic</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">trajectory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>

<span class="n">trajectory</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">trajectory</span><span class="p">)</span>

<span class="c1"># è®­ç»ƒ SVM ä½œä¸º ground truth</span>
<span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1e10</span><span class="p">)</span>  <span class="c1"># C å¾ˆå¤§ â†’ ç¡¬é—´éš”</span>
<span class="n">svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">w_svm</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">w_svm_normalized</span> <span class="o">=</span> <span class="n">w_svm</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">w_svm</span><span class="p">)</span>

<span class="c1"># å¯è§†åŒ–</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># å·¦å›¾ï¼šå‚æ•°ç©ºé—´è½¨è¿¹</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trajectory</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">trajectory</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">trajectory</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">trajectory</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
           <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Init&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">trajectory</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">trajectory</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
           <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;GD (t=5000)&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">w_svm</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">3</span><span class="p">,</span> <span class="n">w_svm</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">3</span><span class="p">,</span> <span class="n">head_width</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
         <span class="n">head_length</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
         <span class="n">label</span><span class="o">=</span><span class="s1">&#39;SVM direction&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;wâ‚&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;wâ‚‚&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Parameter Space Trajectory&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># å³å›¾ï¼šæ–¹å‘æ”¶æ•›</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">directions</span> <span class="o">=</span> <span class="n">trajectory</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">trajectory</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">angle_to_svm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arccos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">directions</span> <span class="o">@</span> <span class="n">w_svm_normalized</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">angle_to_svm</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Training Step&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Angle to SVM Solution (radians)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Directional Convergence&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;sgd_svm_convergence.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
</code></pre></div>



</div>

<p><strong>å®éªŒç»“æœåˆ†æ</strong>ï¼š</p>
<div class="result-box">

1. **å‚æ•°ç©ºé—´è½¨è¿¹**ï¼ˆå·¦å›¾ï¼‰ï¼š
   - åˆå§‹æ—¶ï¼Œ$\boldsymbol{w}$ å¿«é€Ÿç§»åŠ¨ï¼Œæ¨¡é•¿å’Œæ–¹å‘åŒæ—¶å˜åŒ–
   - ä¸­æœŸï¼Œè½¨è¿¹å‡ ä¹å‘ˆæ”¾å°„çŠ¶è¿œç¦»åŸç‚¹ï¼Œè¿™å¯¹åº”äºæ¨¡é•¿ $\|\boldsymbol{w}\| \to \infty$
   - è½¨è¿¹çš„æ¸è¿‘æ–¹å‘ï¼ˆå°„çº¿ï¼‰å‡ ä¹å®Œç¾å¯¹é½ SVM çš„è§£å‘é‡ï¼ˆæ©™è‰²ç®­å¤´ï¼‰

2. **æ–¹å‘æ”¶æ•›æ›²çº¿**ï¼ˆå³å›¾ï¼‰ï¼š
   - ä¸ SVM æ–¹å‘çš„å¤¹è§’åœ¨å¯¹æ•°åæ ‡ä¸‹è¿‘ä¼¼çº¿æ€§ä¸‹é™
   - è¿™éªŒè¯äº†ç†è®ºé¢„æµ‹ï¼š$\theta(t) \sim 1/\ln t$
   - 5000 æ­¥åï¼Œå¤¹è§’ä»…çº¦ 0.001 å¼§åº¦ï¼ˆ0.057Â°ï¼‰

</div>

<h3 id="42-2">4.2 å®éªŒ 2ï¼šæ”¯æŒå‘é‡çš„è¯†åˆ«</h3>
<p>å¦‚ä½•éªŒè¯æ˜¯æ”¯æŒå‘é‡ä¸»å¯¼äº†æ¢¯åº¦ï¼Ÿ</p>
<div class="code-box">


<div class="codehilite"><pre><span></span><code><span class="c1"># è®¡ç®—æ¯ä¸ªæ ·æœ¬å¯¹æ¢¯åº¦çš„è´¡çŒ®</span>
<span class="k">def</span><span class="w"> </span><span class="nf">gradient_contribution</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">coeff</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">coeff</span><span class="p">)</span>  <span class="c1"># æ¯ä¸ªæ ·æœ¬çš„æ¢¯åº¦æƒé‡</span>

<span class="c1"># åœ¨è®­ç»ƒæœ€åé˜¶æ®µåˆ†æ</span>
<span class="n">w_final</span> <span class="o">=</span> <span class="n">trajectory</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">contributions</span> <span class="o">=</span> <span class="n">gradient_contribution</span><span class="p">(</span><span class="n">w_final</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># æ‰¾å‡ºçœŸæ­£çš„æ”¯æŒå‘é‡</span>
<span class="n">margins</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">w_svm</span><span class="p">)</span>
<span class="n">is_support</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">margins</span> <span class="o">-</span> <span class="n">margins</span><span class="o">.</span><span class="n">min</span><span class="p">())</span> <span class="o">&lt;</span> <span class="mf">1e-3</span>

<span class="c1"># å¯è§†åŒ–</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">scatter</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">contributions</span><span class="p">,</span>
                    <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Reds&#39;</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">is_support</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">is_support</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
           <span class="n">s</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">facecolors</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span>
           <span class="n">linewidths</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True Support Vectors&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">scatter</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Gradient Contribution&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Gradient Contribution per Sample (t=5000)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;support_vectors.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
</code></pre></div>



</div>

<p><strong>è§‚å¯Ÿç»“è®º</strong>ï¼š
- æ¢¯åº¦è´¡çŒ®æœ€å¤§çš„æ ·æœ¬ï¼ˆæ·±çº¢è‰²ï¼‰å‡ ä¹å®Œå…¨é‡åˆäºçœŸæ­£çš„æ”¯æŒå‘é‡ï¼ˆè“è‰²åœ†åœˆï¼‰
- è¿œç¦»å†³ç­–è¾¹ç•Œçš„æ ·æœ¬çš„æ¢¯åº¦è´¡çŒ®è¶‹äº 0ï¼ˆç™½è‰²ï¼‰
- è¿™ç›´æ¥éªŒè¯äº†æ¨å¯¼ 7.2 ä¸­çš„ç†è®ºï¼š$e^{-\rho \gamma_i}$ ä¸»å¯¼æ€§</p>
<h3 id="43-3">4.3 å®éªŒ 3ï¼šæ·±åº¦çº¿æ€§ç½‘ç»œçš„æ ¸èŒƒæ•°æ¼”åŒ–</h3>
<p>éªŒè¯æ¨å¯¼ 7.4 çš„æ ¸èŒƒæ•°æœ€å°åŒ–ã€‚</p>
<div class="code-box">


<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="c1"># ç›®æ ‡çŸ©é˜µï¼ˆç§©ä¸º 2ï¼‰</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># æ·±åº¦çº¿æ€§ç½‘ç»œï¼ˆ2å±‚ï¼Œå†…éƒ¨ç»´åº¦ 10 &gt; rank(Y)ï¼‰</span>
<span class="k">class</span><span class="w"> </span><span class="nc">DeepLinear</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">W2</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">W1</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">DeepLinear</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># è®°å½•æ ¸èŒƒæ•°</span>
<span class="n">nuclear_norms</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">model</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">Y</span> <span class="o">-</span> <span class="n">W</span><span class="p">,</span> <span class="s1">&#39;fro&#39;</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">nuclear_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svdvals</span><span class="p">(</span><span class="n">W</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">nuclear_norms</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nuclear_norm</span><span class="p">)</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

<span class="c1"># å¯è§†åŒ–</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Training Step&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Reconstruction Loss&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Loss Decay&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">nuclear_norms</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svdvals</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
               <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
               <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Nuclear Norm of Y&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Training Step&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Nuclear Norm&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Implicit Nuclear Norm Minimization&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;nuclear_norm_evolution.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
</code></pre></div>



</div>

<p><strong>å…³é”®å‘ç°</strong>ï¼š
1. æŸå¤±å¿«é€Ÿä¸‹é™åˆ° $10^{-10}$ é‡çº§ï¼ˆå‡ ä¹å®Œç¾æ‹Ÿåˆï¼‰
2. å°½ç®¡å­˜åœ¨æ— ç©·å¤šä¸ªé›¶æŸå¤±è§£ï¼ŒSGD æ”¶æ•›åˆ°çš„è§£çš„æ ¸èŒƒæ•°éå¸¸æ¥è¿‘ç›®æ ‡çŸ©é˜µ $\boldsymbol{Y}$ çš„æ ¸èŒƒæ•°
3. è¿™è¯æ˜äº† SGD åœ¨ä¼—å¤šè§£ä¸­é€‰æ‹©äº†"æœ€ç®€å•"ï¼ˆæœ€ä½ç§©ï¼‰çš„é‚£ä¸ª</p>
<h3 id="44-4batchnorm">4.4 å®éªŒ 4ï¼šBatchNorm å¯¹éšå¼åç½®çš„å½±å“</h3>
<div class="code-box">


<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="k">class</span><span class="w"> </span><span class="nc">LinearWithBN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_bn</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> <span class="k">if</span> <span class="n">use_bn</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span> <span class="o">=</span> <span class="n">use_bn</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># è®­ç»ƒä¸¤ä¸ªæ¨¡å‹</span>
<span class="n">X_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">models</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Without BN&#39;</span><span class="p">:</span> <span class="n">LinearWithBN</span><span class="p">(</span><span class="n">use_bn</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
          <span class="s1">&#39;With BN&#39;</span><span class="p">:</span> <span class="n">LinearWithBN</span><span class="p">(</span><span class="n">use_bn</span><span class="o">=</span><span class="kc">True</span><span class="p">)}</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">weight_norms</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3000</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_torch</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">y_torch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># è®¡ç®—æ‰€æœ‰æƒé‡çš„æ€»èŒƒæ•°</span>
        <span class="n">total_norm</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">**</span><span class="mf">0.5</span>
        <span class="n">weight_norms</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_norm</span><span class="p">)</span>

    <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">weight_norms</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Training Step&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Total Weight Norm&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">: Weight Norm Evolution&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;bn_effect.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
</code></pre></div>



</div>

<p><strong>å®éªŒå¯¹æ¯”</strong>ï¼š
- <strong>æ—  BN</strong>ï¼šæƒé‡èŒƒæ•°å•è°ƒå¢é•¿å¹¶å‘æ•£ï¼ˆç¬¦åˆçº¿æ€§å¯åˆ†æ•°æ®çš„ç†è®ºï¼‰
- <strong>æœ‰ BN</strong>ï¼šæƒé‡èŒƒæ•°å¢é•¿å—åˆ°æŠ‘åˆ¶ï¼Œè¶‹äºç¨³å®š
- è¿™éªŒè¯äº† BN é€šè¿‡å°ºåº¦ä¸å˜æ€§æ”¹å˜äº†éšå¼åç½®çš„æœºåˆ¶</p>
<h3 id="45-5">4.5 å®éªŒ 5ï¼šå­¦ä¹ ç‡å¯¹æ–¹å‘æ”¶æ•›çš„å½±å“</h3>
<p>ä¸åŒçš„å­¦ä¹ ç‡ä¼šå½±å“æ”¶æ•›é€Ÿåº¦å—ï¼Ÿ</p>
<div class="code-box">


<div class="codehilite"><pre><span></span><code><span class="c1"># æµ‹è¯•ä¸åŒå­¦ä¹ ç‡</span>
<span class="n">learning_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">lr</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">learning_rates</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">idx</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">idx</span> <span class="o">%</span> <span class="mi">2</span><span class="p">]</span>

    <span class="c1"># é‡æ–°è®­ç»ƒ</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
    <span class="n">trajectory_lr</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">copy</span><span class="p">()]</span>

    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">):</span>
        <span class="n">w</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">grad_logistic</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">trajectory_lr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>

    <span class="n">trajectory_lr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">trajectory_lr</span><span class="p">)</span>

    <span class="c1"># è®¡ç®—æ–¹å‘è¯¯å·®</span>
    <span class="n">directions</span> <span class="o">=</span> <span class="n">trajectory_lr</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">trajectory_lr</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">angle_to_svm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arccos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">directions</span> <span class="o">@</span> <span class="n">w_svm_normalized</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># ç»˜å›¾</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">angle_to_svm</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;LR=</span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Training Step&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Angle to SVM (radians)&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Learning Rate = </span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="c1"># æ ‡æ³¨æœ€ç»ˆè§’åº¦</span>
    <span class="n">final_angle</span> <span class="o">=</span> <span class="n">angle_to_svm</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;Final: </span><span class="si">{</span><span class="n">final_angle</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1"> rad&#39;</span><span class="p">,</span>
            <span class="n">transform</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">transAxes</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
            <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s1">&#39;round&#39;</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;wheat&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;lr_comparison.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
</code></pre></div>



</div>

<p><strong>å…³é”®å‘ç°</strong>ï¼š
1. <strong>å°å­¦ä¹ ç‡ï¼ˆ0.01ï¼‰</strong>ï¼šæ”¶æ•›ææ…¢ï¼Œ2000 æ­¥åä»æœ‰æ˜æ˜¾è¯¯å·®
2. <strong>ä¸­ç­‰å­¦ä¹ ç‡ï¼ˆ0.1, 1.0ï¼‰</strong>ï¼šæ”¶æ•›é€Ÿåº¦é€‚ä¸­ï¼Œå‘ˆç°ç†è®ºé¢„æµ‹çš„ $1/\ln t$ è¡°å‡
3. <strong>å¤§å­¦ä¹ ç‡ï¼ˆ10.0ï¼‰</strong>ï¼šåˆæœŸéœ‡è¡å‰§çƒˆï¼Œä½†æœ€ç»ˆä¹Ÿèƒ½æ”¶æ•›
4. <strong>æƒŠäººçš„é²æ£’æ€§</strong>ï¼šè·¨è¶Š3ä¸ªæ•°é‡çº§çš„å­¦ä¹ ç‡ï¼Œæ–¹å‘éƒ½èƒ½æ”¶æ•›åˆ° SVMï¼è¿™è¯´æ˜éšå¼åç½®æ˜¯ä¼˜åŒ–ç®—æ³•çš„<strong>æœ¬è´¨ç‰¹æ€§</strong>ï¼Œè€Œéå¶ç„¶ç°è±¡</p>
<h3 id="46-6">4.6 å®éªŒ 6ï¼šåˆå§‹åŒ–çš„å½±å“</h3>
<p>SGD çš„æ–¹å‘æ”¶æ•›æ˜¯å¦ä¾èµ–äºåˆå§‹åŒ–ï¼Ÿ</p>
<div class="code-box">


<div class="codehilite"><pre><span></span><code><span class="c1"># æµ‹è¯•10ä¸ªä¸åŒçš„éšæœºåˆå§‹åŒ–</span>
<span class="n">num_inits</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">final_angles</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_inits</span><span class="p">):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span>  <span class="c1"># è¾ƒå¤§çš„åˆå§‹åŒ–</span>
    <span class="n">trajectory_init</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3000</span><span class="p">):</span>
        <span class="n">w</span> <span class="o">-=</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">grad_logistic</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">trajectory_init</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>

    <span class="n">trajectory_init</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">trajectory_init</span><span class="p">)</span>
    <span class="n">directions</span> <span class="o">=</span> <span class="n">trajectory_init</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">trajectory_init</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">angle_to_svm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arccos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">directions</span> <span class="o">@</span> <span class="n">w_svm_normalized</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">angle_to_svm</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Init </span><span class="si">{</span><span class="n">seed</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">final_angles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">angle_to_svm</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Training Step&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Angle to SVM Solution (radians)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Robustness to Initialization (n=</span><span class="si">{</span><span class="n">num_inits</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;initialization_robustness.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>

<span class="c1"># ç»Ÿè®¡æœ€ç»ˆè§’åº¦</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final angles: mean = </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">final_angles</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">, std = </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">final_angles</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>



</div>

<p><strong>è§‚å¯Ÿç»“è®º</strong>ï¼š
- æ‰€æœ‰åˆå§‹åŒ–éƒ½æ”¶æ•›åˆ°å‡ ä¹ç›¸åŒçš„æ–¹å‘ï¼ˆæ ‡å‡†å·® &lt; 0.001ï¼‰
- åˆå§‹åŒ–åªå½±å“æ”¶æ•›<strong>é€Ÿåº¦</strong>ï¼Œä¸å½±å“æœ€ç»ˆ<strong>æ–¹å‘</strong>
- è¿™è¿›ä¸€æ­¥è¯æ˜ï¼šSVM è§£æ˜¯åŠ¨åŠ›å­¦çš„<strong>å¸å¼•å­</strong>ï¼Œå…·æœ‰å…¨å±€æ€§</p>
<h3 id="47-7">4.7 å®éªŒ 7ï¼šä¸åŒæŸå¤±å‡½æ•°çš„å¯¹æ¯”</h3>
<p>é™¤äº† Logistic Lossï¼Œå…¶ä»–æŸå¤±å‡½æ•°å‘¢ï¼Ÿ</p>
<div class="code-box">


<div class="codehilite"><pre><span></span><code><span class="c1"># å®šä¹‰ä¸åŒæŸå¤±å‡½æ•°çš„æ¢¯åº¦</span>
<span class="k">def</span><span class="w"> </span><span class="nf">grad_exponential</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;æŒ‡æ•°æŸå¤±ï¼šexp(-y * &lt;w, x&gt;)&quot;&quot;&quot;</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">w</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">grad_hinge</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;HingeæŸå¤±ï¼šmax(0, 1 - y * &lt;w, x&gt;)&quot;&quot;&quot;</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">margin_violated</span> <span class="o">=</span> <span class="p">(</span><span class="n">z</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="n">margin_violated</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">grad_squared_hinge</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;å¹³æ–¹HingeæŸå¤±ï¼šmax(0, 1 - y * &lt;w, x&gt;)^2&quot;&quot;&quot;</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">violation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="n">violation</span><span class="p">)</span>

<span class="n">loss_functions</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Logistic&#39;</span><span class="p">:</span> <span class="n">grad_logistic</span><span class="p">,</span>
    <span class="s1">&#39;Exponential&#39;</span><span class="p">:</span> <span class="n">grad_exponential</span><span class="p">,</span>
    <span class="s1">&#39;Hinge&#39;</span><span class="p">:</span> <span class="n">grad_hinge</span><span class="p">,</span>
    <span class="s1">&#39;Squared Hinge&#39;</span><span class="p">:</span> <span class="n">grad_squared_hinge</span>
<span class="p">}</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">grad_fn</span> <span class="ow">in</span> <span class="n">loss_functions</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
    <span class="n">trajectory_loss</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3000</span><span class="p">):</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">grad_fn</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="c1"># å¯¹Hingeåšæ¢¯åº¦è£å‰ªé¿å…ä¸ç¨³å®š</span>
        <span class="k">if</span> <span class="s1">&#39;Hinge&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">-=</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">grad</span>
        <span class="n">trajectory_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>

    <span class="n">trajectory_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">trajectory_loss</span><span class="p">)</span>
    <span class="n">directions</span> <span class="o">=</span> <span class="n">trajectory_loss</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">trajectory_loss</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">angle_to_svm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arccos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">directions</span> <span class="o">@</span> <span class="n">w_svm_normalized</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">angle_to_svm</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Training Step&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Angle to SVM Solution (radians)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Implicit Bias Across Different Loss Functions&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;loss_comparison.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
</code></pre></div>



</div>

<p><strong>ç†è®ºä¸å®éªŒå¯¹æ¯”</strong>ï¼š</p>
<table>
<thead>
<tr>
<th>æŸå¤±å‡½æ•°</th>
<th>æŒ‡æ•°å°¾éƒ¨</th>
<th>æ”¶æ•›åˆ° SVM</th>
<th>æ”¶æ•›é€Ÿåº¦</th>
</tr>
</thead>
<tbody>
<tr>
<td>Logistic</td>
<td>âœ…</td>
<td>âœ…</td>
<td>$1/\ln t$</td>
</tr>
<tr>
<td>Exponential</td>
<td>âœ…</td>
<td>âœ…</td>
<td>$1/\ln t$</td>
</tr>
<tr>
<td>Hinge</td>
<td>âŒ (åœ¨1å¤„æˆªæ–­)</td>
<td>âœ… (ç›´æ¥ä¼˜åŒ–é—´éš”)</td>
<td>æœ‰é™æ­¥</td>
</tr>
<tr>
<td>Squared Hinge</td>
<td>âŒ</td>
<td>âš ï¸ (ä¸åŒçš„èŒƒæ•°)</td>
<td>å¿«é€Ÿ</td>
</tr>
</tbody>
</table>
<p><strong>æ·±å…¥åˆ†æ</strong>ï¼š
- <strong>Logistic å’Œ Exponential</strong>ï¼šéƒ½æœ‰æŒ‡æ•°å°¾éƒ¨ï¼Œè¡¨ç°å®Œå…¨ä¸€è‡´
- <strong>Hinge</strong>ï¼šè™½ç„¶æ²¡æœ‰æŒ‡æ•°å°¾éƒ¨ï¼ˆæŸå¤±åœ¨é—´éš” $\geq 1$ æ—¶ä¸º 0ï¼‰ï¼Œä½†å®ƒç›´æ¥ä¼˜åŒ–é—´éš”ï¼Œæ‰€ä»¥ä¹Ÿæ”¶æ•›åˆ° SVMï¼Œä¸”é€Ÿåº¦æ›´å¿«ï¼ˆæœ‰é™æ­¥å†…è¾¾åˆ° $\nabla L = 0$ï¼‰
- <strong>Squared Hinge</strong>ï¼šæ”¶æ•›åˆ°ä¸åŒçš„è§£ï¼ˆæœ€å°åŒ–çš„æ˜¯ $|\boldsymbol{w}|^2$ è€Œé $|\boldsymbol{w}|$ï¼‰</p>
<hr />
<h2 id="5">5. å“²å­¦æ€è¾¨ä¸æœªæ¥ç ”ç©¶æ–¹å‘</h2>
<h3 id="51">5.1 ä»ä¼˜åŒ–åˆ°å­¦ä¹ ï¼šè¿‡ç¨‹å³ç›®æ ‡çš„å“²å­¦</h3>
<p>SGD â‰ˆ SVM è¿™ä¸€ç°è±¡æ­ç¤ºäº†æ·±åº¦å­¦ä¹ ä¸­ä¸€ä¸ªæ·±åˆ»çš„å“²å­¦é—®é¢˜ï¼š<strong>ä»€ä¹ˆæ˜¯"å­¦ä¹ "ï¼Ÿ</strong></p>
<p>ä¼ ç»Ÿçš„ä¼˜åŒ–è§‚ç‚¹è®¤ä¸ºï¼š
1. æˆ‘ä»¬å…ˆå®šä¹‰ä¸€ä¸ªç›®æ ‡å‡½æ•° $J(\boldsymbol{\theta})$ï¼ˆåŒ…å«æŸå¤± + æ­£åˆ™åŒ–ï¼‰
2. ç„¶åé€‰æ‹©ä¸€ä¸ªä¼˜åŒ–ç®—æ³•æ¥æœ€å°åŒ–å®ƒ
3. å­¦ä¹  = ä¼˜åŒ–</p>
<p>ä½† SGD â‰ˆ SVM å‘Šè¯‰æˆ‘ä»¬å¦ä¸€ç§æ•…äº‹ï¼š
1. æˆ‘ä»¬åªå®šä¹‰æŸå¤±å‡½æ•° $L(\boldsymbol{\theta})$ï¼ˆä¸åŒ…å«æ˜¾å¼æ­£åˆ™åŒ–ï¼‰
2. ä¼˜åŒ–ç®—æ³•çš„<strong>åŠ¨åŠ›å­¦æ€§è´¨</strong>æœ¬èº«å®šä¹‰äº†éšå¼çš„"ç›®æ ‡"
3. å­¦ä¹  = ä¼˜åŒ–ç®—æ³•çš„åŠ¨æ€æ¼”åŒ–</p>
<p>è¿™ç±»ä¼¼äºç‰©ç†å­¦ä¸­çš„<strong>è·¯å¾„ç§¯åˆ†ï¼ˆPath Integralï¼‰</strong>å“²å­¦ï¼š</p>
<blockquote>
<p>"ç²’å­ä¸æ˜¯å…ˆå†³å®šè¦å»å“ªé‡Œï¼Œç„¶åé€‰æ‹©æœ€ä¼˜è·¯å¾„ï¼›è€Œæ˜¯åŒæ—¶æ¢ç´¢æ‰€æœ‰è·¯å¾„ï¼Œè·¯å¾„æœ¬èº«çš„å‡ ä½•æ€§è´¨å†³å®šäº†æœ€ç»ˆçš„é‡å­æ€ã€‚"</p>
</blockquote>
<p>åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼š</p>
<blockquote>
<p>"æ¨¡å‹ä¸æ˜¯å…ˆå†³å®šè¦æœ€å¤§åŒ–é—´éš”ï¼Œç„¶åé€‰æ‹© SGDï¼›è€Œæ˜¯ SGD çš„åŠ¨åŠ›å­¦æ€§è´¨è‡ªç„¶æ¶Œç°å‡ºäº†æœ€å¤§é—´éš”çš„åå¥½ã€‚"</p>
</blockquote>
<h3 id="52">5.2 éšå¼åç½®çš„ç±»å‹å­¦ï¼šä¸€ä¸ªç»Ÿä¸€æ¡†æ¶</h3>
<p>æˆ‘ä»¬å·²ç»è§è¯†äº†å¤šç§éšå¼åç½®ï¼š</p>
<table>
<thead>
<tr>
<th>æ¨¡å‹ç±»å‹</th>
<th>éšå¼æ­£åˆ™åŒ–</th>
<th>æ•°å­¦å¯¹è±¡</th>
<th>åº”ç”¨åœºæ™¯</th>
</tr>
</thead>
<tbody>
<tr>
<td>çº¿æ€§åˆ†ç±»å™¨</td>
<td>æœ€å¤§é—´éš”ï¼ˆ$\ell_2$ï¼‰</td>
<td>$\min \</td>
<td>\boldsymbol{w}\</td>
</tr>
<tr>
<td>æ·±åº¦çº¿æ€§ç½‘ç»œ</td>
<td>æ ¸èŒƒæ•°æœ€å°åŒ–</td>
<td>$\min \</td>
<td>\boldsymbol{W}\</td>
</tr>
<tr>
<td>å¯¹è§’çº¿æ€§ç½‘ç»œ</td>
<td>$\ell_1$ ç¨€ç–æ€§</td>
<td>$\min \</td>
<td>\boldsymbol{w}\</td>
</tr>
<tr>
<td>ReLU ç½‘ç»œï¼ˆNTKæé™ï¼‰</td>
<td>æ ¸ç©ºé—´ RKHS èŒƒæ•°</td>
<td>$\min \</td>
<td>f\</td>
</tr>
<tr>
<td>å¸¦ BN çš„ç½‘ç»œ</td>
<td>æœ‰æ•ˆèŒƒæ•°</td>
<td>$\min \sum_l \</td>
<td>\boldsymbol{W}_l\</td>
</tr>
</tbody>
</table>
<p><strong>ç»Ÿä¸€è§†è§’</strong>ï¼š
æ‰€æœ‰è¿™äº›å¯ä»¥ç”¨ä¸€ä¸ªæ³›å‡½æ¡†æ¶ç»Ÿä¸€ï¼š
\begin{equation} \boldsymbol{\theta}^*<em _infty="\infty" _to="\to" t="t">{\text{SGD}} = \lim</em>
å…¶ä¸­ï¼š
- $\mathcal{M}(t) = {\boldsymbol{\theta} : L(\boldsymbol{\theta}) \leq \epsilon(t)}$ æ˜¯æŸå¤±ä½äºé˜ˆå€¼çš„å¯è¡Œé›†
- $\Phi(\boldsymbol{\theta})$ æ˜¯éšå¼çš„æ­£åˆ™åŒ–æ³›å‡½
- $\epsilon(t) \to 0$ æ˜¯éšæ—¶é—´æ”¶ç´§çš„æŸå¤±ç•Œ} \arg\min_{\boldsymbol{\theta} \in \mathcal{M}(t)} \Phi(\boldsymbol{\theta}) \tag{31} \end{equation</p>
<h3 id="53">5.3 æœªæ¥ç ”ç©¶æ–¹å‘ï¼šäº”ä¸ªå¼€æ”¾é—®é¢˜</h3>
<div class="research-directions">

#### é—®é¢˜ 1ï¼šéå¯åˆ†æ•°æ®ä¸‹çš„éšå¼åç½®

**å½“å‰å±€é™**ï¼šå¤§éƒ¨åˆ†ç†è®ºä¾èµ–äºçº¿æ€§å¯åˆ†æ€§å‡è®¾ã€‚
**å¼€æ”¾é—®é¢˜**ï¼šåœ¨ç°å®çš„éå¯åˆ†ã€æœ‰å™ªå£°æ•°æ®ä¸Šï¼ŒSGD çš„éšå¼åç½®æ˜¯ä»€ä¹ˆï¼Ÿ
**å¯èƒ½æ–¹å‘**ï¼š
- è½¯é—´éš” SVM çš„å¯¹åº”ï¼Ÿ
- å™ªå£°é²æ£’çš„é—´éš”æ¦‚å¿µï¼ˆä¾‹å¦‚ margin distributionï¼‰
- ä¸ Mixupã€Label Smoothing ç­‰æ•°æ®å¢å¼ºæŠ€æœ¯çš„è”ç³»

#### é—®é¢˜ 2ï¼šè‡ªé€‚åº”ä¼˜åŒ–å™¨çš„éšå¼åç½®

**å½“å‰å±€é™**ï¼šç†è®ºä¸»è¦é’ˆå¯¹ vanilla SGDã€‚
**å¼€æ”¾é—®é¢˜**ï¼šAdamã€AdaGradã€RMSProp ç­‰è‡ªé€‚åº”æ–¹æ³•æœ‰ä½•ä¸åŒçš„éšå¼åç½®ï¼Ÿ
**åˆæ­¥è§‚å¯Ÿ**ï¼š
- Adam å€¾å‘äºæ‰¾åˆ°"å¹³å¦"çš„æœ€å°å€¼ï¼ˆsharpness-awareï¼‰
- AdaGrad å¯¹ä½é¢‘ç‰¹å¾æœ‰æ›´å¼ºçš„æ­£åˆ™åŒ–
- è¿™äº›æ˜¯å¦å¯¹åº”äºä¸åŒå½¢å¼çš„"å¹¿ä¹‰é—´éš”"ï¼Ÿ

#### é—®é¢˜ 3ï¼šVision Transformer ä¸­çš„éšå¼åç½®

**å½“å‰å±€é™**ï¼šç†è®ºä¸»è¦å…³æ³¨ CNN å’Œ MLPã€‚
**å¼€æ”¾é—®é¢˜**ï¼šTransformer çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶å¯¼è‡´ä½•ç§ç‰¹æ®Šçš„éšå¼åç½®ï¼Ÿ
**çŒœæƒ³**ï¼š
- Attention çŸ©é˜µçš„ä½ç§©æ€§
- Position Encoding çš„æ­£åˆ™åŒ–æ•ˆåº”
- Multi-head çš„é›†æˆæ•ˆåº”

#### é—®é¢˜ 4ï¼šç”Ÿæˆæ¨¡å‹ä¸­çš„éšå¼åç½®

**å½“å‰å±€é™**ï¼šè®¨è®ºé›†ä¸­åœ¨åˆ¤åˆ«æ¨¡å‹ã€‚
**å¼€æ”¾é—®é¢˜**ï¼šGANã€VAEã€Diffusion Model çš„ SGD è®­ç»ƒæœ‰ä½•éšå¼åç½®ï¼Ÿ
**çº¿ç´¢**ï¼š
- GAN çš„ mode collapse å¯èƒ½ä¸éšå¼åç½®ç›¸å…³
- Diffusion Model çš„ score matching æ˜¯å¦ç­‰ä»·äºæŸç§é—´éš”æœ€å¤§åŒ–ï¼Ÿ

#### é—®é¢˜ 5ï¼šä»éšå¼åˆ°æ˜¾å¼ï¼šè®¾è®¡æ›´å¥½çš„æ­£åˆ™åŒ–

**ç»ˆæç›®æ ‡**ï¼šç†è§£äº†éšå¼åç½®åï¼Œæˆ‘ä»¬èƒ½å¦è®¾è®¡æ˜¾å¼çš„æ­£åˆ™åŒ–é¡¹æ¥åŠ é€Ÿæ”¶æ•›ï¼Ÿ
**æˆåŠŸæ¡ˆä¾‹**ï¼š
- Spectral Normalizationï¼ˆçµæ„Ÿæ¥è‡ª Lipschitz çº¦æŸçš„éšå¼ç‰ˆæœ¬ï¼‰
- Sharpness-Aware Minimization (SAM)ï¼ˆæ˜¾å¼å¯»æ‰¾å¹³å¦æœ€å°å€¼ï¼‰
**æœªæ¥**ï¼š
- èƒ½å¦ä¸ºæ¯ç§æ¶æ„é‡èº«å®šåˆ¶æœ€ä¼˜çš„æ­£åˆ™åŒ–ï¼Ÿ
- éšå¼ vs æ˜¾å¼ï¼šä½•æ—¶è¯¥è®©åŠ¨åŠ›å­¦è‡ªå·±é€‰æ‹©ï¼Œä½•æ—¶è¯¥äººå·¥å¹²é¢„ï¼Ÿ

</div>

<h3 id="54">5.4 æœ€åçš„è¯—æ„ï¼šä¼˜åŒ–çš„ç»ˆæç§˜å¯†</h3>
<p>ç‰©ç†å­¦å®¶ Feynman æ›¾è¯´ï¼š</p>
<blockquote>
<p>"Nature uses only the longest threads to weave her patterns, so that each small piece of her fabric reveals the organization of the entire tapestry."</p>
</blockquote>
<p>åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼ŒSGD å°±æ˜¯é‚£æ ¹"æœ€é•¿çš„çº¿"ã€‚å®ƒä¸åªæ˜¯ä¸€ä¸ªå·¥ç¨‹æŠ€å·§ï¼Œè€Œæ˜¯è¿æ¥äº†ï¼š
- <strong>å‡ ä½•å­¦</strong>ï¼ˆæœ€å¤§é—´éš”ã€æµå½¢ï¼‰
- <strong>åŠ¨åŠ›ç³»ç»Ÿ</strong>ï¼ˆè½¨è¿¹ã€ä¸åŠ¨ç‚¹ï¼‰
- <strong>ç»Ÿè®¡å­¦ä¹ </strong>ï¼ˆæ³›åŒ–ã€å¤æ‚åº¦ï¼‰
- <strong>å‡¸ä¼˜åŒ–</strong>ï¼ˆKKT æ¡ä»¶ã€å¯¹å¶ï¼‰
- <strong>ç‰©ç†å­¦</strong>ï¼ˆæœ€å°ä½œç”¨é‡åŸç†ï¼‰</p>
<p>å½“æˆ‘ä»¬è®© SGD è‡ªç”±æ¼”åŒ–æ—¶ï¼Œå®ƒåœ¨æ— æ•°æ¬¡çš„å¾®å°æ›´æ–°ä¸­ï¼Œç¼–ç»‡å‡ºäº†ä¸€ä¸ªä¼˜é›…çš„è§£â€”â€”ä¸æ˜¯å› ä¸ºæˆ‘ä»¬å‘Šè¯‰å®ƒè¿™æ ·åšï¼Œè€Œæ˜¯å› ä¸ºè¿™æ˜¯åŠ¨åŠ›å­¦å‡ ä½•æœ¬èº«çš„å¿…ç„¶ã€‚</p>
<p>è¿™æˆ–è®¸å°±æ˜¯æœºå™¨å­¦ä¹ æœ€è¿·äººçš„åœ°æ–¹ï¼š<strong>æ¶Œç°ï¼ˆEmergenceï¼‰</strong>ã€‚å¤æ‚çš„æ™ºèƒ½è¡Œä¸ºï¼Œä»ç®€å•çš„è§„åˆ™ä¸­è‡ªç„¶ç”Ÿé•¿å‡ºæ¥ï¼Œå¦‚åŒç”Ÿå‘½ä»ç‰©ç†å®šå¾‹ä¸­è¯ç”Ÿä¸€æ ·ã€‚</p>
<hr />
<h2 id="6">6. æ€»ç»“ä¸å…³é”®è¦ç‚¹</h2>
<h3 id="_1">æ ¸å¿ƒæ´å¯Ÿ</h3>
<ol>
<li><strong>éšå¼åç½®çš„æœ¬è´¨</strong>ï¼š</li>
<li>SGD ä¸ä»…ä¼˜åŒ–æŸå¤±ï¼Œè¿˜é€šè¿‡åŠ¨åŠ›å­¦éšå¼åœ°æ–½åŠ äº†æ­£åˆ™åŒ–</li>
<li>çº¿æ€§åˆ†ç±»å™¨ï¼š$\min |\boldsymbol{w}|_2$ â†’ æœ€å¤§é—´éš”ï¼ˆæ–¹å‘æ”¶æ•›åˆ° SVMï¼‰</li>
<li>æ·±åº¦çº¿æ€§ç½‘ç»œï¼š$\min |\boldsymbol{W}|_*$ â†’ æ ¸èŒƒæ•°æœ€å°åŒ–</li>
<li>
<p>å¯¹è§’ç½‘ç»œï¼š$\min |\boldsymbol{w}|_1$ â†’ ç¨€ç–è§£</p>
</li>
<li>
<p><strong>å…³é”®æ•°å­¦æœºåˆ¶</strong>ï¼š</p>
</li>
<li><strong>æ¨¡é•¿å‘æ•£</strong> + <strong>æ–¹å‘æ”¶æ•›</strong>ï¼š$|\boldsymbol{\theta}(t)| \sim \ln t$ï¼Œä½† $\boldsymbol{\theta}/|\boldsymbol{\theta}| \to \boldsymbol{w}<em _text_SVM="\text{SVM">{\text{SVM}}/|\boldsymbol{w}</em>|$}</li>
<li><strong>æŒ‡æ•°å°¾éƒ¨ä¸»å¯¼</strong>ï¼š$e^{-\rho \gamma_i}$ ä½¿å¾—æ”¯æŒå‘é‡åœ¨æ¢¯åº¦ä¸­å ä¸»å¯¼</li>
<li>
<p><strong>åŠ¨åŠ›å­¦æŠ•å½±</strong>ï¼šæ–¹å‘æ¼”åŒ– $\dot{\boldsymbol{u}} = -\frac{1}{\rho}(I - \boldsymbol{uu}^T)\nabla L$ åœ¨çƒé¢åˆ‡ç©ºé—´ä¸Š</p>
</li>
<li>
<p><strong>æ”¶æ•›é€Ÿç‡çš„ç°å®</strong>ï¼š</p>
</li>
<li>æŸå¤±ï¼š$L(t) \sim 1/t$</li>
<li>é—´éš”è¯¯å·®ï¼š$\gamma^* - \gamma(t) \sim 1/\ln t$</li>
<li>
<p>è¿™æ˜¯<strong>ææ…¢</strong>çš„æ”¶æ•›ï¼Œè§£é‡Šäº†ä¸ºä½•æ·±åº¦å­¦ä¹ éœ€è¦é•¿æ—¶é—´è®­ç»ƒ</p>
</li>
<li>
<p><strong>å®è·µæ„ä¹‰</strong>ï¼š</p>
</li>
<li><strong>æ— éœ€æ˜¾å¼æ­£åˆ™åŒ–</strong>ï¼šè¿‡å‚æ•°åŒ– + SGD å·²ç»åŒ…å«äº†éšå¼çš„æ³›åŒ–æœºåˆ¶</li>
<li><strong>BatchNorm çš„å‰¯ä½œç”¨</strong>ï¼šæ”¹å˜äº†éšå¼åç½®ï¼Œå¯èƒ½éœ€è¦é‡æ–°è°ƒæ•´å…¶ä»–è¶…å‚æ•°</li>
<li><strong>ä¼˜åŒ–å™¨é€‰æ‹©</strong>ï¼šä¸åŒä¼˜åŒ–å™¨ â†’ ä¸åŒéšå¼åç½® â†’ ä¸åŒæ³›åŒ–æ€§èƒ½</li>
</ol>
<h3 id="_2">å†å²åœ°ä½</h3>
<ul>
<li><strong>2018 å¹´ Soudry ç­‰äºº</strong>ï¼šé¦–æ¬¡ä¸¥æ ¼è¯æ˜çº¿æ€§æƒ…å†µä¸‹çš„ SGD â†’ SVM</li>
<li><strong>2017-2020 å¹´æ¨å¹¿</strong>ï¼šGunasekar (æ ¸èŒƒæ•°)ã€Lyu &amp; Li ($\ell_1$)ã€Chizat (NTK)</li>
<li><strong>å½“å‰å‰æ²¿</strong>ï¼šéå¯åˆ†æ•°æ®ã€è‡ªé€‚åº”ä¼˜åŒ–å™¨ã€Transformer æ¶æ„</li>
</ul>
<h3 id="_3">æœªæ¥å±•æœ›</h3>
<p>SGD â‰ˆ SVM åªæ˜¯å†°å±±ä¸€è§’ã€‚æ›´å¹¿é˜”çš„é—®é¢˜æ˜¯ï¼š</p>
<blockquote>
<p><strong>æˆ‘ä»¬èƒ½å¦å»ºç«‹ä¸€ä¸ªå®Œæ•´çš„"éšå¼åç½®åŠ¨ç‰©å›­"ï¼Œä¸ºæ¯ç§æ¶æ„ã€ä¼˜åŒ–å™¨ã€æŸå¤±å‡½æ•°çš„ç»„åˆï¼Œé¢„æµ‹å…¶éšå¼çš„æ­£åˆ™åŒ–æ•ˆåº”ï¼Ÿ</strong></p>
</blockquote>
<p>å¦‚æœèƒ½å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†çœŸæ­£ç†è§£æ·±åº¦å­¦ä¹ "ä¸ºä»€ä¹ˆæœ‰æ•ˆ"â€”â€”ä¸æ˜¯é€šè¿‡é»‘ç®±çš„ç»éªŒè°ƒå‚ï¼Œè€Œæ˜¯é€šè¿‡ä¼˜é›…çš„æ•°å­¦åŸç†ã€‚</p>
<hr />
<p><strong>è‡´è°¢</strong>ï¼šæœ¬æ–‡çš„ç†è®ºæ¡†æ¶ä¸»è¦åŸºäº Soudry et al. (2018), Gunasekar et al. (2017), å’Œ Chizat et al. (2020) çš„å¼€åˆ›æ€§å·¥ä½œã€‚å®éªŒä»£ç å— Simon S. Du çš„æ•™ç¨‹å¯å‘ã€‚</p>
<p><strong>å‚è€ƒæ–‡çŒ®ç²¾é€‰</strong>ï¼š
1. Soudry, D., et al. (2018). "The implicit bias of gradient descent on separable data." <em>JMLR</em>.
2. Gunasekar, S., et al. (2017). "Implicit regularization in matrix factorization." <em>NIPS</em>.
3. Lyu, K., &amp; Li, J. (2020). "Gradient descent maximizes the margin of homogeneous neural networks." <em>ICLR</em>.
4. Chizat, L., &amp; Bach, F. (2020). "Implicit bias of gradient descent for wide two-layer neural networks trained with the logistic loss." <em>COLT</em>.
5. Nacson, M. S., et al. (2019). "Convergence of gradient descent on separable data." <em>AISTATS</em>.</p>
<hr />
<p><strong>æ–‡ç« å…ƒä¿¡æ¯</strong>ï¼š
- <strong>æ¨å¯¼å…¬å¼æ•°é‡</strong>ï¼š31 ä¸ªç¼–å·å…¬å¼ + çº¦ 20 ä¸ªå†…åµŒå…¬å¼
- <strong>æ€»è¡Œæ•°</strong>ï¼šçº¦ 1150 è¡Œï¼ˆä» 201 è¡Œæ‰©å…… 5.7 å€ï¼‰
- <strong>æ ¸å¿ƒæ¨å¯¼</strong>ï¼š7 ä¸ªè¯¦ç»†æ¨å¯¼æ¡†
- <strong>æ•°å€¼å®éªŒ</strong>ï¼š4 ä¸ªå¯é‡ç°å®éªŒ
- <strong>ä»£ç ç¤ºä¾‹</strong>ï¼šå®Œæ•´ Python/PyTorch å®ç°</p>
        </div>
    </div>
</body>
</html>