<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transformerå‡çº§ä¹‹è·¯ï¼š21ã€MLAå¥½åœ¨å“ªé‡Œ?ï¼ˆä¸‹ï¼‰</title>
    <style>
* { margin: 0; padding: 0; box-sizing: border-box; }
body {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
    line-height: 1.6; color: #333; max-width: 900px; margin: 0 auto; padding: 20px; background: #f5f5f5;
}
.container { background: white; padding: 40px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
header { border-bottom: 2px solid #e0e0e0; padding-bottom: 20px; margin-bottom: 30px; }
h1 { color: #2c3e50; margin-bottom: 10px; font-size: 2em; }
.meta { color: #666; font-size: 0.9em; margin-bottom: 20px; }
.content { margin-top: 30px; overflow-wrap: break-word; }
.content h2 { color: #34495e; margin-top: 30px; margin-bottom: 15px; border-bottom: 1px solid #eee; padding-bottom: 5px; }
.content p { margin-bottom: 15px; }
.content pre { background: #f8f8f8; padding: 15px; border-radius: 5px; overflow-x: auto; border-left: 3px solid #3498db; margin: 15px 0; }
.content code { background: #f8f8f8; padding: 2px 5px; border-radius: 3px; font-family: monospace; font-size: 0.9em; }
.content blockquote { border-left: 4px solid #3498db; padding-left: 20px; margin: 20px 0; color: #555; font-style: italic; }
.content table { border-collapse: collapse; width: 100%; margin: 20px 0; }
.content th, .content td { border: 1px solid #ddd; padding: 10px; text-align: left; }
.back-link { display: inline-block; margin-bottom: 20px; color: #3498db; text-decoration: none; font-weight: 500; }
</style>
    
<script>
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\(', '\)']],
            displayMath: [['$$', '$$'], ['\[', '\]']],
            processEscapes: true
        }
    };
</script>
<script id="MathJax-script" async src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>
    <div class="container">
        <a href="../index.html" class="back-link">â† è¿”å›é¦–é¡µ</a>
        <header>
            <h1>Transformerå‡çº§ä¹‹è·¯ï¼š21ã€MLAå¥½åœ¨å“ªé‡Œ?ï¼ˆä¸‹ï¼‰</h1>
            <div class="meta">ğŸ“… æœ€åæ›´æ–°: 2025-11-26 | ğŸ“„ å¤§å°: 40.4 KB</div>
        </header>
        <div class="content">
            <p><strong>åŸæ–‡é“¾æ¥</strong>: <a href="https://spaces.ac.cn/archives/11111">https://spaces.ac.cn/archives/11111</a></p>
<p><strong>å‘å¸ƒæ—¥æœŸ</strong>: </p>
<hr />
<p>åœ¨æ–‡ç« <a href="/archives/10907">ã€ŠTransformerå‡çº§ä¹‹è·¯ï¼š20ã€MLAå¥½åœ¨å“ªé‡Œ?ï¼ˆä¸Šï¼‰ã€‹</a>ä¸­ï¼Œæˆ‘ä»¬å¯¹<a href="/archives/10091">MLA</a>ç›¸æ¯”å¸¸è§MHAã€GQAã€MQAçš„ä¸€äº›å˜åŒ–åˆ†åˆ«åšäº†æ¶ˆèå®éªŒï¼Œå…¶ä¸­çš„å˜åŒ–åŒ…æ‹¬â€œå¢å¤§head_dimsâ€ã€â€œPartial RoPEâ€å’Œâ€œKVå…±äº«â€ï¼Œå®éªŒçš„åˆæ­¥ç»“æœæ˜¯è¿™ä¸‰ä¸ªå˜åŒ–å¾ˆå¯èƒ½éƒ½æ˜¯MLAæ•ˆæœä¼˜å¼‚çš„åŸå› ã€‚</p>
<p>æœ¬æ–‡æˆ‘ä»¬å°†ä»ä¸€ä¸ªæ›´åŠ åç†è®ºçš„è§’åº¦å‡ºå‘ï¼Œæ¥ç†è§£MLAçš„æˆåŠŸä¹‹å¤„ã€‚</p>
<h2 id="_1">éƒ¨åˆ†æ—‹è½¬</h2>
<p>é¦–å…ˆï¼Œæˆ‘ä»¬æŠŠæœ€ç»ˆçš„æ–­è¨€æ”¾åœ¨å‰é¢ï¼š</p>
<blockquote>
<p>åœ¨ç›¸åŒè®­ç»ƒæˆæœ¬å’Œæ¨ç†æˆæœ¬ä¸‹ï¼ŒMLAå¯èƒ½æ˜¯æ•ˆæœæœ€å¥½çš„Full Attentionå˜ä½“ã€‚</p>
</blockquote>
<p>å¾ˆæ˜æ˜¾ï¼Œè¿™ä¸ªåˆ¤æ–­æŠŠMLAæ‘†åœ¨äº†éå¸¸é«˜çš„ä½ç½®ã€‚è¿™æ˜¯åœ¨æ¯”è¾ƒç†æƒ³å’Œç®€åŒ–çš„å‡è®¾ä¸‹ï¼Œæ ¹æ®ä¸Šä¸€ç¯‡æ–‡ç« çš„å®éªŒç»“æœä»¥åŠæœ¬æ–‡æ¥ä¸‹æ¥çš„ç†è®ºåˆ†ææ‰€å¾—çš„ç»“è®ºã€‚ç”±äºå®é™…çš„è®­ç»ƒå’Œæ¨ç†å­˜åœ¨è¯¸å¤šå¤æ‚çš„å› ç´ ï¼Œæ‰€ä»¥è¯¥ç»“è®ºå¤§æ¦‚ç‡ä¼šæœ‰æ‰€åå·®ï¼Œä½†æˆ‘ä»¬è‡³å°‘å¯ä»¥å¾—å‡ºï¼ŒMLAåº”è¯¥æ˜¯èµ°åœ¨äº†æ­£ç¡®çš„æ”¹è¿›æ–¹å‘ä¸Šã€‚</p>
<p>MLAä¹‹æ‰€ä»¥èƒ½å¤Ÿè¡¨ç°å‡ºè‰²ï¼Œæœ‰ä¸€ä¸ªéå¸¸å¤§çš„å‰æï¼Œé‚£å°±æ˜¯éƒ¨åˆ†æ—‹è½¬çš„<a href="/archives/10122">Partial RoPE</a>æ•ˆæœä¸é€Šè‰²äºç”šè‡³å¯èƒ½ä¼˜äºå®Œå…¨ä½“çš„RoPEã€‚è¿™é‡Œçš„Partial RoPEå¯ä»¥æœ‰ä¸¤ç§å«ä¹‰ï¼šä¸€æ˜¯æˆ‘ä»¬å¯¹Attentionçš„$\boldsymbol{Q}$ã€$\boldsymbol{K}$åŠ RoPEæ—¶ï¼Œå¯ä»¥åªå¯¹å°éƒ¨ä»½ç»´åº¦åŠ ï¼Œå‰©ä¸‹çš„ç»´åº¦ä¿æŒä¸å˜ï¼›äºŒæ˜¯æˆ‘ä»¬å¯ä»¥è€ƒè™‘å±‚é—´RoPEä¸NoPEäº¤æ›¿å‡ºç°ï¼Œå¹¶ä¸”NoPEçš„å±‚å¯ä»¥å å¤šæ•°ã€‚</p>
<p>è¯´ç™½äº†ï¼ŒRoPEå¯ä»¥åªåŠ â€œä¸€ç‚¹ç‚¹â€ï¼Œä½†ä¸èƒ½ä¸åŠ ï¼Œå®Œå…¨ä¸åŠ çš„è¯æ•ˆæœä¸è¡Œã€‚å¦‚æœéœ€è¦ç†è®ºï¼Œç¬”è€…æ¯”è¾ƒè®¤åŒ<a href="/archives/10122">ã€ŠTransformerå‡çº§ä¹‹è·¯ï¼š18ã€RoPEçš„åº•æ•°é€‰æ‹©åŸåˆ™ã€‹</a>çš„è§£é‡Šï¼Œå¤§è‡´æ„æ€æ˜¯Partial RoPEä½¿å¾—æ£€ç´¢ç»“æœæ›´å…¼é¡¾ä½ç½®ä¸è¯­ä¹‰ã€‚æ­¤å¤–ï¼Œåƒ<a href="https://papers.cool/arxiv/2503.02130">FoX</a>ã€<a href="https://papers.cool/arxiv/2410.17980">SBA</a>ç­‰æ–°å·¥ä½œä¹Ÿä½“ç°å‡ºä¸€å®šæ½œåŠ›ï¼Œä½†å¯¹äºMLAæ¥è¯´ï¼Œè¿™äº›å˜ä½“å°±ç›¸å½“äºNoPEï¼Œå› æ­¤ä¸æ”¹å˜ç»“è®ºã€‚</p>
<p>â€œPartial RoPEæ•ˆæœä¸å·®â€çš„ç»“è®ºï¼Œå…è®¸æˆ‘ä»¬æŠŠAttentionçš„ä¸»è¦è®¡ç®—å¤æ‚åº¦æ”¾åˆ°NoPEéƒ¨åˆ†ä¸Šï¼Œè¿™æä¾›äº†æ›´å¤§çš„è…¾æŒªç©ºé—´ï¼ŒMLAä¾¿æ˜¯å¾—ç›Šäºæ­¤ã€‚</p>
<h2 id="_2">é”®å€¼å…±äº«</h2>
<p>Full Attentionçš„å˜åŒ–å¤§è‡´ä¸Šæ˜¯ä»<a href="/archives/4765">MHA</a>ã€<a href="https://papers.cool/arxiv/1911.02150">MQA</a>ã€<a href="https://papers.cool/arxiv/2305.13245">GQA</a>ç„¶ååˆ°MLAï¼Œè™½ç„¶MQAå¯ä»¥çœ‹ä½œæ˜¯GQAçš„ç‰¹ä¾‹ï¼Œä½†æŒ‰æ—¶é—´é¡ºåºæ¥è¯´ç¡®å®æ˜¯GQAåœ¨åã€‚åœ¨MLAä¹‹åï¼Œè¿˜å‡ºç°äº†<a href="https://papers.cool/arxiv/2412.19255">MFA</a>ã€<a href="https://papers.cool/arxiv/2501.06425">TPA</a>ä¸¤ä¸ªå˜ä½“ã€‚è¿™äº›å˜ä½“æœ¬è´¨ä¸Šéƒ½æ˜¯åœ¨å°½é‡ä¿æŒæ•ˆæœçš„å‰æä¸‹ï¼Œå°½å¯èƒ½å‹æ¦¨KV Cacheä»¥æé«˜ç”Ÿæˆé€Ÿåº¦ã€‚</p>
<p>ç®€å•æ¥è¯´ï¼ŒAttentionæ¨¡å‹çš„å¤æ‚åº¦å¯ä»¥åˆ† <em>è®­ç»ƒã€Prefillå’ŒDecoding</em> ä¸‰éƒ¨åˆ†ï¼Œå…¶ä¸­è®­ç»ƒå’ŒPrefillæ˜¯ç›¸ä¼¼çš„ï¼Œæ‰€ä»¥æœ¬è´¨ä¸Šæ˜¯Prefillå’ŒDecodingä¸¤éƒ¨åˆ†ã€‚Prefillæ˜¯æŒ‡æ¨¡å‹å¤„ç†è¾“å…¥ã€ç›´è‡³åå‡ºç¬¬ä¸€ä¸ªtokençš„é˜¶æ®µï¼Œè¿™éƒ¨åˆ†æˆ‘ä»¬ä¸‹èŠ‚å†è°ˆï¼›Decodingæ˜¯æŒ‡Token by Tokençš„ç”Ÿæˆé˜¶æ®µï¼Œå®ƒå¯ä»¥é€šè¿‡KV Cacheæœºåˆ¶æ¥åŠ é€Ÿï¼Œä½†åŒæ—¶ä¹Ÿå¯¼è‡´äº†KV Cacheå¤§å°å‡ ä¹æ˜¯Decodingé€Ÿåº¦çš„å”¯ä¸€ç“¶é¢ˆã€‚</p>
<p>æ‰€ä»¥ï¼Œå‹ç¼©KV Cacheå°±æ˜¯æé«˜Decodingé€Ÿåº¦ã€‚ç°åœ¨é—®å¤§å®¶ä¸€ä¸ªé—®é¢˜ï¼š<strong>åœ¨NoPEèƒŒæ™¯ä¸‹ï¼Œç»™å®šKV Cacheå¤§å°åï¼Œæ•ˆæœæœ€å¥½çš„Attentionæ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ</strong> å¦‚æœä¸è€ƒè™‘å‚æ•°é‡å·®å¼‚ï¼Œåªåœ¨å•å±‚MHA/GQA/MQAå†…è®¨è®ºï¼ˆTPAå’ŒMFAæˆ‘ä»¬åé¢å†è¡¥å……è®¨è®ºï¼‰ï¼Œé‚£ä¹ˆç­”æ¡ˆå°†ä¼šæ˜¯ï¼š</p>
<blockquote>
<p><strong>ä¸€ä¸ªhead_dimsç­‰äºKV Cacheå¤§å°ã€Kå’ŒVå…±äº«çš„MQAã€‚</strong></p>
</blockquote>
<p>çœ‹ä¸Šå»æ˜¯ä¸æ˜¯è®©äººæ„å¤–ï¼Ÿå…¶å®ä¸éš¾ç†è§£ã€‚å› ä¸ºMHAã€MQAéƒ½å¯ä»¥çœ‹æˆæ˜¯GQAçš„ä¸€ä¸ªç‰¹ä¾‹ï¼Œæ‰€ä»¥æˆ‘ä»¬åªéœ€è¦åˆ†æGQAï¼Œæˆ‘ä»¬åœ¨<a href="/archives/10091">ã€Šç¼“å­˜ä¸æ•ˆæœçš„æé™æ‹‰æ‰¯ï¼šä»MHAã€MQAã€GQAåˆ°MLAã€‹</a>å·²ç»ç»™å‡ºäº†ï¼ŒGQAå¯ä»¥é‡æ–°è¡¨ç¤ºæˆä¸€ä¸ªKã€Væ‹¼æ¥èµ·æ¥çš„æ¨¡å‹ï¼š<br />
\begin{equation}\underbrace{\left[\boldsymbol{k}<em _boldsymbol_c="\boldsymbol{c">i^{(1)},\cdots,\boldsymbol{k}_i^{(g)},\boldsymbol{v}_i^{(1)},\cdots,\boldsymbol{v}_i^{(g)}\right]}</em><em _boldsymbol_W="\boldsymbol{W">i\in\mathbb{R}^{g(d_k+d_v)}} = \boldsymbol{x}_i \underbrace{\left[\boldsymbol{W}_k^{(1)},\cdots,\boldsymbol{W}_k^{(g)},\boldsymbol{W}_v^{(1)},\cdots,\boldsymbol{W}_v^{(g)}\right]}</em>}_c\in\mathbb{R}^{d\times g(d_k+d_v)}}\end{equation<br />
è¿™é‡Œ$g(d_k+d_v)$æ­£æ˜¯å•ä¸ªTokençš„KV Cacheæ€»å¤§å°ã€‚æ¥ç€æˆ‘ä»¬ç®—Attentionçš„æ—¶å€™ï¼Œ$\boldsymbol{c}$åˆ°$\boldsymbol{k},\boldsymbol{v}$çš„å˜æ¢åˆ†åˆ«å¸æ”¶åˆ°$\boldsymbol{W}_q$å’Œ$\boldsymbol{W}_o$é‚£è¾¹å»ï¼Œé‚£ä¹ˆå°±å¾—åˆ°äº†ä¸€ä¸ªKã€Véƒ½æ˜¯$\boldsymbol{c}$çš„MQAã€‚æ‰€ä»¥è¯´ï¼Œâ€œhead_dimsç­‰äºKV Cacheå¤§å°ã€Kå’ŒVå…±äº«çš„MQAâ€ï¼Œå®é™…ä¸Šæ˜¯ç»™å®šKV Cacheå¤§å°åMHA/GQA/MQAçš„â€œè¶…é›†â€ï¼Œé‚£ä¹ˆå®ƒè‡ªç„¶æ˜¯ç†è®ºä¸Šæ•ˆæœæœ€å¥½çš„é€‰æ‹©ã€‚</p>
<h2 id="_3">åŒé‡æŠ•å½±</h2>
<p>ç»¼ä¸Šæ‰€è¿°ï¼Œå¦‚æœæˆ‘ä»¬æƒ³è¦åœ¨ç›¸åŒDecodingé€Ÿåº¦ä¸‹æ•ˆæœæœ€ä¼˜ï¼Œé‚£ä¹ˆåº”è¯¥è®­ç»ƒä¸€ä¸ªæŒ‡å®šhead_dimsçš„ã€KVå…±äº«çš„MQAï¼Œæ¯”å¦‚çº¦å®šKV Cacheä¸è¶…è¿‡512ï¼Œé‚£ä¹ˆhead_dims=512çš„ã€KVå…±äº«çš„MQAå°±æ˜¯æœ€ä½³é€‰æ‹©ã€‚äº‹å®ä¸Šï¼ŒMLAåœ¨Decodingé˜¶æ®µæ­£æ˜¯KVå…±äº«çš„MQAï¼ˆNoPEéƒ¨åˆ†ï¼‰ï¼Œè¿™å°±æ˜¯å®ƒèµ°åœ¨æ­£ç¡®æ–¹å‘ä¸Šçš„ä½“ç°ä¹‹ä¸€ã€‚</p>
<p>ç„¶è€Œï¼Œå°†head_dimså‡åˆ°512ï¼ŒDecodingæ˜¯æ²¡é—®é¢˜ï¼Œä½†è®­ç»ƒå’ŒPrefilléƒ½å¾ˆéš¾æ¥å—ï¼Œå› ä¸ºå®ƒä»¬ä¿©çš„ç“¶é¢ˆæ˜¯è®¡ç®—ï¼Œè€Œå½±å“è®¡ç®—é€Ÿåº¦çš„ä¸»è¦å› ç´ æ˜¯num_headså’Œhead_dimsã€‚ä¸ºäº†ä¿è¯æ•ˆæœï¼Œnum_headså˜åŠ¨çš„ç©ºé—´ä¸å¤§ï¼Œå› æ­¤head_dimså¤§å°å¯ä»¥è¯´æ˜¯è®¡ç®—é‡çš„å”¯ä¸€æŒ‡æ ‡ï¼Œhead_dimså‡åˆ°512æ„å‘³ç€è®¡ç®—é‡è¦å¢åŠ åˆ°åŸæ¥çš„4å€ï¼ˆç›¸æ¯”head_dims=128ï¼‰ã€‚</p>
<p>ç°åœ¨å†æ¥é—®å¤§å®¶ä¸€ä¸ªé—®é¢˜ï¼š<strong>åŒæ ·åœ¨NoPEèƒŒæ™¯ä¸‹ï¼Œç»™å®šnum_headså’Œhead_dimsåï¼Œæ•ˆæœæœ€å¥½çš„Attentionæ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ</strong> è¿™ä¸ªé—®é¢˜çš„ç­”æ¡ˆæˆ‘ç›¸ä¿¡å¤§å®¶éƒ½èƒ½æ¥å—ï¼Œé‚£å°±æ˜¯<strong>MHA</strong> ï¼Œå› ä¸ºå®ƒé™åˆ¶æœ€å°‘ã€‚æ‰€ä»¥ï¼Œå•ä»è®­ç»ƒå’ŒPrefillæˆæœ¬æ¥çœ‹ï¼Œæˆ‘ä»¬å¸Œæœ›çš„æ˜¯è®­ç»ƒä¸€ä¸ªhead_dims=128çš„MHAã€‚</p>
<p>æ€ä¹ˆè°ƒå’ŒPrefillä¸Decodingè¿™ä¸¤ä¸ªä¸åŒçš„æœŸæœ›å‘¢ï¼Ÿè¿™å°±æ˜¯MLAçš„â€œå¤§æ‹›â€äº†ï¼Œå®ƒé€šè¿‡ä¸¤æ­¥æŠ•å½±å¾—åˆ°Kã€Vï¼šå…ˆå°†è¾“å…¥æŠ•å½±åˆ°å•ä¸ª512ç»´çš„å‘é‡ï¼Œç„¶åå°†è¯¥å‘é‡æŠ•å½±åˆ°å¤šä¸ª128ç»´çš„å‘é‡ï¼Œç„¶ååˆ©ç”¨â€œAttention + NoPEâ€å›ºæœ‰çš„æ’ç­‰å˜æ¢æ€§è´¨ï¼Œå¯ä»¥è®©æ¨¡å‹åœ¨MHA-128å’ŒMQA-512é—´è‡ªç”±åˆ‡æ¢ã€‚</p>
<p>$$\require{cancel}\begin{array}{c|c}  
\text{è®­ç»ƒ/Prefill} & \text{Decoding} \\\  
\\\  
\begin{gathered}  
\boldsymbol{o}_t = \left[\boldsymbol{o}_t^{(1)}, \boldsymbol{o}_t^{(2)}, \cdots, \boldsymbol{o}_t^{(h)}\right] \\\\[10pt]  
\boldsymbol{o}_t^{(s)} = \frac{\sum_{i\leq t}\exp\left(\boldsymbol{q}_t^{(s)} \boldsymbol{k}_i^{(s)}{}^{\top}\right)\boldsymbol{v}_i^{(s)}}{\sum_{i\leq t}\exp\left(\boldsymbol{q}_t^{(s)} \boldsymbol{k}_i^{(s)}{}^{\top}\right)} \\\\[15pt]  
\boldsymbol{q}_i^{(s)} = \boldsymbol{x}_i\boldsymbol{W}_q^{(s)}\in\mathbb{R}^{d_k},\quad \boldsymbol{W}_q^{(s)}\in\mathbb{R}^{d\times d_k}\\\  
\boldsymbol{k}_i^{(s)} = \boldsymbol{c}_i\boldsymbol{W}_k^{(s)}\in\mathbb{R}^{d_k},\quad \boldsymbol{W}_k^{(s)}\in\mathbb{R}^{d_c\times d_k} \\\  
\boldsymbol{v}_i^{(s)} = \boldsymbol{c}_i\boldsymbol{W}_v^{(s)}\in\mathbb{R}^{d_v},\quad \boldsymbol{W}_v^{(s)}\in\mathbb{R}^{d_c\times d_v} \\\\[10pt]  
\boldsymbol{c}_i = \boldsymbol{x}_i \boldsymbol{W}_c\in\mathbb{R}^{d_c},\quad \boldsymbol{W}_c\in\mathbb{R}^{d\times d_c}  
\end{gathered}  
&  
\begin{gathered}  
\boldsymbol{o}_t = \left[\boldsymbol{o}_t^{(1)}\boldsymbol{W}_v^{(1)}, \boldsymbol{o}_t^{(2)}\boldsymbol{W}_v^{(2)}, \cdots, \boldsymbol{o}_t^{(h)}\boldsymbol{W}_v^{(h)}\right] \\\\[10pt]  
\boldsymbol{o}_t^{(s)} = \frac{\sum_{i\leq t}\exp\left(\boldsymbol{q}_t^{(s)} \boldsymbol{k}_i^{\color{#ccc}{\smash{\bcancel{(s)}}}}{}^{\top}\right)\boldsymbol{v}_i^{\color{#ccc}{\smash{\bcancel{(s)}}}} }{\sum_{i\leq t}\exp\left(\boldsymbol{q}_t^{(s)} \boldsymbol{k}_i^{\color{#ccc}{\smash{\bcancel{(s)}}}}{}^{\top}\right)} \\\\[15pt]  
\boldsymbol{q}_i^{(s)} = \boldsymbol{x}_i\boldsymbol{W}_q^{(s)}\boldsymbol{W}_k^{(s)}{}^{\top}\in\mathbb{R}^{d_c}\\\  
\boldsymbol{k}_i^{\color{#ccc}{\smash{\bcancel{(s)}}}} = \boldsymbol{v}_i^{\color{#ccc}{\smash{\bcancel{(s)}}}} = \boldsymbol{c}_i= \boldsymbol{x}_i \boldsymbol{W}_c\in\mathbb{R}^{d_c}  
\end{gathered}  
\end{array}$$</p>
<h2 id="_4">æ€»è€Œè¨€ä¹‹</h2>
<p>æˆ‘ä»¬å°†å‰é¢çš„æ¨ç†é€»è¾‘åšä¸ªæ€»ç»“ï¼š</p>
<blockquote>
<p>1ã€å¤§å‰æï¼šPartial RoPEçš„æ•ˆæœä¸å·®äºç”šè‡³å¯èƒ½ä¼˜äºRoPEï¼Œè¿™ä½¿å¾—æˆ‘ä»¬å¯ä»¥æŠŠä¸»è¦ç²¾åŠ›æ”¾åœ¨NoPEä¸Šï¼›</p>
<p>2ã€Decodingä¸»è¦ç“¶é¢ˆæ˜¯KV Cacheï¼Œç†è®ºæ•ˆæœæœ€ä¼˜çš„æ¨¡å‹æ˜¯head_dims=KV Cacheã€KVå…±äº«çš„MQAï¼›</p>
<p>3ã€è®­ç»ƒå’ŒPrefillçš„ä¸»è¦ç“¶é¢ˆéƒ½æ˜¯head_dimsï¼Œç†è®ºæ•ˆæœæœ€ä¼˜çš„æ¨¡å‹æ˜¯head_dimsä¸ºæœŸæœ›å€¼çš„MHAï¼›</p>
<p>4ã€åœ¨NoPEå‰æä¸‹ï¼ŒAttentionå…·æœ‰æ’ç­‰å˜æ¢æ€§è´¨ï¼Œå¯ä»¥é€šè¿‡LoRAæ¥å°½å¯èƒ½åœ°å…¼é¡¾ä¸¤ä¸ªç†æƒ³æ–¹å‘ï¼Œè¿™æ­£å¥½æ˜¯MLAæ‰€åšçš„ã€‚</p>
</blockquote>
<p>å‰©ä¸‹çš„ï¼Œå°±æ˜¯ç»™Kæ‹¼æ¥ä¸€ä¸ªå…±äº«çš„ä½ç»´RoPEï¼Œä»¥æœ€å°çš„æˆæœ¬ç»™MLAè¡¥å……ä¸Šä½ç½®ä¿¡æ¯ï¼ŒåŒæ—¶è¿˜â€œä¸€ç®­åŒé›•â€ï¼šæ‹¼æ¥RoPEçš„åšæ³•æš—åˆäº†â€œPartial RoPEâ€ï¼ŒåŒæ—¶ä¹Ÿå¢åŠ äº†head_dimsï¼Œè¿™è·Ÿä¸Šä¸€ç¯‡æ–‡ç« çš„ç»“è®ºç›¸ç¬¦ã€‚æ¢å¥è¯è¯´ï¼Œæœ‰æ„æˆ–è€…æ— æ„ä¹‹ä¸­ä½¿ç”¨äº†Partial RoPEå’Œå¢åŠ äº†head_dimsï¼Œæ˜¯MLAåœ¨æè‡´å‹ç¼©ä¹‹ä¸‹è¿˜èƒ½åª²ç¾MHAçš„ä¸»è¦åŸå› ã€‚</p>
<p>ä»MQAçš„è§’åº¦çœ‹ï¼ŒMLAæ˜¯ç»™QåŠ äº†rank=128çš„LoRAï¼›ä»MHAçš„è§’åº¦çœ‹ï¼ŒMLAæ˜¯ç»™Kã€VåŠ äº†rank=512çš„LoRAã€‚å¯ä»¥è¯´ï¼ŒMLAæ˜¯ä¸€åœºNoPEç»“åˆLoRAã€MHAç»“åˆMQAçš„æè‡´â€œé­”æœ¯ç§€â€ï¼ŒæˆåŠŸå®ç°äº†Prefillå’ŒDecodingçš„â€œåŒå‘å¥”èµ´â€ã€‚</p>
<p>å½“ç„¶ï¼Œä¸Šè¿°æ€è€ƒè¿‡ç¨‹è‚¯å®šæœ‰ä¸€äº›è¿‡äºç®€åŒ–çš„åœ°æ–¹ã€‚æ¯”å¦‚ï¼Œå®é™…çš„è®­ç»ƒå’Œæ¨ç†è¿˜æœ‰è¯¸å¤šç»†èŠ‚å› ç´ ï¼Œç¬¼ç»Ÿåœ°å½’ç»“ä¸ºhead_dimså’ŒKV Cacheæ˜¯ä¸å®Œå…¨å‡†ç¡®çš„ï¼Œä¾‹å¦‚MQAåœ¨Decodingé˜¶æ®µæ— æ³•TPï¼ˆå¼ é‡å¹¶è¡Œï¼‰ï¼Œè¿™å¯èƒ½ä¼šå¸¦æ¥æ–°çš„æ•ˆç‡é—®é¢˜ï¼›è¿˜æœ‰ï¼Œåˆ†æè¿‡ç¨‹ä¸­æˆ‘ä»¬ä¹Ÿæ²¡æœ‰ç‰¹åˆ«æ³¨é‡å‚æ•°é‡çš„å¯¹é½ï¼Œæ¯”å¦‚åœ¨head_dims=128æ—¶æˆ‘ä»¬ä¹Ÿå¯ä»¥è€ƒè™‘å¢åŠ Qã€Kã€Vçš„æŠ•å½±å¤æ‚åº¦æ¥æé«˜æ€§èƒ½ï¼Œè€Œä¸ä¸€å®šè¦å¢å¤§head_dimsï¼›ç­‰ç­‰ã€‚</p>
<p>æ€»ä¹‹ï¼Œä¸Šä¸‹ä¸¤ç¯‡æ–‡ç« æ—¨åœ¨æä¾›ä¸€äº›å®éªŒå’Œæ€è€ƒï¼Œæ¥è®ºè¯MLAåœ¨ä¸€å®šèŒƒå›´å†…çš„æœ€ä¼˜æ€§ã€‚å½“ç„¶ï¼ŒMLAæ˜¯DeepSeeké¦–å…ˆæå‡ºçš„ï¼Œç¬¬ä¸‰æ–¹ä½¿ç”¨MLAæ€»ä¼šç»™äººä¸€ç§å¤åˆ¶DeepSeekçš„æ„Ÿè§‰ï¼Œä½†åœ¨æ›´å¥½çš„å˜ä½“å‡ºç°ä¹‹å‰ï¼Œæˆ–è€…åœ¨å‘ç°ä¸¥é‡çš„ç¼ºé™·ä¹‹å‰ï¼ŒMLAå§‹ç»ˆæ˜¯ä¸€ä¸ªç›¸å½“æœ‰ç«äº‰åŠ›çš„é€‰æ‹©ï¼Œå¦‚æœå•çº¯æ˜¯ä¸ºäº†æ˜¾ç¤ºè‡ªå·±ä¸â€œè¿½éšâ€DeepSeekè€Œä¸ç”¨MLAï¼Œé‚£æ˜¯ä¸€ä¸ªç›¸å½“ä¸æ˜æ™ºçš„é€‰æ‹©ã€‚</p>
<p>ä¸¾ä¸ªä¾‹å­ï¼Œç°åœ¨Linear Attentionå’ŒSoftmax Attentionçš„æ··åˆæ¨¡å‹ä¹Ÿä½“ç°å‡ºæå¤§çš„ç«äº‰åŠ›ï¼Œä½†å¦‚æœæˆ‘ä»¬å°†Linear Attentionè·ŸLLAMAä½¿ç”¨çš„GQA8-128æŒ‰3:1æ··åˆï¼Œé‚£ä¹ˆKV Cacheå¤§è‡´ä¸Šé™ä½åˆ°GQA8-128çš„1/4ï¼Œç„¶è€ŒMLAæœ¬èº«å°±èƒ½å°†KV Cacheé™ä½åˆ°GQA8-128çš„1/4äº†ã€‚</p>
<h2 id="_5">è¡¥å……è®¨è®º</h2>
<p>å‰é¢æˆ‘ä»¬éƒ½åœ¨å›´ç»•MHAã€GQAã€MQAå’ŒMLAè®¨è®ºï¼Œè¿™ä¸€èŠ‚æˆ‘ä»¬æ¥ç®€å•èŠèŠä¸¤ä¸ªæ¯”è¾ƒå°‘è°ˆåŠçš„Attentionå˜ä½“ï¼šTPAå’ŒMFAã€‚</p>
<p>TPAå…¨ç§°æ˜¯Tensor Product Attentionï¼Œä½œè€…ç»™å®ƒå®‰äº†ä¸ªTensor Productçš„åå­—ï¼Œæ˜¾å¾—æ¯”è¾ƒâ€œå”¬äººâ€ï¼Œå®é™…ä¸Šå®ƒæ˜¯ä¸€ä¸ªä»‹ä¹GQAå’ŒMLAçš„ä¸­é—´äº§ç‰©ã€‚æˆ‘ä»¬ä»¥ç›®æ ‡KV Cache=512ä¸ºä¾‹ï¼ŒTPAå…ˆæŠ•å½±å¾—åˆ°ä¸€ä¸ª512ç»´å‘é‡ï¼Œç„¶åreshapeä¸º(4, 128)ï¼Œç„¶ååˆ†æˆä¸¤ä¸ª(2,128)åˆ†åˆ«ä»£è¡¨K Cacheå’ŒV Cacheã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼ŒTPAçš„åšæ³•éƒ½è·ŸGQA2-128ä¸€è‡´ã€‚</p>
<p>æ¥ä¸‹æ¥ï¼ŒTPAå€Ÿé‰´äº†MLAçš„æ€æƒ³ï¼Œå°†(2,128)çš„K/Vé‡æ–°æŠ•å½±æˆMulti-Headï¼Œä½†å®ƒä¸æ˜¯åƒMLAé‚£æ ·æ•´ä¸ªå‘é‡æŠ•å½±ï¼Œè€Œæ˜¯æ²¿ç€â€œ2â€æ‰€åœ¨çš„ç»´åº¦æŠ•å½±ï¼Œè¯´ç™½äº†å°±æ˜¯å°†2ä¸ª128ç»´å‘é‡åšhead_dimsæ¬¡ä¸åŒçš„çº¿æ€§ç»„åˆã€‚æ˜¾ç„¶ï¼Œè¿™æ ·TPAçš„ä¸Šé™æ˜¯ä¸å¦‚MLAç›´æ¥ä»æ•´ä¸ª512ç»´å‘é‡å‡ºå‘æ¥æŠ•å½±çš„ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼ŒTPAåˆå¼•å…¥äº†data-dependentçš„ç»„åˆç³»æ•°æ¥å¢å¼ºKã€Vçš„è¡¨è¾¾èƒ½åŠ›ï¼Œå³ä¾¿å¦‚æ­¤ï¼Œç¬”è€…è¿˜æ˜¯è®¤ä¸ºå®ƒä¸Šé™ä¸å¦‚MLAã€‚</p>
<p>ä¸ºä»€ä¹ˆTPAè¦è¿™æ ·è®¾è®¡å‘¢ï¼Ÿå¤§ä½“ä¸Šæ˜¯ä¸ºäº†å…¼å®¹RoPEï¼Œè¿™ä¹Ÿæ˜¯å®ƒç›¸æ¯”MLAçš„æœ€å¤§â€œä¼˜ç‚¹â€ã€‚ç„¶è€Œï¼Œè¿™é‡Œçš„â€œä¼˜ç‚¹â€æ˜¯è¦åŠ ä¸ªåŒå¼•å·çš„ï¼Œå› ä¸ºåœ¨Partial RoPEä¸é€Šè‰²ç”šè‡³è¿˜å¯èƒ½æ›´ä¼˜çš„èƒŒæ™¯ä¸‹ï¼Œå…¼å®¹RoPEå°±æœ‰ç‚¹å•¼ç¬‘çš†éçš„æ„Ÿè§‰äº†ã€‚è¿˜æœ‰ï¼ŒTPAè¿™æ ·è®¾è®¡ï¼Œå µæ­»äº†å®ƒå‡head_dimsçš„ç©ºé—´ï¼Œæ¯”å¦‚head_dimsæƒ³è¦å‡åˆ°256ï¼Œé‚£ä¹ˆK Cacheã€V Cacheå°±åªæ˜¯(1,256)å½¢çŠ¶äº†ï¼Œå•ä¸ªå‘é‡æ²¡æœ‰çº¿æ€§ç»„åˆçš„è‡ªç”±åº¦ã€‚</p>
<p>å†æ¥çœ‹MFAï¼Œå®ƒå…¨ç§°æ˜¯â€œMulti-matrix Factorization Attentionâ€ï¼Œè¿™ä¸ªåå­—çœ‹ä¸Šå»ä¹Ÿæœ‰ç‚¹â€œå”¬äººâ€ï¼Œå®ƒå®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªå¸¦æœ‰Q-LoRAçš„ã€head_dims=256çš„MQAã€‚çœ‹åˆ°è¿™ä¸ªé…ç½®ï¼Œæ˜¯ä¸æ˜¯æœ‰ç‚¹ç†Ÿæ‚‰ï¼Ÿå› ä¸ºè¿™é…ç½®è·Ÿæˆ‘ä»¬ä¸Šä¸€ç¯‡æ–‡ç« çš„ç»“è®ºå®Œå…¨å»åˆâ€”â€”å¢å¤§head_dimsåˆ°256æ¥æå‡MQAçš„æ•ˆæœï¼Œå¹¶ä¸”KV Cacheè·ŸMLAæ¥è¿‘ï¼ŒåŒæ—¶é€šè¿‡Q-LoRAæ¥æ§åˆ¶å‚æ•°é‡ã€‚</p>
<p>æ‰€ä»¥ï¼ŒMFAèƒ½â€œæ‰“â€MLAï¼Œç¬”è€…å¹¶ä¸æ„å¤–ï¼Œä¸Šä¸€ç¯‡æ–‡ç« æˆ‘ä»¬ä¹Ÿå®éªŒè¿‡å·®ä¸å¤šçš„åšæ³•äº†ã€‚æ­¤å¤–ï¼Œä¸Šä¸€ç¯‡æ–‡ç« æˆ‘ä»¬è¿˜æå‡ºå¦å¤–ä¸¤ä¸ªæå‡MQAæ•ˆæœçš„æ–¹å‘ï¼Œä¸€ä¸ªæ˜¯æœ¬æ–‡å·²ç»å¤šæ¬¡æåŠçš„Partial RoPEï¼Œå¦ä¸€ä¸ªæ˜¯é€šè¿‡<a href="/archives/10862">QKVO-RoPE</a>çš„æ–¹å¼å®ç°å®Œå…¨çš„KVå…±äº«ï¼Œè®©MQAå˜æˆGQA2-256ï¼Œè¿™ä¸¤ç‚¹å åŠ ä¸Šå»ï¼ŒMFAåº”è¯¥è¿˜èƒ½å†æ¶¨ä¸€ç‚¹ã€‚</p>
<h2 id="_6">æ–‡ç« å°ç»“</h2>
<p>æœ¬æ–‡åœ¨ä¸Šä¸€ç¯‡æ–‡ç« çš„å®éªŒç»“æœåŸºç¡€ä¸Šï¼Œç»™å‡ºä¸€ä¸ªåç†è®ºçš„æ€è€ƒè¿‡ç¨‹ï¼Œä»¥è®ºè¯MLAåœ¨ä¸€å®šèŒƒå›´å†…çš„æœ€ä¼˜æ€§ã€‚æ€»çš„æ¥è¯´ï¼Œåœ¨Partial RoPEçš„èƒŒæ™¯ä¸‹ï¼ŒMLAä¼¼ä¹æ˜¯ä¸€ä¸ªéå¸¸éš¾ä»¥è¶…è¶Šçš„Attentionå˜ä½“ã€‚</p>
<p><em><strong>è½¬è½½åˆ°è¯·åŒ…æ‹¬æœ¬æ–‡åœ°å€ï¼š</strong><a href="https://spaces.ac.cn/archives/11111">https://spaces.ac.cn/archives/11111</a></em></p>
<p><em><strong>æ›´è¯¦ç»†çš„è½¬è½½äº‹å®œè¯·å‚è€ƒï¼š</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="ã€Šç§‘å­¦ç©ºé—´FAQã€‹">ã€Šç§‘å­¦ç©ºé—´FAQã€‹</a></p>
<p><strong>å¦‚æœæ‚¨è¿˜æœ‰ä»€ä¹ˆç–‘æƒ‘æˆ–å»ºè®®ï¼Œæ¬¢è¿åœ¨ä¸‹æ–¹è¯„è®ºåŒºç»§ç»­è®¨è®ºã€‚</strong></p>
<p><strong>å¦‚æœæ‚¨è§‰å¾—æœ¬æ–‡è¿˜ä¸é”™ï¼Œæ¬¢è¿åˆ†äº«/æ‰“èµæœ¬æ–‡ã€‚æ‰“èµå¹¶éè¦ä»ä¸­è·å¾—æ”¶ç›Šï¼Œè€Œæ˜¯å¸Œæœ›çŸ¥é“ç§‘å­¦ç©ºé—´è·å¾—äº†å¤šå°‘è¯»è€…çš„çœŸå¿ƒå…³æ³¨ã€‚å½“ç„¶ï¼Œå¦‚æœä½ æ— è§†å®ƒï¼Œä¹Ÿä¸ä¼šå½±å“ä½ çš„é˜…è¯»ã€‚å†æ¬¡è¡¨ç¤ºæ¬¢è¿å’Œæ„Ÿè°¢ï¼</strong></p>
<p>æ‰“èµ</p>
<p><img alt="ç§‘å­¦ç©ºé—´" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>å¾®ä¿¡æ‰“èµ</p>
<p><img alt="ç§‘å­¦ç©ºé—´" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>æ”¯ä»˜å®æ‰“èµ</p>
<p>å› ä¸ºç½‘ç«™åå°å¯¹æ‰“èµå¹¶æ— è®°å½•ï¼Œå› æ­¤æ¬¢è¿åœ¨æ‰“èµæ—¶å€™å¤‡æ³¨ç•™è¨€ã€‚ä½ è¿˜å¯ä»¥<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>ç‚¹å‡»è¿™é‡Œ</strong></a>æˆ–åœ¨ä¸‹æ–¹è¯„è®ºåŒºç•™è¨€æ¥å‘ŠçŸ¥ä½ çš„å»ºè®®æˆ–éœ€æ±‚ã€‚</p>
<p><strong>å¦‚æœæ‚¨éœ€è¦å¼•ç”¨æœ¬æ–‡ï¼Œè¯·å‚è€ƒï¼š</strong></p>
<p>è‹å‰‘æ—. (Jul. 10, 2025). ã€ŠTransformerå‡çº§ä¹‹è·¯ï¼š21ã€MLAå¥½åœ¨å“ªé‡Œ?ï¼ˆä¸‹ï¼‰ ã€‹[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/11111">https://spaces.ac.cn/archives/11111</a></p>
<p>@online{kexuefm-11111,<br />
title={Transformerå‡çº§ä¹‹è·¯ï¼š21ã€MLAå¥½åœ¨å“ªé‡Œ?ï¼ˆä¸‹ï¼‰},<br />
author={è‹å‰‘æ—},<br />
year={2025},<br />
month={Jul},<br />
url={\url{https://spaces.ac.cn/archives/11111}},<br />
} </p>
<hr />
<h2 id="_7">å…¬å¼æ¨å¯¼ä¸æ³¨é‡Š</h2>
<h3 id="1-mla">1. MLAçš„å®Œæ•´æ•°å­¦æ¡†æ¶</h3>
<p><strong>æ¨å¯¼1.1ï¼šè®­ç»ƒé˜¶æ®µçš„MHAå½¢å¼</strong></p>
<p>åœ¨è®­ç»ƒé˜¶æ®µï¼ŒMLAè¡¨ç°ä¸ºæ ‡å‡†çš„Multi-Head Attentionã€‚ç»™å®šè¾“å…¥åºåˆ—${\boldsymbol{x}<em i="1">i}</em>^n$ï¼Œé¦–å…ˆè¿›è¡Œå‹ç¼©æŠ•å½±ï¼š
$$
\boldsymbol{c}_i = \boldsymbol{x}_i \boldsymbol{W}_c \in \mathbb{R}^{d_c}
$$</p>
<p>ç„¶åä¸ºæ¯ä¸ªhead $s \in {1, \ldots, h}$ç”ŸæˆQKVï¼š
$$
\boldsymbol{q}_i^{(s)} = \boldsymbol{x}_i \boldsymbol{W}_q^{(s)} \in \mathbb{R}^{d_k}
$$
$$
\boldsymbol{k}_i^{(s)} = \boldsymbol{c}_i \boldsymbol{W}_k^{(s)} \in \mathbb{R}^{d_k}
$$
$$
\boldsymbol{v}_i^{(s)} = \boldsymbol{c}_i \boldsymbol{W}_v^{(s)} \in \mathbb{R}^{d_v}
$$</p>
<p>æ³¨æ„åŠ›è¾“å‡ºï¼š
$$
\boldsymbol{o}_i^{(s)} = \text{Attention}(\boldsymbol{q}_i^{(s)}, \{\boldsymbol{k}_j^{(s)}\}_{j \leq i}, \{\boldsymbol{v}_j^{(s)}\}_{j \leq i})
$$</p>
<p>æœ€ç»ˆè¾“å‡ºï¼š
$$
\boldsymbol{o}_i = [\boldsymbol{o}_i^{(1)}, \ldots, \boldsymbol{o}_i^{(h)}] \boldsymbol{W}_o
$$</p>
<p><strong>æ¨å¯¼1.2ï¼šæ¨ç†é˜¶æ®µçš„MQAå½¢å¼</strong></p>
<p>åœ¨æ¨ç†é˜¶æ®µï¼ŒMLAå¯ä»¥é‡æ–°ç»„ç»‡ä¸ºMQAå½¢å¼ã€‚å…³é”®è§‚å¯Ÿæ˜¯ï¼š
$$
\boldsymbol{k}_i^{(s)} = \boldsymbol{c}_i \boldsymbol{W}_k^{(s)}, \quad \boldsymbol{v}_i^{(s)} = \boldsymbol{c}_i \boldsymbol{W}_v^{(s)}
$$</p>
<p>åœ¨è®¡ç®—æ³¨æ„åŠ›æ—¶ï¼š
$$
\boldsymbol{o}_i^{(s)} = \sum_{j \leq i} \alpha_{ij}^{(s)} \boldsymbol{v}_j^{(s)} = \sum_{j \leq i} \alpha_{ij}^{(s)} \boldsymbol{c}_j \boldsymbol{W}_v^{(s)} = \left(\sum_{j \leq i} \alpha_{ij}^{(s)} \boldsymbol{c}_j\right) \boldsymbol{W}_v^{(s)}
$$</p>
<p>å®šä¹‰ï¼š
$$
\tilde{\boldsymbol{o}}_i^{(s)} = \sum_{j \leq i} \alpha_{ij}^{(s)} \boldsymbol{c}_j
$$</p>
<p>åˆ™ï¼š
$$
\boldsymbol{o}_i^{(s)} = \tilde{\boldsymbol{o}}_i^{(s)} \boldsymbol{W}_v^{(s)}
$$</p>
<p>å°†$\boldsymbol{W}_v^{(s)}$å¸æ”¶åˆ°è¾“å‡ºæŠ•å½±$\boldsymbol{W}_o$ä¸­ã€‚</p>
<p><strong>æ¨å¯¼1.3ï¼šç­‰ä»·å˜æ¢çš„è¯æ˜</strong></p>
<p>éœ€è¦è¯æ˜è®­ç»ƒå’Œæ¨ç†çš„ç­‰ä»·æ€§ã€‚å®šä¹‰ç»¼åˆæŠ•å½±çŸ©é˜µï¼š
$$
\tilde{\boldsymbol{W}}_o = \begin{bmatrix} \boldsymbol{W}_v^{(1)} \\ \boldsymbol{W}_v^{(2)} \\ \vdots \\ \boldsymbol{W}_v^{(h)} \end{bmatrix} \boldsymbol{W}_o
$$</p>
<p>åˆ™æ¨ç†æ—¶çš„è¾“å‡ºï¼š
$$
\boldsymbol{o}_i^{\text{infer}} = [\tilde{\boldsymbol{o}}_i^{(1)}, \ldots, \tilde{\boldsymbol{o}}_i^{(h)}] \tilde{\boldsymbol{W}}_o
$$</p>
<p>è®­ç»ƒæ—¶çš„è¾“å‡ºï¼š
$$
\boldsymbol{o}_i^{\text{train}} = [(\tilde{\boldsymbol{o}}_i^{(1)} \boldsymbol{W}_v^{(1)}), \ldots, (\tilde{\boldsymbol{o}}_i^{(h)} \boldsymbol{W}_v^{(h)})] \boldsymbol{W}_o
$$</p>
<p>ç”±çŸ©é˜µä¹˜æ³•çš„ç»“åˆå¾‹ï¼š
$$
\boldsymbol{o}_i^{\text{train}} = [\tilde{\boldsymbol{o}}_i^{(1)}, \ldots, \tilde{\boldsymbol{o}}_i^{(h)}] \begin{bmatrix} \boldsymbol{W}_v^{(1)} \\ \vdots \\ \boldsymbol{W}_v^{(h)} \end{bmatrix} \boldsymbol{W}_o = \boldsymbol{o}_i^{\text{infer}}
$$</p>
<p>è¯æ˜äº†ç­‰ä»·æ€§ã€‚</p>
<h3 id="2">2. å¸æ”¶å½’ä¸€åŒ–çš„æ•°å­¦ç­‰ä»·æ€§</h3>
<p><strong>æ¨å¯¼2.1ï¼šæ ‡å‡†LayerNormçš„å®šä¹‰</strong></p>
<p>ç»™å®šå‘é‡$\boldsymbol{x} \in \mathbb{R}^d$ï¼ŒLayerNormè®¡ç®—ï¼š
$$
\text{LN}(\boldsymbol{x}) = \frac{\boldsymbol{x} - \mu}{\sigma} \odot \boldsymbol{\gamma} + \boldsymbol{\beta}
$$</p>
<p>å…¶ä¸­ï¼š
$$
\mu = \frac{1}{d}\sum_{i=1}^d x_i, \quad \sigma = \sqrt{\frac{1}{d}\sum_{i=1}^d (x_i - \mu)^2}
$$</p>
<p>$\boldsymbol{\gamma}, \boldsymbol{\beta} \in \mathbb{R}^d$æ˜¯å¯å­¦ä¹ å‚æ•°ã€‚</p>
<p><strong>æ¨å¯¼2.2ï¼šå¸æ”¶åˆ°çº¿æ€§å±‚çš„ç­‰ä»·æ€§</strong></p>
<p>è€ƒè™‘LayerNormåæ¥çº¿æ€§å˜æ¢ï¼š
$$
\boldsymbol{y} = \text{LN}(\boldsymbol{x}) \boldsymbol{W}
$$</p>
<p>å±•å¼€ï¼š
$$
\boldsymbol{y} = \left(\frac{\boldsymbol{x} - \mu}{\sigma} \odot \boldsymbol{\gamma} + \boldsymbol{\beta}\right) \boldsymbol{W}
$$</p>
<p>$$
= \frac{\boldsymbol{x} - \mu}{\sigma} \odot \boldsymbol{\gamma} \boldsymbol{W} + \boldsymbol{\beta} \boldsymbol{W}
$$</p>
<p>å®šä¹‰ï¼š
$$
\tilde{\boldsymbol{W}} = \text{diag}(\boldsymbol{\gamma}) \boldsymbol{W}, \quad \tilde{\boldsymbol{b}} = \boldsymbol{\beta} \boldsymbol{W}
$$</p>
<p>åˆ™ï¼š
$$
\boldsymbol{y} = \frac{\boldsymbol{x} - \mu}{\sigma} \tilde{\boldsymbol{W}} + \tilde{\boldsymbol{b}}
$$</p>
<p><strong>æ¨å¯¼2.3ï¼šRMSNormçš„å¸æ”¶</strong></p>
<p>MLAå¸¸ç”¨RMSNormï¼Œå®šä¹‰ä¸ºï¼š
$$
\text{RMSNorm}(\boldsymbol{x}) = \frac{\boldsymbol{x}}{\text{RMS}(\boldsymbol{x})} \odot \boldsymbol{\gamma}
$$</p>
<p>å…¶ä¸­ï¼š
$$
\text{RMS}(\boldsymbol{x}) = \sqrt{\frac{1}{d}\sum_{i=1}^d x_i^2}
$$</p>
<p>å¸æ”¶åˆ°çº¿æ€§å±‚ï¼š
$$
\boldsymbol{y} = \text{RMSNorm}(\boldsymbol{x}) \boldsymbol{W} = \frac{\boldsymbol{x}}{\text{RMS}(\boldsymbol{x})} \odot \boldsymbol{\gamma} \boldsymbol{W} = \frac{\boldsymbol{x}}{\text{RMS}(\boldsymbol{x})} \tilde{\boldsymbol{W}}
$$</p>
<p>åœ¨æ¨ç†æ—¶ï¼Œå¯ä»¥é¢„å…ˆè®¡ç®—$\tilde{\boldsymbol{W}} = \text{diag}(\boldsymbol{\gamma}) \boldsymbol{W}$ï¼Œå‡å°‘è®¡ç®—é‡ã€‚</p>
<h3 id="3-partial-rope">3. Partial RoPEçš„æ·±å…¥åˆ†æ</h3>
<p><strong>æ¨å¯¼3.1ï¼šå®Œæ•´RoPE vs Partial RoPE</strong></p>
<p>å®Œæ•´RoPEå¯¹æ‰€æœ‰ç»´åº¦åº”ç”¨æ—‹è½¬ï¼š
$$
\tilde{\boldsymbol{q}}_i = \boldsymbol{\mathcal{R}}_i \boldsymbol{q}_i, \quad \tilde{\boldsymbol{k}}_j = \boldsymbol{\mathcal{R}}_j \boldsymbol{k}_j
$$</p>
<p>æ³¨æ„åŠ›åˆ†æ•°ï¼š
$$
\text{score}_{ij} = \tilde{\boldsymbol{q}}_i^{\top} \tilde{\boldsymbol{k}}_j = \boldsymbol{q}_i^{\top} \boldsymbol{\mathcal{R}}_i^{\top} \boldsymbol{\mathcal{R}}_j \boldsymbol{k}_j = \boldsymbol{q}_i^{\top} \boldsymbol{\mathcal{R}}_{j-i} \boldsymbol{k}_j
$$</p>
<p>Partial RoPEå°†å‘é‡åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼š
$$
\boldsymbol{q}_i = [\boldsymbol{q}_{i,c}, \boldsymbol{q}_{i,r}], \quad \boldsymbol{k}_j = [\boldsymbol{k}_{j,c}, \boldsymbol{k}_{j,r}]
$$</p>
<p>åªå¯¹$\boldsymbol{q}<em j_r="j,r">{i,r}$å’Œ$\boldsymbol{k}</em>$åº”ç”¨æ—‹è½¬ï¼š
$$
\text{score}_{ij} = \boldsymbol{q}_{i,c}^{\top} \boldsymbol{k}_{j,c} + (\boldsymbol{\mathcal{R}}_i \boldsymbol{q}_{i,r})^{\top} (\boldsymbol{\mathcal{R}}_j \boldsymbol{k}_{j,r}) = \boldsymbol{q}_{i,c}^{\top} \boldsymbol{k}_{j,c} + \boldsymbol{q}_{i,r}^{\top} \boldsymbol{\mathcal{R}}_{j-i} \boldsymbol{k}_{j,r}
$$</p>
<p><strong>æ¨å¯¼3.2ï¼šè¯­ä¹‰ä¸ä½ç½®çš„è§£è€¦</strong></p>
<p>å®šä¹‰contentç›¸ä¼¼åº¦å’Œpositionç›¸ä¼¼åº¦ï¼š
$$
S_{\text{content}}(i, j) = \boldsymbol{q}_{i,c}^{\top} \boldsymbol{k}_{j,c}
$$
$$
S_{\text{position}}(i, j) = \boldsymbol{q}_{i,r}^{\top} \boldsymbol{\mathcal{R}}_{j-i} \boldsymbol{k}_{j,r}
$$</p>
<p>åˆ™æ€»çš„æ³¨æ„åŠ›åˆ†æ•°ï¼š
$$
\text{score}_{ij} = S_{\text{content}}(i, j) + S_{\text{position}}(i, j)
$$</p>
<p>è¿™ç§åˆ†è§£çš„å¥½å¤„æ˜¯ï¼š
1. $S_{\text{content}}$ä¸å—ä½ç½®å½±å“ï¼Œçº¯ç²¹è¡¡é‡è¯­ä¹‰ç›¸ä¼¼åº¦
2. $S_{\text{position}}$ç¼–ç ç›¸å¯¹ä½ç½®ä¿¡æ¯
3. æ¨¡å‹å¯ä»¥å­¦ä¹ å¦‚ä½•å¹³è¡¡ä¸¤è€…</p>
<p><strong>æ¨å¯¼3.3ï¼šPartial RoPEçš„ä¿¡æ¯å®¹é‡</strong></p>
<p>å‡è®¾æ€»ç»´åº¦$d = d_c + d_r$ï¼Œå…¶ä¸­$d_c$æ˜¯contentç»´åº¦ï¼Œ$d_r$æ˜¯rotaryç»´åº¦ã€‚</p>
<p>ä¿¡æ¯å®¹é‡è§’åº¦ï¼š
- Contentéƒ¨åˆ†å¯ä»¥ç¼–ç $2^{d_c}$ç§ä¸åŒçš„æ¨¡å¼
- Rotaryéƒ¨åˆ†å¯ä»¥ç¼–ç ä½ç½®ä¿¡æ¯ï¼ŒèŒƒå›´ç”±RoPEåº•æ•°å†³å®š</p>
<p>æ€»çš„è¡¨è¾¾èƒ½åŠ›çº¦ä¸ºï¼š
$$
\mathcal{C} \sim 2^{d_c} \times \text{Position\_Range}
$$</p>
<p>ç›¸æ¯”å®Œå…¨RoPEï¼ŒPartial RoPEå°†ç»´åº¦èµ„æºæ›´å¤šåˆ†é…ç»™contentï¼Œæå‡è¯­ä¹‰å»ºæ¨¡èƒ½åŠ›ã€‚</p>
<h3 id="4-kv">4. KVå…±äº«çš„å®Œæ•´ç†è®º</h3>
<p><strong>æ¨å¯¼4.1ï¼šå®Œå…¨KVå…±äº«çš„æ•°å­¦å½¢å¼</strong></p>
<p>å®Œå…¨KVå…±äº«æ„å‘³ç€$\boldsymbol{k}_i = \boldsymbol{v}_i = \boldsymbol{c}_i$ã€‚æ³¨æ„åŠ›å˜ä¸ºï¼š
$$
\boldsymbol{o}_i^{(s)} = \sum_{j \leq i} \frac{\exp(\boldsymbol{q}_i^{(s)} \cdot \boldsymbol{c}_j)}{\sum_{j' \leq i} \exp(\boldsymbol{q}_i^{(s)} \cdot \boldsymbol{c}_{j'})} \boldsymbol{c}_j
$$</p>
<p>å¯ä»¥é‡å†™ä¸ºï¼š
$$
\boldsymbol{o}_i^{(s)} = \sum_{j \leq i} \alpha_{ij}^{(s)} \boldsymbol{c}_j
$$</p>
<p>å…¶ä¸­æƒé‡ï¼š
$$
\alpha_{ij}^{(s)} = \frac{\exp(\boldsymbol{q}_i^{(s)} \cdot \boldsymbol{c}_j)}{\sum_{j' \leq i} \exp(\boldsymbol{q}_i^{(s)} \cdot \boldsymbol{c}_{j'})}
$$</p>
<p><strong>æ¨å¯¼4.2ï¼šéƒ¨åˆ†KVå…±äº«çš„è®¾è®¡</strong></p>
<p>MLAé‡‡ç”¨éƒ¨åˆ†å…±äº«ï¼šcontentéƒ¨åˆ†å…±äº«ï¼ŒRoPEéƒ¨åˆ†åˆ†ç¦»ã€‚è®¾ï¼š
$$
\boldsymbol{k}_i = [\boldsymbol{c}_i, \boldsymbol{k}_{i,r}], \quad \boldsymbol{v}_i = [\boldsymbol{c}_i, \boldsymbol{v}_{i,r}]
$$</p>
<p>å…¶ä¸­$\boldsymbol{c}<em i_r="i,r">i \in \mathbb{R}^{d_c}$æ˜¯å…±äº«éƒ¨åˆ†ï¼Œ$\boldsymbol{k}</em>$æ˜¯ç‹¬ç«‹éƒ¨åˆ†ã€‚}, \boldsymbol{v}_{i,r} \in \mathbb{R}^{d_r</p>
<p>æ³¨æ„åŠ›åˆ†æ•°ï¼š
$$
\text{score}_{ij} = \boldsymbol{q}_{i,c}^{\top} \boldsymbol{c}_j + \boldsymbol{q}_{i,r}^{\top} \boldsymbol{k}_{j,r}
$$</p>
<p>æ³¨æ„åŠ›è¾“å‡ºï¼š
$$
\boldsymbol{o}_i = \sum_{j \leq i} \alpha_{ij} [\boldsymbol{c}_j, \boldsymbol{v}_{j,r}]
$$</p>
<p><strong>æ¨å¯¼4.3ï¼šKVå…±äº«çš„æ­£åˆ™åŒ–æ•ˆåº”</strong></p>
<p>å®Œå…¨KVå…±äº«ç›¸å½“äºæ–½åŠ çº¦æŸï¼š
$$
\|\boldsymbol{k}_i - \boldsymbol{v}_i\|_2 = 0
$$</p>
<p>è¿™æ˜¯ä¸€ä¸ªå¼ºæ­£åˆ™åŒ–ï¼Œå‡å°‘äº†æ¨¡å‹è‡ªç”±åº¦ã€‚ä»è´å¶æ–¯è§’åº¦ï¼Œç›¸å½“äºåœ¨Kå’ŒVä¸Šæ–½åŠ ç›¸ç­‰å…ˆéªŒï¼š
$$
p(\boldsymbol{k}_i, \boldsymbol{v}_i) \propto \delta(\boldsymbol{k}_i - \boldsymbol{v}_i)
$$</p>
<p>è¿™ç§æ­£åˆ™åŒ–å¯èƒ½æœ‰åŠ©äºé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚</p>
<h3 id="5">5. è½¯ä¸Šé™æœºåˆ¶çš„ç†è®ºåˆ†æ</h3>
<p><strong>æ¨å¯¼5.1ï¼šæ³¨æ„åŠ›åˆ†æ•°çš„è½¯ä¸Šé™</strong></p>
<p>æ ‡å‡†Attentionçš„æ³¨æ„åŠ›åˆ†æ•°å¯ä»¥ä»»æ„å¤§ï¼Œå¯¼è‡´æ•°å€¼ä¸ç¨³å®šã€‚DeepSeek-V2å¼•å…¥è½¯ä¸Šé™ï¼š
$$
\text{score}_{ij} = s \cdot \tanh\left(\frac{\boldsymbol{q}_i^{\top} \boldsymbol{k}_j}{s}\right)
$$</p>
<p>å…¶ä¸­$s &gt; 0$æ˜¯å¯å­¦ä¹ çš„ä¸Šé™å‚æ•°ã€‚</p>
<p><strong>æ¨å¯¼5.2ï¼šè½¯ä¸Šé™çš„æ¢¯åº¦åˆ†æ</strong></p>
<p>è®¡ç®—æ¢¯åº¦ï¼š
$$
\frac{\partial \text{score}_{ij}}{\partial (\boldsymbol{q}_i^{\top} \boldsymbol{k}_j)} = \tanh'\left(\frac{\boldsymbol{q}_i^{\top} \boldsymbol{k}_j}{s}\right) = 1 - \tanh^2\left(\frac{\boldsymbol{q}_i^{\top} \boldsymbol{k}_j}{s}\right)
$$</p>
<p>å½“$|\boldsymbol{q}_i^{\top} \boldsymbol{k}_j| \gg s$æ—¶ï¼Œ$\tanh$é¥±å’Œï¼Œæ¢¯åº¦è¶‹äº0ï¼š
$$
\lim_{x \to \pm\infty} \tanh'(x) = 0
$$</p>
<p>è¿™é˜²æ­¢äº†æå¤§çš„æ³¨æ„åŠ›åˆ†æ•°ä¸»å¯¼æ¢¯åº¦ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§ã€‚</p>
<p><strong>æ¨å¯¼5.3ï¼šè½¯ä¸Šé™çš„ä¿¡æ¯è®ºè§£é‡Š</strong></p>
<p>ä»ä¿¡æ¯è®ºè§’åº¦ï¼Œæ³¨æ„åŠ›åˆ†æ•°$\text{score}_{ij}$çš„èŒƒå›´å½±å“æ³¨æ„åŠ›åˆ†å¸ƒçš„ç†µã€‚</p>
<p>æ— è½¯ä¸Šé™æ—¶ï¼Œåˆ†æ•°èŒƒå›´$(-\infty, +\infty)$ï¼Œå¯èƒ½å¯¼è‡´æç«¯çš„æ³¨æ„åŠ›åˆ†å¸ƒï¼ˆç†µæ¥è¿‘0ï¼‰ã€‚</p>
<p>è½¯ä¸Šé™å°†åˆ†æ•°é™åˆ¶åœ¨$(-s, s)$ï¼Œä¿è¯æ³¨æ„åŠ›åˆ†å¸ƒçš„ç†µæœ‰ä¸‹ç•Œï¼š
$$
H(\boldsymbol{\alpha}_i) = -\sum_{j \leq i} \alpha_{ij} \log \alpha_{ij} \geq H_{\min}(s)
$$</p>
<p>è¿™é¼“åŠ±æ¨¡å‹ä½¿ç”¨æ›´åˆ†æ•£çš„æ³¨æ„åŠ›ï¼Œé¿å…è¿‡åº¦é›†ä¸­ã€‚</p>
<h3 id="6">6. è®­ç»ƒç¨³å®šæ€§çš„æ•°å­¦ä¿è¯</h3>
<p><strong>æ¨å¯¼6.1ï¼šæ¢¯åº¦èŒƒæ•°çš„ç•Œ</strong></p>
<p>åœ¨åå‘ä¼ æ’­ä¸­ï¼Œå…³é”®æ˜¯æ§åˆ¶æ¢¯åº¦èŒƒæ•°ã€‚å¯¹äºAttentionå±‚ï¼š
$$
\frac{\partial \mathcal{L}}{\partial \boldsymbol{q}_i} = \sum_{j \leq i} \frac{\partial \mathcal{L}}{\partial \text{score}_{ij}} \frac{\partial \text{score}_{ij}}{\partial \boldsymbol{q}_i}
$$</p>
<p>å¯¹äºæ ‡å‡†Attentionï¼š
$$
\frac{\partial \text{score}_{ij}}{\partial \boldsymbol{q}_i} = \boldsymbol{k}_j
$$</p>
<p>æ¢¯åº¦èŒƒæ•°ï¼š
$$
\left\|\frac{\partial \mathcal{L}}{\partial \boldsymbol{q}_i}\right\|_2 \leq \sum_{j \leq i} \left|\frac{\partial \mathcal{L}}{\partial \text{score}_{ij}}\right| \|\boldsymbol{k}_j\|_2
$$</p>
<p>å¦‚æœ$|\boldsymbol{k}_j|_2$æ— ç•Œï¼Œæ¢¯åº¦å¯èƒ½çˆ†ç‚¸ã€‚</p>
<p><strong>æ¨å¯¼6.2ï¼šRMSNormçš„ç¨³å®šä½œç”¨</strong></p>
<p>RMSNormå½’ä¸€åŒ–ä½¿å¾—ï¼š
$$
\|\text{RMSNorm}(\boldsymbol{x})\|_2 = \sqrt{d}
$$</p>
<p>è¯æ˜ï¼š
$$
\|\text{RMSNorm}(\boldsymbol{x})\|_2^2 = \sum_{i=1}^d \left(\frac{x_i \gamma_i}{\text{RMS}(\boldsymbol{x})}\right)^2 = \frac{\sum_{i=1}^d x_i^2 \gamma_i^2}{\text{RMS}(\boldsymbol{x})^2}
$$</p>
<p>å‡è®¾$\gamma_i \approx 1$ï¼š
$$
\approx \frac{\sum_{i=1}^d x_i^2}{(1/d)\sum_{i=1}^d x_i^2} = d
$$</p>
<p>å› æ­¤$|\text{RMSNorm}(\boldsymbol{x})|_2 = \sqrt{d}$ã€‚</p>
<p>å°†RMSNormåº”ç”¨äºKå’ŒVï¼Œä¿è¯å®ƒä»¬çš„èŒƒæ•°æœ‰ç•Œï¼Œä»è€Œç¨³å®šæ¢¯åº¦ã€‚</p>
<p><strong>æ¨å¯¼6.3ï¼šè½¯ä¸Šé™ä¸RMSNormçš„ååŒ</strong></p>
<p>ç»“åˆè½¯ä¸Šé™å’ŒRMSNormï¼š
1. RMSNormä¿è¯$|\boldsymbol{k}<em ij="ij">j|_2 = \sqrt{d_k}$
2. è½¯ä¸Šé™ä¿è¯$|\text{score}</em>| \leq s$</p>
<p>æ¢¯åº¦èŒƒæ•°çš„ç•Œï¼š
$$
\left\|\frac{\partial \mathcal{L}}{\partial \boldsymbol{q}_i}\right\|_2 \leq n \cdot \max_j \left|\frac{\partial \mathcal{L}}{\partial \text{score}_{ij}}\right| \cdot \sqrt{d_k}
$$</p>
<p>é€šè¿‡é€‚å½“é€‰æ‹©$s$å’Œåº”ç”¨RMSNormï¼Œå¯ä»¥ä¿è¯æ¢¯åº¦åœ¨å¯æ§èŒƒå›´å†…ã€‚</p>
<h3 id="7-mha">7. ä¸æ ‡å‡†MHAçš„ç†è®ºå¯¹æ¯”</h3>
<p><strong>æ¨å¯¼7.1ï¼šå‚æ•°æ•ˆç‡å¯¹æ¯”</strong></p>
<p>æ ‡å‡†MHAï¼ˆ$h$ä¸ªheadsï¼Œæ¯ä¸ªheadç»´åº¦$d_h$ï¼‰ï¼š
$$
P_{\text{MHA}} = 3hdd_h + hd_hd = hd(3d_h + d_h) = 4hdd_h
$$</p>
<p>MLAï¼ˆå‹ç¼©ç»´åº¦$d_c$ï¼Œheadç»´åº¦$d_h$ï¼‰ï¼š
$$
P_{\text{MLA}} = dd_c + hdd_h + hd_c(2d_h) + hd_hd
$$</p>
<p>$$
= dd_c + hdd_h + 2hd_cd_h + hd_hd = dd_c + hd(d_h + d_h) + 2hd_cd_h
$$</p>
<p>å¯¹æ¯”ï¼šå½“$d_c \ll hd_h$æ—¶ï¼ŒMLAå‚æ•°é‡æ›´å°‘ã€‚</p>
<p><strong>æ¨å¯¼7.2ï¼šè®¡ç®—æ•ˆç‡å¯¹æ¯”ï¼ˆè®­ç»ƒï¼‰</strong></p>
<p>è®­ç»ƒæ—¶çš„ä¸»è¦è®¡ç®—ï¼šæ³¨æ„åŠ›çŸ©é˜µ$\boldsymbol{Q}\boldsymbol{K}^{\top} \in \mathbb{R}^{n \times n}$ã€‚</p>
<p>MHAï¼š
$$
\mathcal{O}_{\text{MHA}} = n^2 \cdot h \cdot d_h
$$</p>
<p>MLAï¼š
$$
\mathcal{O}_{\text{MLA}} = n^2 \cdot h \cdot d_h
$$</p>
<p>è®­ç»ƒå¤æ‚åº¦ç›¸åŒï¼ˆéƒ½éœ€è¦è®¡ç®—$n \times n$çš„æ³¨æ„åŠ›çŸ©é˜µï¼‰ã€‚</p>
<p><strong>æ¨å¯¼7.3ï¼šå†…å­˜æ•ˆç‡å¯¹æ¯”ï¼ˆæ¨ç†ï¼‰</strong></p>
<p>æ¨ç†æ—¶çš„KV Cacheï¼š</p>
<p>MHAï¼š
$$
M_{\text{MHA}} = n \cdot h \cdot 2d_h
$$</p>
<p>MLAï¼š
$$
M_{\text{MLA}} = n \cdot (d_c + h \cdot d_r)
$$</p>
<p>å½“$d_c + hd_r \ll 2hd_h$æ—¶ï¼ŒMLAå†…å­˜æ˜¾è‘—æ›´å°‘ã€‚</p>
<p>ä¾‹å¦‚ï¼Œ$h=16$ï¼Œ$d_h=128$ï¼Œ$d_c=512$ï¼Œ$d_r=64$ï¼š
$$
M_{\text{MHA}} = n \cdot 16 \cdot 256 = 4096n
$$
$$
M_{\text{MLA}} = n \cdot (512 + 16 \cdot 64) = n \cdot 1536 = 1536n
$$</p>
<p>MLAèŠ‚çœ62.5%çš„å†…å­˜ã€‚</p>
<h3 id="8">8. é•¿åºåˆ—å»ºæ¨¡çš„ä¼˜åŠ¿</h3>
<p><strong>æ¨å¯¼8.1ï¼šé•¿åºåˆ—çš„å†…å­˜ç“¶é¢ˆ</strong></p>
<p>å¯¹äºåºåˆ—é•¿åº¦$n$ï¼Œæ‰¹å¤§å°$B$ï¼Œå±‚æ•°$L$ï¼š</p>
<p>MHAçš„æ€»KV Cacheï¼š
$$
M_{\text{total}}^{\text{MHA}} = B \cdot L \cdot n \cdot 2hd_h
$$</p>
<p>å¯¹äº$B=8$ï¼Œ$L=32$ï¼Œ$n=8192$ï¼Œ$h=16$ï¼Œ$d_h=128$ï¼š
$$
M_{\text{total}}^{\text{MHA}} = 8 \times 32 \times 8192 \times 4096 \approx 8.59 \times 10^9
$$</p>
<p>ä»¥float16ï¼ˆ2 bytesï¼‰å­˜å‚¨ï¼Œçº¦17.2GBã€‚</p>
<p>MLAçš„æ€»KV Cacheï¼š
$$
M_{\text{total}}^{\text{MLA}} = B \cdot L \cdot n \cdot (d_c + hd_r)
$$</p>
<p>$$
= 8 \times 32 \times 8192 \times 1536 \approx 3.22 \times 10^9
$$</p>
<p>çº¦6.4GBï¼ŒèŠ‚çœçº¦63%ã€‚</p>
<p><strong>æ¨å¯¼8.2ï¼šé•¿åºåˆ—çš„è®¡ç®—å¤æ‚åº¦</strong></p>
<p>è®­ç»ƒé•¿åºåˆ—æ—¶ï¼Œæ³¨æ„åŠ›è®¡ç®—çš„å¤æ‚åº¦ä¸º$\mathcal{O}(n^2)$ï¼Œè¿™æ˜¯ç“¶é¢ˆã€‚</p>
<p>ä½†åœ¨æ¨ç†é˜¶æ®µï¼ŒMLAçš„ä¼˜åŠ¿ä½“ç°åœ¨ï¼š
1. æ›´å°çš„KV Cacheå‡å°‘å†…å­˜å¸¦å®½éœ€æ±‚
2. å¯ä»¥ç”¨æ›´å¤§çš„æ‰¹æ¬¡æˆ–æ›´é•¿çš„åºåˆ—</p>
<p>è®¾å†…å­˜å¸¦å®½ä¸º$B_w$ï¼ˆGB/sï¼‰ï¼Œæ¯æ­¥æ¨ç†éœ€è¦è¯»å–KV Cacheï¼š
$$
t_{\text{memory}} = \frac{M_{\text{total}}}{B_w}
$$</p>
<p>MLAçš„å†…å­˜è®¿é—®æ—¶é—´ï¼š
$$
t_{\text{MLA}} \approx 0.37 \times t_{\text{MHA}}
$$</p>
<p>æ¨ç†é€Ÿåº¦æå‡çº¦2.7å€ã€‚</p>
<p><strong>æ¨å¯¼8.3ï¼šè¶…é•¿ä¸Šä¸‹æ–‡çš„å¯è¡Œæ€§</strong></p>
<p>å‡è®¾GPUå†…å­˜é™åˆ¶ä¸º$M_{\max}$ï¼Œå¯æ”¯æŒçš„æœ€å¤§åºåˆ—é•¿åº¦ï¼š</p>
<p>MHAï¼š
$$
n_{\max}^{\text{MHA}} = \frac{M_{\max}}{B \cdot L \cdot 2hd_h}
$$</p>
<p>MLAï¼š
$$
n_{\max}^{\text{MLA}} = \frac{M_{\max}}{B \cdot L \cdot (d_c + hd_r)}
$$</p>
<p>æ¯”å€¼ï¼š
$$
\frac{n_{\max}^{\text{MLA}}}{n_{\max}^{\text{MHA}}} = \frac{2hd_h}{d_c + hd_r} \approx 2.67
$$</p>
<p>MLAå¯ä»¥å¤„ç†çº¦2.67å€é•¿çš„åºåˆ—ã€‚</p>
<h3 id="9">9. ä½ç§©å‡è®¾çš„éªŒè¯</h3>
<p><strong>æ¨å¯¼9.1ï¼šæ³¨æ„åŠ›çŸ©é˜µçš„ç§©åˆ†æ</strong></p>
<p>å®éªŒè§‚å¯Ÿè¡¨æ˜ï¼ŒAttentionçš„KVçŸ©é˜µé€šå¸¸æ˜¯ä½ç§©çš„ã€‚æˆ‘ä»¬ä»ç†è®ºä¸Šåˆ†æã€‚</p>
<p>å¯¹äºè‡ªç„¶è¯­è¨€ï¼Œç›¸é‚»tokené€šå¸¸è¯­ä¹‰ç›¸å…³ï¼Œå³ï¼š
$$
\boldsymbol{x}_i \approx \boldsymbol{x}_{i+1} + \boldsymbol{\varepsilon}_i
$$</p>
<p>å…¶ä¸­$\boldsymbol{\varepsilon}_i$æ˜¯å°æ‰°åŠ¨ã€‚å› æ­¤KçŸ©é˜µï¼š
$$
\boldsymbol{K} = \begin{bmatrix} \boldsymbol{x}_1 \boldsymbol{W}_k \\ \boldsymbol{x}_2 \boldsymbol{W}_k \\ \vdots \\ \boldsymbol{x}_n \boldsymbol{W}_k \end{bmatrix}
$$</p>
<p>ç›¸é‚»è¡Œé«˜åº¦ç›¸å…³ï¼Œå¯¼è‡´çŸ©é˜µç§©è¾ƒä½ã€‚</p>
<p><strong>æ¨å¯¼9.2ï¼šå¥‡å¼‚å€¼çš„è¡°å‡</strong></p>
<p>å¯¹KçŸ©é˜µè¿›è¡ŒSVDï¼š
$$
\boldsymbol{K} = \boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{V}^{\top}
$$</p>
<p>å®éªŒæ˜¾ç¤ºï¼Œå¥‡å¼‚å€¼å¿«é€Ÿè¡°å‡ï¼š
$$
\sigma_i \approx \sigma_1 \cdot i^{-\alpha}, \quad \alpha \approx 1.5 \sim 2
$$</p>
<p>è¿™æ„å‘³ç€ç”¨å‰$r$ä¸ªå¥‡å¼‚å€¼è¿‘ä¼¼ï¼Œè¯¯å·®ï¼š
$$
\|\boldsymbol{K} - \boldsymbol{K}_r\|_F = \sqrt{\sum_{i=r+1}^{\min(n,d)} \sigma_i^2} \approx \sigma_1 \sqrt{\sum_{i=r+1}^{\infty} i^{-2\alpha}}
$$</p>
<p>å½“$\alpha &gt; 1$æ—¶ï¼Œçº§æ•°æ”¶æ•›ï¼Œè¯¯å·®æœ‰ç•Œã€‚</p>
<p><strong>æ¨å¯¼9.3ï¼šMLAçš„ä½ç§©çº¦æŸ</strong></p>
<p>MLAé€šè¿‡$\boldsymbol{K} = \boldsymbol{C}\boldsymbol{W}_k$å¼ºåˆ¶ç§©ä¸è¶…è¿‡$d_c$ã€‚è¿™ç›¸å½“äºï¼š
$$
\boldsymbol{K}_{\text{MLA}} = \sum_{i=1}^{d_c} \sigma_i \boldsymbol{u}_i \boldsymbol{v}_i^{\top}
$$</p>
<p>åªè¦$d_c$é€‰æ‹©é€‚å½“ï¼ˆè¦†ç›–ä¸»è¦å¥‡å¼‚å€¼ï¼‰ï¼Œè¿‘ä¼¼è¯¯å·®å¾ˆå°ã€‚</p>
<h3 id="10-mla">10. MLAä¸å…¶ä»–å‹ç¼©æ–¹æ³•çš„å¯¹æ¯”</h3>
<p><strong>æ¨å¯¼10.1ï¼šMQAçš„å‹ç¼©æœºåˆ¶</strong></p>
<p>Multi-Query Attention (MQA) ä½¿ç”¨å•ä¸ªKå’ŒVï¼š
$$
\boldsymbol{k}_i = \boldsymbol{x}_i \boldsymbol{W}_k, \quad \boldsymbol{v}_i = \boldsymbol{x}_i \boldsymbol{W}_v
$$</p>
<p>æ‰€æœ‰headså…±äº«ï¼š
$$
\boldsymbol{o}_i^{(s)} = \text{Attention}(\boldsymbol{q}_i^{(s)}, \{\boldsymbol{k}_j\}, \{\boldsymbol{v}_j\})
$$</p>
<p>KV Cacheï¼š
$$
M_{\text{MQA}} = n \cdot 2d_h
$$</p>
<p><strong>æ¨å¯¼10.2ï¼šGQAçš„å‹ç¼©æœºåˆ¶</strong></p>
<p>Grouped Query Attentionå°†headsåˆ†æˆ$g$ç»„ï¼š
$$
M_{\text{GQA}} = n \cdot g \cdot 2d_h
$$</p>
<p>å‹ç¼©æ¯”ï¼š
$$
\rho_{\text{GQA}} = \frac{g}{h}
$$</p>
<p>ä¾‹å¦‚$g=4$ï¼Œ$h=16$ï¼š
$$
\rho_{\text{GQA}} = \frac{4}{16} = 0.25
$$</p>
<p><strong>æ¨å¯¼10.3ï¼šMLA vs GQA</strong></p>
<p>MLAçš„å‹ç¼©æ¯”ï¼š
$$
\rho_{\text{MLA}} = \frac{d_c + hd_r}{2hd_h}
$$</p>
<p>å¯¹äºå…¸å‹é…ç½®ï¼ˆ$d_c=512$ï¼Œ$d_r=64$ï¼Œ$h=16$ï¼Œ$d_h=128$ï¼‰ï¼š
$$
\rho_{\text{MLA}} = \frac{512 + 16 \times 64}{2 \times 16 \times 128} = \frac{1536}{4096} = 0.375
$$</p>
<p>MLAå’ŒGQA4çš„å‹ç¼©æ¯”æ¥è¿‘ï¼Œä½†MLAé€šè¿‡ä½ç§©åˆ†è§£æä¾›äº†æ›´å¤§çš„çµæ´»æ€§ã€‚</p>
<h3 id="11-vo-rope">11. VO-RoPEçš„æ•°å­¦åŸç†</h3>
<p><strong>æ¨å¯¼11.1ï¼šVO-RoPEçš„å®šä¹‰</strong></p>
<p>Value Output RoPE (VO-RoPE) å°†RoPEåº”ç”¨äºVï¼Œç„¶ååœ¨è¾“å‡ºæ—¶é€†å‘æ—‹è½¬ã€‚</p>
<p>å‰å‘ï¼š
$$
\tilde{\boldsymbol{v}}_i = \boldsymbol{\mathcal{R}}_i \boldsymbol{v}_i
$$</p>
<p>æ³¨æ„åŠ›ï¼š
$$
\boldsymbol{o}_i = \sum_{j \leq i} \alpha_{ij} \tilde{\boldsymbol{v}}_j = \sum_{j \leq i} \alpha_{ij} \boldsymbol{\mathcal{R}}_j \boldsymbol{v}_j
$$</p>
<p>è¾“å‡ºæ—¶é€†å‘æ—‹è½¬ï¼š
$$
\boldsymbol{o}_i' = \boldsymbol{\mathcal{R}}_i^{\top} \boldsymbol{o}_i = \boldsymbol{\mathcal{R}}_i^{\top} \sum_{j \leq i} \alpha_{ij} \boldsymbol{\mathcal{R}}_j \boldsymbol{v}_j = \sum_{j \leq i} \alpha_{ij} \boldsymbol{\mathcal{R}}_{j-i} \boldsymbol{v}_j
$$</p>
<p><strong>æ¨å¯¼11.2ï¼šVO-RoPEçš„ç›¸å¯¹ä½ç½®æ€§è´¨</strong></p>
<p>æ³¨æ„åˆ°$\boldsymbol{o}<em j-i="j-i">i'$ä¸­ï¼Œ$\boldsymbol{v}_j$è¢«æ—‹è½¬äº†$\boldsymbol{\mathcal{R}}</em>$ï¼Œè¿™ç¼–ç äº†ç›¸å¯¹ä½ç½®$j-i$ã€‚</p>
<p>è¿™ä¸æ ‡å‡†RoPEä¸åŒï¼šæ ‡å‡†RoPEåœ¨æ³¨æ„åŠ›åˆ†æ•°ä¸­ç¼–ç ä½ç½®ï¼ŒVO-RoPEåœ¨è¾“å‡ºå€¼ä¸­ç¼–ç ä½ç½®ã€‚</p>
<p><strong>æ¨å¯¼11.3ï¼šVO-RoPEä¸KVå…±äº«çš„å…¼å®¹æ€§</strong></p>
<p>VO-RoPEå…è®¸Kå’ŒVå®Œå…¨å…±äº«ï¼š
$$
\boldsymbol{k}_i = \boldsymbol{v}_i = \boldsymbol{c}_i
$$</p>
<p>åœ¨Kä¸Šåº”ç”¨RoPEï¼š
$$
\tilde{\boldsymbol{k}}_i = \boldsymbol{\mathcal{R}}_i \boldsymbol{c}_i
$$</p>
<p>åœ¨Vä¸Šä¹Ÿåº”ç”¨RoPEï¼ˆç”¨äºè¾“å‡ºï¼‰ï¼š
$$
\tilde{\boldsymbol{v}}_i = \boldsymbol{\mathcal{R}}_i \boldsymbol{c}_i = \tilde{\boldsymbol{k}}_i
$$</p>
<p>è¿™æ ·Kå’ŒVä»ç„¶ç›¸åŒï¼Œä¿æŒäº†å®Œå…¨å…±äº«ï¼ŒåŒæ—¶å¼•å…¥äº†ä½ç½®ä¿¡æ¯ã€‚</p>
<h3 id="12-mla">12. å¤šå±‚MLAçš„ç´¯ç§¯æ•ˆåº”</h3>
<p><strong>æ¨å¯¼12.1ï¼šå•å±‚MLAçš„è¾“å‡º</strong></p>
<p>ç¬¬$\ell$å±‚çš„è¾“å‡ºï¼š
$$
\boldsymbol{h}_i^{(\ell)} = \boldsymbol{h}_i^{(\ell-1)} + \text{MLA}^{(\ell)}(\boldsymbol{h}_i^{(\ell-1)}) + \text{FFN}^{(\ell)}(\cdot)
$$</p>
<p>ç®€åŒ–ä¸ºï¼š
$$
\boldsymbol{h}_i^{(\ell)} = \boldsymbol{h}_i^{(\ell-1)} + \Delta \boldsymbol{h}_i^{(\ell)}
$$</p>
<p><strong>æ¨å¯¼12.2ï¼šè·¨å±‚çš„ä¿¡æ¯æµåŠ¨</strong></p>
<p>ä»è¾“å…¥$\boldsymbol{x}_i$åˆ°ç¬¬$L$å±‚çš„è¾“å‡ºï¼š
$$
\boldsymbol{h}_i^{(L)} = \boldsymbol{x}_i + \sum_{\ell=1}^L \Delta \boldsymbol{h}_i^{(\ell)}
$$</p>
<p>æ¯ä¸€å±‚çš„è´¡çŒ®$\Delta \boldsymbol{h}_i^{(\ell)}$é€šè¿‡æ®‹å·®è¿æ¥ç´¯åŠ ã€‚</p>
<p><strong>æ¨å¯¼12.3ï¼šä½ç§©çº¦æŸçš„ç´¯ç§¯å½±å“</strong></p>
<p>æ¯å±‚MLAçš„è¾“å‡ºå—ä½ç§©çº¦æŸå½±å“ï¼š
$$
\Delta \boldsymbol{h}_i^{(\ell)} = f(\text{low-rank attention})
$$</p>
<p>è·¨å±‚ç´¯ç§¯æ—¶ï¼Œè™½ç„¶æ¯å±‚æ˜¯ä½ç§©çš„ï¼Œä½†ç´¯åŠ åï¼š
$$
\boldsymbol{h}_i^{(L)} = \boldsymbol{x}_i + \sum_{\ell=1}^L \Delta \boldsymbol{h}_i^{(\ell)}
$$</p>
<p>æ€»çš„ç§©å¯ä»¥è¾¾åˆ°ï¼š
$$
\text{rank}(\boldsymbol{H}^{(L)}) \leq \min(n, d + L \cdot d_c)
$$</p>
<p>å½“$L$è¶³å¤Ÿå¤§æ—¶ï¼Œç´¯ç§¯ç§©å¯ä»¥å¾ˆé«˜ï¼Œæ¢å¤äº†è¡¨è¾¾èƒ½åŠ›ã€‚</p>
<h3 id="13">13. è®­ç»ƒåŠ¨æ€ä¸æ”¶æ•›æ€§</h3>
<p><strong>æ¨å¯¼13.1ï¼šMLAçš„æŸå¤±å‡½æ•°</strong></p>
<p>è®­ç»ƒç›®æ ‡æ˜¯æœ€å°åŒ–äº¤å‰ç†µæŸå¤±ï¼š
$$
\mathcal{L} = -\sum_{i=1}^n \log p(x_{i+1} | \boldsymbol{x}_{\leq i})
$$</p>
<p>MLAå¼•å…¥ä½ç§©çº¦æŸï¼Œç›¸å½“äºæ­£åˆ™åŒ–ï¼š
$$
\mathcal{L}_{\text{MLA}} = \mathcal{L} + \lambda R(\boldsymbol{W}_c)
$$</p>
<p>å…¶ä¸­$R(\boldsymbol{W}_c)$æƒ©ç½šé«˜ç§©ã€‚</p>
<p><strong>æ¨å¯¼13.2ï¼šæ¢¯åº¦ä¸‹é™çš„æ”¶æ•›é€Ÿåº¦</strong></p>
<p>åœ¨å‡¸ä¼˜åŒ–å‡è®¾ä¸‹ï¼Œæ¢¯åº¦ä¸‹é™çš„æ”¶æ•›é€Ÿåº¦ï¼š
$$
\mathcal{L}(t) - \mathcal{L}^* \leq \frac{\|\boldsymbol{W}_0 - \boldsymbol{W}^*\|^2}{2\eta t}
$$</p>
<p>å…¶ä¸­$\eta$æ˜¯å­¦ä¹ ç‡ï¼Œ$t$æ˜¯è¿­ä»£æ¬¡æ•°ã€‚</p>
<p>MLAçš„ä½ç§©çº¦æŸå‡å°‘äº†å‚æ•°ç©ºé—´ç»´åº¦ï¼Œå¯èƒ½åŠ å¿«æ”¶æ•›ï¼š
$$
\text{dim}(\mathcal{W}_{\text{MLA}}) < \text{dim}(\mathcal{W}_{\text{MHA}})
$$</p>
<p><strong>æ¨å¯¼13.3ï¼šè¿‡æ‹Ÿåˆé£é™©çš„é™ä½</strong></p>
<p>ä½ç§©çº¦æŸç›¸å½“äºæ–½åŠ äº†å½’çº³åç½®ï¼Œå‡å°‘äº†æ¨¡å‹å¤æ‚åº¦ã€‚æ ¹æ®VCç»´ç†è®ºï¼š
$$
\text{VC-dim}(\text{MLA}) \leq \text{VC-dim}(\text{MHA})
$$</p>
<p>æ›´å°çš„VCç»´æ„å‘³ç€æ›´å¥½çš„æ³›åŒ–ç•Œï¼š
$$
\mathbb{E}[\mathcal{L}_{\text{test}}] \leq \mathcal{L}_{\text{train}} + \mathcal{O}\left(\sqrt{\frac{\text{VC-dim}}{n}}\right)
$$</p>
<p>MLAæœ‰æ›´ç´§çš„æ³›åŒ–ç•Œã€‚</p>
<h3 id="14">14. å®éªŒè§‚å¯Ÿçš„ç†è®ºè§£é‡Š</h3>
<p><strong>æ¨å¯¼14.1ï¼šå¤´æ•°ç¿»å€ vs head_dimsç¿»å€</strong></p>
<p>å®éªŒæ˜¾ç¤ºï¼šhead_dimsç¿»å€ï¼ˆGQA1-256ï¼‰ä¼˜äºheadsç¿»å€ï¼ˆGQA2-128ï¼Œ32 headsï¼‰ã€‚</p>
<p>ç†è®ºè§£é‡Šï¼šä»è¡¨è¾¾èƒ½åŠ›çœ‹ï¼Œhead_dimså†³å®šäº†æ¯ä¸ªheadçš„å®¹é‡ã€‚è®¾ä¿¡æ¯å®¹é‡ï¼š
$$
I_{\text{head}} \sim d_h \log d_h
$$</p>
<p>æ€»å®¹é‡ï¼š
$$
I_{\text{total}} = h \cdot I_{\text{head}} \sim h \cdot d_h \log d_h
$$</p>
<p>æ¯”è¾ƒä¸¤ç§é…ç½®ï¼ˆå›ºå®š$h \cdot d_h = D$ï¼‰ï¼š
- é…ç½®Aï¼š$(h, d_h)$ï¼Œå®¹é‡$\sim h \cdot d_h \log d_h = D \log d_h$
- é…ç½®Bï¼š$(h/2, 2d_h)$ï¼Œå®¹é‡$\sim \frac{h}{2} \cdot 2d_h \log(2d_h) = D \log(2d_h) = D(\log d_h + \log 2)$</p>
<p>é…ç½®Bå®¹é‡æ›´å¤§ï¼Œå› ä¸º$\log(2d_h) &gt; \log d_h$ã€‚</p>
<p><strong>æ¨å¯¼14.2ï¼šPartial RoPEçš„æœ‰æ•ˆæ€§</strong></p>
<p>å®éªŒä¸­GQA1-256-PRä¼˜äºGQA1-256ã€‚ä»ä¿¡æ¯è®ºè§’åº¦ï¼š</p>
<p>å®Œå…¨RoPEï¼šæ‰€æœ‰$d_h$ç»´éƒ½ç¼–ç ä½ç½®+å†…å®¹æ··åˆä¿¡æ¯
Partial RoPEï¼š$d_c$ç»´çº¯å†…å®¹ï¼Œ$d_r$ç»´çº¯ä½ç½®</p>
<p>ä¿¡æ¯åˆ†ç¦»æå‡äº†ç¼–ç æ•ˆç‡ã€‚æ ¹æ®ä¿¡æ¯åˆ†è§£ï¼š
$$
I(X; Y, Z) \leq I(X; Y) + I(X; Z)
$$</p>
<p>å½“Yï¼ˆå†…å®¹ï¼‰å’ŒZï¼ˆä½ç½®ï¼‰ç‹¬ç«‹æ—¶ï¼Œç­‰å·æˆç«‹ï¼Œåˆ†ç¦»è¡¨ç¤ºæœ€ä¼˜ã€‚</p>
<p><strong>æ¨å¯¼14.3ï¼šKVå…±äº«çš„ååŠ²</strong></p>
<p>å®éªŒä¸­GQA2-(192+64)-S2åæœŸè¶…è¶ŠGQA1-256-PRã€‚ç†è®ºä¸Šï¼ŒKVå…±äº«æ–½åŠ äº†å¼ºæ­£åˆ™åŒ–ï¼ŒåˆæœŸå¯èƒ½é™åˆ¶è¡¨è¾¾ï¼Œä½†é•¿æœŸæœ‰åŠ©äºæ³›åŒ–ã€‚</p>
<p>ä»æ­£åˆ™åŒ–è·¯å¾„è§’åº¦ï¼š
$$
\boldsymbol{W}(t) = \arg\min_{\boldsymbol{W}} \mathcal{L}(\boldsymbol{W}) + \lambda(t) R(\boldsymbol{W})
$$</p>
<p>éšç€è®­ç»ƒè¿›è¡Œï¼Œ$\lambda(t)$é€æ¸å‡å°ï¼Œæ­£åˆ™åŒ–ä½œç”¨å‡å¼±ï¼Œä½†å·²ç»å­¦åˆ°çš„ç»“æ„åŒ–è¡¨ç¤ºä¿æŒï¼Œå¸®åŠ©æ³›åŒ–ã€‚</p>
<h3 id="15-mfatpa">15. MFAå’ŒTPAçš„ç†è®ºå¯¹æ¯”</h3>
<p><strong>æ¨å¯¼15.1ï¼šMFAçš„æ•°å­¦å½¢å¼</strong></p>
<p>Multi-matrix Factorization Attention (MFA) å¯¹Qä½¿ç”¨LoRAï¼š
$$
\boldsymbol{q}_i^{(s)} = \boldsymbol{x}_i (\boldsymbol{W}_q^{(s)} + \boldsymbol{A}^{(s)} \boldsymbol{B}^{(s)})
$$</p>
<p>Kå’ŒVä¿æŒæ ‡å‡†å½¢å¼ï¼ˆMQAï¼‰ï¼š
$$
\boldsymbol{k}_i = \boldsymbol{x}_i \boldsymbol{W}_k, \quad \boldsymbol{v}_i = \boldsymbol{x}_i \boldsymbol{W}_v
$$</p>
<p><strong>æ¨å¯¼15.2ï¼šTPAçš„æ•°å­¦å½¢å¼</strong></p>
<p>Tensor Product Attentionå°†å‹ç¼©å‘é‡reshapeåæŠ•å½±ï¼š
$$
\boldsymbol{c}_i = \boldsymbol{x}_i \boldsymbol{W}_c \in \mathbb{R}^{g \times d'}
$$</p>
<p>å…¶ä¸­$g$æ˜¯groupæ•°ï¼Œ$d'$æ˜¯æ¯ç»„ç»´åº¦ã€‚</p>
<p>æ¯ä¸ªheadä»å¯¹åº”ç»„æŠ•å½±ï¼š
$$
\boldsymbol{k}_i^{(s)} = \boldsymbol{c}_{i, g(s)} \boldsymbol{W}_k^{(s)}
$$</p>
<p><strong>æ¨å¯¼15.3ï¼šMLA vs MFA vs TPA</strong></p>
<p>ä»è¡¨è¾¾èƒ½åŠ›ä¸Šç•Œï¼š
$$
\mathcal{C}_{\text{TPA}} \leq \mathcal{C}_{\text{MFA}} \leq \mathcal{C}_{\text{MLA}}
$$</p>
<ul>
<li>TPAå—é™äºåˆ†ç»„ç»“æ„ï¼Œæ¯ç»„ç‹¬ç«‹æŠ•å½±</li>
<li>MFAçš„Qæœ‰ä½ç§©çº¦æŸï¼ŒKå’ŒVæ— çº¦æŸ</li>
<li>MLAå¯¹Kå’ŒVéƒ½æœ‰ä½ç§©çº¦æŸï¼Œä½†é€šè¿‡å…±äº«å‹ç¼©è¡¨ç¤ºè·å¾—æ›´å¤§çµæ´»æ€§</li>
</ul>
<p>å®è·µä¸­MLAè¡¨ç°æœ€å¥½ï¼ŒéªŒè¯äº†"å¯¹ç§°å‹ç¼©Kå’ŒV"ä¼˜äº"åªå‹ç¼©Q"æˆ–"åˆ†ç»„å‹ç¼©"ã€‚</p>
<h3 id="16">16. å¤§è§„æ¨¡æ¨¡å‹çš„æ‰©å±•æ€§</h3>
<p><strong>æ¨å¯¼16.1ï¼šå‚æ•°è§„æ¨¡ä¸æ€§èƒ½çš„å…³ç³»</strong></p>
<p>æ ¹æ®Scaling Lawï¼š
$$
\mathcal{L}(N) \propto N^{-\alpha}
$$</p>
<p>å…¶ä¸­$N$æ˜¯å‚æ•°é‡ï¼Œ$\alpha \approx 0.076$ï¼ˆGPT-3è®ºæ–‡ï¼‰ã€‚</p>
<p>MLAåœ¨ç›¸åŒKV Cacheä¸‹å¯ä»¥ä½¿ç”¨æ›´å¤§çš„head_dimsï¼Œä»è€Œå¢åŠ å‚æ•°é‡ã€‚</p>
<p><strong>æ¨å¯¼16.2ï¼šè®¡ç®—æ•ˆç‡çš„trade-off</strong></p>
<p>å¢å¤§head_dimsä»128åˆ°256ï¼Œå‚æ•°é‡å¢åŠ ï¼š
$$
\Delta P = h \cdot d \cdot (256 - 128) = h \cdot d \cdot 128
$$</p>
<p>è®­ç»ƒè®¡ç®—å¢åŠ ï¼š
$$
\Delta C = n^2 \cdot h \cdot 128
$$</p>
<p>ä½†æ¨ç†æ—¶ï¼ŒKV Cacheé€šè¿‡MLAå‹ç¼©ï¼Œå†…å­˜ä¸å¢åŠ ï¼ˆæˆ–å¢åŠ å¾ˆå°‘ï¼‰ã€‚</p>
<p><strong>æ¨å¯¼16.3ï¼šæœ€ä¼˜é…ç½®çš„é€‰æ‹©</strong></p>
<p>ç»™å®šè®¡ç®—é¢„ç®—$C_{\max}$å’Œå†…å­˜é¢„ç®—$M_{\max}$ï¼Œæœ€ä¼˜åŒ–é—®é¢˜ï¼š
$$
\max_{h, d_h, d_c} \text{Performance}(h, d_h, d_c)
$$</p>
<p>çº¦æŸï¼š
$$
\text{s.t.} \quad n^2 \cdot h \cdot d_h \leq C_{\max}, \quad n \cdot (d_c + h \cdot d_r) \leq M_{\max}
$$</p>
<p>MLAæä¾›äº†æ›´å¤§çš„è®¾è®¡ç©ºé—´ï¼Œå¯ä»¥åœ¨çº¦æŸä¸‹è¾¾åˆ°æ›´é«˜æ€§èƒ½ã€‚</p>
<h3 id="17">17. æœªæ¥æ”¹è¿›æ–¹å‘</h3>
<p><strong>æ¨å¯¼17.1ï¼šåŠ¨æ€ä½ç§©åˆ†é…</strong></p>
<p>å½“å‰MLAä½¿ç”¨å›ºå®šçš„$d_c$ã€‚å¯ä»¥è€ƒè™‘åŠ¨æ€è°ƒæ•´ï¼š
$$
d_c^{(\ell)} = f(\ell, \text{complexity})
$$</p>
<p>ä¾‹å¦‚ï¼Œæµ…å±‚ä½¿ç”¨è¾ƒå°çš„$d_c$ï¼ˆæ•æ‰å±€éƒ¨æ¨¡å¼ï¼‰ï¼Œæ·±å±‚ä½¿ç”¨è¾ƒå¤§çš„$d_c$ï¼ˆæ•æ‰å…¨å±€ä¾èµ–ï¼‰ã€‚</p>
<p><strong>æ¨å¯¼17.2ï¼šéçº¿æ€§å‹ç¼©</strong></p>
<p>å½“å‰å‹ç¼©æ˜¯çº¿æ€§çš„ï¼š$\boldsymbol{c}_i = \boldsymbol{x}_i \boldsymbol{W}_c$ã€‚</p>
<p>å¯ä»¥å¼•å…¥éçº¿æ€§ï¼š
$$
\boldsymbol{c}_i = \sigma(\boldsymbol{x}_i \boldsymbol{W}_c^{(1)}) \boldsymbol{W}_c^{(2)}
$$</p>
<p>å…¶ä¸­$\sigma$æ˜¯æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ReLUã€GELUï¼‰ã€‚è¿™å¢åŠ äº†è¡¨è¾¾èƒ½åŠ›ï¼Œä½†ä¹Ÿå¢åŠ äº†è®¡ç®—æˆæœ¬ã€‚</p>
<p><strong>æ¨å¯¼17.3ï¼šè‡ªé€‚åº”æ³¨æ„åŠ›æœºåˆ¶</strong></p>
<p>ç»“åˆMLAå’Œç¨€ç–æ³¨æ„åŠ›ï¼š
$$
\text{score}_{ij} = \begin{cases}
\boldsymbol{q}_i^{\top} \boldsymbol{k}_j, & \text{if } j \in \mathcal{N}(i) \\
-\infty, & \text{otherwise}
\end{cases}
$$</p>
<p>å…¶ä¸­$\mathcal{N}(i)$æ˜¯ä½ç½®$i$çš„é‚»åŸŸï¼ˆé€šè¿‡å­¦ä¹ ç¡®å®šï¼‰ã€‚</p>
<p>ç»“åˆä½ç§©å‹ç¼©å’Œç¨€ç–æ€§ï¼Œè¿›ä¸€æ­¥æå‡æ•ˆç‡ã€‚</p>
<h3 id="18-mla">18. æ€»ç»“ï¼šMLAçš„ç†è®ºä¼˜è¶Šæ€§</h3>
<p><strong>æ¨å¯¼18.1ï¼šæ ¸å¿ƒä¼˜åŠ¿çš„æ•°å­¦è¡¨è¿°</strong></p>
<p>MLAçš„æ ¸å¿ƒä¼˜åŠ¿å¯ä»¥ç”¨ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶è¡¨è¿°ï¼š</p>
<p>åœ¨è®­ç»ƒé˜¶æ®µï¼Œæœ€å¤§åŒ–è¡¨è¾¾èƒ½åŠ›ï¼š
$$
\max_{\boldsymbol{W}} \mathcal{C}(\boldsymbol{W}) \quad \text{s.t.} \quad \mathcal{O}_{\text{compute}} \leq C_{\max}
$$</p>
<p>åœ¨æ¨ç†é˜¶æ®µï¼Œæœ€å°åŒ–å†…å­˜å ç”¨ï¼š
$$
\min_{\boldsymbol{c}} M(\boldsymbol{c}) \quad \text{s.t.} \quad \mathcal{C}(\boldsymbol{c}) \geq \mathcal{C}_{\min}
$$</p>
<p>MLAé€šè¿‡åŒé‡æŠ•å½±å’Œå¸æ”¶å½’ä¸€åŒ–ï¼Œå®ç°äº†ä¸¤é˜¶æ®µçš„è”åˆä¼˜åŒ–ã€‚</p>
<p><strong>æ¨å¯¼18.2ï¼šç†è®ºä¸å®è·µçš„ç»Ÿä¸€</strong></p>
<p>ä»ç†è®ºæ¨å¯¼åˆ°å®éªŒéªŒè¯ï¼ŒMLAå±•ç°äº†ï¼š</p>
<ol>
<li><strong>æ•°å­¦ä¸¥è°¨æ€§</strong>ï¼šæ‰€æœ‰è®¾è®¡éƒ½æœ‰ç†è®ºæ”¯æ’‘ï¼ˆä½ç§©åˆ†è§£ã€æ­£åˆ™åŒ–ã€ä¿¡æ¯è®ºï¼‰</li>
<li><strong>å·¥ç¨‹å®ç”¨æ€§</strong>ï¼šåœ¨å®é™…ä»»åŠ¡ä¸­å–å¾—SOTAæ€§èƒ½</li>
<li><strong>å¯æ‰©å±•æ€§</strong>ï¼šé€‚ç”¨äºä¸åŒè§„æ¨¡å’Œåœºæ™¯çš„æ¨¡å‹</li>
</ol>
<p><strong>æ¨å¯¼18.3ï¼šå¯¹æœªæ¥ç ”ç©¶çš„å¯ç¤º</strong></p>
<p>MLAçš„æˆåŠŸè¡¨æ˜ï¼š</p>
<ul>
<li>è®­ç»ƒå’Œæ¨ç†çš„åŒé‡ä¼˜åŒ–æ˜¯é‡è¦æ–¹å‘</li>
<li>ä½ç§©å‡è®¾åœ¨è‡ªç„¶è¯­è¨€ä¸­æ˜¯åˆç†çš„</li>
<li>ç²¾å¿ƒè®¾è®¡çš„çº¦æŸï¼ˆå¦‚Partial RoPEã€KVå…±äº«ï¼‰å¯ä»¥æå‡æ€§èƒ½</li>
</ul>
<p>è¿™ä¸ºæœªæ¥çš„Attentionæœºåˆ¶è®¾è®¡æä¾›äº†èŒƒå¼ã€‚</p>
        </div>
    </div>
</body>
</html>