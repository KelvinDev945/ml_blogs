<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Seq2Seq中Exposure Bias现象的浅析与对策</title>
    <style>
* { margin: 0; padding: 0; box-sizing: border-box; }
body {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
    line-height: 1.6; color: #333; max-width: 900px; margin: 0 auto; padding: 20px; background: #f5f5f5;
}
.container { background: white; padding: 40px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
header { border-bottom: 2px solid #e0e0e0; padding-bottom: 20px; margin-bottom: 30px; }
h1 { color: #2c3e50; margin-bottom: 10px; font-size: 2em; }
.meta { color: #666; font-size: 0.9em; margin-bottom: 20px; }
.content { margin-top: 30px; overflow-wrap: break-word; }
.content h2 { color: #34495e; margin-top: 30px; margin-bottom: 15px; border-bottom: 1px solid #eee; padding-bottom: 5px; }
.content p { margin-bottom: 15px; }
.content pre { background: #f8f8f8; padding: 15px; border-radius: 5px; overflow-x: auto; border-left: 3px solid #3498db; margin: 15px 0; }
.content code { background: #f8f8f8; padding: 2px 5px; border-radius: 3px; font-family: monospace; font-size: 0.9em; }
.content blockquote { border-left: 4px solid #3498db; padding-left: 20px; margin: 20px 0; color: #555; font-style: italic; }
.content table { border-collapse: collapse; width: 100%; margin: 20px 0; }
.content th, .content td { border: 1px solid #ddd; padding: 10px; text-align: left; }
.back-link { display: inline-block; margin-bottom: 20px; color: #3498db; text-decoration: none; font-weight: 500; }
</style>
    
<script>
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\(', '\)']],
            displayMath: [['$$', '$$'], ['\[', '\]']],
            processEscapes: true
        }
    };
</script>
<script id="MathJax-script" async src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>
    <div class="container">
        <a href="../index.html" class="back-link">← 返回首页</a>
        <header>
            <h1>Seq2Seq中Exposure Bias现象的浅析与对策</h1>
            <div class="meta">📅 最后更新: 2025-12-31 | 📄 大小: 18.6 KB</div>
        </header>
        <div class="content">
            <p><strong>原文链接</strong>: <a href="https://spaces.ac.cn/archives/7259">https://spaces.ac.cn/archives/7259</a></p>
<p><strong>发布日期</strong>: </p>
<hr />
<p>前些天笔者写了<a href="/archives/7213">《CRF用过了，不妨再了解下更快的MEMM？》</a>，里边提到了MEMM的局部归一化和CRF的全局归一化的优劣。同时，笔者联想到了Seq2Seq模型，因为Seq2Seq模型的典型训练方案Teacher Forcing就是一个局部归一化模型，所以它也存在着局部归一化所带来的毛病——也就是我们经常说的“Exposure Bias”。带着这个想法，笔者继续思考了一翻，将最后的思考结果记录在此文。</p>
<p><a href="/usr/uploads/2020/03/355516437.png" title="点击查看原图"><img alt="经典的Seq2Seq模型图示" src="/usr/uploads/2020/03/355516437.png" /></a></p>
<p>经典的Seq2Seq模型图示</p>
<p>本文算是一篇进阶文章，适合对Seq2Seq模型已经有一定的了解、希望进一步提升模型的理解或表现的读者。关于Seq2Seq的入门文章，可以阅读旧作<a href="/archives/5861">《玩转Keras之seq2seq自动生成标题》</a>和<a href="/archives/6933">《从语言模型到Seq2Seq：Transformer如戏，全靠Mask》</a>。</p>
<p>本文的内容大致为：</p>
<blockquote>
<p>1、Exposure Bias的成因分析及例子；</p>
<p>2、简单可行的缓解Exposure Bias问题的策略。</p>
</blockquote>
<h2 id="softmax">Softmax</h2>
<p>首先，我们来回顾Softmax相关内容。大家都知道，对于向量$(x_1,x_2,\dots,x_n)$，它的Softmax为<br />
\begin{equation}(p_1,p_2,\dots,p_n)=\frac{1}{\sum\limits_{i=1}^n e^{x_i}}\left(e^{x_1},e^{x_2},\dots,e^{x_n}\right)\end{equation}<br />
由于$e^t$是关于$t$的严格单调递增函数，所以如果$x_k$是$x_1,x_2,\dots,x_n$中的最大者，那么$p_k$也是$p_1,p_2,\dots,p_n$中的最大者。</p>
<p>对于分类问题，我们所用的loss一般是交叉熵，也就是<br />
\begin{equation}-\log p_t = \log\left(\sum\limits_{i=1}^n e^{x_i}\right) - x_t\end{equation}<br />
其中$t$是目标类。如文章<a href="/archives/3290">《寻求一个光滑的最大值函数》</a>所述，上式第一项实际上是$\max\left(x_1,x_2,\dots,x_n\right)$的光滑近似，所以为了形象理解交叉熵，我们可以写出<br />
\begin{equation}-\log p_t \approx \max\left(x_1,x_2,\dots,x_n\right) - x_t\end{equation}<br />
也就是说，交叉熵实际上在缩小目标类得分$x_t$与全局最大值的差距，显然这个差距最小只能为0，并且此时目标类得分就是最大值者。所以，Softmax加交叉熵的效果就是“希望目标类的得分成为最大值”。</p>
<h2 id="teacher-forcing">Teacher Forcing</h2>
<p>现在，我们来看Seq2Seq，它通过条件分解来建模联合概率分布：<br />
\begin{equation}\begin{aligned}p(\boldsymbol{y}|\boldsymbol{x})=&amp;\,p(y_1,y_2,\dots,y_n|\boldsymbol{x})\\\<br />
=&amp;\,p(y_1|\boldsymbol{x})p(y_2|\boldsymbol{x},y_1)\dots p(y_n|\boldsymbol{x},y_1,\dots,y_{n-1})<br />
\end{aligned}\end{equation}<br />
每一项自然也就用Softmax来建模的，即<br />
\begin{equation}\begin{aligned}&amp;p(y_1|\boldsymbol{x})=\frac{e^{f(y_1;\boldsymbol{x})}}{\sum\limits_{y_1}e^{f(y_1;\boldsymbol{x})}},\\\<br />
&amp;p(y_2|\boldsymbol{x},y_1)=\frac{e^{f(y_1,y_2;\boldsymbol{x})}}{\sum\limits_{y_2}e^{f(y_1,y_2;\boldsymbol{x})}},\\\<br />
&amp;\dots,\\\<br />
&amp;p(y_n|\boldsymbol{x},y_1,\dots,y_{n-1})=\frac{e^{f(y_1,y_2,\dots,y_n;\boldsymbol{x})}}{\sum\limits_{y_n}e^{f(y_1,y_2,\dots,y_n;\boldsymbol{x})}}<br />
\end{aligned}\end{equation}<br />
乘起来就是<br />
\begin{equation}p(\boldsymbol{y}|\boldsymbol{x})=\frac{e^{f(y_1;\boldsymbol{x})+f(y_1,y_2;\boldsymbol{x})+\dots+f(y_1,y_2,\dots,y_n;\boldsymbol{x})}}{\left(\sum\limits_{y_1}e^{f(y_1;\boldsymbol{x})}\right)\left(\sum\limits_{y_2}e^{f(y_1,y_2;\boldsymbol{x})}\right)\dots\left(\sum\limits_{y_n}e^{f(y_1,y_2,\dots,y_n;\boldsymbol{x})}\right)}\label{eq:join-target}\end{equation}<br />
而训练目标就是<br />
\begin{equation}-\log p(\boldsymbol{y}|\boldsymbol{x})=-\log p(y_1|\boldsymbol{x})-\log p(y_2|\boldsymbol{x},y_1)-\dots -\log p(y_n|\boldsymbol{x},y_1,\dots,y_{n-1})\end{equation}<br />
这个直接的训练目标就叫做Teacher Forcing，因为在算$-\log p(y_2|\boldsymbol{x},y_1)$的时候我们要知道真实的$y_1$，在算$-\log p(y_3|\boldsymbol{x},y_1,y_2)$我们需要知道真实的$y_1,y_2$，依此类推，这就好像有一个经验丰富的老师预先给我们铺好了大部分的路，让我们只需要求下一步即可。这种方法训练起来简单，而且结合CNN或Transformer那样的模型就可以实现并行的训练，但它可能会带来Exposure Bias问题。</p>
<h2 id="exposure-bias">Exposure Bias</h2>
<p>其实Teacher Forcing这个名称本身就意味着它本身会存在Exposure Bias问题。回想一下老师教学生解题的过程，一般的步骤为：</p>
<blockquote>
<p>1、第一步应该怎么思考；</p>
<p>2、第一步想出来后，第二步我们有哪些选择；</p>
<p>3、确定了第二步后，第三步我们可以怎么做；</p>
<p>...</p>
<p>n、有了这n-1步后，最后一步就不难想到了。</p>
</blockquote>
<p>这个过程其实跟Seq2Seq的Teacher Forcing方案的假设是一样的。有过教学经验的读者就知道，通常来说学生们都能听得频频点头，感觉全都懂了，然后让学生课后自己做题，多数还是一脸懵比。为什么会这样呢？其中一个原因就是Exposure Bias。说白了，问题就在于，老师总是假设学生能想到前面若干步后，然后教学生下一步，但如果前面有一步想错了或者想不出来呢？这时候这个过程就无法进行下去了，也就是没法得到正确答案了，这就是Exposure Bias问题。</p>
<h2 id="beam-search">Beam Search</h2>
<p>事实上，我们真正做题的时候并不总是这样子，假如我们卡在某步无法确定时，我们就遍历几种选择，然后继续推下去，看后面的结果反过来辅助我们确定前面无法确定的那步。对应到Seq2Seq来说，这其实就相当于基于Beam Search的解码过程。</p>
<p>对于Beam Search，我们应该能发现，beam size并不是越大越好，有些情况甚至是beam size等于1时最好，这看起来有点不合理，因为beam size越大，理论上找到的序列就越接近最优序列，所以应该越有可能正确才对。事实上这也算是Exposure Bias的现象之一。</p>
<p>从式$\eqref{eq:join-target}$我们可以看出，Seq2Seq对目标序列$y_1,y_2,\dots,y_n$的打分函数为：<br />
\begin{equation}f(y_1;\boldsymbol{x})+f(y_1,y_2;\boldsymbol{x})+\dots+f(y_1,y_2,\dots,y_n;\boldsymbol{x})\end{equation}<br />
正常来说，我们希望目标序列是所有候选序列之中分数最高的，根据本文开头介绍的Softmax方法，我们建立的概率分布应该是<br />
\begin{equation}p(\boldsymbol{y}|\boldsymbol{x})=\frac{e^{f(y_1;\boldsymbol{x})+f(y_1,y_2;\boldsymbol{x})+\dots+f(y_1,y_2,\dots,y_n;\boldsymbol{x})}}{\sum\limits_{y_1,y_2,\dots,y_n}e^{f(y_1;\boldsymbol{x})+f(y_1,y_2;\boldsymbol{x})+\dots+f(y_1,y_2,\dots,y_n;\boldsymbol{x})}}\label{eq:ideal-target}\end{equation}<br />
但上式的分母需要遍历所有路径求和，难以实现，而式$\eqref{eq:join-target}$就作为一种折衷的选择得到了广泛应用。但式$\eqref{eq:join-target}$跟式$\eqref{eq:ideal-target}$并不等价，因此哪怕模型已经成功优化，也可能出现“最优序列并不是目标序列”的现象。</p>
<h2 id="_1">简单例子</h2>
<p>我们来举一个简单例子。设序列长度只有2，候选序列是$(a,b)$和$(c,d)$，而目标序列是$(a,b)$，训练完成后，模型的概率分布情况为<br />
$$\begin{array}{c|c}  
\hline  
p(a) & p(c)\\\  
\hline  
0.6 & 0.4 \\\  
\hline  
\end{array}\qquad \begin{array}{c|c|c|c}  
\hline  
p(b|a) & p(d|a) & p(b|c) & p(d|c)\\\  
\hline  
0.55 & 0.45 & 0.1 & 0.9\\\  
\hline  
\end{array}$$</p>
<p>如果beam size为1，那么因为$p(a) &gt; p(c)$，所以第一步只能输出$a$，接着因为$p(b|a) &gt; p(d|a)$，所以第二步只能输出$b$，成功输出了正确序列$(a,b)$。但如果beam size为2，那么第一步输出$(a,0.6),(c,0.4)$，而第二步遍历所有组合，我们得到<br />
\begin{array}{c|c|c|c}<br />
\hline<br />
(a, b) &amp; (a, d) &amp; (c, b) &amp; (c, d)\\\<br />
\hline<br />
0.33 &amp; 0.27 &amp; 0.04 &amp; 0.36\\\<br />
\hline<br />
\end{array}<br />
所以输出了错误的序列$(c,d)$。</p>
<p>那是因为模型没训练好吗？并不是，前面说过Softmax加交叉熵的目的就是让目标的得分最大，对于第一步我们有$p(a) &gt; p(c)$，所以第一步的训练目标已经达到了，而第二步在$a$已经预先知道的前提下我们有$p(b|a) &gt; p(d|a)$，这说明第二步的训练目标也达到了。因此，模型已经算是训练好了，只不过可能因为模型表达能力限制等原因，得分并没有特别高，但“让目标的得分最大”这个目标已经完成了。</p>
<h2 id="_2">思考对策</h2>
<p>从上述例子中读者或许可以看出问题所在了：主要是$p(d|c)$太高了，而$p(d|c)$是没有经过训练的，没有任何显式的机制去抑制$p(d|c)$变大，因此就出现了“最优序列并不是目标序列”的现象。</p>
<p>看到这里，读者可能就能想到一个朴素的对策了：添加额外的优化目标，降低那些Beam Search出来的非目标序列不就行了？事实上，这的确是一个有效的解决方法，相关结果发表在2016年的论文<a href="https://papers.cool/arxiv/1606.02960">《Sequence-to-Sequence Learning as Beam-Search Optimization》</a>。但这样一来几乎要求每步训练前的每个样本都要进行一次Beam Search，计算成本太大。还有一些更新的结果，比如ACL 2019的最佳长论文<a href="https://papers.cool/arxiv/1906.02448">《Bridging the Gap between Training and Inference for Neural Machine Translation》</a>就是聚焦于解决Exposure Bias问题。此外，通过强化学习直接优化BLEU等方法，也能一定程度上缓解Exposure Bias。</p>
<p>然而，据笔者所了解，这些致力于解决Exposure Bias的方法，大部分都是大刀阔斧地改动了训练过程，甚至会牺牲原来模型的训练并行性（需要递归地采样负样本，如果模型本身是RNN那倒无妨，但如果本身是CNN或Transformer，那伤害就很大了），成本的提升幅度比效果的提升幅度大得多。</p>
<h2 id="_3">构建负样本</h2>
<p>纵观大部分解决Exposure Bias的论文，以及结合我们前面的例子和体会，不难想到，其主要思想就是构造有代表性的负样本，然后在训练过程中降低这些负样本的概率，所以问题就是如何构造“有代表性”的负样本了。这里给出笔者构思的一种简单策略，实验证明它能一定程度上缓解Exposure Bias，提升文本生成的表现，重要的是，这种策略比较简单，基本能做到即插即用，几乎不损失训练性能。</p>
<p>方法很简单，就是随机替换一下Decoder的输入词（Decoder的输入词有个专门的名字，叫做oracle words），如下图所示：  </p>
<p><a href="/usr/uploads/2020/03/2554075951.png" title="点击查看原图"><img alt="一种缓解Exposure Bias的简单策略：直接将Decoder的部分输入词随机替换为别的词。" src="/usr/uploads/2020/03/2554075951.png" /></a></p>
<p>一种缓解Exposure Bias的简单策略：直接将Decoder的部分输入词随机替换为别的词。</p>
<p>其中紫色的[R]代表被随机替换的词。其实不少Exposure Bias的论文也是这个思路，只不过随机选词的方案不一样。笔者提出的方案很简单：</p>
<blockquote>
<p>1、50%的概率不做改变；</p>
<p>2、50%的概率把输入序列中30%的词替换掉，替换对象为原目标序列的任意一个词。</p>
</blockquote>
<p>也就是说，随机替换发生概率是50%，随机替换的比例是30%，随机抽取空间就是目标序列的词集。这个策略的灵感在于：尽管Seq2Seq不一定能完全生成目标序列，但它通常能生成大部分目标序列的词（但顺序可能不对，或者重复出现同一些词），因此这样替换后的输入序列通常可以作为有代表性的负样本。对了，说明一下，50%和30%这两个比例纯粹是拍脑袋的，没仔细调参，因为生成模型调一次实在是太累了。</p>
<p>效果如何呢？笔者做了两个标题（摘要）生成的实验（就是<a href="https://github.com/CLUEbenchmark/CLGE">CLGE</a>的前两个），其中baseline是<a href="https://github.com/bojone/bert4keras/blob/master/examples/task_seq2seq_autotitle_csl.py">task_seq2seq_autotitle_csl.py</a>，代码开源于：</p>
<blockquote>
<p><strong>Github地址：</strong><a href="https://github.com/bojone/exposure_bias">https://github.com/bojone/exposure_bias</a></p>
</blockquote>
<p>结果如下表：<br />
\begin{array}{c}<br />
\text{CSL标题生成实验结果}\\\<br />
{\begin{array}{c|c|cccc}<br />
\hline<br />
&amp; \text{beam size} &amp; \text{Rouge-L} &amp; \text{Rouge-1} &amp; \text{Rouge-2} &amp; \text{BLEU} \\\<br />
\hline<br />
\text{baseline} &amp; 1 &amp; 63.81 &amp; 65.45 &amp; 54.91 &amp; 45.52 \\\<br />
\text{随机替换} &amp; 1 &amp; \textbf{64.44} &amp; \textbf{66.09} &amp; \textbf{55.56} &amp; \textbf{46.1} \\\<br />
\hline<br />
\text{baseline} &amp; 2 &amp; 64.44 &amp; 66.09 &amp; 55.75 &amp; 46.39 \\\<br />
\text{随机替换} &amp; 2 &amp; \textbf{65.04} &amp; \textbf{66.75} &amp; \textbf{56.51} &amp; \textbf{47.19} \\\<br />
\hline<br />
\text{baseline} &amp; 3 &amp; 64.75 &amp; 66.34 &amp; 56.06 &amp; 46.7 \\\<br />
\text{随机替换} &amp; 3 &amp; \textbf{65.15} &amp; \textbf{66.96} &amp; \textbf{56.74} &amp; \textbf{47.42} \\\<br />
\hline<br />
\end{array}}\\\<br />
\\\<br />
\text{LCSTS摘要生成实验结果}\\\<br />
{\begin{array}{c|c|cccc}<br />
\hline<br />
&amp; \text{beam size} &amp; \text{Rouge-L} &amp; \text{Rouge-1} &amp; \text{Rouge-2} &amp; \text{BLEU} \\\<br />
\hline<br />
\text{baseline} &amp; 1 &amp; 27.99 &amp; 29.57 &amp; \textbf{18.04} &amp; \textbf{11.72} \\\<br />
\text{随机替换} &amp; 1 &amp; \textbf{28.61} &amp; \textbf{29.92} &amp; 17.72 &amp; 11.23 \\\<br />
\hline<br />
\text{baseline} &amp; 2 &amp; \textbf{29.2} &amp; 30.7 &amp; \textbf{19.17} &amp; \textbf{12.64} \\\<br />
\text{随机替换} &amp; 2 &amp; 29.15 &amp; \textbf{30.79} &amp; 18.56 &amp; 11.75 \\\<br />
\hline<br />
\text{baseline} &amp; 3 &amp; \textbf{29.45} &amp; \textbf{30.95} &amp; \textbf{19.5} &amp; \textbf{12.93} \\\<br />
\text{随机替换} &amp; 3 &amp; 29.14 &amp; 30.88 &amp; 18.76 &amp; 11.91 \\\<br />
\hline<br />
\end{array}}<br />
\end{array}</p>
<p>可以发现，在CSL任务中，基于随机替换的策略稳定提升了文本生成的所有指标，而LCSTS任务的各个指标则各有优劣，考虑到LCSTS本身比较难，各项指标本来就低，所以应该说CSL的结果更有说服力一些。这表明，笔者提出的上述策略确实是一种值得尝试的方案。（注：所有实验都重复了两次然后取平均，所以实验结果应该是比较可靠的了。）</p>
<h2 id="_4">对抗训练</h2>
<p>思考到这里，我们不妨再“天马行空”一下：既然解决Exposure Bias的思路之一就是要构造有代表性的负样本输入，说白了就是让模型在扰动下依然能预测正确，而前些天我们不是才讨论了一种生成扰动样本的方法吗？不错，那就是<a href="/archives/7234">对抗训练</a>。如果直接往baseline模型里边加入对抗训练，能不能提升模型的性能呢？简单起见，笔者做了往baseline模型里边梯度惩罚（也算是对抗训练的一种）的实验，结果对比如下：<br />
\begin{array}{c}<br />
\text{CSL标题生成实验结果}\\\<br />
{\begin{array}{c|c|cccc}<br />
\hline<br />
&amp; \text{beam size} &amp; \text{Rouge-L} &amp; \text{Rouge-1} &amp; \text{Rouge-2} &amp; \text{BLEU} \\\<br />
\hline<br />
\text{baseline} &amp; 1 &amp; 63.81 &amp; 65.45 &amp; 54.91 &amp; 45.52 \\\<br />
\text{随机替换} &amp; 1 &amp; 64.44 &amp; 66.09 &amp; 55.56 &amp; 46.1 \\\<br />
\text{梯度惩罚} &amp; 1 &amp; \textbf{65.41} &amp; \textbf{67.29} &amp; \textbf{56.64} &amp; \textbf{47.37} \\\<br />
\hline<br />
\text{baseline} &amp; 2 &amp; 64.44 &amp; 66.09 &amp; 55.75 &amp; 46.39 \\\<br />
\text{随机替换} &amp; 2 &amp; 65.04 &amp; 66.75 &amp; 56.51 &amp; 47.19 \\\<br />
\text{梯度惩罚} &amp; 2 &amp; \textbf{65.94} &amp; \textbf{67.84} &amp; \textbf{57.38} &amp; \textbf{48.16} \\\<br />
\hline<br />
\text{baseline} &amp; 3 &amp; 64.75 &amp; 66.34 &amp; 56.06 &amp; 46.7 \\\<br />
\text{随机替换} &amp; 3 &amp; 65.15 &amp; 66.96 &amp; 56.74 &amp; 47.42 \\\<br />
\text{梯度惩罚} &amp; 3 &amp; \textbf{66.1} &amp; \textbf{68.08} &amp; \textbf{57.7} &amp; \textbf{48.56} \\\<br />
\hline<br />
\end{array}}\\\<br />
\\\<br />
\text{LCSTS摘要生成实验结果}\\\<br />
{\begin{array}{c|c|cccc}<br />
\hline<br />
&amp; \text{beam size} &amp; \text{Rouge-L} &amp; \text{Rouge-1} &amp; \text{Rouge-2} &amp; \text{BLEU} \\\<br />
\hline<br />
\text{baseline} &amp; 1 &amp; 27.99 &amp; 29.57 &amp; 18.04 &amp; 11.72 \\\<br />
\text{随机替换} &amp; 1 &amp; 28.61 &amp; 29.92 &amp; 17.72 &amp; 11.23 \\\<br />
\text{梯度惩罚} &amp; 1 &amp; \textbf{30.75} &amp; \textbf{31.83} &amp; \textbf{19.38} &amp; \textbf{11.78} \\\<br />
\hline<br />
\text{baseline} &amp; 2 &amp; 29.2 &amp; 30.7 &amp; 19.17 &amp; \textbf{12.64} \\\<br />
\text{随机替换} &amp; 2 &amp; 29.15 &amp; 30.79 &amp; 18.56 &amp; 11.75 \\\<br />
\text{梯度惩罚} &amp; 2 &amp; \textbf{30.88} &amp; \textbf{32.19} &amp; \textbf{19.96} &amp; 12.32 \\\<br />
\hline<br />
\text{baseline} &amp; 3 &amp; 29.45 &amp; 30.95 &amp; 19.5 &amp; \textbf{12.93} \\\<br />
\text{随机替换} &amp; 3 &amp; 29.14 &amp; 30.88 &amp; 18.76 &amp; 11.91 \\\<br />
\text{梯度惩罚} &amp; 3 &amp; \textbf{30.39} &amp; \textbf{31.76} &amp; \textbf{19.74} &amp; 12.14 \\\<br />
\hline<br />
\end{array}}<br />
\end{array}</p>
<p>可以看到，对抗训练（梯度惩罚）进一步提升了CSL生成的所有指标，而LCSTS上主要提升的是Roune指标，BLEU则有所下降。因此，对抗训练也可以列入“提升文本生成模型的潜力技巧”名单之中。</p>
<h2 id="_5">本文小结</h2>
<p>本文讨论了Seq2Seq中的Exposure Bias现象，尝试从直观上和理论上分析Exposure Bias的原因，并给出了简单可行的缓解Exposure Bias问题的对策，其中包括笔者构思的一种随机替换策略，以及基于对抗训练的策略，这两种策略的好处是它们几乎是即插即用的，并且实验表明它们能一定程度上提升文本生成的各个指标。</p>
<p><em><strong>转载到请包括本文地址：</strong><a href="https://spaces.ac.cn/archives/7259">https://spaces.ac.cn/archives/7259</a></em></p>
<p><em><strong>更详细的转载事宜请参考：</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="《科学空间FAQ》">《科学空间FAQ》</a></p>
<p><strong>如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。</strong></p>
<p><strong>如果您觉得本文还不错，欢迎分享/打赏本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！</strong></p>
<p>打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>微信打赏</p>
<p><img alt="科学空间" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>支付宝打赏</p>
<p>因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>点击这里</strong></a>或在下方评论区留言来告知你的建议或需求。</p>
<p><strong>如果您需要引用本文，请参考：</strong></p>
<p>苏剑林. (Mar. 09, 2020). 《Seq2Seq中Exposure Bias现象的浅析与对策 》[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/7259">https://spaces.ac.cn/archives/7259</a></p>
<p>@online{kexuefm-7259,<br />
title={Seq2Seq中Exposure Bias现象的浅析与对策},<br />
author={苏剑林},<br />
year={2020},<br />
month={Mar},<br />
url={\url{https://spaces.ac.cn/archives/7259}},<br />
} </p>
<hr />
<h2 id="_6">公式推导与注释</h2>
<p>TODO: 添加详细的数学公式推导和注释</p>
        </div>
    </div>
</body>
</html>