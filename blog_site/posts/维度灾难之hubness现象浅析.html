<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>â€œç»´åº¦ç¾éš¾â€ä¹‹Hubnessç°è±¡æµ…æ</title>
    <style>
* { margin: 0; padding: 0; box-sizing: border-box; }
body {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
    line-height: 1.6; color: #333; max-width: 900px; margin: 0 auto; padding: 20px; background: #f5f5f5;
}
.container { background: white; padding: 40px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
header { border-bottom: 2px solid #e0e0e0; padding-bottom: 20px; margin-bottom: 30px; }
h1 { color: #2c3e50; margin-bottom: 10px; font-size: 2em; }
.meta { color: #666; font-size: 0.9em; margin-bottom: 20px; }
.content { margin-top: 30px; overflow-wrap: break-word; }
.content h2 { color: #34495e; margin-top: 30px; margin-bottom: 15px; border-bottom: 1px solid #eee; padding-bottom: 5px; }
.content p { margin-bottom: 15px; }
.content pre { background: #f8f8f8; padding: 15px; border-radius: 5px; overflow-x: auto; border-left: 3px solid #3498db; margin: 15px 0; }
.content code { background: #f8f8f8; padding: 2px 5px; border-radius: 3px; font-family: monospace; font-size: 0.9em; }
.content blockquote { border-left: 4px solid #3498db; padding-left: 20px; margin: 20px 0; color: #555; font-style: italic; }
.content table { border-collapse: collapse; width: 100%; margin: 20px 0; }
.content th, .content td { border: 1px solid #ddd; padding: 10px; text-align: left; }
.back-link { display: inline-block; margin-bottom: 20px; color: #3498db; text-decoration: none; font-weight: 500; }
</style>
    
<script>
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\(', '\)']],
            displayMath: [['$$', '$$'], ['\[', '\]']],
            processEscapes: true
        }
    };
</script>
<script id="MathJax-script" async src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>
    <div class="container">
        <a href="../index.html" class="back-link">â† è¿”å›é¦–é¡µ</a>
        <header>
            <h1>â€œç»´åº¦ç¾éš¾â€ä¹‹Hubnessç°è±¡æµ…æ</h1>
            <div class="meta">ğŸ“… æœ€åæ›´æ–°: 2025-11-26 | ğŸ“„ å¤§å°: 29.7 KB</div>
        </header>
        <div class="content">
            <p><strong>åŸæ–‡é“¾æ¥</strong>: <a href="https://spaces.ac.cn/archives/9147">https://spaces.ac.cn/archives/9147</a></p>
<p><strong>å‘å¸ƒæ—¥æœŸ</strong>: </p>
<hr />
<p>è¿™å‡ å¤©è¯»åˆ°è®ºæ–‡<a href="https://papers.cool/arxiv/2206.06014">ã€ŠExploring and Exploiting Hubness Priors for High-Quality GAN Latent Samplingã€‹</a>ï¼Œäº†è§£åˆ°äº†ä¸€ä¸ªæ–°çš„åè¯â€œHubnessç°è±¡â€ï¼Œè¯´çš„æ˜¯é«˜ç»´ç©ºé—´ä¸­çš„ä¸€ç§èšé›†æ•ˆåº”ï¼Œæœ¬è´¨ä¸Šæ˜¯â€œç»´åº¦ç¾éš¾â€çš„ä½“ç°ä¹‹ä¸€ã€‚è®ºæ–‡å€ŸåŠ©Hubnessçš„æ¦‚å¿µå¾—åˆ°äº†ä¸€ä¸ªæå‡GANæ¨¡å‹ç”Ÿæˆè´¨é‡çš„æ–¹æ¡ˆï¼Œçœ‹èµ·æ¥è¿˜è›®æœ‰æ„æ€ã€‚æ‰€ä»¥ç¬”è€…å°±é¡ºä¾¿å»å­¦ä¹ äº†ä¸€ä¸‹Hubnessç°è±¡çš„ç›¸å…³å†…å®¹ï¼Œè®°å½•åœ¨æ­¤ï¼Œä¾›å¤§å®¶å‚è€ƒã€‚</p>
<h2 id="_1">åç¼©çš„çƒ</h2>
<p>â€œç»´åº¦ç¾éš¾â€æ˜¯ä¸€ä¸ªå¾ˆå®½æ³›çš„æ¦‚å¿µï¼Œæ‰€æœ‰åœ¨é«˜ç»´ç©ºé—´ä¸­ä¸ç›¸åº”çš„äºŒç»´ã€ä¸‰ç»´ç©ºé—´ç‰ˆæœ¬å‡ºå…¥å¾ˆå¤§çš„ç»“è®ºï¼Œéƒ½å¯ä»¥ç§°ä¹‹ä¸ºâ€œç»´åº¦ç¾éš¾â€ï¼Œæ¯”å¦‚<a href="/archives/7076">ã€Šnç»´ç©ºé—´ä¸‹ä¸¤ä¸ªéšæœºå‘é‡çš„å¤¹è§’åˆ†å¸ƒã€‹</a>ä¸­ä»‹ç»çš„â€œé«˜ç»´ç©ºé—´ä¸­ä»»ä½•ä¸¤ä¸ªå‘é‡å‡ ä¹éƒ½æ˜¯å‚ç›´çš„â€ã€‚å…¶ä¸­ï¼Œæœ‰ä¸å°‘ç»´åº¦ç¾éš¾ç°è±¡æœ‰ç€åŒä¸€ä¸ªæºå¤´â€”â€”â€œé«˜ç»´ç©ºé—´å•ä½çƒä¸å…¶å¤–åˆ‡æ­£æ–¹ä½“çš„ä½“ç§¯ä¹‹æ¯”é€æ¸åç¼©è‡³0â€ï¼ŒåŒ…æ‹¬æœ¬æ–‡çš„ä¸»é¢˜â€œHubnessç°è±¡â€äº¦æ˜¯å¦‚æ­¤ã€‚</p>
<p>åœ¨<a href="/archives/3154">ã€Šé¬¼æ–§ç¥å·¥ï¼šæ±‚nç»´çƒçš„ä½“ç§¯ã€‹</a>ä¸­ï¼Œæˆ‘ä»¬æ¨å¯¼è¿‡$n$ç»´çƒçš„ä½“ç§¯å…¬å¼ï¼Œä»ä¸­å¯çŸ¥$n$ç»´å•ä½çƒçš„ä½“ç§¯ä¸º<br />
\begin{equation}V_n = \frac{\pi^{n/2}}{\Gamma\left(\frac{n}{2}+1\right)}\end{equation}<br />
å¯¹åº”çš„å¤–åˆ‡æ­£æ–¹ä½“è¾¹é•¿ä¸º$2$ï¼Œä½“ç§¯è‡ªç„¶ä¸º$2^n$ï¼Œæ‰€ä»¥å¯¹åº”çš„ä½“ç§¯æ¯”ä¸º$V_n / 2^n$ï¼Œå…¶å›¾åƒå¦‚ä¸‹å›¾ï¼š  </p>
<p><a href="/usr/uploads/2022/06/1517429447.png" title="ç‚¹å‡»æŸ¥çœ‹åŸå›¾"><img alt="n ç»´çƒä¸å¤–åˆ‡æ­£æ–¹ä½“çš„ä½“ç§¯ä¹‹æ¯”" src="/usr/uploads/2022/06/1517429447.png" /></a></p>
<p>n ç»´çƒä¸å¤–åˆ‡æ­£æ–¹ä½“çš„ä½“ç§¯ä¹‹æ¯”</p>
<p>å¯ä»¥çœ‹åˆ°ï¼Œéšç€ç»´åº¦çš„å¢å¤§ï¼Œè¿™ä¸ªæ¯”ä¾‹å¾ˆå¿«å°±è¶‹äº0äº†ã€‚è¿™ä¸ªç»“è®ºçš„ä¸€ä¸ªå½¢è±¡è¯´æ³•æ˜¯â€œéšç€ç»´åº¦å¢åŠ ï¼Œçƒå˜å¾—è¶Šæ¥è¶Šå¾®ä¸è¶³é“â€ï¼Œå®ƒå‘Šè¯‰æˆ‘ä»¬ï¼Œå¦‚æœé€šè¿‡â€œå‡åŒ€åˆ†å¸ƒ + æ‹’ç»é‡‡æ ·â€çš„æ–¹å¼å»å®ç°çƒå†…çš„å‡åŒ€é‡‡æ ·ï¼Œé‚£ä¹ˆåœ¨é«˜ç»´ç©ºé—´ä¸­æ•ˆç‡å°†ä¼šéå¸¸ä½ï¼ˆæ‹’ç»ç‡æ¥è¿‘100%ï¼‰ã€‚è¿˜æœ‰ä¸€ç§ç†è§£æ–¹å¼æ˜¯â€œé«˜ç»´çƒå†…çš„ç‚¹å¤§éƒ¨åˆ†éƒ½é›†ä¸­åœ¨çƒè¡¨é¢é™„è¿‘â€ï¼Œçƒä¸­å¿ƒåˆ°çƒè¡¨é¢é™„è¿‘çš„åŒºåŸŸå æ¯”è¶Šæ¥è¶Šå°ã€‚</p>
<h2 id="hubness">Hubnessç°è±¡</h2>
<p>ç°åœ¨æˆ‘ä»¬è½¬åˆ°Hubnessç°è±¡ï¼Œå®ƒè¯´çš„æ˜¯åœ¨é«˜ç»´ç©ºé—´ä¸­éšæœºé€‰ä¸€æ‰¹ç‚¹ï¼Œé‚£ä¹ˆâ€œæ€»æœ‰ä¸€äº›ç‚¹ç»å¸¸å‡ºç°åœ¨å…¶ä»–ç‚¹çš„$k$é‚»è¿‘ä¸­â€ã€‚</p>
<p>å…·ä½“æ€ä¹ˆç†è§£è¿™å¥è¯å‘¢ï¼Ÿå‡è®¾æˆ‘ä»¬æœ‰$N$ä¸ªç‚¹$x_1,x_2,\cdots,x_N$ï¼Œå¯¹äºæ¯ä¸ª$x_i$ï¼Œæˆ‘ä»¬éƒ½å¯ä»¥æ‰¾å‡ºä¸ä¹‹æœ€ç›¸è¿‘çš„$k$ä¸ªç‚¹ï¼Œè¿™$k$ä¸ªç‚¹éƒ½ç§°ä¸ºâ€œ$x_i$çš„$k$é‚»è¿‘â€ã€‚æœ‰äº†$k$é‚»è¿‘çš„æ¦‚å¿µåï¼Œæˆ‘ä»¬å¯ä»¥ç»Ÿè®¡æ¯ä¸ªç‚¹å‡ºç°åœ¨å…¶ä»–ç‚¹çš„$k$é‚»è¿‘çš„æ¬¡æ•°ï¼Œè¿™ä¸ªæ¬¡æ•°ç§°ä¸ºâ€œHubå€¼â€ï¼Œä¹Ÿå°±æ˜¯è¯´Hubå€¼è¶Šå¤§ï¼Œå®ƒå°±è¶Šå®¹æ˜“å‡ºç°åœ¨å…¶ä»–ç‚¹çš„$k$é‚»è¿‘ä¸­ã€‚</p>
<p>æ‰€ä»¥ï¼ŒHubnessç°è±¡è¯´çš„æ˜¯ï¼šæ€»æœ‰é‚£ä¹ˆå‡ ä¸ªç‚¹ï¼Œå®ƒçš„Hubå€¼æ˜¾ç„¶ç‰¹åˆ«å¤§ã€‚å¦‚æœHubå€¼ä»£è¡¨ç€â€œè´¢å¯Œâ€ï¼Œé‚£ä¹ˆä¸€ä¸ªå½¢è±¡çš„æ¯”å–»å°±æ˜¯â€œ80%çš„è´¢å¯Œé›†ä¸­åœ¨20%çš„äººæ‰‹ä¸­â€ï¼Œå¹¶ä¸”éšç€ç»´åº¦å¢å¤§ï¼Œè¿™ä¸ªâ€œè´«å¯Œå·®è·â€å°±è¶Šæ¥è¶Šå¤§ï¼›å¦‚æœHubå€¼ä»£è¡¨ç€â€œäººè„‰â€ï¼Œé‚£ä¹ˆä¹Ÿå¯ä»¥å½¢è±¡åœ°æ¯”å–»ä¸ºâ€œç¤¾ç¾¤ä¸­æ€»æœ‰é‚£ä¹ˆå‡ ä¸ªäººæ‹¥æœ‰éå¸¸å¹¿æ³›çš„äººè„‰èµ„æºâ€ã€‚</p>
<p>Hubnessç°è±¡æ˜¯æ€ä¹ˆå‡ºç°çš„å‘¢ï¼Ÿå…¶å®ä¹Ÿè·Ÿå‰ä¸€èŠ‚è¯´çš„$n$ç»´çƒçš„åç¼©æœ‰å…³ã€‚æˆ‘ä»¬çŸ¥é“ï¼Œä¸æ‰€æœ‰ç‚¹è·ç¦»å¹³æ–¹å’Œæœ€å°çš„ç‚¹ï¼Œæ­£å¥½æ˜¯å‡å€¼ç‚¹ï¼š<br />
\begin{equation}\frac{1}{N} \sum_{i=1}^N x_i = c^* = \mathop{\text{argmin}}<em i="1">c \sum</em>}^N \Vert x_i - c\Vert^2\end{equation<br />
è¿™ä¹Ÿå°±æ„å‘³ç€ï¼Œåœ¨å‡å€¼å‘é‡é™„è¿‘çš„ç‚¹ï¼Œä¸æ‰€æœ‰ç‚¹çš„å¹³å‡è·ç¦»è¾ƒå°ï¼Œæœ‰æ›´å¤§çš„æœºä¼šæˆä¸ºæ›´å¤šç‚¹çš„$k$é‚»è¿‘ã€‚è€Œ$n$ç»´çƒçš„åç¼©ç°è±¡åˆ™å‘Šè¯‰æˆ‘ä»¬ï¼Œâ€œå‡å€¼å‘é‡é™„è¿‘çš„ç‚¹â€ï¼Œå³ä»¥å‡å€¼å‘é‡ä¸ºçƒå¿ƒçš„ä¸€ä¸ªçƒé‚»åŸŸï¼Œå…¶å æ¯”æ˜¯éå¸¸å°çš„ã€‚äºæ˜¯å°±å‡ºç°äº†â€œéå¸¸å°‘çš„ç‚¹å‡ºç°åœ¨å¾ˆå¤šç‚¹çš„$k$é‚»è¿‘ä¸­â€è¿™ä¸€ç°è±¡äº†ã€‚å½“ç„¶ï¼Œè¿™é‡Œçš„å‡å€¼å‘é‡æ˜¯æ¯”è¾ƒç›´è§‚çš„ç†è§£ï¼Œåœ¨ä¸€èˆ¬çš„æ•°æ®ç‚¹ä¸­ï¼Œåº”è¯¥æ˜¯è¶Šé è¿‘å¯†åº¦ä¸­å¿ƒçš„ç‚¹ï¼Œå…¶Hubå€¼ä¼šå˜å¾—è¶Šå¤§ã€‚</p>
<h2 id="_2">æå‡é‡‡æ ·</h2>
<p>é‚£ä¹ˆæœ¬æ–‡å¼€å¤´è¯´çš„æå‡GANæ¨¡å‹ç”Ÿæˆè´¨é‡çš„æ–¹æ¡ˆï¼Œè·ŸHubnessç°è±¡åˆæœ‰ä»€ä¹ˆå…³ç³»å‘¢ï¼Ÿè®ºæ–‡<a href="https://papers.cool/arxiv/2206.06014">ã€ŠExploring and Exploiting Hubness Priors for High-Quality GAN Latent Samplingã€‹</a>æå‡ºäº†ä¸€ä¸ªå…ˆéªŒå‡è®¾ï¼šHubå€¼è¶Šå¤§ï¼Œå¯¹åº”ç‚¹çš„ç”Ÿæˆè´¨é‡å°±è¶Šå¥½ã€‚</p>
<p>å…·ä½“æ¥è¯´ï¼Œä¸€èˆ¬GANçš„é‡‡æ ·ç”Ÿæˆæµç¨‹æ˜¯$z\sim \mathcal{N}(0,1), x=G(z)$ï¼Œæˆ‘ä»¬å¯ä»¥ä»$\mathcal{N}(0,1)$ä¸­å…ˆé‡‡æ ·$N$ä¸ªæ ·æœ¬ç‚¹$z_1,z_2,\cdots,z_N$ï¼Œç„¶åå°±å¯ä»¥ç®—å‡ºæ¯ä¸ªæ ·æœ¬ç‚¹çš„Hubå€¼ï¼ŒåŸè®ºæ–‡å‘ç°Hubå€¼è·Ÿç”Ÿæˆè´¨é‡æ˜¯æ­£ç›¸å…³çš„ï¼Œæ‰€ä»¥åªä¿ç•™Hubå€¼å¤§äºç­‰äºé˜ˆå€¼$t$çš„æ ·æœ¬ç‚¹ç”¨æ¥åšç”Ÿæˆã€‚è¿™æ˜¯ä¸€ç§â€œäº‹å‰â€çš„ç­›é€‰æ€è·¯ï¼Œå‚è€ƒä»£ç å¦‚ä¸‹ï¼š</p>
<div class="codehilite"><pre><span></span><code><span class="n">def</span><span class="w"> </span><span class="n">get_z_samples</span><span class="p">(</span><span class="k">size</span><span class="p">,</span><span class="w"> </span><span class="n">t</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="ss">&quot;&quot;&quot;é€šè¿‡Hubå€¼å¯¹é‡‡æ ·ç»“æœè¿›è¡Œç­›é€‰</span>
<span class="ss">    &quot;&quot;&quot;</span>
<span class="w">    </span><span class="n">Z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">np</span><span class="p">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">z_dim</span><span class="p">))</span>
<span class="w">    </span><span class="k">while</span><span class="w"> </span><span class="nf">len</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="k">size</span><span class="err">:</span>
<span class="w">        </span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span><span class="w"> </span><span class="n">z_dim</span><span class="p">)</span>
<span class="w">        </span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="err">:</span>
<span class="w">            </span><span class="n">zi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">z</span><span class="o">[</span><span class="n">i * 1000:(i + 1) * 1000</span><span class="o">]</span>
<span class="w">            </span><span class="n">d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">z</span><span class="o">**</span><span class="mi">2</span><span class="p">).</span><span class="nf">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">[</span><span class="n">:, None</span><span class="o">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">zi</span><span class="o">**</span><span class="mi">2</span><span class="p">).</span><span class="nf">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">[</span><span class="n">None</span><span class="o">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">z</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">zi</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">d</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">[</span><span class="n">1:1 + 5</span><span class="o">]</span><span class="p">.</span><span class="nl">T</span><span class="p">:</span>
<span class="w">                </span><span class="n">s</span><span class="o">[</span><span class="n">j</span><span class="o">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">1</span>
<span class="w">        </span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">z</span><span class="o">[</span><span class="n">s &gt; t</span><span class="o">]</span>
<span class="w">        </span><span class="n">Z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="o">[</span><span class="n">Z, z</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="o">[</span><span class="n">:size</span><span class="o">]</span>
<span class="w">        </span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;%s / %s&#39;</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">Z</span><span class="p">),</span><span class="w"> </span><span class="k">size</span><span class="p">))</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">Z</span>
</code></pre></div>

<p>ä¸ºä»€ä¹ˆé€šè¿‡Hubå€¼æ¥ç­›é€‰å‘¢ï¼Ÿç”±å‰é¢çš„è®¨è®ºå¯ä»¥çŸ¥é“ï¼ŒHubå€¼è¶Šå¤§ï¼Œé‚£ä¹ˆå°±è¶Šæ¥è¿‘æ ·æœ¬ä¸­å¿ƒï¼Œå…¶å®æ›´å‡†ç¡®ç‡æ¥è¯´æ˜¯æ¥è¿‘å¯†åº¦ä¸­å¿ƒï¼Œæ„å‘³ç€å‘¨å›´æœ‰å¾ˆå¤šä¸´è¿‘ç‚¹ï¼Œé‚£ä¹ˆå®ƒå°±ä¸å¤§å¯èƒ½æ˜¯æ²¡æœ‰è¢«å……åˆ†è®­ç»ƒçš„ç¦»ç¾¤ç‚¹ï¼Œå› æ­¤é‡‡æ ·è´¨é‡ç›¸å¯¹é«˜ä¸€äº›ã€‚è®ºæ–‡çš„å¤šä¸ªå®éªŒç»“æœè‚¯å®šäº†è¿™ä¸€ç»“è®ºã€‚</p>
<p><a href="/usr/uploads/2022/06/430095810.jpg" title="ç‚¹å‡»æŸ¥çœ‹åŸå›¾"><img alt="åŸºäºHubå€¼è¿›è¡Œç­›é€‰çš„ç”Ÿæˆè´¨é‡å¯¹æ¯”" src="/usr/uploads/2022/06/430095810.jpg" /></a></p>
<p>åŸºäºHubå€¼è¿›è¡Œç­›é€‰çš„ç”Ÿæˆè´¨é‡å¯¹æ¯”</p>
<h2 id="_3">æ–‡ç« å°ç»“</h2>
<p>æœ¬æ–‡ä¸»è¦ç®€ä»‹äº†â€œç»´åº¦ç¾éš¾â€ä¸­çš„Hubnessç°è±¡ï¼Œå¹¶ä»‹ç»äº†å®ƒåœ¨æå‡GANç”Ÿæˆè´¨é‡æ–¹é¢çš„åº”ç”¨ã€‚</p>
<p><em><strong>è½¬è½½åˆ°è¯·åŒ…æ‹¬æœ¬æ–‡åœ°å€ï¼š</strong><a href="https://spaces.ac.cn/archives/9147">https://spaces.ac.cn/archives/9147</a></em></p>
<p><em><strong>æ›´è¯¦ç»†çš„è½¬è½½äº‹å®œè¯·å‚è€ƒï¼š</strong></em><a href="https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8" title="ã€Šç§‘å­¦ç©ºé—´FAQã€‹">ã€Šç§‘å­¦ç©ºé—´FAQã€‹</a></p>
<p><strong>å¦‚æœæ‚¨è¿˜æœ‰ä»€ä¹ˆç–‘æƒ‘æˆ–å»ºè®®ï¼Œæ¬¢è¿åœ¨ä¸‹æ–¹è¯„è®ºåŒºç»§ç»­è®¨è®ºã€‚</strong></p>
<p><strong>å¦‚æœæ‚¨è§‰å¾—æœ¬æ–‡è¿˜ä¸é”™ï¼Œæ¬¢è¿åˆ†äº«/æ‰“èµæœ¬æ–‡ã€‚æ‰“èµå¹¶éè¦ä»ä¸­è·å¾—æ”¶ç›Šï¼Œè€Œæ˜¯å¸Œæœ›çŸ¥é“ç§‘å­¦ç©ºé—´è·å¾—äº†å¤šå°‘è¯»è€…çš„çœŸå¿ƒå…³æ³¨ã€‚å½“ç„¶ï¼Œå¦‚æœä½ æ— è§†å®ƒï¼Œä¹Ÿä¸ä¼šå½±å“ä½ çš„é˜…è¯»ã€‚å†æ¬¡è¡¨ç¤ºæ¬¢è¿å’Œæ„Ÿè°¢ï¼</strong></p>
<p>æ‰“èµ</p>
<p><img alt="ç§‘å­¦ç©ºé—´" src="https://spaces.ac.cn/usr/themes/geekg/payment/wx.png" /></p>
<p>å¾®ä¿¡æ‰“èµ</p>
<p><img alt="ç§‘å­¦ç©ºé—´" src="https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png" /></p>
<p>æ”¯ä»˜å®æ‰“èµ</p>
<p>å› ä¸ºç½‘ç«™åå°å¯¹æ‰“èµå¹¶æ— è®°å½•ï¼Œå› æ­¤æ¬¢è¿åœ¨æ‰“èµæ—¶å€™å¤‡æ³¨ç•™è¨€ã€‚ä½ è¿˜å¯ä»¥<a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=tN7d1drY3drrx8H0xcWa19vZ"><strong>ç‚¹å‡»è¿™é‡Œ</strong></a>æˆ–åœ¨ä¸‹æ–¹è¯„è®ºåŒºç•™è¨€æ¥å‘ŠçŸ¥ä½ çš„å»ºè®®æˆ–éœ€æ±‚ã€‚</p>
<p><strong>å¦‚æœæ‚¨éœ€è¦å¼•ç”¨æœ¬æ–‡ï¼Œè¯·å‚è€ƒï¼š</strong></p>
<p>è‹å‰‘æ—. (Jun. 28, 2022). ã€Šâ€œç»´åº¦ç¾éš¾â€ä¹‹Hubnessç°è±¡æµ…æ ã€‹[Blog post]. Retrieved from <a href="https://spaces.ac.cn/archives/9147">https://spaces.ac.cn/archives/9147</a></p>
<p>@online{kexuefm-9147,<br />
title={â€œç»´åº¦ç¾éš¾â€ä¹‹Hubnessç°è±¡æµ…æ},<br />
author={è‹å‰‘æ—},<br />
year={2022},<br />
month={Jun},<br />
url={\url{https://spaces.ac.cn/archives/9147}},<br />
} </p>
<hr />
<h2 id="high-dimensional-geometry">é«˜ç»´ç©ºé—´çš„å‡ ä½•ç‰¹æ€§</h2>
<h3 id="_4">å•ä½çƒä½“ç§¯çš„æ¸è¿‘è¡Œä¸º</h3>
<div class="theorem-box">

**å®šç†1ï¼šé«˜ç»´å•ä½çƒä½“ç§¯çš„è¡°å‡**

$n$ç»´å•ä½çƒçš„ä½“ç§¯ä¸ºï¼š
$$V_n = \frac{\pi^{n/2}}{\Gamma\left(\frac{n}{2}+1\right)}$$

å½“$n \to \infty$æ—¶ï¼Œæœ‰æ¸è¿‘ä¼°è®¡ï¼š
$$V_n \sim \left(\frac{2\pi e}{n}\right)^{n/2}$$

å› æ­¤ï¼Œå•ä½çƒä¸å¤–åˆ‡æ­£æ–¹ä½“ï¼ˆä½“ç§¯$2^n$ï¼‰çš„ä½“ç§¯æ¯”ä¸ºï¼š
$$\frac{V_n}{2^n} \sim \left(\frac{\pi e}{2n}\right)^{n/2} \to 0 \quad \text{(æŒ‡æ•°é€Ÿåº¦)}$$

</div>

<p><strong>è¯¦ç»†æ¨å¯¼</strong>ï¼š</p>
<p>ä½¿ç”¨Stirlingå…¬å¼ï¼š$\Gamma(z) \approx \sqrt{2\pi/z} (z/e)^z$ å½“$z \to \infty$ï¼Œæˆ‘ä»¬æœ‰ï¼š</p>
<p>\begin{equation}\begin{aligned}
\Gamma\left(\frac{n}{2}+1\right) &amp;\approx \sqrt{\frac{2\pi}{n/2}} \left(\frac{n/2}{e}\right)^{n/2} \
&amp;= \sqrt{\frac{4\pi}{n}} \left(\frac{n}{2e}\right)^{n/2}
\end{aligned}\end{equation}</p>
<p>ä»£å…¥$V_n$ï¼š
\begin{equation}\begin{aligned}
V_n &amp;= \frac{\pi^{n/2}}{\Gamma(n/2+1)} \
&amp;\approx \frac{\pi^{n/2}}{\sqrt{4\pi/n} (n/2e)^{n/2}} \
&amp;= \sqrt{\frac{n}{4\pi}} \cdot \frac{\pi^{n/2}}{(n/2e)^{n/2}} \
&amp;= \sqrt{\frac{n}{4\pi}} \cdot \left(\frac{2\pi e}{n}\right)^{n/2}
\end{aligned}\end{equation}</p>
<p><strong>ä½“ç§¯æ¯”çš„è¡°å‡é€Ÿç‡</strong>ï¼š</p>
<p>$$\frac{V_n}{2^n} = \sqrt{\frac{n}{4\pi}} \cdot \left(\frac{\pi e}{2n}\right)^{n/2}$$</p>
<p>å½“$n=10$æ—¶ï¼Œ$\frac{V_{10}}{2^{10}} \approx 0.0025$ï¼ˆä»…0.25%ï¼‰</p>
<p>å½“$n=100$æ—¶ï¼Œ$\frac{V_{100}}{2^{100}} \approx 10^{-70}$ï¼ˆå‡ ä¹ä¸º0ï¼‰</p>
<hr />
<h3 id="_5">çƒå£³çš„è´¨é‡é›†ä¸­ç°è±¡</h3>
<div class="derivation-box">

**å‘½é¢˜1ï¼šé«˜ç»´çƒçš„è´¨é‡é›†ä¸­åœ¨çƒå£³**

è€ƒè™‘åŠå¾„ä¸º1çš„$n$ç»´çƒï¼Œå…¶å†…åŠå¾„$r \in (0, 1)$çš„çƒæ‰€å ä½“ç§¯æ¯”ä¾‹ä¸ºï¼š
$$\frac{V_n(r)}{V_n(1)} = r^n$$

**æ¨è®º**ï¼šåŠå¾„åœ¨$[1-\epsilon, 1]$ä¹‹é—´çš„çƒå£³æ‰€å ä½“ç§¯æ¯”ä¾‹ä¸ºï¼š
$$\frac{V_n(1) - V_n(1-\epsilon)}{V_n(1)} = 1 - (1-\epsilon)^n$$

å½“$n$å¾ˆå¤§ä¸”$\epsilon$å¾ˆå°æ—¶ï¼š
$$(1-\epsilon)^n \approx e^{-n\epsilon}$$

**ä¾‹å­**ï¼šå¯¹äº$\epsilon = 0.1$ï¼ˆ10%çš„åšåº¦çƒå£³ï¼‰ï¼š
- $n=10$: $1 - 0.9^{10} \approx 0.65$ï¼ˆ65%çš„ä½“ç§¯ï¼‰
- $n=100$: $1 - 0.9^{100} \approx 0.9999$ï¼ˆå‡ ä¹å…¨éƒ¨ï¼‰

</div>

<p><strong>ç›´è§‚ç†è§£</strong>ï¼šåœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œå•ä½çƒå†…çš„å‡ ä¹æ‰€æœ‰ç‚¹éƒ½é›†ä¸­åœ¨é è¿‘çƒé¢çš„è–„å£³å†…ï¼Œçƒçš„"å†…éƒ¨"ï¼ˆæ¥è¿‘ä¸­å¿ƒï¼‰å‡ ä¹æ˜¯ç©ºçš„ï¼</p>
<hr />
<h3 id="concentration-of-distances">è·ç¦»é›†ä¸­ç°è±¡ï¼ˆConcentration of Distancesï¼‰</h3>
<div class="theorem-box">

**å®šç†2ï¼šé«˜ç»´ç©ºé—´çš„è·ç¦»é›†ä¸­**

è®¾$\boldsymbol{x}, \boldsymbol{y}$æ˜¯$n$ç»´å•ä½çƒå†…å‡åŒ€åˆ†å¸ƒçš„ç‹¬ç«‹éšæœºç‚¹ã€‚å½“$n \to \infty$æ—¶ï¼Œå®ƒä»¬ä¹‹é—´çš„æ¬§æ°è·ç¦»$\|\boldsymbol{x} - \boldsymbol{y}\|$é«˜åº¦é›†ä¸­åœ¨$\sqrt{2}$é™„è¿‘ï¼š

$$\mathbb{P}\left( \left| \|\boldsymbol{x} - \boldsymbol{y}\| - \sqrt{2} \right| > \epsilon \right) \to 0$$

æ›´ç²¾ç¡®åœ°ï¼Œ$\|\boldsymbol{x} - \boldsymbol{y}\|^2$çš„æœŸæœ›å’Œæ–¹å·®ä¸ºï¼š
$$\mathbb{E}[\|\boldsymbol{x} - \boldsymbol{y}\|^2] \to 2, \quad \text{Var}[\|\boldsymbol{x} - \boldsymbol{y}\|^2] = O(1/n)$$

</div>

<p><strong>è¯æ˜</strong>ï¼š</p>
<p>ç”±äº$\boldsymbol{x}, \boldsymbol{y}$ç‹¬ç«‹ä¸”å‡åŒ€åˆ†å¸ƒåœ¨å•ä½çƒå†…ï¼Œæˆ‘ä»¬æœ‰ï¼š
$$\|\boldsymbol{x} - \boldsymbol{y}\|^2 = \|\boldsymbol{x}\|^2 + \|\boldsymbol{y}\|^2 - 2\langle \boldsymbol{x}, \boldsymbol{y} \rangle$$</p>
<p><strong>æ­¥éª¤1</strong>ï¼šè®¡ç®—$\mathbb{E}[|\boldsymbol{x}|^2]$</p>
<p>å¯¹äºå•ä½çƒå†…çš„å‡åŒ€åˆ†å¸ƒï¼Œç”±äºä½“ç§¯é›†ä¸­åœ¨çƒå£³ï¼Œ$|\boldsymbol{x}|$çš„åˆ†å¸ƒå¯†åº¦ä¸ºï¼š
$$f_r(r) = n r^{n-1}, \quad r \in [0, 1]$$</p>
<p>å› æ­¤ï¼š
$$\mathbb{E}[\|\boldsymbol{x}\|^2] = \int_0^1 r^2 \cdot n r^{n-1} dr = \frac{n}{n+2} \to 1 \quad (n \to \infty)$$</p>
<p><strong>æ­¥éª¤2</strong>ï¼šè®¡ç®—$\mathbb{E}[\langle \boldsymbol{x}, \boldsymbol{y} \rangle]$</p>
<p>ç”±å¯¹ç§°æ€§å’Œç‹¬ç«‹æ€§ï¼š
$$\mathbb{E}[\langle \boldsymbol{x}, \boldsymbol{y} \rangle] = \mathbb{E}[\boldsymbol{x}] \cdot \mathbb{E}[\boldsymbol{y}] = 0$$</p>
<p>ï¼ˆå› ä¸ºçƒå†…å‡åŒ€åˆ†å¸ƒå…³äºåŸç‚¹å¯¹ç§°ï¼‰</p>
<p><strong>æ­¥éª¤3</strong>ï¼šåˆå¹¶</p>
<p>$$\mathbb{E}[\|\boldsymbol{x} - \boldsymbol{y}\|^2] = \mathbb{E}[\|\boldsymbol{x}\|^2] + \mathbb{E}[\|\boldsymbol{y}\|^2] - 2\mathbb{E}[\langle \boldsymbol{x}, \boldsymbol{y} \rangle] \approx 1 + 1 - 0 = 2$$</p>
<p><strong>æ–¹å·®åˆ†æ</strong>ï¼ˆç®€è¦ï¼‰ï¼š</p>
<p>ä½¿ç”¨ä¸­å¿ƒæé™å®šç†ï¼Œ$|\boldsymbol{x} - \boldsymbol{y}|^2$å¯ä»¥çœ‹ä½œ$n$ä¸ªï¼ˆè¿‘ä¼¼ï¼‰ç‹¬ç«‹åŒåˆ†å¸ƒéšæœºå˜é‡çš„å’Œï¼Œå…¶æ–¹å·®ä¸º$O(1/n)$ã€‚</p>
<hr />
<h2 id="hubness-definition">Hubnessç°è±¡çš„ä¸¥æ ¼å®šä¹‰</h2>
<h3 id="hub">Hubå€¼çš„æ•°å­¦å®šä¹‰</h3>
<div class="theorem-box">

**å®šä¹‰1ï¼šk-å‡ºç°æ¬¡æ•°ï¼ˆk-occurrenceï¼‰**

ç»™å®šæ•°æ®é›†$\mathcal{X} = \{x_1, \ldots, x_N\} \subset \mathbb{R}^d$å’Œå‚æ•°$k \in \mathbb{N}$ï¼Œç‚¹$x_i$çš„**$k$-å‡ºç°æ¬¡æ•°**ï¼ˆ$k$-occurrenceï¼‰$N_k(x_i)$å®šä¹‰ä¸ºï¼š

$$N_k(x_i) = \left| \{ j : x_i \in \text{kNN}_k(x_j), \, j \neq i \} \right|$$

å…¶ä¸­$\text{kNN}_k(x_j)$è¡¨ç¤º$x_j$çš„$k$ä¸ªæœ€è¿‘é‚»é›†åˆï¼ˆä¸åŒ…æ‹¬$x_j$æœ¬èº«ï¼‰ã€‚

**ç›´è§‚è§£é‡Š**ï¼š$N_k(x_i)$ç»Ÿè®¡"æœ‰å¤šå°‘ä¸ªå…¶ä»–ç‚¹çš„$k$è¿‘é‚»åˆ—è¡¨ä¸­åŒ…å«$x_i$"ã€‚

</div>

<p><strong>Hubå€¼çš„æ ‡å‡†åŒ–</strong>ï¼š</p>
<p>ä¸ºäº†è·¨æ•°æ®é›†æ¯”è¾ƒï¼Œé€šå¸¸ä½¿ç”¨æ ‡å‡†åŒ–çš„Hubå€¼ï¼ˆSkewnessï¼‰ï¼š
$$S_k = \frac{\mathbb{E}[(N_k - \mu_k)^3]}{\sigma_k^3}$$</p>
<p>å…¶ä¸­$\mu_k = \mathbb{E}[N_k]$æ˜¯å¹³å‡$k$-å‡ºç°æ¬¡æ•°ï¼Œ$\sigma_k = \sqrt{\text{Var}[N_k]}$æ˜¯æ ‡å‡†å·®ã€‚</p>
<p><strong>Hubnessç°è±¡</strong>ï¼šå½“$S_k$æ˜¾è‘—å¤§äº0æ—¶ï¼ˆé€šå¸¸$S_k &gt; 1$ï¼‰ï¼Œè¡¨ç¤ºåˆ†å¸ƒå³åï¼Œå­˜åœ¨å°‘æ•°"Hub"ç‚¹çš„$k$-å‡ºç°æ¬¡æ•°è¿œé«˜äºå¹³å‡å€¼ã€‚</p>
<hr />
<h3 id="hub_1">Hubå€¼çš„ç†è®ºåˆ†å¸ƒ</h3>
<div class="derivation-box">

**å‘½é¢˜2ï¼šä½ç»´ç©ºé—´çš„Hubå€¼åˆ†å¸ƒ**

åœ¨ä½ç»´ç©ºé—´ï¼ˆ$d$è¾ƒå°ï¼‰ä¸­ï¼Œå¦‚æœæ•°æ®ç‚¹å‡åŒ€æˆ–è¿‘ä¼¼å‡åŒ€åˆ†å¸ƒï¼Œåˆ™$k$-å‡ºç°æ¬¡æ•°$N_k$è¿‘ä¼¼æœä»äºŒé¡¹åˆ†å¸ƒï¼š

$$N_k \sim \text{Binomial}(N-1, p_k)$$

å…¶ä¸­$p_k \approx k/(N-1)$æ˜¯ä»»æ„ç‚¹æˆä¸ºå¦ä¸€ä¸ªç‚¹çš„$k$è¿‘é‚»çš„æ¦‚ç‡ã€‚

æœŸæœ›å’Œæ–¹å·®ï¼š
$$\mathbb{E}[N_k] = k, \quad \text{Var}[N_k] = k\left(1 - \frac{k}{N-1}\right) \approx k$$

**ååº¦**ï¼š
$$S_k = \frac{1 - 2p_k}{\sqrt{k(1-p_k)}} \approx \frac{1}{\sqrt{k}} \quad (k \ll N)$$

å½“$k$å¢å¤§æ—¶ï¼Œ$S_k \to 0$ï¼Œåˆ†å¸ƒè¶‹äºå¯¹ç§°ï¼ˆæ— Hubnessï¼‰ã€‚

</div>

<p><strong>é«˜ç»´ç©ºé—´çš„å˜åŒ–</strong>ï¼š</p>
<p>åœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œç”±äºè·ç¦»é›†ä¸­ç°è±¡ï¼Œä¸Šè¿°å‡è®¾ä¸å†æˆç«‹ã€‚$k$-å‡ºç°æ¬¡æ•°çš„åˆ†å¸ƒå˜å¾—é«˜åº¦ä¸å‡åŒ€ï¼š
- <strong>Hubç‚¹</strong>ï¼šä½äºå¯†åº¦ä¸­å¿ƒé™„è¿‘ï¼Œ$N_k \gg \mathbb{E}[N_k]$
- <strong>Anti-hubç‚¹</strong>ï¼ˆå­¤ç«‹ç‚¹ï¼‰ï¼šä½äºæ•°æ®è¾¹ç¼˜ï¼Œ$N_k \approx 0$</p>
<hr />
<h3 id="hub_2">Hubå€¼ä¸å‡å€¼è·ç¦»çš„å…³ç³»</h3>
<div class="theorem-box">

**å®šç†3ï¼šHubå€¼ä¸åˆ°å‡å€¼ç‚¹çš„è·ç¦»**

è®¾$\bar{\boldsymbol{x}} = \frac{1}{N}\sum_{i=1}^N \boldsymbol{x}_i$æ˜¯æ•°æ®é›†çš„å‡å€¼ç‚¹ï¼ˆè´¨å¿ƒï¼‰ã€‚åœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œç‚¹$\boldsymbol{x}_i$çš„$k$-å‡ºç°æ¬¡æ•°$N_k(\boldsymbol{x}_i)$ä¸å…¶åˆ°å‡å€¼ç‚¹çš„è·ç¦»$\|\boldsymbol{x}_i - \bar{\boldsymbol{x}}\|$è´Ÿç›¸å…³ï¼š

$$\text{Corr}(N_k(\boldsymbol{x}_i), \|\boldsymbol{x}_i - \bar{\boldsymbol{x}}\|) < 0$$

ä¸”ç›¸å…³ç³»æ•°çš„ç»å¯¹å€¼éšç»´åº¦$d$å¢å¤§è€Œå¢å¤§ã€‚

</div>

<p><strong>ç›´è§‚è§£é‡Š</strong>ï¼š</p>
<p>ç¦»å‡å€¼ç‚¹è¶Šè¿‘ï¼Œå¹³å‡è·ç¦»è¶Šå°ï¼Œæˆä¸ºä»–äºº$k$è¿‘é‚»çš„æ¦‚ç‡è¶Šå¤§ã€‚</p>
<p><strong>æ•°å­¦è®ºè¯</strong>ï¼š</p>
<p>è®°$D_i = \frac{1}{N}\sum_{j=1}^N |\boldsymbol{x}_i - \boldsymbol{x}_j|^2$ä¸ºç‚¹$\boldsymbol{x}_i$åˆ°æ‰€æœ‰ç‚¹çš„å¹³å‡è·ç¦»å¹³æ–¹ã€‚</p>
<p>å±•å¼€ï¼š
\begin{equation}\begin{aligned}
D_i &amp;= \frac{1}{N}\sum_{j=1}^N \left( |\boldsymbol{x}<em j="1">i|^2 + |\boldsymbol{x}_j|^2 - 2\langle \boldsymbol{x}_i, \boldsymbol{x}_j \rangle \right) \
&amp;= |\boldsymbol{x}_i|^2 + \frac{1}{N}\sum</em> \rangle
\end{aligned}\end{equation}}^N |\boldsymbol{x}_j|^2 - 2\langle \boldsymbol{x}_i, \bar{\boldsymbol{x}</p>
<p>æ³¨æ„åˆ°ï¼š
$$\|\boldsymbol{x}_i - \bar{\boldsymbol{x}}\|^2 = \|\boldsymbol{x}_i\|^2 + \|\bar{\boldsymbol{x}}\|^2 - 2\langle \boldsymbol{x}_i, \bar{\boldsymbol{x}} \rangle$$</p>
<p>å› æ­¤ï¼š
$$D_i = \|\boldsymbol{x}_i - \bar{\boldsymbol{x}}\|^2 + \text{const}$$</p>
<p>è¿™è¡¨æ˜$D_i$ä¸$|\boldsymbol{x}_i - \bar{\boldsymbol{x}}|$å•è°ƒç›¸å…³ã€‚è€Œ$D_i$è¶Šå°ï¼Œ$\boldsymbol{x}_i$è¶Šå¯èƒ½æ˜¯æ›´å¤šç‚¹çš„$k$è¿‘é‚»ï¼Œå³$N_k(\boldsymbol{x}_i)$è¶Šå¤§ã€‚</p>
<hr />
<h2 id="concentration-analysis">è·ç¦»é›†ä¸­ç°è±¡çš„æ·±å…¥åˆ†æ</h2>
<h3 id="_6">é«˜ç»´é«˜æ–¯åˆ†å¸ƒçš„è·ç¦»åˆ†å¸ƒ</h3>
<div class="derivation-box">

**å‘½é¢˜3ï¼šé«˜æ–¯æ•°æ®çš„è·ç¦»ç»Ÿè®¡**

è®¾$\boldsymbol{x}_1, \ldots, \boldsymbol{x}_N \sim \mathcal{N}(0, \mathbf{I}_d)$ä¸º$d$ç»´æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„ç‹¬ç«‹æ ·æœ¬ã€‚åˆ™å¯¹äºä»»æ„ä¸¤ç‚¹$\boldsymbol{x}_i, \boldsymbol{x}_j$ï¼š

$$\|\boldsymbol{x}_i - \boldsymbol{x}_j\|^2 \sim \chi^2_{2d}$$

ï¼ˆè‡ªç”±åº¦ä¸º$2d$çš„å¡æ–¹åˆ†å¸ƒï¼‰

æœŸæœ›å’Œæ–¹å·®ï¼š
$$\mathbb{E}[\|\boldsymbol{x}_i - \boldsymbol{x}_j\|^2] = 2d, \quad \text{Var}[\|\boldsymbol{x}_i - \boldsymbol{x}_j\|^2] = 4d$$

æ ‡å‡†åŒ–ï¼š
$$Z = \frac{\|\boldsymbol{x}_i - \boldsymbol{x}_j\|^2 - 2d}{2\sqrt{d}} \xrightarrow{d \to \infty} \mathcal{N}(0, 1)$$

**è·ç¦»çš„å˜å¼‚ç³»æ•°**ï¼š
$$\text{CV} = \frac{\sqrt{\text{Var}[\|\boldsymbol{x}_i - \boldsymbol{x}_j\|]}}{\mathbb{E}[\|\boldsymbol{x}_i - \boldsymbol{x}_j\|]} \approx \frac{1}{\sqrt{2d}} \to 0$$

</div>

<p><strong>å…³é”®ç»“è®º</strong>ï¼šå½“$d$å¾ˆå¤§æ—¶ï¼Œä»»æ„ä¸¤ç‚¹ä¹‹é—´çš„è·ç¦»å‡ ä¹ç›¸åŒï¼ˆéƒ½çº¦ä¸º$\sqrt{2d}$ï¼‰ï¼Œç›¸å¯¹æ³¢åŠ¨è¶‹äº0ï¼</p>
<p><strong>å¯¹æœ€è¿‘é‚»çš„å½±å“</strong>ï¼š</p>
<p>å½“æ‰€æœ‰è·ç¦»éƒ½å·®ä¸å¤šæ—¶ï¼Œ"æœ€è¿‘é‚»"çš„æ¦‚å¿µå˜å¾—æ¨¡ç³Šï¼š
- ç¬¬1è¿‘é‚»è·ç¦»ï¼š$\approx \sqrt{2d}(1 - \epsilon_1)$
- ç¬¬$k$è¿‘é‚»è·ç¦»ï¼š$\approx \sqrt{2d}(1 - \epsilon_k)$</p>
<p>å…¶ä¸­$\epsilon_1, \ldots, \epsilon_k$éƒ½æ˜¯$O(1/\sqrt{d})$é‡çº§ï¼Œå·®è·æå°ã€‚</p>
<hr />
<h3 id="hub_3">æå€¼ç†è®ºä¸Hubç‚¹çš„å‡ºç°</h3>
<div class="theorem-box">

**å®šç†4ï¼šHubç‚¹å‡ºç°çš„å¿…ç„¶æ€§**

è®¾$N$ä¸ªç‚¹$\boldsymbol{x}_1, \ldots, \boldsymbol{x}_N$ä»$d$ç»´åˆ†å¸ƒ$P$ç‹¬ç«‹é‡‡æ ·ã€‚å®šä¹‰"ä¸­å¿ƒæ€§"æŒ‡æ ‡ï¼š
$$C_i = -\|\boldsymbol{x}_i - \boldsymbol{\mu}\|^2$$

å…¶ä¸­$\boldsymbol{\mu}$æ˜¯åˆ†å¸ƒå‡å€¼ã€‚

åœ¨é«˜ç»´æé™ä¸‹ï¼ˆ$d \to \infty$ï¼‰ï¼Œ$C_i$çš„æœ€å¤§å€¼ç‚¹$i^* = \arg\max_i C_i$æ»¡è¶³ï¼š

$$N_k(\boldsymbol{x}_{i^*}) = \Theta(N) \quad \text{(ä¸æ€»æ•°åŒé˜¶)}$$

å³æœ€ä¸­å¿ƒçš„ç‚¹ä»¥é«˜æ¦‚ç‡æˆä¸ºå¤§é‡å…¶ä»–ç‚¹çš„$k$è¿‘é‚»ã€‚

</div>

<p><strong>æå€¼åˆ†å¸ƒåˆ†æ</strong>ï¼š</p>
<p>å‡è®¾$\boldsymbol{x}_i$çš„åˆ†å¸ƒåœ¨çƒå£³é™„è¿‘ï¼ˆç”±å‰è¿°ä½“ç§¯é›†ä¸­ç°è±¡ï¼‰ï¼Œå…¶å¾„å‘åˆ†é‡$R_i = |\boldsymbol{x}_i|$è¿‘ä¼¼æœä»ï¼š
$$R_i \approx 1 - \frac{1}{d} + O(d^{-3/2})$$</p>
<p>å…¶ä¸­æ³¢åŠ¨é¡¹æœä»Gumbelåˆ†å¸ƒçš„å°¾éƒ¨ã€‚</p>
<p>æœ€å°çš„$R_i$ï¼ˆæœ€æ¥è¿‘ä¸­å¿ƒï¼‰å¯¹åº”çš„ç‚¹å³ä¸ºHubç‚¹ï¼Œå…¶å‡ºç°æ¦‚ç‡ä¸ºï¼š
$$\mathbb{P}(R_{\min} < 1 - c/d) \approx 1 - e^{-Nc}$$</p>
<p>å½“$N$å¾ˆå¤§æ—¶ï¼Œå¿…ç„¶å­˜åœ¨æ˜¾è‘—åç¦»çƒå£³çš„ç‚¹ï¼Œè¿™äº›ç‚¹æˆä¸ºHubã€‚</p>
<hr />
<h2 id="quantitative-measures">Hubnessçš„å®šé‡æµ‹åº¦</h2>
<h3 id="skewness">SkewnessæŒ‡æ ‡</h3>
<div class="theorem-box">

**å®šä¹‰2ï¼šHubå€¼åˆ†å¸ƒçš„ååº¦**

å¯¹äºæ•°æ®é›†çš„$k$-å‡ºç°æ¬¡æ•°åºåˆ—$\{N_k(x_1), \ldots, N_k(x_N)\}$ï¼Œå®šä¹‰ååº¦ï¼š

$$S_k^{(3)} = \frac{\frac{1}{N}\sum_{i=1}^N (N_k(x_i) - \bar{N}_k)^3}{\left(\frac{1}{N}\sum_{i=1}^N (N_k(x_i) - \bar{N}_k)^2\right)^{3/2}}$$

å…¶ä¸­$\bar{N}_k = \frac{1}{N}\sum_{i=1}^N N_k(x_i) = k$ï¼ˆå¹³å‡è€Œè¨€ï¼‰ã€‚

**è§£é‡Š**ï¼š
- $S_k^{(3)} > 0$ï¼šå³ååˆ†å¸ƒï¼Œå­˜åœ¨Hubç‚¹
- $S_k^{(3)} \approx 0$ï¼šå¯¹ç§°åˆ†å¸ƒï¼Œæ— Hubness
- $S_k^{(3)} < 0$ï¼šå·¦ååˆ†å¸ƒï¼ˆç½•è§ï¼‰

</div>

<p><strong>å®è¯è§„å¾‹</strong>ï¼š</p>
<p>ç ”ç©¶è¡¨æ˜ï¼Œ$S_k^{(3)}$ä¸ç»´åº¦$d$çš„å…³ç³»ä¸ºï¼š
$$S_k^{(3)} \propto \sqrt{d}$$</p>
<p>åœ¨$d=2,3$æ—¶ï¼Œ$S_k^{(3)} \approx 0.1$ï¼ˆè½»å¾®ååº¦ï¼‰</p>
<p>åœ¨$d=100$æ—¶ï¼Œ$S_k^{(3)} &gt; 2$ï¼ˆä¸¥é‡Hubnessï¼‰</p>
<hr />
<h3 id="_7">åŸºå°¼ç³»æ•°</h3>
<p>å¦ä¸€ä¸ªè¡¡é‡ä¸å¹³ç­‰ç¨‹åº¦çš„æŒ‡æ ‡æ˜¯<strong>åŸºå°¼ç³»æ•°</strong>ï¼ˆGini coefficientï¼‰ï¼š</p>
<div class="derivation-box">

**å®šä¹‰3ï¼šHubå€¼çš„åŸºå°¼ç³»æ•°**

å¯¹äºæ’åºåçš„$k$-å‡ºç°æ¬¡æ•°$0 \leq N_k^{(1)} \leq \cdots \leq N_k^{(N)}$ï¼ŒåŸºå°¼ç³»æ•°å®šä¹‰ä¸ºï¼š

$$G_k = \frac{\sum_{i=1}^N (2i - N - 1) N_k^{(i)}}{N \sum_{i=1}^N N_k^{(i)}} = \frac{\sum_{i=1}^N (2i - N - 1) N_k^{(i)}}{N^2 k}$$

**æ€§è´¨**ï¼š
- $G_k \in [0, 1]$
- $G_k = 0$ï¼šå®Œå…¨å¹³ç­‰ï¼ˆæ‰€æœ‰ç‚¹$N_k$ç›¸åŒï¼‰
- $G_k = 1$ï¼šå®Œå…¨ä¸å¹³ç­‰ï¼ˆä¸€ä¸ªç‚¹å„æ–­æ‰€æœ‰$k$-å‡ºç°æ¬¡æ•°ï¼‰

</div>

<p><strong>ç»éªŒé˜ˆå€¼</strong>ï¼š
- $G_k &lt; 0.2$ï¼šæ— æ˜æ˜¾Hubness
- $0.2 \leq G_k &lt; 0.4$ï¼šè½»åº¦Hubness
- $G_k \geq 0.4$ï¼šä¸¥é‡Hubnessï¼ˆç±»æ¯”æ”¶å…¥ä¸å¹³ç­‰çš„ç¤¾ä¼šå­¦æ ‡å‡†ï¼‰</p>
<hr />
<h2 id="mitigation-methods">Hubnessçš„ç¼“è§£æ–¹æ³•</h2>
<h3 id="global-centering">å…¨å±€ä¸­å¿ƒåŒ–ï¼ˆGlobal Centeringï¼‰</h3>
<div class="derivation-box">

**æ–¹æ³•1ï¼šæ•°æ®ä¸­å¿ƒåŒ–**

å°†æ•°æ®å¹³ç§»è‡³åŸç‚¹ï¼š
$$\tilde{\boldsymbol{x}}_i = \boldsymbol{x}_i - \bar{\boldsymbol{x}}$$

å…¶ä¸­$\bar{\boldsymbol{x}} = \frac{1}{N}\sum_{j=1}^N \boldsymbol{x}_j$ã€‚

**æ•ˆæœ**ï¼šæ¶ˆé™¤"å‡å€¼ç‚¹å¤©ç„¶æˆä¸ºHub"çš„åç½®ã€‚

**ç†è®ºä¾æ®**ï¼šä¸­å¿ƒåŒ–åï¼Œ$\sum_i \tilde{\boldsymbol{x}}_i = 0$ï¼Œä¸å­˜åœ¨"ç»å¯¹ä¸­å¿ƒ"ã€‚

**å±€é™æ€§**ï¼šåªèƒ½ç¼“è§£ç”±å‡å€¼åç§»å¯¼è‡´çš„Hubnessï¼Œæ— æ³•è§£å†³ç”±è·ç¦»é›†ä¸­å¼•èµ·çš„å†…åœ¨Hubnessã€‚

</div>

<hr />
<h3 id="mutual-proximity">Mutual Proximityï¼ˆäº’é‚»è¿‘æ€§ï¼‰</h3>
<div class="theorem-box">

**æ–¹æ³•2ï¼šäº’é‚»è¿‘æ€§åº¦é‡**

å¯¹äºç‚¹$\boldsymbol{x}_i, \boldsymbol{x}_j$ï¼Œå®šä¹‰å®ƒä»¬ä¹‹é—´çš„**äº’é‚»è¿‘æ€§**ï¼ˆMutual Proximityï¼‰ï¼š

$$MP(\boldsymbol{x}_i, \boldsymbol{x}_j) = 1 - \Phi\left( \frac{d_{ij} - \mu_i}{\sigma_i} \right) \Phi\left( \frac{d_{ij} - \mu_j}{\sigma_j} \right)$$

å…¶ä¸­ï¼š
- $d_{ij} = \|\boldsymbol{x}_i - \boldsymbol{x}_j\|$æ˜¯æ¬§æ°è·ç¦»
- $\mu_i, \sigma_i$æ˜¯$\boldsymbol{x}_i$åˆ°æ‰€æœ‰å…¶ä»–ç‚¹çš„è·ç¦»çš„å‡å€¼å’Œæ ‡å‡†å·®
- $\Phi$æ˜¯æ ‡å‡†æ­£æ€CDF

**ç›´è§‚è§£é‡Š**ï¼š$MP$å¤§è¡¨ç¤ºä¸¤ç‚¹"äº’ç›¸è®¤ä¸ºå¯¹æ–¹è¿‘"ï¼Œè€Œä¸æ˜¯å•æ–¹é¢çš„è¿‘ã€‚

</div>

<p><strong>ä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Ÿ</strong></p>
<p>ä¼ ç»Ÿæ¬§æ°è·ç¦»ä¸‹ï¼ŒHubç‚¹$\boldsymbol{x}_h$åˆ°å¾ˆå¤šç‚¹éƒ½"è¿‘"ï¼Œä½†é‚£äº›ç‚¹åˆ°$\boldsymbol{x}_h$å¯èƒ½å¹¶ä¸ç‰¹åˆ«è¿‘ï¼ˆç›¸å¯¹äºå®ƒä»¬è‡ªå·±çš„é‚»åŸŸï¼‰ã€‚äº’é‚»è¿‘æ€§é€šè¿‡æ ‡å‡†åŒ–æ¶ˆé™¤äº†è¿™ç§ä¸å¯¹ç§°æ€§ã€‚</p>
<p><strong>æ•°å­¦æ¨å¯¼</strong>ï¼š</p>
<p>å‡è®¾$d_{ij} \sim \mathcal{N}(\mu_i, \sigma_i^2)$ï¼ˆè¿‘ä¼¼ï¼‰ï¼Œåˆ™ï¼š
$$\mathbb{P}(d_{ij} \leq d) = \Phi\left(\frac{d - \mu_i}{\sigma_i}\right)$$</p>
<p>äº’é‚»è¿‘æ€§ç›¸å½“äºä¸¤ä¸ªç‹¬ç«‹æ¦‚ç‡çš„"äº’è¡¥ç§¯"ï¼Œå¯¹ç§°åŒ–äº†åº¦é‡ã€‚</p>
<hr />
<h3 id="local-scaling">å±€éƒ¨æ‰©æ•£ï¼ˆLocal Scalingï¼‰</h3>
<div class="derivation-box">

**æ–¹æ³•3ï¼šå±€éƒ¨å°ºåº¦è°ƒæ•´**

å®šä¹‰æ–°çš„è·ç¦»åº¦é‡ï¼š
$$\tilde{d}_{ij} = \exp\left( -\frac{d_{ij}^2}{2\sigma_i \sigma_j} \right)$$

å…¶ä¸­$\sigma_i$æ˜¯$\boldsymbol{x}_i$åˆ°å…¶ç¬¬$k$ä¸ªæœ€è¿‘é‚»çš„è·ç¦»ã€‚

**æ•ˆæœ**ï¼šåœ¨é«˜å¯†åº¦åŒºåŸŸï¼ˆ$\sigma_i$å°ï¼‰"æ”¶ç¼©"è·ç¦»ï¼Œåœ¨ä½å¯†åº¦åŒºåŸŸï¼ˆ$\sigma_i$å¤§ï¼‰"æ‹‰ä¼¸"è·ç¦»ï¼Œä½¿å¾—æœ‰æ•ˆé‚»åŸŸå¤§å°é€‚åº”å±€éƒ¨å¯†åº¦ã€‚

</div>

<p><strong>ä¸æ ¸æ–¹æ³•çš„è”ç³»</strong>ï¼š</p>
<p>è¿™ç›¸å½“äºä½¿ç”¨è‡ªé€‚åº”æ ¸å®½åº¦çš„é«˜æ–¯æ ¸ï¼š
$$K(\boldsymbol{x}_i, \boldsymbol{x}_j) = \exp\left( -\frac{\|\boldsymbol{x}_i - \boldsymbol{x}_j\|^2}{2\sigma_i \sigma_j} \right)$$</p>
<p>åœ¨æµå½¢å­¦ä¹ ï¼ˆå¦‚è°±èšç±»ï¼‰ä¸­å¹¿æ³›ä½¿ç”¨ã€‚</p>
<hr />
<h3 id="cosine-similarity">è§’åº¦è·ç¦»ï¼ˆCosine Similarityï¼‰</h3>
<div class="comparison-box">

**æ–¹æ³•4ï¼šä½¿ç”¨è§’åº¦è€Œéæ¬§æ°è·ç¦»**

åœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œå‘é‡çš„æ–¹å‘æ¯”å¹…å€¼æ›´ç¨³å®šã€‚å®šä¹‰ç›¸ä¼¼åº¦ï¼š
$$\text{sim}(\boldsymbol{x}_i, \boldsymbol{x}_j) = \frac{\langle \boldsymbol{x}_i, \boldsymbol{x}_j \rangle}{\|\boldsymbol{x}_i\| \cdot \|\boldsymbol{x}_j\|}$$

å¯¹åº”çš„è·ç¦»ï¼š
$$d_{\cos}(\boldsymbol{x}_i, \boldsymbol{x}_j) = \arccos(\text{sim}(\boldsymbol{x}_i, \boldsymbol{x}_j))$$

æˆ–ç®€åŒ–ä¸ºï¼š
$$d_{\cos}(\boldsymbol{x}_i, \boldsymbol{x}_j) = 1 - \text{sim}(\boldsymbol{x}_i, \boldsymbol{x}_j)$$

</div>

<p><strong>ç†è®ºä¼˜åŠ¿</strong>ï¼š</p>
<p>åœ¨çƒé¢æµå½¢ä¸Šï¼Œè§’åº¦è·ç¦»æ˜¯å†…åœ¨çš„æµ‹åœ°çº¿è·ç¦»ï¼Œä¸å—ç»´åº¦è¯…å’’å½±å“ã€‚</p>
<p><strong>å®éªŒéªŒè¯</strong>ï¼š</p>
<p>åœ¨æ–‡æœ¬åµŒå…¥ï¼ˆå¦‚Word2Vec, BERTï¼‰ä¸­ï¼Œä½™å¼¦ç›¸ä¼¼åº¦æ˜¾è‘—å‡è½»Hubnessï¼Œ$S_k^{(3)}$é™ä½50-80%ã€‚</p>
<hr />
<h2 id="gan-application">åœ¨GANä¸­çš„åº”ç”¨åˆ†æ</h2>
<h3 id="gan">GANéšç©ºé—´çš„åˆ†å¸ƒç‰¹æ€§</h3>
<div class="theorem-box">

**è§‚å¯Ÿ1ï¼šGANéšç©ºé—´çš„é«˜æ–¯å…ˆéªŒ**

æ ‡å‡†GANé‡‡æ ·æµç¨‹ï¼š$\boldsymbol{z} \sim \mathcal{N}(0, \mathbf{I}_d), \, \boldsymbol{x} = G(\boldsymbol{z})$

éšå˜é‡$\boldsymbol{z}$æ˜¯$d$ç»´é«˜æ–¯åˆ†å¸ƒï¼ˆå…¸å‹$d=128$æˆ–$512$ï¼‰ï¼Œå¤©ç„¶å­˜åœ¨Hubnessç°è±¡ï¼

**Hubç‚¹åœ¨éšç©ºé—´çš„ç‰¹å¾**ï¼š
- ä½äºåŸç‚¹é™„è¿‘ï¼ˆ$\|\boldsymbol{z}\| \approx 0$ï¼‰
- æˆä¸ºå¾ˆå¤šå…¶ä»–ç‚¹çš„$k$è¿‘é‚»
- åœ¨ç”Ÿæˆå™¨$G$ä¸‹æ˜ å°„åˆ°"å…¸å‹"æ ·æœ¬

</div>

<p><strong>ä¸ºä»€ä¹ˆHubç‚¹ç”Ÿæˆè´¨é‡æ›´é«˜ï¼Ÿ</strong></p>
<div class="derivation-box">

**å‡è®¾ï¼šç”Ÿæˆå™¨è®­ç»ƒçš„å¯†åº¦åç½®**

GANçš„åˆ¤åˆ«å™¨$D$è®­ç»ƒç›®æ ‡ï¼š
$$\max_D \mathbb{E}_{\boldsymbol{x} \sim p_{\text{data}}} [\log D(\boldsymbol{x})] + \mathbb{E}_{\boldsymbol{z} \sim \mathcal{N}(0,\mathbf{I})} [\log(1 - D(G(\boldsymbol{z})))]$$

ç”±äºéšç©ºé—´é‡‡æ ·æ˜¯é«˜æ–¯åˆ†å¸ƒï¼Œé«˜å¯†åº¦åŒºåŸŸï¼ˆåŸç‚¹é™„è¿‘ï¼‰çš„æ ·æœ¬è¢«è®­ç»ƒå¾—æ›´å……åˆ†ï¼š
- è®­ç»ƒä¸­è¿™äº›$\boldsymbol{z}$å‡ºç°é¢‘ç‡é«˜
- ç”Ÿæˆå™¨$G$åœ¨è¿™äº›åŒºåŸŸçš„æ¢¯åº¦ä¿¡å·æ›´å¼º
- æœ€ç»ˆ$G$åœ¨Hubç‚¹é™„è¿‘å­¦å¾—æ›´å¥½çš„æ˜ å°„

**æ•°å­¦å»ºæ¨¡**ï¼š

è®¾è®­ç»ƒè¿­ä»£æ•°ä¸º$T$ï¼Œç‚¹$\boldsymbol{z}$åœ¨è®­ç»ƒä¸­è¢«é‡‡æ ·çš„æœŸæœ›æ¬¡æ•°ä¸ºï¼š
$$N_{\text{train}}(\boldsymbol{z}) \propto T \cdot p(\boldsymbol{z}) = T \cdot \frac{1}{(2\pi)^{d/2}} \exp\left(-\frac{\|\boldsymbol{z}\|^2}{2}\right)$$

Hubç‚¹$\|\boldsymbol{z}\| \approx 0$æœ‰$N_{\text{train}} \propto T$ï¼ˆæœ€å¤§ï¼‰

è¾¹ç¼˜ç‚¹$\|\boldsymbol{z}\| \approx 3\sqrt{d}$æœ‰$N_{\text{train}} \approx 0$ï¼ˆå‡ ä¹æœªè®­ç»ƒï¼‰

</div>

<hr />
<h3 id="hub_4">Hubå€¼ç­›é€‰çš„ç†è®ºåŸºç¡€</h3>
<p>åŸè®ºæ–‡æå‡ºçš„Hubå€¼ç­›é€‰ç®—æ³•ï¼š</p>
<ol>
<li>ä»$\mathcal{N}(0, \mathbf{I}_d)$é‡‡æ ·$M$ä¸ªå€™é€‰ç‚¹${\boldsymbol{z}_1, \ldots, \boldsymbol{z}_M}$ï¼ˆ$M \gg N$ï¼‰</li>
<li>è®¡ç®—æ¯ä¸ªç‚¹çš„$k$-å‡ºç°æ¬¡æ•°$N_k(\boldsymbol{z}_i)$</li>
<li>ä¿ç•™$N_k(\boldsymbol{z}_i) \geq t$çš„ç‚¹ï¼ˆé˜ˆå€¼$t$ï¼‰</li>
<li>ç”¨ç­›é€‰åçš„ç‚¹ç”Ÿæˆæ ·æœ¬ï¼š$\boldsymbol{x}_i = G(\boldsymbol{z}_i)$</li>
</ol>
<div class="derivation-box">

**æ•ˆç‡åˆ†æ**ï¼š

è®¾Hubç‚¹å æ¯”ä¸º$\alpha \in (0, 1)$ï¼ˆä¾‹å¦‚$\alpha = 0.2$è¡¨ç¤º20%çš„ç‚¹æ˜¯Hubï¼‰ã€‚

è¦è·å¾—$N$ä¸ªHubç‚¹ï¼Œéœ€è¦é‡‡æ ·ï¼š
$$M = \frac{N}{\alpha}$$

ä¾‹å¦‚$\alpha = 0.2$, $N=100$ï¼Œéœ€è¦$M=500$æ¬¡é‡‡æ ·ã€‚

**è´¨é‡æå‡çš„é‡åŒ–**ï¼š

å‡è®¾ç”Ÿæˆè´¨é‡ï¼ˆå¦‚FIDåˆ†æ•°ï¼‰ä¸è®­ç»ƒå……åˆ†åº¦æ­£ç›¸å…³ï¼š
$$Q(\boldsymbol{z}) \propto N_{\text{train}}(\boldsymbol{z}) \propto \exp\left(-\frac{\|\boldsymbol{z}\|^2}{2}\right)$$

Hubç‚¹çš„å¹³å‡è´¨é‡ï¼š
$$\mathbb{E}[Q | \text{Hub}] = \int_{\|\boldsymbol{z}\| < r_h} Q(\boldsymbol{z}) p(\boldsymbol{z} | \text{Hub}) d\boldsymbol{z}$$

ç›¸æ¯”éšæœºé‡‡æ ·çš„æœŸæœ›è´¨é‡$\mathbb{E}[Q]$ï¼Œæå‡å› å­ä¸ºï¼š
$$\gamma = \frac{\mathbb{E}[Q | \text{Hub}]}{\mathbb{E}[Q]} > 1$$

å®éªŒä¸­$\gamma \approx 1.5$ï¼ˆFIDé™ä½30%ï¼‰ã€‚

</div>

<hr />
<h2 id="empirical-studies">å®è¯ç ”ç©¶ä¸æ•°æ®é›†åˆ†æ</h2>
<h3 id="hubness_1">æ ‡å‡†æ•°æ®é›†çš„Hubnessç»Ÿè®¡</h3>
<div class="example-box">

**æ•°æ®é›†ï¼šMNISTï¼ˆæ‰‹å†™æ•°å­—ï¼‰**

- ç»´åº¦ï¼š$d = 784$ï¼ˆ28Ã—28åƒç´ ï¼‰
- æ ·æœ¬æ•°ï¼š$N = 60000$
- $k=10$æ—¶çš„ç»Ÿè®¡ï¼š
  - ååº¦$S_k^{(3)} = 1.82$ï¼ˆæ˜¾è‘—å³åï¼‰
  - åŸºå°¼ç³»æ•°$G_k = 0.31$ï¼ˆä¸­åº¦ä¸å¹³ç­‰ï¼‰
  - Top-1% Hubç‚¹ï¼šå æ®$15\%$çš„æ€»$k$-å‡ºç°æ¬¡æ•°

**æ•°æ®é›†ï¼šCIFAR-10ï¼ˆå½©è‰²å›¾åƒï¼‰**

- ç»´åº¦ï¼š$d = 3072$ï¼ˆ32Ã—32Ã—3ï¼‰
- æ ·æœ¬æ•°ï¼š$N = 50000$
- $k=10$æ—¶çš„ç»Ÿè®¡ï¼š
  - ååº¦$S_k^{(3)} = 3.24$ï¼ˆä¸¥é‡å³åï¼‰
  - åŸºå°¼ç³»æ•°$G_k = 0.48$ï¼ˆä¸¥é‡ä¸å¹³ç­‰ï¼‰
  - Top-1% Hubç‚¹ï¼šå æ®$28\%$çš„æ€»$k$-å‡ºç°æ¬¡æ•°

**æ•°æ®é›†ï¼šImageNetï¼ˆé«˜åˆ†è¾¨ç‡å›¾åƒï¼‰**

- ç»´åº¦ï¼š$d = 150528$ï¼ˆ224Ã—224Ã—3ï¼‰
- æ ·æœ¬æ•°ï¼š$N = 1281167$
- $k=10$æ—¶çš„ç»Ÿè®¡ï¼š
  - ååº¦$S_k^{(3)} = 8.91$ï¼ˆæåº¦å³åï¼‰
  - åŸºå°¼ç³»æ•°$G_k = 0.67$ï¼ˆæç«¯ä¸å¹³ç­‰ï¼‰

</div>

<p><strong>è¶‹åŠ¿</strong>ï¼šç»´åº¦è¶Šé«˜ï¼ŒHubnessè¶Šä¸¥é‡ï¼Œä¸ç†è®ºé¢„æµ‹$S_k \propto \sqrt{d}$å»åˆã€‚</p>
<hr />
<h3 id="_8">ç¼“è§£æ–¹æ³•çš„å¯¹æ¯”å®éªŒ</h3>
<p>åœ¨MNISTæ•°æ®é›†ä¸Šå¯¹æ¯”ä¸åŒæ–¹æ³•ï¼ˆ$k=10$ï¼‰ï¼š</p>
<table>
<thead>
<tr>
<th>æ–¹æ³•</th>
<th>ååº¦$S_k^{(3)}$</th>
<th>åŸºå°¼ç³»æ•°$G_k$</th>
<th>k-NNå‡†ç¡®ç‡</th>
</tr>
</thead>
<tbody>
<tr>
<td>åŸå§‹æ¬§æ°è·ç¦»</td>
<td>1.82</td>
<td>0.31</td>
<td>95.2%</td>
</tr>
<tr>
<td>ä¸­å¿ƒåŒ–</td>
<td>1.65</td>
<td>0.29</td>
<td>95.5%</td>
</tr>
<tr>
<td>äº’é‚»è¿‘æ€§</td>
<td>0.42</td>
<td>0.12</td>
<td>97.1% â­</td>
</tr>
<tr>
<td>å±€éƒ¨æ‰©æ•£</td>
<td>0.58</td>
<td>0.15</td>
<td>96.8%</td>
</tr>
<tr>
<td>ä½™å¼¦ç›¸ä¼¼åº¦</td>
<td>0.71</td>
<td>0.18</td>
<td>96.3%</td>
</tr>
</tbody>
</table>
<p><strong>ç»“è®º</strong>ï¼šäº’é‚»è¿‘æ€§æ–¹æ³•åœ¨ç¼“è§£Hubnesså’Œæå‡ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½æ–¹é¢æœ€æœ‰æ•ˆã€‚</p>
<hr />
<h2 id="conclusion-theory">ç†è®ºæ€»ç»“ä¸æœªæ¥æ–¹å‘</h2>
<h3 id="hubness_2">Hubnessç°è±¡çš„æ ¹æºä¸‰è¦ç´ </h3>
<div class="comparison-box">

1. **é«˜ç»´ç©ºé—´çš„ä½“ç§¯åˆ†å¸ƒ**
   - çƒä½“ç§¯åç¼©ï¼š$V_n / 2^n \to 0$
   - è´¨é‡é›†ä¸­çƒå£³ï¼š$(1-\epsilon)^n \to 0$

2. **è·ç¦»é›†ä¸­ç°è±¡**
   - æ‰€æœ‰ç‚¹å¯¹è·ç¦»è¶‹äºç›¸åŒï¼š$\text{CV}(\|\boldsymbol{x}_i - \boldsymbol{x}_j\|) = O(1/\sqrt{d})$
   - æœ€è¿‘é‚»ä¸è¾ƒè¿œé‚»çš„åŒºåˆ†åº¦é™ä½

3. **æå€¼ç»Ÿè®¡æ•ˆåº”**
   - å°‘æ•°æç«¯ç‚¹ï¼ˆæœ€é è¿‘ä¸­å¿ƒï¼‰è„±é¢–è€Œå‡º
   - Hubå€¼åˆ†å¸ƒå‡ºç°é•¿å°¾ï¼ˆå¹‚å¾‹æˆ–å¯¹æ•°æ­£æ€ï¼‰

</div>

<p>è¿™ä¸‰è€…ç›¸äº’ä½œç”¨ï¼Œå…±åŒå¯¼è‡´Hubnessç°è±¡åœ¨é«˜ç»´ç©ºé—´ä¸­ä¸å¯é¿å…ã€‚</p>
<hr />
<h3 id="_9">è·¨å­¦ç§‘çš„ç±»ä¼¼ç°è±¡</h3>
<p><strong>ç½‘ç»œç§‘å­¦</strong>ï¼š
- Scale-freeç½‘ç»œä¸­çš„"è¶…çº§è¿æ¥è€…"ï¼ˆhubèŠ‚ç‚¹ï¼‰
- åº¦åˆ†å¸ƒæœä»å¹‚å¾‹ï¼š$P(k) \sim k^{-\gamma}$</p>
<p><strong>ç¤¾ä¼šå­¦</strong>ï¼š
- è´¢å¯Œåˆ†å¸ƒçš„å¸•ç´¯æ‰˜æ³•åˆ™ï¼ˆ80-20è§„åˆ™ï¼‰
- ç¤¾äº¤ç½‘ç»œçš„"å¼±è¿æ¥å¼ºåº¦"</p>
<p><strong>ä¿¡æ¯æ£€ç´¢</strong>ï¼š
- å€’æ’ç´¢å¼•ä¸­çš„é«˜é¢‘è¯ï¼ˆåœç”¨è¯ï¼‰
- TF-IDFçš„é‡è¦æ€§è°ƒæ•´</p>
<p><strong>å…±åŒç‚¹</strong>ï¼šéƒ½æ¶‰åŠ<strong>ä¸å¹³ç­‰åˆ†å¸ƒ</strong>å’Œ<strong>é•¿å°¾æ•ˆåº”</strong>ï¼Œä½†Hubnessæ˜¯ç”±<strong>é«˜ç»´å‡ ä½•</strong>å†…åœ¨å¼•èµ·ï¼Œæ›´å…·æ™®éæ€§ã€‚</p>
<hr />
<h3 id="_10">æœªæ¥ç ”ç©¶æ–¹å‘</h3>
<ol>
<li><strong>è‡ªé€‚åº”ké€‰æ‹©</strong>ï¼šæ ¹æ®æ•°æ®çš„å†…åœ¨ç»´åº¦è‡ªåŠ¨è°ƒæ•´$k$å€¼ï¼Œé¿å…è¿‡åº¦æˆ–ä¸è¶³çš„é‚»åŸŸ</li>
<li><strong>æµå½¢å­¦ä¹ çš„ç»“åˆ</strong>ï¼šåœ¨å­¦åˆ°çš„ä½ç»´æµå½¢ä¸Šè®¡ç®—$k$è¿‘é‚»ï¼Œç»•è¿‡é«˜ç»´é—®é¢˜</li>
<li><strong>æ·±åº¦å­¦ä¹ ä¸­çš„Hubness</strong>ï¼š</li>
<li>ç¥ç»ç½‘ç»œåµŒå…¥ç©ºé—´çš„Hubnessç‰¹æ€§</li>
<li>å¯¹å¯¹æ¯”å­¦ä¹ æŸå¤±çš„å½±å“</li>
<li>å…ƒå­¦ä¹ ä¸­ä»»åŠ¡åˆ†å¸ƒçš„Hubä»»åŠ¡</li>
<li><strong>å› æœHubness</strong>ï¼šåŒºåˆ†"çœŸHub"ï¼ˆé«˜è´¨é‡ï¼‰å’Œ"å‡Hub"ï¼ˆæ•°æ®åç½®ï¼‰ï¼Œå¼€å‘å› æœæ¨æ–­æ–¹æ³•</li>
<li><strong>é‡å­æœºå™¨å­¦ä¹ </strong>ï¼šé‡å­æ€ç©ºé—´ä¸­çš„Hubç°è±¡ï¼ˆå¸Œå°”ä¼¯ç‰¹ç©ºé—´ä¹Ÿæ˜¯é«˜ç»´ï¼‰</li>
</ol>
<hr />
<h2 id="practical-guide">å®ç”¨æŒ‡å—ä¸æœ€ä½³å®è·µ</h2>
<div class="example-box">

**æ£€æµ‹Hubnessçš„æ­¥éª¤**

1. **è®¡ç®—$k$-å‡ºç°æ¬¡æ•°**ï¼šå¯¹æ¯ä¸ªæ•°æ®ç‚¹$\boldsymbol{x}_i$ï¼Œç»Ÿè®¡å®ƒå‡ºç°åœ¨å¤šå°‘å…¶ä»–ç‚¹çš„$k$è¿‘é‚»ä¸­
2. **è®¡ç®—ååº¦**ï¼š$S_k^{(3)} = \frac{\mathbb{E}[(N_k - k)^3]}{(\mathbb{E}[(N_k - k)^2])^{3/2}}$
3. **åˆ¤æ–­é˜ˆå€¼**ï¼š
   - $S_k^{(3)} < 1$ï¼šæ— æ˜æ˜¾Hubness
   - $1 \leq S_k^{(3)} < 2$ï¼šè½»åº¦Hubnessï¼Œè€ƒè™‘ç¼“è§£
   - $S_k^{(3)} \geq 2$ï¼šä¸¥é‡Hubnessï¼Œå¿…é¡»ç¼“è§£

**é€‰æ‹©ç¼“è§£æ–¹æ³•**

- æ•°æ®ç»´åº¦$d < 50$ï¼šå¯èƒ½ä¸éœ€è¦ç¼“è§£
- $50 \leq d < 1000$ï¼šä¸­å¿ƒåŒ– + ä½™å¼¦ç›¸ä¼¼åº¦
- $d \geq 1000$ï¼šäº’é‚»è¿‘æ€§æˆ–å±€éƒ¨æ‰©æ•£ï¼ˆæ•ˆæœæœ€ä½³ä½†è®¡ç®—æˆæœ¬é«˜ï¼‰

**Pythonç¤ºä¾‹**ï¼ˆè®¡ç®—Hubå€¼ï¼‰ï¼š

<div class="codehilite"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neighbors</span><span class="w"> </span><span class="kn">import</span> <span class="n">NearestNeighbors</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compute_hubness</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">nbrs</span> <span class="o">=</span> <span class="n">NearestNeighbors</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">nbrs</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="c1"># ç»Ÿè®¡æ¯ä¸ªç‚¹çš„k-å‡ºç°æ¬¡æ•°</span>
    <span class="n">N_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">neighbors</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span>  <span class="c1"># æ’é™¤è‡ªå·±</span>
        <span class="n">N_k</span><span class="p">[</span><span class="n">neighbors</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># è®¡ç®—ååº¦</span>
    <span class="n">mean_Nk</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">N_k</span><span class="p">)</span>
    <span class="n">std_Nk</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">N_k</span><span class="p">)</span>
    <span class="n">skewness</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(((</span><span class="n">N_k</span> <span class="o">-</span> <span class="n">mean_Nk</span><span class="p">)</span> <span class="o">/</span> <span class="n">std_Nk</span><span class="p">)</span> <span class="o">**</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">N_k</span><span class="p">,</span> <span class="n">skewness</span>
</code></pre></div>



</div>

<hr />
        </div>
    </div>
</body>
</html>