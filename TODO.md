# TODO
在每一步开始前将步骤重点步骤写入PROGRESS_REPORT.md并再完成后更新进度。最新进度放在PROGRESS_REPORT.md的最前面，每一步或阶段结束后进行commit并push到master
在完成当前blog后，抓取全部blog并完成blog_list.txt中所有页面
## 阶段 1：模板与首页 ✅
- [x] 克隆并研究 `iclr-blogposts/2025` 模板仓库，梳理布局、构建流程与静态资源位置
- [x] 在 `docs/index.html` 实现搜索首页骨架，保持模板风格并适配本项目信息架构
- [x] 本地验证首页搜索与资源加载，整理 GitHub Pages 部署要点

## 阶段 2：内容抓取与整理 🔄
- [x] 编写 `scripts/fetch_and_filter.py` 抓取 `https://spaces.ac.cn/feed`，筛选数学或机器学习相关博文
- [x] 将抓取内容保存到 `blogs_raw/<slug>.md` 并在 `blog_list.txt` 记录标题、路径及完成状态
- [ ] **当前任务**：为选定博文中的数学公式撰写逐步推导与简要注释

## 阶段 3：页面生成与发布 ✅
- [x] 基于模板生成 `docs/posts/<slug>.html`，补充导航、元信息与公式推导说明
- [x] 验证整站链接、样式与搜索功能，准备 GitHub Pages 发布方案

## 下一步：内容增强与部署 ✅
- [x] 选择 1-2 篇文章添加详细的数学公式推导（已完成2篇）
- [x] 提交代码并部署到 GitHub Pages
- [x] 设置 GitHub Actions 自动部署

## 已完成：自动化与部署 ✅
- [x] 抓取 RSS feed 中的博客文章（10篇）
- [x] 将所有 blog 内容转化为网页
- [x] 补充 GitHub Action 的 workflow
- [x] 创建部署文档（DEPLOY.md）

## 后续迭代计划 📝

### 短期目标（进行中）
- [x] 程序化抓取所有blog，并存储于blog_list.txt（已完成：234篇）
- [ ] **【当前任务】为234篇文章添加极详细数学推导（67/234篇已完成，29%）**
  - 策略：按主题分批处理
  - 批次大小：10-15篇/批
  - 详细程度：极详细（20+公式，200+行，多角度解释）
  - 主题分类：
    * 随机矩阵/概率: 14篇
    * 优化理论: 25篇
    * 扩散模型: 32篇
    * Transformer: 32篇
    * 矩阵理论: 10篇
    * 梯度分析: 12篇
    * 其他: 109篇
  - **第一批（随机矩阵/概率主题，7篇）** ✅：
    * [x] #234 - n个正态随机数的最大值的渐近估计 ✅
    * [x] #229 - 随机矩阵的谱范数的快速估计 ✅
    * [x] #234 - 概率分布的熵归一化 ✅
    * [x] #208 - 从重参数的角度看离散概率分布的构建 ✅
    * [x] #188 - 圆内随机n点在同一个圆心角为θ的扇形的概率 ✅
    * [x] #106 - 通向概率分布之路：盘点Softmax及其替代品 ✅
    * [x] #118 - 用傅里叶级数拟合一维概率密度函数 ✅
  - **第二批（矩阵理论主题，12篇）** ✅：
    * [x] 矩阵r次方根和逆r次方根的高效计算 ✅
    * [x] 矩阵平方根和逆平方根的高效计算 ✅
    * [x] "对角+低秩"三角阵的高效求逆方法 ✅
    * [x] 通过msign来计算奇异值裁剪mclip（上） ✅
    * [x] 通过msign来计算奇异值裁剪mclip（下） ✅
    * [x] 矩阵符号函数mcsgn能计算什么？ ✅
    * [x] msign的导数 ✅
    * [x] SVD的导数 ✅
    * [x] 矩阵的有效秩（Effective Rank） ✅
    * [x] 低秩近似之路（一）：伪逆 ✅
    * [x] 低秩近似之路（二）：SVD ✅
    * [x] 低秩近似之路（三）：CR ✅
  - **第三批（优化理论主题，15篇）** ✅：
    * [x] 初探MuP：超参数的跨模型尺度迁移规律 ✅
    * [x] 高阶MuP：更简明但更高明的谱条件缩放 ✅
    * [x] 从谱范数梯度到新式权重衰减的思考 ✅
    * [x] Muon优化器赏析：从向量到矩阵的本质跨越 ✅
    * [x] Muon续集：为什么我们选择尝试Muon？ ✅
    * [x] 为什么梯度裁剪的默认模长是1？ ✅
    * [x] 重新思考学习率与Batch Size（二）：平均场 ✅
    * [x] 为什么Adam的Update RMS是0.2？ ✅
    * [x] 流形上的最速下降：1. SGD + 超球面 ✅
    * [x] 流形上的最速下降：2. Muon + 正交 ✅
    * [x] AdamW的Weight RMS的渐近估计 ✅
    * [x] 从Hessian近似看自适应学习率优化器 ✅
    * [x] MoE环游记：3、换个思路来分配 ✅
    * [x] 通过梯度近似寻找Normalization的替代品 ✅
    * [x] 重新思考学习率与Batch Size（一）：现状 ✅
  - **第四批（扩散模型主题，15篇）** ✅：
    * [x] 生成扩散模型漫谈一：DDPM-拆楼-建楼 ✅
    * [x] 生成扩散模型漫谈三：DDPM-贝叶斯-去噪 ✅
    * [x] 生成扩散模型漫谈四：DDIM-高观点DDPM ✅
    * [x] 生成扩散模型漫谈五：一般框架之SDE篇 ✅
    * [x] 生成扩散模型漫谈六：一般框架之ODE篇 ✅
    * [x] 生成扩散模型漫谈十八：得分匹配=条件得分匹配 ✅
    * [x] 生成扩散模型漫谈二十八：分步理解一致性模型 ✅
    * [x] 测试函数法推导连续性方程和Fokker-Planck方程 ✅
    * [x] 生成扩散模型漫谈十四：构建ODE的一般步骤（上） ✅
    * [x] 生成扩散模型漫谈十五：构建ODE的一般步骤（中） ✅
    * [x] 生成扩散模型漫谈十七：构建ODE的一般步骤（下） ✅
    * [x] 生成扩散模型漫谈二十一：中值定理加速ODE采样 ✅
    * [x] 生成扩散模型漫谈二十二：信噪比与大图生成（上） ✅
    * [x] 生成扩散模型漫谈十六：W距离≤得分匹配 ✅
    * [x] 生成扩散模型漫谈十三：从万有引力到扩散模型 ✅
  - **第五批（Transformer/Attention主题，18篇）** ✅：
    * [x] Transformer升级之路6：旋转位置编码的完备性分析 ✅
    * [x] Transformer升级之路7：长度外推性与局部注意力 ✅
    * [x] Transformer升级之路8：长度外推性与位置鲁棒性 ✅
    * [x] Transformer升级之路9：一种全局长度外推的新思路 ✅
    * [x] Transformer升级之路10：RoPE是一种β进制编码 ✅
    * [x] Transformer升级之路11：将β进制位置进行到底 ✅
    * [x] Transformer升级之路12：无限外推的ReRoPE ✅
    * [x] Transformer升级之路13：逆用Leaky ReRoPE ✅
    * [x] Transformer升级之路14：当HWFA遇见ReRoPE ✅
    * [x] Transformer升级之路15：Key归一化助力长度外推 ✅
    * [x] Transformer升级之路16：复盘长度外推技术 ✅
    * [x] Transformer升级之路17：多模态位置编码的简单思考 ✅
    * [x] Transformer升级之路18：RoPE的底数选择原则 ✅
    * [x] Transformer升级之路20：MLA好在哪里（上） ✅
    * [x] Transformer升级之路21：MLA好在哪里（下） ✅
    * [x] 为什么线性注意力要加Short Conv？ ✅
    * [x] 低精度Attention可能存在有偏的舍入误差 ✅
    * [x] 相对位置编码Transformer的一个理论缺陷与对策 ✅
- [x] 优化首页搜索功能（添加标签筛选）
- [x] 添加文章分类功能

### 中期目标（1个月）
- [ ] 实现深色模式切换
- [ ] 添加文章目录（TOC）

### 长期目标（持续）
- [ ] 添加交互式可视化

## 部署说明

请参阅 DEPLOY.md 了解如何：
- 启用 GitHub Pages
- 配置自动部署
- 本地预览和测试
- 更新内容
- 故障排查


