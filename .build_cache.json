{
  "/home/kelvin/dev/ml_posts/blogs_raw/从emdwmd到wrd文本向量序列的相似度计算.md": "6d8145982d8abb40e994f4adfc90f73b",
  "/home/kelvin/dev/ml_posts/blogs_raw/bert4keras在手baseline我有百度lic2020.md": "d1341dc1edb34b177bf5caa8868a9b7a",
  "/home/kelvin/dev/ml_posts/blogs_raw/让mathjax更好地兼容谷歌翻译和延时加载.md": "a19bd11b092355942ace8fd3566242ba",
  "/home/kelvin/dev/ml_posts/blogs_raw/搜狐文本匹配基于条件layernorm的多任务baseline.md": "bcd9a90f592759c3f0a662f4bc3f86ae",
  "/home/kelvin/dev/ml_posts/blogs_raw/让炼丹更科学一些三sgd的终.md": "f7ed5a9399c37930153a5665048ecbd2",
  "/home/kelvin/dev/ml_posts/blogs_raw/让炼丹更科学一些二将结论推广.md": "aca23b1b36bce2310d0e3e8b5e930874",
  "/home/kelvin/dev/ml_posts/blogs_raw/一个二值化词向量模型是怎么跟果蝇搭上关系的.md": "d323cd18334cd97d802b8cd2f10c51ce",
  "/home/kelvin/dev/ml_posts/blogs_raw/muon优化器指南快速上手与关键细节.md": "28231218e2f1fd094a9f6408f9a11409",
  "/home/kelvin/dev/ml_posts/blogs_raw/提速不掉点基于词颗粒度的中文wobert.md": "5c115fc407d7268f5ed241afc5c0ec0a",
  "/home/kelvin/dev/ml_posts/blogs_raw/线性注意力简史从模仿创新到反哺.md": "acf1389813cebdbd61039d460cba183b",
  "/home/kelvin/dev/ml_posts/blogs_raw/对抗训练浅谈意义方法和思考附keras实现.md": "352fc2d493d3d8eab3199ea03c5bfda7",
  "/home/kelvin/dev/ml_posts/blogs_raw/用albert和electra之前请确认你真的了解它们.md": "59d3c1695f12019fe7f428af09a9b289",
  "/home/kelvin/dev/ml_posts/blogs_raw/鱼与熊掌兼得融合检索和生成的simbert模型.md": "9a3b2e71b28d3119f29c709c44032839",
  "/home/kelvin/dev/ml_posts/blogs_raw/crf用过了不妨再了解下更快的memm.md": "d17c8d66856fe1906aa24c302b8189b3",
  "/home/kelvin/dev/ml_posts/blogs_raw/gelu的两个初等函数近似是怎么来的.md": "b2be0f605097df925149ceca577f193c",
  "/home/kelvin/dev/ml_posts/blogs_raw/两个多元正态分布的kl散度巴氏距离和w距离.md": "96515826fa8caa07dc15d106c1b12101",
  "/home/kelvin/dev/ml_posts/blogs_raw/中文任务还是sota吗我们给simcse补充了一些实验.md": "ad71b32b19c550ea2c2740dab1bd6941",
  "/home/kelvin/dev/ml_posts/blogs_raw/seq2seq重复解码现象的理论分析尝试.md": "3d4d3925d61edc74b627f034a4232076",
  "/home/kelvin/dev/ml_posts/blogs_raw/为什么deltanet要加l2-n.md": "4e91e45ca7f8d21c7de69ca9fa046171",
  "/home/kelvin/dev/ml_posts/blogs_raw/动手做个dialogpt基于lm的生成式多轮对话模型.md": "42318f66ed041d2e0e219da1c77e3b07",
  "/home/kelvin/dev/ml_posts/blogs_raw/我们真的需要把训练集的损失降低到零吗.md": "776f8118cca4292192b7d62200010567",
  "/home/kelvin/dev/ml_posts/blogs_raw/通过互信息思想来缓解类别不平衡问题.md": "35bd3e0400208e3eed187f9d18c4e436",
  "/home/kelvin/dev/ml_posts/blogs_raw/殊途同归的策略梯度与零阶优化.md": "a1fd651374c9f70e15efe9aa0e0f596a",
  "/home/kelvin/dev/ml_posts/blogs_raw/cool-papers更新简单适配zotero-connector.md": "2335976f35d2f5a7208180a343ae5418",
  "/home/kelvin/dev/ml_posts/blogs_raw/基于树莓派zero2w搭建一个随身旁路由.md": "3b8d0f02cd9fc34375cb8e1fd76a0dbe",
  "/home/kelvin/dev/ml_posts/blogs_raw/用开源的人工标注数据来增强roformer-sim.md": "9eb959a939f74ac6c5b6d30ed2df184d",
  "/home/kelvin/dev/ml_posts/blogs_raw/2020年全年天象.md": "9ebfeb9208d1def5cd706c5336221dac",
  "/home/kelvin/dev/ml_posts/blogs_raw/t5-pegasus开源一个中文生成式预训练模型.md": "4b4d3ef62847af5edbf54f8516b515a5",
  "/home/kelvin/dev/ml_posts/blogs_raw/cool-papers-站内搜索的一些新尝试.md": "e82d14aa0603c76db7f6a8ffb1787f2f",
  "/home/kelvin/dev/ml_posts/blogs_raw/对比学习可以使用梯度累积吗.md": "94dc8f701fa5aea177fab15c7da4a278",
  "/home/kelvin/dev/ml_posts/blogs_raw/从动力学角度看优化算法六为什么simsiam不退化.md": "0aa0ae790d3c0b6c5b81921fa121aa06",
  "/home/kelvin/dev/ml_posts/blogs_raw/生活杂记炒锅的尽头是铁锅.md": "e9d27a185fd70315235e934148d8d306",
  "/home/kelvin/dev/ml_posts/blogs_raw/开局一段扯数据全靠编真被一篇神论文气到了.md": "fa7237dc65ae6efaf42046e361887d91",
  "/home/kelvin/dev/ml_posts/blogs_raw/p-tuning自动构建模版释放语言模型潜能.md": "78ab8c0b82c991516ee8f286357e0dfd",
  "/home/kelvin/dev/ml_posts/blogs_raw/wgan的成功可能跟wasserstein距离没啥关系.md": "c2b2da57045b5caf96b68e9e77bcdd8d",
  "/home/kelvin/dev/ml_posts/blogs_raw/那个屠榜的t5模型现在可以在中文上玩玩了.md": "46aab03b8a4ee848796903ecb6ebdf3d",
  "/home/kelvin/dev/ml_posts/blogs_raw/曾被嫌弃的预训练任务nsp做出了优秀的zero-shot效果.md": "f8bd9fde656288d063faf137d1b87171",
  "/home/kelvin/dev/ml_posts/blogs_raw/nyströmformer基于矩阵分解的线性化attention方案.md": "cacdccd08726c3c0251cbfa59ab13bc8",
  "/home/kelvin/dev/ml_posts/blogs_raw/如何划分一个跟测试集更接近的验证集.md": "db64791f59a8f6f4eb667587248e9cb8",
  "/home/kelvin/dev/ml_posts/blogs_raw/seq2seq中exposure-bias现象的浅析与对策.md": "6db552269b7bbd9e1fac26a01ed12892",
  "/home/kelvin/dev/ml_posts/blogs_raw/google新作synthesizer我们还不够了解自注意力.md": "82e59578ccc1a6afab4618a8436cfd0d",
  "/home/kelvin/dev/ml_posts/blogs_raw/cool-papers浏览器扩展升级至v020.md": "baad0e0865a9a060eb7dd47fdb5bc770",
  "/home/kelvin/dev/ml_posts/blogs_raw/突破瓶颈打造更强大的transformer.md": "d3527e3dd049a7f40ec68d3560dadfd7",
  "/home/kelvin/dev/ml_posts/blogs_raw/你可能不需要bert-flow一个线性变换媲美bert-flow.md": "fff632af80c5ef44c19eab2975658dc7",
  "/home/kelvin/dev/ml_posts/blogs_raw/更便捷的cool-papers打开方式chrome重定向扩展.md": "1cee6690c7a93f6786f3064db7d19423",
  "/home/kelvin/dev/ml_posts/blogs_raw/基于conditional-layer-normalization的条件文本生成.md": "97a8afc4a74cec5a41e4affbe9208bbe",
  "/home/kelvin/dev/ml_posts/blogs_raw/bert可以上几年级了seq2seq硬刚小学数学应用题.md": "c3f66e797afe295ba8eb6b67b5dd5641",
  "/home/kelvin/dev/ml_posts/blogs_raw/个性邮箱.md": "88873da5b4f92e7e322f005016a45432",
  "/home/kelvin/dev/ml_posts/blogs_raw/变分自编码器六从几何视角来理解vae的尝试.md": "09d62b35237400536dde4c5d05c860c3",
  "/home/kelvin/dev/ml_posts/blogs_raw/浅谈transformer的初始化参数化与标准化.md": "83df7953dcdc43eee41c36b7c6563a56",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路5作为无限维的线性attention.md": "c174a14f0d6a6e509e6e1d13713a7646",
  "/home/kelvin/dev/ml_posts/blogs_raw/近乎完美地解决mathjax与marked的冲突.md": "24e857c179ebf98f216775eaac689ec0",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路19第二类旋转位置编码.md": "976b1bad293a95df2acc4d516eac13ee",
  "/home/kelvin/dev/ml_posts/blogs_raw/节省显存的重计算技巧也有了keras版了.md": "df9d15729753ea001c63c0c6ab0e57dd",
  "/home/kelvin/dev/ml_posts/blogs_raw/让炼丹更科学一些四新恒等式.md": "085c1db24df552314928b5a2a906272b",
  "/home/kelvin/dev/ml_posts/blogs_raw/搜出来的文本三基于bert的文本采样.md": "d369a8caefede31e9a2d1f600a2e7b6e",
  "/home/kelvin/dev/ml_posts/blogs_raw/关于维度公式n-833-log-n的可用性分析.md": "4f0215173a29efb4cb40fb9ee5305fed",
  "/home/kelvin/dev/ml_posts/blogs_raw/智能家居之热水器零冷水技术原理浅析.md": "6bffa1afb62b67276f124f7661b6e07a",
  "/home/kelvin/dev/ml_posts/blogs_raw/智能家居之手搓一套能接入米家的零冷水装置.md": "a6b52498833d6e858c4942ef6e8771da",
  "/home/kelvin/dev/ml_posts/blogs_raw/变分自编码器七球面上的vaevmf-vae.md": "92ec559aab2a4f522be224ec87d20c55",
  "/home/kelvin/dev/ml_posts/blogs_raw/写了个刷论文的辅助网站cool-papers.md": "7d9411647c819b6cacb9a85e609cb072",
  "/home/kelvin/dev/ml_posts/blogs_raw/从动力学角度看优化算法五为什么学习率不宜过小.md": "3f587836f27f81c0e1de2656a8549d60",
  "/home/kelvin/dev/ml_posts/blogs_raw/mitchell近似乘法变为加法误差不超过19.md": "97ed0fccbb1042dbe44f581f5c7e9f81",
  "/home/kelvin/dev/ml_posts/blogs_raw/又是dropout两次这次它做到了有监督任务的sota.md": "39ba910702d6891b438668328e27ab91",
  "/home/kelvin/dev/ml_posts/blogs_raw/层次分解位置编码让bert可以处理超长文本.md": "2a36e221ec3dd5d762b707546d7e1536",
  "/home/kelvin/dev/ml_posts/blogs_raw/从一个单位向量变换到另一个单位向量的正交矩阵.md": "6c574d9558000789e6d467b1536024a2",
  "/home/kelvin/dev/ml_posts/blogs_raw/必须要gpt3吗不bert的mlm模型也能小样本学习.md": "f43660fc1622c06860656ce0310581f1",
  "/home/kelvin/dev/ml_posts/blogs_raw/非自回归也不差基于mlm的阅读理解问答.md": "e6797bc0b8f76c994e34174c28bf3ecb",
  "/home/kelvin/dev/ml_posts/blogs_raw/teaforn让teacher-forcing更有远见一些.md": "bbf7ba753e9fdb60df18e930c5f917fd",
  "/home/kelvin/dev/ml_posts/blogs_raw/万能的seq2seq基于seq2seq的阅读理解问答.md": "5960474d8af4e3d34196544506dc730c",
  "/home/kelvin/dev/ml_posts/blogs_raw/苏剑林-x与单位阵的平均平方误差mse作为它跟单位阵的差距有什.md": "15fbcc569a743f155b6794a8be6cb4f6",
  "/home/kelvin/dev/ml_posts/blogs_raw/苏剑林-是梯度均值为零的假设这个问题不是在数值模拟一节讨论过了吗.md": "da5cf2c3867e6482b59bbe5a5b88a9dd",
  "/home/kelvin/dev/ml_posts/blogs_raw/搜出来的文本二从mcmc到模拟退火.md": "c074ff34ee56bd7e3662c1aea7b49d5e",
  "/home/kelvin/dev/ml_posts/blogs_raw/realformer把残差转移到attention矩阵上面去.md": "f1cb5bc37593392a97f928ca2e6f387d",
  "/home/kelvin/dev/ml_posts/blogs_raw/再谈类别不平衡问题调节权重与魔改loss的对比联系.md": "c7e4836c6418fd5296d8e2ce4c0f964f",
  "/home/kelvin/dev/ml_posts/blogs_raw/搜出来的文本一从文本生成到搜索采样.md": "0d83b0af3d97107b5b7a706995c90852",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈三十一预测数.md": "501d56876ebd6ee59300276823ccd550",
  "/home/kelvin/dev/ml_posts/blogs_raw/线性transformer应该不是你要等的那个模型.md": "5fa270a979fc5c5376b60cc3e06f9cff",
  "/home/kelvin/dev/ml_posts/blogs_raw/抛开约束增强模型一行代码提升albert表现.md": "b30e9fa38f59b6469f62ecd650bf79d6",
  "/home/kelvin/dev/ml_posts/blogs_raw/也来谈谈rnn的梯度消失爆炸问题.md": "7f292daa7b8de0d17db43682b0114557",
  "/home/kelvin/dev/ml_posts/blogs_raw/有限内存下全局打乱几百g文件python.md": "2964bc962f04d6700d866e7e2244a776",
  "/home/kelvin/dev/ml_posts/blogs_raw/l2正则没有想象那么好可能是权重尺度偏移惹的祸.md": "f4edb8aa641130747007da357b42c5e9",
  "/home/kelvin/dev/ml_posts/blogs_raw/观测iss.md": "cf00d0606c9968d5b1691a3ba143b79e",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路3从performer到线性attention.md": "605c846f1acabbdf9bbd4a7bb734eb0b",
  "/home/kelvin/dev/ml_posts/blogs_raw/让人惊叹的johnson-lindenstrauss引理应用篇.md": "2ab004215c5e836e762a04691bc6cc4f",
  "/home/kelvin/dev/ml_posts/blogs_raw/univae基于transformer的单模型多尺度的vae模型.md": "495688d4acb1fc6edca3fe5e4b65aa93",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路4二维位置的旋转式位置编码.md": "c8a55665c75e009c730eafcf49aec15d",
  "/home/kelvin/dev/ml_posts/blogs_raw/用bert4keras做三元组抽取.md": "0529e93ced308c994cbe315f60ee15ba",
  "/home/kelvin/dev/ml_posts/blogs_raw/让人惊叹的johnson-lindenstrauss引理理论篇.md": "890276326281bb21ecdee5a188082a1f",
  "/home/kelvin/dev/ml_posts/blogs_raw/printemps-苏神怎么看log-linear-attention这种变长的h.md": "e7b4191e0f357048566596dcda10374e",
  "/home/kelvin/dev/ml_posts/blogs_raw/智能家居之小爱同学控制极米投影仪的简单方案.md": "1f6876a74555b51a68cff2956f5c71b8",
  "/home/kelvin/dev/ml_posts/blogs_raw/eae自编码器-bn-最大熵-生成模型.md": "578ef008d9ebce137bf1d0d4964f7a37",
  "/home/kelvin/dev/ml_posts/blogs_raw/designing-gans又一个gan生产车间.md": "1484c6d3ebee7500679730cc1891829a",
  "/home/kelvin/dev/ml_posts/blogs_raw/学会提问的bert端到端地从篇章中构建问答对.md": "b14f5822684e00c1baa51ead396c3b0a",
  "/home/kelvin/dev/ml_posts/blogs_raw/生活杂记用电饭锅来煮米汤.md": "330684011b5f31e07f133e017176af35",
  "/home/kelvin/dev/ml_posts/blogs_raw/将softmax交叉熵推广到多标签分类问题.md": "264f842e0d2f2b60cc4791fd9d36df97",
  "/home/kelvin/dev/ml_posts/blogs_raw/泛化性乱弹从随机噪声梯度惩罚到虚拟对抗训练.md": "d66c15972b48bbc04e60712d0ab6dfba",
  "/home/kelvin/dev/ml_posts/blogs_raw/短文本匹配baseline脱敏数据使用预训练模型的尝试.md": "72bbb932e3e69edfd2e9a95336dd378c",
  "/home/kelvin/dev/ml_posts/blogs_raw/我们可以无损放大一个transformer模型吗一.md": "ad528cbb1cb6b13e49efbe95e1ce0102",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路2博采众长的旋转式位置编码.md": "1dab9ae9b06688df60295b6ea0ed4de3",
  "/home/kelvin/dev/ml_posts/blogs_raw/globalpointer用统一的方式处理嵌套和非嵌套ner.md": "46084870d6c1e88d5b30aae2bd7c46b6",
  "/home/kelvin/dev/ml_posts/blogs_raw/expx在x0处的偶次泰勒展开式总是正的.md": "e7cd2f9d61d2e37db711351f431625ec",
  "/home/kelvin/dev/ml_posts/blogs_raw/cool-papers更新简单搭建了一个站内检索系统.md": "395a112ed3e1358d615d3e22b9ae2fbf",
  "/home/kelvin/dev/ml_posts/blogs_raw/搜出来的文本四通过增删改来用词造句.md": "eaeafe110507c91538e9dc2968d37a80",
  "/home/kelvin/dev/ml_posts/blogs_raw/spaces抽取-生成式长文本摘要法研杯总结.md": "bad82806f27949fa8aae6dc9b53e2e79",
  "/home/kelvin/dev/ml_posts/blogs_raw/旁门左道之如何让python的重试代码更加优雅.md": "8df1a9975ea1396e3b8b44250f2eea18",
  "/home/kelvin/dev/ml_posts/blogs_raw/苏剑林-相对位置编码似乎没有太多选择了要不rope这种算是乘性了.md": "2eeeacc3096860a03a7d74ba8294a258",
  "/home/kelvin/dev/ml_posts/blogs_raw/隐藏在动量中的梯度累积少更新几步效果反而更好.md": "75f1ea9fdeabcabc38e54f3475c7128c",
  "/home/kelvin/dev/ml_posts/blogs_raw/从动力学角度看优化算法七sgd-svm.md": "347d5a2c3c68e4483d25ec6b5b7ed9e8",
  "/home/kelvin/dev/ml_posts/blogs_raw/performer用随机投影将attention的复杂度线性化.md": "c6ca8fac187d9e7ac654f5b59b9de30e",
  "/home/kelvin/dev/ml_posts/blogs_raw/线性attention的探索attention必须有个softmax吗.md": "4af146d424988091267325d4fc1e0a23",
  "/home/kelvin/dev/ml_posts/blogs_raw/从采样看优化可导优化与不可导优化的统一视角.md": "b60522ce50f2aa73ea0ae8694ae0297b",
  "/home/kelvin/dev/ml_posts/blogs_raw/让mathjax的数学公式随窗口大小自动缩放.md": "8a296d61e2c6d8b73e8ddff7f8775a68",
  "/home/kelvin/dev/ml_posts/blogs_raw/第1000篇文章.md": "c3ec688017c7250e1e4a8a5356e0df7f",
  "/home/kelvin/dev/ml_posts/blogs_raw/积分梯度一种新颖的神经网络可视化方法.md": "87fb478c3e855d8edd7df1b41652de20",
  "/home/kelvin/dev/ml_posts/blogs_raw/利用熄火保护-通断器实现燃气灶智能关火.md": "e97efc03228e7e4377378e08872d0f52",
  "/home/kelvin/dev/ml_posts/blogs_raw/滑动平均视角下的权重衰减和学习率.md": "382d80794969a77acd23a9319c338d91",
  "/home/kelvin/dev/ml_posts/blogs_raw/adafactor优化器浅析附开源实现.md": "b9f380e882a4a43c3ae283910bc4bf10",
  "/home/kelvin/dev/ml_posts/blogs_raw/日食记.md": "60e047823c3186206bc2f18ede708bbb",
  "/home/kelvin/dev/ml_posts/blogs_raw/从三角不等式到margin-softmax.md": "da635c475d194d3967702e932a11fc0d",
  "/home/kelvin/dev/ml_posts/blogs_raw/你的crf层的学习率可能不够大.md": "a4a5cb5455d86f9db4d11b0c3dc2323f",
  "/home/kelvin/dev/ml_posts/blogs_raw/无监督语义相似度哪家强我们做了个比较全面的评测.md": "45b541bbccfb44c6ad1f67e92846fc1e",
  "/home/kelvin/dev/ml_posts/blogs_raw/强大的nvae以后再也不能说vae生成的图像模糊了.md": "3d1a4863b6c350f74b53f2bdbc9b1df0",
  "/home/kelvin/dev/ml_posts/blogs_raw/龟鱼记全陶粒的同程底滤生态缸.md": "9c1fab14ba4caa928ccabb6442bb375b",
  "/home/kelvin/dev/ml_posts/blogs_raw/self-orthogonality-module一个即插即用的核正交化模块.md": "dba06c22ecd5e180fffacf7cb7457199",
  "/home/kelvin/dev/ml_posts/blogs_raw/为什么梯度裁剪能加速训练过程一个简明的分析.md": "3f7c212c50d0399279534e1d2d88dec7",
  "/home/kelvin/dev/ml_posts/blogs_raw/simbertv2来了融合检索和生成的roformer-sim模型.md": "3a66d1887c630a27ed5700c0d1f11f5a",
  "/home/kelvin/dev/ml_posts/blogs_raw/现在可以用keras玩中文gpt2了gpt2-ml.md": "f15771de68456da5cc16491d529f42e0",
  "/home/kelvin/dev/ml_posts/blogs_raw/flatnce小批次对比学习效果差的原因竟是浮点误差.md": "bcf265674c7ed446c239bb6c8996df09",
  "/home/kelvin/dev/ml_posts/blogs_raw/adax优化器浅析附开源实现.md": "75248f2b1c6db3e01776af8b8a7f6a1b",
  "/home/kelvin/dev/ml_posts/blogs_raw/adamw的weight-rms的渐近估计上.md": "be82c5359293abd42842b3e9ec31afe9",
  "/home/kelvin/dev/ml_posts/blogs_raw/概率视角下的线性模型逻辑回归有解析解吗.md": "5ceab6332ef112f42038a14827ddd732",
  "/home/kelvin/dev/ml_posts/blogs_raw/也来扯几句全国青少年科技创新大赛.md": "6f65f7a2eb61b0750d1d84836d478b1d",
  "/home/kelvin/dev/ml_posts/blogs_raw/关于whiteningbert原创性的疑问和沟通.md": "6de44bb04fbcc584994f8592224edd51",
  "/home/kelvin/dev/ml_posts/blogs_raw/也来盘点一些最近的非transformer工作.md": "7c7611a1cd7df8bdbd0596e90b8eadf9",
  "/home/kelvin/dev/ml_posts/blogs_raw/变分自编码器五vae-bn-更好的vae.md": "ca5f797ae438148f6abe7bccebcbe800",
  "/home/kelvin/dev/ml_posts/blogs_raw/苏剑林-从公式12到公式15都在推导和解释你说的这个.md": "6aab2b0c3fb386bdcfc62632ff68b054",
  "/home/kelvin/dev/ml_posts/blogs_raw/当gpt遇上中国象棋写过文章解过题要不再来下盘棋.md": "17beeecb8837cfc7cb30ab6ffa8335ed",
  "/home/kelvin/dev/ml_posts/blogs_raw/无监督分词和句法分析原来bert还可以这样用.md": "849ac602654425f90501e98898fa0e31",
  "/home/kelvin/dev/ml_posts/blogs_raw/bert-of-theseus基于模块替换的模型压缩方法.md": "d96ed7ffcda3b69e9039f0e33f515f6d",
  "/home/kelvin/dev/ml_posts/blogs_raw/如何应对seq2seq中的根本停不下来问题.md": "ff8e032c01f3f59e153d07956f818f11",
  "/home/kelvin/dev/ml_posts/blogs_raw/最小熵原理六词向量的维度应该怎么选择.md": "e4061f3f9924405e45b40dede4e59331",
  "/home/kelvin/dev/ml_posts/blogs_raw/新年快乐记录一下-cool-papers-的开发体验.md": "0d68d8038848311e7b0ef7da9933bb58",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路1sinusoidal位置编码追根溯源.md": "21939533be03be04a871a343b71640eb",
  "/home/kelvin/dev/ml_posts/blogs_raw/跟风玩玩目前最大的中文gpt2模型bert4keras.md": "c2749bdc1dacc8a7000b004a74c7bf2f",
  "/home/kelvin/dev/ml_posts/blogs_raw/修改transformer结构设计一个更快更好的mlm模型.md": "1b1e3dba58680dfdaa4e26f2024d0d70",
  "/home/kelvin/dev/ml_posts/blogs_raw/用狄拉克函数来构造非光滑函数的光滑近似.md": "df65464b302e28ff88e3c517a7b486a4",
  "/home/kelvin/dev/ml_posts/blogs_raw/初始化方法中非方阵的维度平均策略思考.md": "d3be76c10b07b62674123551ad0dd5ca",
  "/home/kelvin/dev/ml_posts/blogs_raw/can借助先验分布提升分类性能的简单后处理技巧.md": "278e9ca9c1ea259d51bc0342910f9d4b",
  "/home/kelvin/dev/ml_posts/blogs_raw/bert4keras在手baseline我有clue基准代码.md": "13c269621a300e86316c03d4b15f9745",
  "/home/kelvin/dev/ml_posts/blogs_raw/模型优化漫谈bert的初始标准差为什么是002.md": "8c7b32850aa810d6025abbe6d5cdf004",
  "/home/kelvin/dev/ml_posts/blogs_raw/wgan新方案通过梯度归一化来实现l约束.md": "79ee38f2e341b6d2f52ab2f2df14a15c",
  "/home/kelvin/dev/ml_posts/blogs_raw/childtuning试试把dropout加到梯度上去.md": "5780c7994c1ef7442bc42ca7a18f1de3",
  "/home/kelvin/dev/ml_posts/blogs_raw/dropout视角下的mlm和mae一些新的启发.md": "d61e9822d7e12dacb1a7520f1d277c25",
  "/home/kelvin/dev/ml_posts/blogs_raw/变分自编码器八估计样本概率密度.md": "25965ca0c053718aec85ceb508e00216",
  "/home/kelvin/dev/ml_posts/blogs_raw/输入梯度惩罚与参数梯度惩罚的一个不等式.md": "8aefce07b9ce1f96c2fe74d6330ce809",
  "/home/kelvin/dev/ml_posts/blogs_raw/seq2seq前缀树检索任务新范式以kgclue为例.md": "f59394ff6430a5d93e497e9f0f9044f6",
  "/home/kelvin/dev/ml_posts/blogs_raw/从熵不变性看attention的scale操作.md": "718853f2d823f25f65cd282b03017189",
  "/home/kelvin/dev/ml_posts/blogs_raw/概率分布的熵归一化entropy-normalization.md": "4f5c455b1e430dc45770fc65a64b7ff2",
  "/home/kelvin/dev/ml_posts/blogs_raw/squareplus可能是运算最简单的relu光滑近似.md": "ed2ba589142207157dc81b4702d2e27e",
  "/home/kelvin/dev/ml_posts/blogs_raw/cosent一比sentence-bert更有效的句向量方案.md": "f9eedf77c5eeaf57b7e8042f0dba882b",
  "/home/kelvin/dev/ml_posts/blogs_raw/cosent二特征式匹配与交互式匹配有多大差距.md": "d21a499ed0f5beb732d56db638cc3d29",
  "/home/kelvin/dev/ml_posts/blogs_raw/多任务学习漫谈一以损失之名.md": "34cf3b9fbac23752a8c204767949fb2d",
  "/home/kelvin/dev/ml_posts/blogs_raw/efficient-globalpointer少点参数多点效果.md": "1da084ffa0aa8fefa7b1fd5055b07935",
  "/home/kelvin/dev/ml_posts/blogs_raw/gplinker基于globalpointer的实体关系联合抽取.md": "55687caa8b5fac120f19407fcf13e045",
  "/home/kelvin/dev/ml_posts/blogs_raw/多任务学习漫谈二行梯度之事.md": "ddf0ad6f15048a15c35467447260a7c3",
  "/home/kelvin/dev/ml_posts/blogs_raw/多任务学习漫谈三分主次之序.md": "a420226842df4d22c56f186d944ec494",
  "/home/kelvin/dev/ml_posts/blogs_raw/gplinker基于globalpointer的事件联合抽取.md": "7b1795595eca5e28ae2d4f31e7c30fc4",
  "/home/kelvin/dev/ml_posts/blogs_raw/flash可能是近来最有意思的高效transformer设计.md": "1e78072b69bb43bc7e9eb84c4f68f964",
  "/home/kelvin/dev/ml_posts/blogs_raw/指数梯度下降-元学习-自适应学习率.md": "65ee37fd2e4180ac98eda6a877829e6f",
  "/home/kelvin/dev/ml_posts/blogs_raw/训练1000层的transformer究竟有什么困难.md": "3cea8c4db701a76d299de27f8477ed56",
  "/home/kelvin/dev/ml_posts/blogs_raw/门控注意力单元gau还需要warmup吗.md": "9e05926b13abc9449dc487d21fc18777",
  "/home/kelvin/dev/ml_posts/blogs_raw/为什么需要残差一个来自deepnet的视角.md": "e0d35a6f1d22db284916bf410180988e",
  "/home/kelvin/dev/ml_posts/blogs_raw/roformerv2自然语言理解的极限探索.md": "0ecc8ce4154ac734ba88254384df3df0",
  "/home/kelvin/dev/ml_posts/blogs_raw/为什么pre-norm的效果不如post-norm.md": "24c40c60c77e8506c52de1ac4f3da63f",
  "/home/kelvin/dev/ml_posts/blogs_raw/听说attention与softmax更配哦.md": "f8e530bf5a67215a705fe75ba052bb69",
  "/home/kelvin/dev/ml_posts/blogs_raw/熵不变性softmax的一个快速推导.md": "b7f487e171b6678dcb69290fecea1005",
  "/home/kelvin/dev/ml_posts/blogs_raw/globalpointer下的kl散度应该是怎样的.md": "54dc6ffb560d96271a0d475c92e7e76b",
  "/home/kelvin/dev/ml_posts/blogs_raw/你的语言模型有没有无法预测的词.md": "fbe61da72ca9d7b6f3636d860da9203b",
  "/home/kelvin/dev/ml_posts/blogs_raw/gau-α尝鲜体验快好省的下一代attention.md": "fe16964a0da626e8fcc623a6e2286187",
  "/home/kelvin/dev/ml_posts/blogs_raw/在bert4keras中使用混合精度和xla加速训练.md": "adc4bb9948ad5992f5890a4b49f7c644",
  "/home/kelvin/dev/ml_posts/blogs_raw/多标签softmax交叉熵的软标签版本.md": "06a1cb013b633bfebea05c0f34d3e313",
  "/home/kelvin/dev/ml_posts/blogs_raw/logsumexp运算的几个不等式.md": "8f590b670b70e8bf69165e0227ba8d07",
  "/home/kelvin/dev/ml_posts/blogs_raw/当bert-whitening引入超参数总有一款适合你.md": "77d887fcd00ae980befafd045371b1ce",
  "/home/kelvin/dev/ml_posts/blogs_raw/从重参数的角度看离散概率分布的构建.md": "83249445bdc6ad1c96a10c9befd2f0c7",
  "/home/kelvin/dev/ml_posts/blogs_raw/如何训练你的准确率.md": "a97b5763f2df10e01ec35b4bb5437d7a",
  "/home/kelvin/dev/ml_posts/blogs_raw/相对位置编码transformer的一个理论缺陷与对策.md": "613c876c5c98fa7038ce876c4bcf1ead",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈一ddpm-拆楼-建楼.md": "610b230935ba7f40ac575e0f4da25bbc",
  "/home/kelvin/dev/ml_posts/blogs_raw/ladder-side-tuning预训练模型的过墙梯.md": "50ecd96b8e6fe8d5ed68304200c55b9c",
  "/home/kelvin/dev/ml_posts/blogs_raw/维度灾难之hubness现象浅析.md": "b6892349a00d9f8820ba7863f02b3057",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈二ddpm-自回归式vae.md": "fffd90cd8ba9bf7823a55f5139c9c2b9",
  "/home/kelvin/dev/ml_posts/blogs_raw/不成功的尝试将多标签交叉熵推广到n个m分类上去.md": "36b2875d06cfc9b313ed3faf1d33228f",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈三ddpm-贝叶斯-去噪.md": "bf86aee6c8a96a94d7be705fae08ee09",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈四ddim-高观点ddpm.md": "6d514ebf2793ee111d2d393eadefab17",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈五一般框架之sde篇.md": "adc66e7b5e1c64ae31be873346282d0e",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈六一般框架之ode篇.md": "23c76ac9d14895590c7a0cff78a25233",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈七最优扩散方差估计上.md": "6487901c4726a01147d25ae3297d6202",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈八最优扩散方差估计下.md": "10b39de7de3ccc8fc6a6c7f52c34557d",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈九条件控制生成结果.md": "28f3b6aaeafb2458fd8d2a7da49206a7",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈十统一扩散模型理论篇.md": "7ee6604048bd292b3cf8a2a5c7d79697",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈十一统一扩散模型应用篇.md": "68193ac79d3689c534193209222347df",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈十二硬刚扩散ode.md": "535e0fe7bfdb37fddc8c77def1aa5957",
  "/home/kelvin/dev/ml_posts/blogs_raw/十字架组合计数问题浅试.md": "fa1473517bb5ecb33aeee1a980a78ac9",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈十三从万有引力到扩散模型.md": "2ac880aa5bf4344d31b7bcdaf5d01126",
  "/home/kelvin/dev/ml_posts/blogs_raw/圆内随机n点在同一个圆心角为θ的扇形的概率.md": "e08f7950a26b939334b68753892fc143",
  "/home/kelvin/dev/ml_posts/blogs_raw/利用cur分解加速交互式相似度模型的检索.md": "500b8369ce7ddd581761b5cb2bc67d72",
  "/home/kelvin/dev/ml_posts/blogs_raw/cosent三作为交互式相似度的损失函数.md": "515567719d9e76688517b21d0c0b52ea",
  "/home/kelvin/dev/ml_posts/blogs_raw/基于amos优化器思想推导出来的一些炼丹策略.md": "c253be79108b04dcd7d9d1f83074898a",
  "/home/kelvin/dev/ml_posts/blogs_raw/用热传导方程来指导自监督学习.md": "569a1722f8961afca1403c8ce8b19a75",
  "/home/kelvin/dev/ml_posts/blogs_raw/从局部到全局语义相似度的测地线距离.md": "9dcaddf16e024365a91b37e2b11e86a4",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈十四构建ode的一般步骤上.md": "e4357286f9024c5a2564376a893d6ced",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈十五构建ode的一般步骤中.md": "968d3b24996c634e21eae8b776394353",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路6旋转位置编码的完备性分析.md": "e0ec5527470a08547b59919ab2a54eea",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路7长度外推性与局部注意力.md": "1a1be13bd7e4d2ede23976f41f077af9",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路8长度外推性与位置鲁棒性.md": "5c36904dd4d8cf859237be2c4495c3c9",
  "/home/kelvin/dev/ml_posts/blogs_raw/测试函数法推导连续性方程和fokker-planck方程.md": "ad37092f5fd6247f294e5c9c3be4b4e0",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈十六w距离-得分匹配.md": "42af7ff4dc46228857b11c52f9f375c2",
  "/home/kelvin/dev/ml_posts/blogs_raw/google新搜出的优化器lion效率与效果兼得的训练狮.md": "d89870a3b5ab418b2689733c40de5f71",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈十七构建ode的一般步骤下.md": "efd8efedc25ba216f409b15bfc293223",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈十八得分匹配-条件得分匹配.md": "1b9861134cb539e5d5695c46a19b9d13",
  "/home/kelvin/dev/ml_posts/blogs_raw/tiger一个抠到极致的优化器.md": "2ae5101c4fde7e305794c2d3707ef9ef",
  "/home/kelvin/dev/ml_posts/blogs_raw/缓解交叉熵过度自信的一个简明方案.md": "82d2d4d73bad1ce9112143fa2a231469",
  "/home/kelvin/dev/ml_posts/blogs_raw/为什么现在的llm都是decoder-only的架构.md": "b457d8bc75f369582a79aaf9a8d16cc3",
  "/home/kelvin/dev/ml_posts/blogs_raw/为什么现在的llm都是decoder-only的架构faq.md": "059ac1d6309f1b5ac0ea90f7d17c1f8b",
  "/home/kelvin/dev/ml_posts/blogs_raw/google新作试图复活rnnrnn能否再次辉煌.md": "f964ff283f89059d4d89f99e6b754642",
  "/home/kelvin/dev/ml_posts/blogs_raw/bias项的神奇作用rope-bias-更好的长度外推性.md": "ecd11fa816769fc6fc843e89603bada4",
  "/home/kelvin/dev/ml_posts/blogs_raw/从jl引理看熵不变性attention.md": "92a63012293699d41a637e0b9d70165c",
  "/home/kelvin/dev/ml_posts/blogs_raw/梯度视角下的lora简介分析猜测及推广.md": "752659a5177ac03fdf39a4c151c49159",
  "/home/kelvin/dev/ml_posts/blogs_raw/注意力和softmax的两点有趣发现鲁棒性和信息量.md": "f57be27a876f916e7cbad8265bc8f625",
  "/home/kelvin/dev/ml_posts/blogs_raw/如何度量数据的稀疏程度.md": "df7407af8d951e63167713b277554812",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路9一种全局长度外推的新思路.md": "3c5b78695ebf2371525184eaeddc5fdf",
  "/home/kelvin/dev/ml_posts/blogs_raw/基于量子化假设推导模型的尺度定律scaling-law.md": "3865a6b96a7bef04ffa8c7572718a411",
  "/home/kelvin/dev/ml_posts/blogs_raw/nbce使用朴素贝叶斯扩展llm的context处理长度.md": "916f4ab416a75d96989cca3d4acfbec5",
  "/home/kelvin/dev/ml_posts/blogs_raw/关于nbce方法的一些补充说明和分析.md": "e4873138a05661acce8b2e7d3e902dd8",
  "/home/kelvin/dev/ml_posts/blogs_raw/naive-bayes-is-all-you-need.md": "82981fed9e62e7f96d59edad87a1ef5a",
  "/home/kelvin/dev/ml_posts/blogs_raw/梯度流探索通向最小值之路.md": "aed2d264fda382fdcc853643847ff190",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈十九作为扩散ode的gan.md": "4c195c36d7df00204e17d553f9ac206e",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈二十从reflow到wgan-gp.md": "c863c693437590158f51604feeec81c7",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路10rope是一种β进制编码.md": "88b903e0bdcd6a17bd50594b874e54c6",
  "/home/kelvin/dev/ml_posts/blogs_raw/当生成模型肆虐互联网将有疯牛病之忧.md": "b65565577de69741ff61c5be6460f556",
  "/home/kelvin/dev/ml_posts/blogs_raw/语言模型输出端共享embedding的重新探索.md": "4831dd1d7a6a39d979bcae0d01601021",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路11将β进制位置进行到底.md": "f4cb44bba8891e50a94b9528fe1876d4",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路12无限外推的rerope.md": "2a90e762988a570db35a55677ffc0f08",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路13逆用leaky-rerope.md": "656902a7885fe0d73e2908a5896d3e93",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路14当hwfa遇见rerope.md": "d7089a66c8d1502a49e510790a95109e",
  "/home/kelvin/dev/ml_posts/blogs_raw/liontiger优化器训练下的embedding异常和对策.md": "94377d46eefab44d39b93593051cc62d",
  "/home/kelvin/dev/ml_posts/blogs_raw/bytepiece更纯粹更高压缩率的tokenizer.md": "dd29602631c47bae456bb4933e18bf87",
  "/home/kelvin/dev/ml_posts/blogs_raw/大词表语言模型在续写任务上的一个问题及对策.md": "1c9a8fbc6775da99760931ca5436e4c0",
  "/home/kelvin/dev/ml_posts/blogs_raw/随机分词浅探从viterbi-decoding到viterbi-sampling.md": "1d23fb799792348627da155ef1606b8a",
  "/home/kelvin/dev/ml_posts/blogs_raw/自然数集中-n-ab-c-时-a-b-c-的最小值.md": "2941540c2aa37500de40b979b038db3c",
  "/home/kelvin/dev/ml_posts/blogs_raw/脑洞大开非线性rnn居然也可以并行计算.md": "f3994a6e264b039c505cc70af65d7051",
  "/home/kelvin/dev/ml_posts/blogs_raw/预训练一下transformer的长序列成绩还能涨不少.md": "dc07d5c8cdf9b210475f3b7d97a588bd",
  "/home/kelvin/dev/ml_posts/blogs_raw/emo基于最优传输思想设计的分类损失函数.md": "17cee030f146c6df044ed73c9ea19063",
  "/home/kelvin/dev/ml_posts/blogs_raw/随机分词再探从viterbi-sampling到完美采样算法.md": "807fd3148ebc5c9078c5dcb84b1a35ff",
  "/home/kelvin/dev/ml_posts/blogs_raw/从梯度最大化看attention的scale操作.md": "e59f37480c2217150381b81cd78cfdf6",
  "/home/kelvin/dev/ml_posts/blogs_raw/简单得令人尴尬的fsq四舍五入超越了vq-vae.md": "18420af324f598083ac752f62a0280c7",
  "/home/kelvin/dev/ml_posts/blogs_raw/vq一下keytransformer的复杂度就变成线性了.md": "73597fc080e581670da6bf3095380918",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路15key归一化助力长度外推.md": "1cccbdb23073ef3a406d5add104dbfa2",
  "/home/kelvin/dev/ml_posts/blogs_raw/我在performer中发现了transformer-vq的踪迹.md": "6c92f68059a970b1c84b3d49c605ade5",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈二十一中值定理加速ode采样.md": "7e25349fdf519414c6396fc3e827aec6",
  "/home/kelvin/dev/ml_posts/blogs_raw/通向概率分布之路盘点softmax及其替代品.md": "b09f88f0e8d830696a8ebf170adda2b2",
  "/home/kelvin/dev/ml_posts/blogs_raw/注意力机制真的可以集中注意力吗.md": "36c23b8b34d050ea71199f1e14f8b60c",
  "/home/kelvin/dev/ml_posts/blogs_raw/让炼丹更科学一些一sgd的平均损失收敛.md": "93227806a3c616b9623a4e907025b90e",
  "/home/kelvin/dev/ml_posts/blogs_raw/局部余弦相似度大全局余弦相似度一定也大吗.md": "11ed65db6b08e1a9e85c04fa6960ad74",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路16复盘长度外推技术.md": "0be62099ffad65a13ea5f29f56dd7833",
  "/home/kelvin/dev/ml_posts/blogs_raw/幂等生成网络ign试图将判别和生成合二为一的gan.md": "046bff9c50a23842057cbb157543adaa",
  "/home/kelvin/dev/ml_posts/blogs_raw/闭门造车之多模态思路浅谈一无损输入.md": "362dcb69e7bb1485d78dd3a4a97c8f8d",
  "/home/kelvin/dev/ml_posts/blogs_raw/配置不同的学习率lora还能再涨一点.md": "6399c6c9234403fa7cf149340f6f8d74",
  "/home/kelvin/dev/ml_posts/blogs_raw/用傅里叶级数拟合一维概率密度函数.md": "b5a6ecb5a2835fe5f05439310caa636f",
  "/home/kelvin/dev/ml_posts/blogs_raw/时空之章将attention视为平方复杂度的rnn.md": "06b50cc689277201fa22d9f28ee9bf50",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路17多模态位置编码的简单思考.md": "f36889f4bbecc8711f67e56c30e317c6",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈二十二信噪比与大图生成上.md": "ce5b24cdf249cbf7f0a07e64c1c83b31",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈二十三信噪比与大图生成下.md": "7206d9f3da2293b792a1a5e36a7871cd",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈二十四少走捷径更快到达.md": "f7f56069b6bcf9885df1926ae5a9c6d0",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈二十五基于恒等式的蒸馏上.md": "32ebf7fe610d614d3c279d082ae74ad7",
  "/home/kelvin/dev/ml_posts/blogs_raw/缓存与效果的极限拉扯从mhamqagqa到mla.md": "51e32f0630fa9d3878f421636eaac37c",
  "/home/kelvin/dev/ml_posts/blogs_raw/重温ssm一线性系统和hippo矩阵.md": "daab69b0e788f36e9a363e5a7d7df29a",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路18rope的底数选择原则.md": "768ac5569711d8cafdc0160f9b7b8775",
  "/home/kelvin/dev/ml_posts/blogs_raw/重温ssm二hippo的一些遗留问题.md": "6485d6d8a3213b8a47a4fbd113ab565f",
  "/home/kelvin/dev/ml_posts/blogs_raw/重温ssm三hippo的高效计算s4.md": "d583ed0cc513bd51828b9c4183c4f776",
  "/home/kelvin/dev/ml_posts/blogs_raw/重温ssm四有理生成函数的新视角.md": "193f69a26e4d0b6f0d7d2d74c3e5e200",
  "/home/kelvin/dev/ml_posts/blogs_raw/闭门造车之多模态思路浅谈二自回归.md": "d7becb9b2e0a94266a345ade4d683b89",
  "/home/kelvin/dev/ml_posts/blogs_raw/对齐全量微调这是我看过最精彩的lora改进一.md": "933c16bcb7086b5cb72a6307f8205b46",
  "/home/kelvin/dev/ml_posts/blogs_raw/monarch矩阵计算高效的稀疏型矩阵分解.md": "33b4213d6be0b17a482e0c183e2edcb9",
  "/home/kelvin/dev/ml_posts/blogs_raw/对齐全量微调这是我看过最精彩的lora改进二.md": "9a756636eb1019b19b6b79710c6cd8f7",
  "/home/kelvin/dev/ml_posts/blogs_raw/通向最优分布之路概率空间的最小化.md": "119cec9cc7e470ea7dc4faa29510ee3f",
  "/home/kelvin/dev/ml_posts/blogs_raw/decoder-only的llm为什么需要位置编码.md": "035739450a29500e9c3cbc6ba8d21582",
  "/home/kelvin/dev/ml_posts/blogs_raw/闭门造车之多模态思路浅谈三位置编码.md": "b65499aec2735aba43b0caf50df96fd4",
  "/home/kelvin/dev/ml_posts/blogs_raw/低秩近似之路一伪逆.md": "78d1e27625537db8a779056383b3179e",
  "/home/kelvin/dev/ml_posts/blogs_raw/softmax后传寻找top-k的光滑近似.md": "7b5a96aa49c93391e198080545b14488",
  "/home/kelvin/dev/ml_posts/blogs_raw/低秩近似之路二svd.md": "df93a72289102e046b6d986304734244",
  "/home/kelvin/dev/ml_posts/blogs_raw/低秩近似之路三cr.md": "90a0c6b04023fc7f72fb723b4a4ba080",
  "/home/kelvin/dev/ml_posts/blogs_raw/vq的旋转技巧梯度直通估计的一般推广.md": "28a52fd99fe35408c0c1e185fa40ab4f",
  "/home/kelvin/dev/ml_posts/blogs_raw/低秩近似之路四id.md": "681b4277852e58f8bd2696f57dc8de2f",
  "/home/kelvin/dev/ml_posts/blogs_raw/vq的又一技巧给编码表加一个线性变换.md": "bb228939932b87c4843b9d38517da2c5",
  "/home/kelvin/dev/ml_posts/blogs_raw/当batch-size增大时学习率该如何随之变化.md": "3171a066726023d7d783903b6062325e",
  "/home/kelvin/dev/ml_posts/blogs_raw/adam的epsilon如何影响学习率的scaling-law.md": "6f9b1a7b77d6c5108d975b1db1876208",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈二十六基于恒等式的蒸馏下.md": "8e6770d745c9846727f34e25de84a12f",
  "/home/kelvin/dev/ml_posts/blogs_raw/从hessian近似看自适应学习率优化器.md": "a95c5b286fb0b8ca6323e9d2a453facc",
  "/home/kelvin/dev/ml_posts/blogs_raw/muon优化器赏析从向量到矩阵的本质跨越.md": "41075a3c9b5f1e0511775a5c3c80426f",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈二十七将步长作为条件输入.md": "65ce616c22c499c44472a9302968fe1f",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈二十八分步理解一致性模型.md": "92aa74a04b2d28f8ea68598d10e96c6a",
  "/home/kelvin/dev/ml_posts/blogs_raw/从谱范数梯度到新式权重衰减的思考.md": "53797c6cfbb95b6aeb677b77415a1052",
  "/home/kelvin/dev/ml_posts/blogs_raw/为什么梯度裁剪的默认模长是1.md": "b3c712cb940224d86ebc7c8bff3653e2",
  "/home/kelvin/dev/ml_posts/blogs_raw/低秩近似之路五cur.md": "bc0b92616fff4b0883b6edeced21c8c9",
  "/home/kelvin/dev/ml_posts/blogs_raw/细水长flow之tarflow流模型满血归来.md": "c3841603ecc4c528d1245a75f4169d3e",
  "/home/kelvin/dev/ml_posts/blogs_raw/三个球的交点坐标三球交会定位.md": "2e224dd0cd030dfac81d00aabac782bd",
  "/home/kelvin/dev/ml_posts/blogs_raw/moe环游记1从几何意义出发.md": "c4d2636033e10b30a8cffd49d3bd44ae",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈二十九用ddpm来离散编码.md": "d7e0b063a6fb54c48ab83e892021ee46",
  "/home/kelvin/dev/ml_posts/blogs_raw/moe环游记2不患寡而患不均.md": "d52fb0d436118f987c7153ca26eb9c6d",
  "/home/kelvin/dev/ml_posts/blogs_raw/muon续集为什么我们选择尝试muon.md": "8b746b79f8b1104195b5ede8168393e5",
  "/home/kelvin/dev/ml_posts/blogs_raw/moe环游记3换个思路来分配.md": "e45ba39a84eb4bc1dfdf7d9ce253e092",
  "/home/kelvin/dev/ml_posts/blogs_raw/初探mup超参数的跨模型尺度迁移规律.md": "66362990db7af2b7b3198803e7d8db44",
  "/home/kelvin/dev/ml_posts/blogs_raw/高阶mup更简明但更高明的谱条件缩放.md": "850af068921fa93530247fc03558d5bb",
  "/home/kelvin/dev/ml_posts/blogs_raw/moe环游记4难处应当多投入.md": "acf73bc12ef1c7833064fd2d5b704682",
  "/home/kelvin/dev/ml_posts/blogs_raw/通过梯度近似寻找normalization的替代品.md": "11d05474eeff5df07cd647791eece45e",
  "/home/kelvin/dev/ml_posts/blogs_raw/矩阵的有效秩effective-rank.md": "64e86e345a64997c1bf9b587410fcf3c",
  "/home/kelvin/dev/ml_posts/blogs_raw/svd的导数.md": "e6af4ac3dbc8a668c58a642af4f0264b",
  "/home/kelvin/dev/ml_posts/blogs_raw/一道概率不等式盯着它到显然成立为止.md": "5faa2a5ddd24a1d8be407754b0487e6a",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路20mla好在哪里上.md": "e5e3da228eaee3c8d31b2ec52820a66c",
  "/home/kelvin/dev/ml_posts/blogs_raw/msign算子的newton-schulz迭代上.md": "e0f6f1d4d943b35b67c3f7e18d24228f",
  "/home/kelvin/dev/ml_posts/blogs_raw/moe环游记5均匀分布的反思.md": "2221ee8f54cfe10c5f63e58ba8601f6d",
  "/home/kelvin/dev/ml_posts/blogs_raw/生成扩散模型漫谈三十从瞬时速度到平均速度.md": "ce2335674d6149b0508c93d83b0b27f7",
  "/home/kelvin/dev/ml_posts/blogs_raw/等值振荡定理最优多项式逼近的充要条件.md": "429c0d4e60750c216355fc226d57f312",
  "/home/kelvin/dev/ml_posts/blogs_raw/msign算子的newton-schulz迭代下.md": "4e4fd0299f92f14289fd4675dd2d7e32",
  "/home/kelvin/dev/ml_posts/blogs_raw/通过msign来计算奇异值裁剪mclip上.md": "ef80830caa304d5c53119b5f4f639ce1",
  "/home/kelvin/dev/ml_posts/blogs_raw/msign的导数.md": "fc7d354d27e8ef37e26d0f94e27fe685",
  "/home/kelvin/dev/ml_posts/blogs_raw/通过msign来计算奇异值裁剪mclip下.md": "b1b6f41814a2f03058305382e47fe8e9",
  "/home/kelvin/dev/ml_posts/blogs_raw/矩阵符号函数mcsgn能计算什么.md": "4267a40470f4da277d8477a2b4523f44",
  "/home/kelvin/dev/ml_posts/blogs_raw/对角低秩三角阵的高效求逆方法.md": "f46ae2f7ac333536e671ce834ba7eb41",
  "/home/kelvin/dev/ml_posts/blogs_raw/transformer升级之路21mla好在哪里下.md": "3ea20458dfcc18c2fa03c40ed58ede88",
  "/home/kelvin/dev/ml_posts/blogs_raw/qk-clip让muon在scaleup之路上更进一步.md": "aff0ed51919c81212edb1f09cc5300db",
  "/home/kelvin/dev/ml_posts/blogs_raw/矩阵平方根和逆平方根的高效计算.md": "831a40ef990c53943dd6bb3b7c5e213c",
  "/home/kelvin/dev/ml_posts/blogs_raw/矩阵r次方根和逆r次方根的高效计算.md": "64b9254f65cdb3d9bc8ce274c4304686",
  "/home/kelvin/dev/ml_posts/blogs_raw/流形上的最速下降1-sgd-超球面.md": "1769e774a3cb059bd8780ede10fcfac5",
  "/home/kelvin/dev/ml_posts/blogs_raw/流形上的最速下降2-muon-正交.md": "3d2126934f073934b94838753e3ca1d7",
  "/home/kelvin/dev/ml_posts/blogs_raw/流形上的最速下降3-muon-stiefel.md": "c01c373582bdafdb802e4e9d5f0599a1",
  "/home/kelvin/dev/ml_posts/blogs_raw/relugeluswish的一个恒等式.md": "2c9e029e1c50107301cdb357d6dd057f",
  "/home/kelvin/dev/ml_posts/blogs_raw/流形上的最速下降4-muon-谱球面.md": "a18eb159860d903cc59841f86f832bef",
  "/home/kelvin/dev/ml_posts/blogs_raw/重新思考学习率与batch-size一现状.md": "564966ef9f4e64ea75a4e62e9672c277",
  "/home/kelvin/dev/ml_posts/blogs_raw/为什么adam的update-rms是02.md": "35995be3d01946eeec0d782df757c325",
  "/home/kelvin/dev/ml_posts/blogs_raw/重新思考学习率与batch-size二平均场.md": "36b64257d9d527bbff46551be0f3a20b",
  "/home/kelvin/dev/ml_posts/blogs_raw/重新思考学习率与batch-size三muon.md": "b3ffb33d7d8388c42c2ea781fd75bd9f",
  "/home/kelvin/dev/ml_posts/blogs_raw/重新思考学习率与batch-size四ema.md": "5cb9aadbcdbc33f136cb48d45f81c44d",
  "/home/kelvin/dev/ml_posts/blogs_raw/重新思考学习率与batch-siz.md": "e753e09ba78c4b2e9ca71aea6c75f687",
  "/home/kelvin/dev/ml_posts/blogs_raw/adamw的weight-rms的.md": "66aed9afdf29a5b4b64fc19e8fb699b6",
  "/home/kelvin/dev/ml_posts/blogs_raw/adamw的weight-rms的渐近估计.md": "ce210c2681902aa6d774445ff39c532e",
  "/home/kelvin/dev/ml_posts/blogs_raw/为什么线性注意力要加short-c.md": "40fada0d98e2cea31df6227e57170072",
  "/home/kelvin/dev/ml_posts/blogs_raw/为什么线性注意力要加short-conv.md": "bdb403c3f4a033acce726d65f7e5dfa9",
  "/home/kelvin/dev/ml_posts/blogs_raw/diveq一种非常简洁的vq训练方案.md": "12eb36e3ba22452f6d506dbcbd718795",
  "/home/kelvin/dev/ml_posts/blogs_raw/随机矩阵的谱范数的快速估计.md": "928e2a98216716d1de44a905eacf8a7b",
  "/home/kelvin/dev/ml_posts/blogs_raw/mup之上1-好模型的三个特征.md": "da9a7cf5f72aeb6dded6a25ebe080189",
  "/home/kelvin/dev/ml_posts/blogs_raw/低精度attention可能存在有.md": "7ea7fe941d04a32af7f5b0b3d678b7e6",
  "/home/kelvin/dev/ml_posts/blogs_raw/低精度attention可能存在有偏的舍入误差.md": "a5f9ebbab848150f48fb20b6229e1c64",
  "/home/kelvin/dev/ml_posts/blogs_raw/流形上的最速下降5-对偶梯度下降.md": "3e5b4b63167a5116a0d5030d87facb40",
  "/home/kelvin/dev/ml_posts/blogs_raw/n个正态随机数的最大值的渐近估计.md": "52ebfc7ab99d7fd51b118793e77e6156"
}