需要添加详细推导的文件列表
====================================================================================================

无推导部分 (12 个):
----------------------------------------------------------------------------------------------------
msign的导数.md
n个正态随机数的最大值的渐近估计.md
低秩近似之路一伪逆.md
低秩近似之路三cr.md
生成扩散模型漫谈一ddpm-拆楼-建楼.md
生成扩散模型漫谈二十一中值定理加速ode采样.md
生成扩散模型漫谈二十八分步理解一致性模型.md
生成扩散模型漫谈十八得分匹配-条件得分匹配.md
生成扩散模型漫谈十四构建ode的一般步骤上.md
用傅里叶级数拟合一维概率密度函数.md
矩阵符号函数mcsgn能计算什么.md
通过msign来计算奇异值裁剪mclip上.md


简单推导需要增强 (128 个):
----------------------------------------------------------------------------------------------------
adamw的weight-rms的.md - 2 行
bert4keras在手baseline我有clue基准代码.md - 2 行
bias项的神奇作用rope-bias-更好的长度外推性.md - 2 行
bytepiece更纯粹更高压缩率的tokenizer.md - 2 行
can借助先验分布提升分类性能的简单后处理技巧.md - 2 行
childtuning试试把dropout加到梯度上去.md - 2 行
cosent一比sentence-bert更有效的句向量方案.md - 2 行
cosent三作为交互式相似度的损失函数.md - 2 行
cosent二特征式匹配与交互式匹配有多大差距.md - 2 行
decoder-only的llm为什么需要位置编码.md - 2 行
dropout视角下的mlm和mae一些新的启发.md - 2 行
efficient-globalpointer少点参数多点效果.md - 2 行
emo基于最优传输思想设计的分类损失函数.md - 2 行
flash可能是近来最有意思的高效transformer设计.md - 2 行
gau-α尝鲜体验快好省的下一代attention.md - 2 行
globalpointer下的kl散度应该是怎样的.md - 2 行
google新作试图复活rnnrnn能否再次辉煌.md - 2 行
google新搜出的优化器lion效率与效果兼得的训练狮.md - 2 行
gplinker基于globalpointer的事件联合抽取.md - 2 行
gplinker基于globalpointer的实体关系联合抽取.md - 2 行
ladder-side-tuning预训练模型的过墙梯.md - 2 行
liontiger优化器训练下的embedding异常和对策.md - 2 行
logsumexp运算的几个不等式.md - 2 行
moe环游记1从几何意义出发.md - 2 行
moe环游记5均匀分布的反思.md - 2 行
monarch矩阵计算高效的稀疏型矩阵分解.md - 2 行
msign算子的newton-schulz迭代上.md - 2 行
msign算子的newton-schulz迭代下.md - 2 行
mup之上1-好模型的三个特征.md - 2 行
naive-bayes-is-all-you-need.md - 2 行
nbce使用朴素贝叶斯扩展llm的context处理长度.md - 2 行
qk-clip让muon在scaleup之路上更进一步.md - 2 行
relugeluswish的一个恒等式.md - 2 行
roformerv2自然语言理解的极限探索.md - 2 行
seq2seq前缀树检索任务新范式以kgclue为例.md - 2 行
squareplus可能是运算最简单的relu光滑近似.md - 2 行
tiger一个抠到极致的优化器.md - 2 行
wgan新方案通过梯度归一化来实现l约束.md - 2 行
一道概率不等式盯着它到显然成立为止.md - 2 行
三个球的交点坐标三球交会定位.md - 2 行
不成功的尝试将多标签交叉熵推广到n个m分类上去.md - 2 行
为什么pre-norm的效果不如post-norm.md - 2 行
为什么现在的llm都是decoder-only的架构.md - 2 行
为什么现在的llm都是decoder-only的架构faq.md - 2 行
为什么线性注意力要加short-c.md - 2 行
为什么需要残差一个来自deepnet的视角.md - 2 行
从jl引理看熵不变性attention.md - 2 行
从局部到全局语义相似度的测地线距离.md - 2 行
从梯度最大化看attention的scale操作.md - 2 行
从熵不变性看attention的scale操作.md - 2 行
低秩近似之路二svd.md - 460 行
低秩近似之路五cur.md - 2 行
低秩近似之路四id.md - 2 行
低精度attention可能存在有.md - 2 行
你的语言模型有没有无法预测的词.md - 2 行
关于nbce方法的一些补充说明和分析.md - 2 行
初始化方法中非方阵的维度平均策略思考.md - 2 行
利用cur分解加速交互式相似度模型的检索.md - 2 行
十字架组合计数问题浅试.md - 2 行
变分自编码器八估计样本概率密度.md - 2 行
听说attention与softmax更配哦.md - 2 行
在bert4keras中使用混合精度和xla加速训练.md - 2 行
基于amos优化器思想推导出来的一些炼丹策略.md - 2 行
基于量子化假设推导模型的尺度定律scaling-law.md - 2 行
多任务学习漫谈一以损失之名.md - 2 行
多任务学习漫谈三分主次之序.md - 2 行
多任务学习漫谈二行梯度之事.md - 2 行
多标签softmax交叉熵的软标签版本.md - 2 行
大词表语言模型在续写任务上的一个问题及对策.md - 2 行
如何度量数据的稀疏程度.md - 2 行
如何训练你的准确率.md - 2 行
局部余弦相似度大全局余弦相似度一定也大吗.md - 2 行
幂等生成网络ign试图将判别和生成合二为一的gan.md - 2 行
当bert-whitening引入超参数总有一款适合你.md - 2 行
当生成模型肆虐互联网将有疯牛病之忧.md - 2 行
我在performer中发现了transformer-vq的踪迹.md - 2 行
指数梯度下降-元学习-自适应学习率.md - 2 行
时空之章将attention视为平方复杂度的rnn.md - 2 行
梯度流探索通向最小值之路.md - 2 行
模型优化漫谈bert的初始标准差为什么是002.md - 2 行
注意力和softmax的两点有趣发现鲁棒性和信息量.md - 2 行
注意力机制真的可以集中注意力吗.md - 2 行
熵不变性softmax的一个快速推导.md - 2 行
生成扩散模型漫谈七最优扩散方差估计上.md - 2 行
生成扩散模型漫谈三十从瞬时速度到平均速度.md - 2 行
生成扩散模型漫谈九条件控制生成结果.md - 2 行
生成扩散模型漫谈二ddpm-自回归式vae.md - 2 行
生成扩散模型漫谈二十七将步长作为条件输入.md - 2 行
生成扩散模型漫谈二十三信噪比与大图生成下.md - 2 行
生成扩散模型漫谈二十九用ddpm来离散编码.md - 2 行
生成扩散模型漫谈二十五基于恒等式的蒸馏上.md - 2 行
生成扩散模型漫谈二十从reflow到wgan-gp.md - 2 行
生成扩散模型漫谈二十六基于恒等式的蒸馏下.md - 2 行
生成扩散模型漫谈二十四少走捷径更快到达.md - 2 行
生成扩散模型漫谈八最优扩散方差估计下.md - 2 行
生成扩散模型漫谈十一统一扩散模型应用篇.md - 2 行
生成扩散模型漫谈十九作为扩散ode的gan.md - 2 行
生成扩散模型漫谈十二硬刚扩散ode.md - 2 行
生成扩散模型漫谈十统一扩散模型理论篇.md - 2 行
用热传导方程来指导自监督学习.md - 2 行
用狄拉克函数来构造非光滑函数的光滑近似.md - 2 行
等值振荡定理最优多项式逼近的充要条件.md - 2 行
细水长flow之tarflow流模型满血归来.md - 2 行
维度灾难之hubness现象浅析.md - 2 行
缓存与效果的极限拉扯从mhamqagqa到mla.md - 2 行
缓解交叉熵过度自信的一个简明方案.md - 2 行
脑洞大开非线性rnn居然也可以并行计算.md - 2 行
自然数集中-n-ab-c-时-a-b-c-的最小值.md - 2 行
让炼丹更科学一些一sgd的平均损失收敛.md - 2 行
训练1000层的transformer究竟有什么困难.md - 2 行
语言模型输出端共享embedding的重新探索.md - 2 行
输入梯度惩罚与参数梯度惩罚的一个不等式.md - 2 行
通向概率分布之路盘点softmax及其替代品.md - 649 行
通过msign来计算奇异值裁剪mclip下.md - 558 行
重新思考学习率与batch-siz.md - 2 行
重新思考学习率与batch-size三muon.md - 2 行
重新思考学习率与batch-size四ema.md - 2 行
重温ssm一线性系统和hippo矩阵.md - 2 行
重温ssm三hippo的高效计算s4.md - 2 行
重温ssm二hippo的一些遗留问题.md - 2 行
重温ssm四有理生成函数的新视角.md - 2 行
门控注意力单元gau还需要warmup吗.md - 2 行
闭门造车之多模态思路浅谈一无损输入.md - 2 行
闭门造车之多模态思路浅谈三位置编码.md - 2 行
闭门造车之多模态思路浅谈二自回归.md - 2 行
随机分词再探从viterbi-sampling到完美采样算法.md - 2 行
随机分词浅探从viterbi-decoding到viterbi-sampling.md - 2 行
预训练一下transformer的长序列成绩还能涨不少.md - 2 行
