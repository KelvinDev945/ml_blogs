---
title: logsumexpè¿ç®—çš„å‡ ä¸ªä¸ç­‰å¼
slug: logsumexpè¿ç®—çš„å‡ ä¸ªä¸ç­‰å¼
date: 2022-05-10
tags: ä¸ç­‰å¼, å‡½æ•°, ç”Ÿæˆæ¨¡å‹, attention, ä¼˜åŒ–, æ•°å€¼ç¨³å®šæ€§, å‡¸ä¼˜åŒ–, Softmax, Lipschitz, è©¹æ£®ä¸ç­‰å¼
status: completed
tags_reviewed: true
---

# logsumexpè¿ç®—çš„å‡ ä¸ªä¸ç­‰å¼

**åŸæ–‡é“¾æ¥**: [https://spaces.ac.cn/archives/9070](https://spaces.ac.cn/archives/9070)

**å‘å¸ƒæ—¥æœŸ**: 

---

$\text{logsumexp}$æ˜¯æœºå™¨å­¦ä¹ ç»å¸¸é‡åˆ°çš„è¿ç®—ï¼Œå°¤å…¶æ˜¯äº¤å‰ç†µçš„ç›¸å…³å®ç°å’Œæ¨å¯¼ä¸­éƒ½ä¼šç»å¸¸å‡ºç°ï¼ŒåŒæ—¶å®ƒè¿˜æ˜¯$\max$çš„å…‰æ»‘è¿‘ä¼¼ï¼ˆå‚è€ƒ[ã€Šå¯»æ±‚ä¸€ä¸ªå…‰æ»‘çš„æœ€å¤§å€¼å‡½æ•°ã€‹](/archives/3290)ï¼‰ã€‚è®¾$x=(x_1,x_2,\cdots,x_n)$ï¼Œ$\text{logsumexp}$å®šä¹‰ä¸º  
\begin{equation}\text{logsumexp}(x)=\log\sum_{i=1}^n e^{x_i}\end{equation}  
æœ¬æ–‡æ¥ä»‹ç»$\text{logsumexp}$çš„å‡ ä¸ªåœ¨ç†è®ºæ¨å¯¼ä¸­å¯èƒ½ç”¨å¾—åˆ°çš„ä¸ç­‰å¼ã€‚

## åŸºæœ¬ç•Œ #

è®°$x_{\max} = \max(x_1,x_2,\cdots,x_n)$ï¼Œé‚£ä¹ˆæ˜¾ç„¶æœ‰  
\begin{equation}e^{x_{\max}} < \sum_{i=1}^n e^{x_i} \leq \sum_{i=1}^n e^{x_{\max}} = ne^{x_{\max}}\end{equation}  
å„ç«¯å–å¯¹æ•°å³å¾—  
\begin{equation}x_{\max} < \text{logsumexp}(x) \leq x_{\max} + \log n\end{equation}  
è¿™æ˜¯å…³äº$\text{logsumexp}$ä¸Šä¸‹ç•Œçš„æœ€åŸºæœ¬ç»“æœï¼Œå®ƒè¡¨æ˜$\text{logsumexp}$å¯¹$\max$çš„è¿‘ä¼¼è¯¯å·®ä¸è¶…è¿‡$\log n$ã€‚æ³¨æ„è¿™ä¸ªè¯¯å·®è·Ÿ$x$æœ¬èº«æ— å…³ï¼Œäºæ˜¯æˆ‘ä»¬æœ‰  
\begin{equation}x_{\max}/\tau < \text{logsumexp}(x/\tau) \leq x_{\max}/\tau + \log n\end{equation}  
å„ç«¯ä¹˜ä»¥$\tau$å¾—åˆ°  
\begin{equation}x_{\max} < \tau\text{logsumexp}(x/\tau) \leq x_{\max} + \tau\log n\end{equation}  
å½“$\tau\to 0$æ—¶ï¼Œè¯¯å·®å°±è¶‹äº0äº†ï¼Œè¿™å‘Šè¯‰æˆ‘ä»¬å¯ä»¥é€šè¿‡é™ä½æ¸©åº¦å‚æ•°æ¥æé«˜å¯¹$\max$çš„è¿‘ä¼¼ç¨‹åº¦ã€‚

## å¹³å‡ç•Œ #

æˆ‘ä»¬çŸ¥é“$e^x$æ˜¯å‡¸å‡½æ•°ï¼Œæ»¡è¶³[è©¹æ£®ä¸ç­‰å¼](https://en.wikipedia.org/wiki/Jensen%27s_inequality)$\mathbb{E}[e^{x}]\geq e^{\mathbb{E}[x]}$ï¼Œå› æ­¤  
\begin{equation}\frac{1}{n}\sum_{i=1}^n e^{x_i}\geq e^{\bar{x}}\end{equation}  
è¿™é‡Œ$\bar{x}=\frac{1}{n}\sum\limits_{i=1}^n x_i$ï¼Œä¸¤è¾¹ä¹˜ä»¥$n$åå–å¯¹æ•°å¾—  
\begin{equation}\text{logsumexp}(x)\geq \bar{x} + \log n\end{equation}  
è¿™æ˜¯å…³äº$\text{logsumexp}$ä¸‹ç•Œçš„å¦ä¸€ä¸ªç»“æœã€‚è¯¥ç»“æœå¯ä»¥è¿›ä¸€æ­¥æ¨å¹¿åˆ°åŠ æƒå¹³å‡çš„æƒ…å½¢ï¼šè®¾æœ‰$p_1,p_2,\cdots,p_n\geq 0$ä¸”$\sum\limits_{i=1}^n p_i = 1$ï¼Œç”±æŸ¯è¥¿ä¸ç­‰å¼å¾—  
\begin{equation}\left[\sum_{i=1}^n (e^{x_i/2})^2\right]\left[\sum_{i=1}^n p_i^2\right]\geq \left[\sum_{i=1}^n p_i e^{x_i/2}\right]^2\end{equation}  
å¯¹å³ç«¯æ–¹æ‹¬å·å†…çš„å¼å­åº”ç”¨è©¹æ£®ä¸ç­‰å¼å¾—åˆ°  
\begin{equation}\left[\sum_{i=1}^n p_i e^{x_i/2}\right]^2\geq \left[e^{\left(\sum\limits_{i=1}^n p_i x_i/2\right)}\right]^2 = e^{\left(\sum\limits_{i=1}^n p_i x_i\right)}\end{equation}  
å„å¼ä¸¤ç«¯å–å¯¹æ•°ï¼Œæ•´ç†å¾—åˆ°  
\begin{equation}\text{logsumexp}(x)\geq \sum_{i=1}^n p_i x_i - \log\sum_{i=1}^n p_i^2\end{equation}  
å¦‚æœå¼€å§‹ä¸ç”¨æŸ¯è¥¿ä¸ç­‰å¼è€Œæ˜¯ç”¨æ›´ä¸€èˆ¬çš„[HÃ¶lderä¸ç­‰å¼](https://en.wikipedia.org/wiki/H%C3%B6lder%27s_inequality)ï¼Œé‚£ä¹ˆè¿˜å¯ä»¥å¾—åˆ°  
\begin{equation}\text{logsumexp}(x)\geq \sum_{i=1}^n p_i x_i - \frac{1}{t-1}\log\sum_{i=1}^n p_i^t,\quad \forall t > 1\end{equation}  
ç‰¹åˆ«åœ°ï¼Œå–$t\to 1$çš„æé™ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°  
\begin{equation}\text{logsumexp}(x)\geq \sum_{i=1}^n p_i x_i - \sum_{i=1}^n p_i \log p_i\end{equation}  
å®ƒå¯ä»¥ç­‰ä»·åœ°æ”¹å†™ä¸º$\sum\limits_{i=1}^n p_i \log \frac{p_i}{e^{x_i}/Z} \geq 0$ï¼Œå…¶ä¸­$Z=e^{\text{logsumexp}(x)}$æ˜¯å½’ä¸€åŒ–å› å­ï¼Œæ‰€ä»¥å®ƒå®é™…å°±æ˜¯ä¸¤ä¸ªåˆ†å¸ƒçš„$KL$æ•£åº¦ã€‚

## Lçº¦æŸ #

åœ¨æ— ç©·èŒƒæ•°ä¸‹ï¼Œ$\text{logsumexp}$è¿˜æ»¡è¶³Lipschitzçº¦æŸï¼Œå³  
\begin{equation}|\text{logsumexp}(x) - \text{logsumexp}(y)| \leq |x - y|_{\infty}\end{equation}  
è¿™é‡Œçš„$|x-y|_{\infty} = \max\limits_i |x_i - y_i|$ï¼ˆå…¶å®è®°ä¸º$|x - y|_{\max}$è¿˜æ›´ç›´è§‚ä¸€äº›ï¼‰ã€‚è¯æ˜ä¹Ÿä¸ç®—å›°éš¾ï¼Œå®šä¹‰  
\begin{equation}f(t) = \text{logsumexp}(tx + (1-t)y),\quad t\in[0, 1]\end{equation}  
å°†å®ƒè§†ä¸ºå…³äº$t$çš„ä¸€å…ƒå‡½æ•°ï¼Œç”±[ä¸­å€¼å®šç†](https://en.wikipedia.org/wiki/Mean_value_theorem)çŸ¥å­˜åœ¨$\varepsilon\in(0, 1)$ï¼Œä½¿å¾—  
\begin{equation}f'(\varepsilon) = \frac{f(1) - f(0)}{1 - 0} = \text{logsumexp}(x) - \text{logsumexp}(y) \end{equation}  
ä¸éš¾æ±‚å‡º  
\begin{equation}f'(\varepsilon) = \frac{\sum\limits_{i=1}^n e^{\varepsilon x_i + (1-\varepsilon)y_i}(x_i - y_i)}{\sum\limits_{i=1}^n e^{\varepsilon x_i + (1-\varepsilon)y_i}} \end{equation}  
æ‰€ä»¥  
\begin{equation}\begin{aligned}&\,|\text{logsumexp}(x) - \text{logsumexp}(y)| = \left|\frac{\sum\limits_{i=1}^n e^{\varepsilon x_i + (1-\varepsilon)y_i}(x_i - y_i)}{\sum\limits_{i=1}^n e^{\varepsilon x_i + (1-\varepsilon)y_i}}\right| \\\  
\leq &\, \frac{\sum\limits_{i=1}^n e^{\varepsilon x_i + (1-\varepsilon)y_i} |x_i - y_i|}{\sum\limits_{i=1}^n e^{\varepsilon x_i + (1-\varepsilon)y_i}} \leq \frac{\sum\limits_{i=1}^n e^{\varepsilon x_i + (1-\varepsilon)y_i} |x - y|_{\infty}}{\sum\limits_{i=1}^n e^{\varepsilon x_i + (1-\varepsilon)y_i}} = |x - y|_{\infty}  
\end{aligned}\end{equation}

## å‡¸å‡½æ•° #

æœ€åæ˜¯ä¸€ä¸ªå¾ˆå¼ºçš„ç»“è®ºï¼š$\text{logsumexp}$è¿˜æ˜¯ä¸€ä¸ªå‡¸å‡½æ•°ï¼è¿™æ„å‘³ç€å‡¸å‡½æ•°ç›¸å…³çš„æ‰€æœ‰ä¸ç­‰å¼éƒ½é€‚ç”¨äº$\text{logsumexp}$ï¼Œæ¯”å¦‚æœ€åŸºæœ¬çš„è©¹æ£®ä¸ç­‰å¼ï¼š  
\begin{equation} \mathbb{E}[\text{logsumexp}(x)] \geq \text{logsumexp}(\mathbb{E}[x])\end{equation}

è¦è¯æ˜$\text{logsumexp}$æ˜¯å‡¸å‡½æ•°ï¼Œå°±æ˜¯è¦è¯æ˜å¯¹äº$\forall t\in[0, 1]$ï¼Œéƒ½æˆç«‹  
\begin{equation} t\text{logsumexp}(x) + (1-t)\text{logsumexp}(y)\geq \text{logsumexp}(tx + (1-t)y)\end{equation}  
è¯æ˜è¿‡ç¨‹å…¶å®å°±æ˜¯[HÃ¶lderä¸ç­‰å¼](https://en.wikipedia.org/wiki/H%C3%B6lder%27s_inequality)çš„åŸºæœ¬åº”ç”¨ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æœ‰  
\begin{equation}t\text{logsumexp}(x) + (1-t)\text{logsumexp}(y) = \log\left(\sum_{i=1}^n e^{x_i}\right)^t \left(\sum_{i=1}^n e^{y_i}\right)^{(1-t)}\end{equation}  
ç°åœ¨ç›´æ¥åº”ç”¨HÃ¶lderä¸ç­‰å¼å°±å¯ä»¥å¾—åˆ°  
\begin{equation}\log\left(\sum_{i=1}^n e^{x_i}\right)^t \left(\sum_{i=1}^n e^{y_i}\right)^{(1-t)}\geq \log\sum_{i=1}^n e^{tx_i + (1-t)y_i} = \text{logsumexp}(tx + (1-t)y)\end{equation}  
è¿™å°±è¯æ˜äº†$\text{logsumexp}$æ˜¯å‡¸å‡½æ•°ã€‚

## æ–‡æœ«ç»“ #

ä¸»è¦æ€»ç»“äº†$\text{logsumexp}$è¿ç®—çš„ç›¸å…³ä¸ç­‰å¼ï¼Œä»¥å¤‡ä¸æ—¶ä¹‹éœ€ã€‚

_**è½¬è½½åˆ°è¯·åŒ…æ‹¬æœ¬æ–‡åœ°å€ï¼š**<https://spaces.ac.cn/archives/9070>_

_**æ›´è¯¦ç»†çš„è½¬è½½äº‹å®œè¯·å‚è€ƒï¼š**_[ã€Šç§‘å­¦ç©ºé—´FAQã€‹](https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8 "ã€Šç§‘å­¦ç©ºé—´FAQã€‹")

**å¦‚æœæ‚¨è¿˜æœ‰ä»€ä¹ˆç–‘æƒ‘æˆ–å»ºè®®ï¼Œæ¬¢è¿åœ¨ä¸‹æ–¹è¯„è®ºåŒºç»§ç»­è®¨è®ºã€‚**

**å¦‚æœæ‚¨è§‰å¾—æœ¬æ–‡è¿˜ä¸é”™ï¼Œæ¬¢è¿åˆ†äº«/æ‰“èµæœ¬æ–‡ã€‚æ‰“èµå¹¶éè¦ä»ä¸­è·å¾—æ”¶ç›Šï¼Œè€Œæ˜¯å¸Œæœ›çŸ¥é“ç§‘å­¦ç©ºé—´è·å¾—äº†å¤šå°‘è¯»è€…çš„çœŸå¿ƒå…³æ³¨ã€‚å½“ç„¶ï¼Œå¦‚æœä½ æ— è§†å®ƒï¼Œä¹Ÿä¸ä¼šå½±å“ä½ çš„é˜…è¯»ã€‚å†æ¬¡è¡¨ç¤ºæ¬¢è¿å’Œæ„Ÿè°¢ï¼**

æ‰“èµ

![ç§‘å­¦ç©ºé—´](https://spaces.ac.cn/usr/themes/geekg/payment/wx.png)

å¾®ä¿¡æ‰“èµ

![ç§‘å­¦ç©ºé—´](https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png)

æ”¯ä»˜å®æ‰“èµ

å› ä¸ºç½‘ç«™åå°å¯¹æ‰“èµå¹¶æ— è®°å½•ï¼Œå› æ­¤æ¬¢è¿åœ¨æ‰“èµæ—¶å€™å¤‡æ³¨ç•™è¨€ã€‚ä½ è¿˜å¯ä»¥[**ç‚¹å‡»è¿™é‡Œ**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ)æˆ–åœ¨ä¸‹æ–¹è¯„è®ºåŒºç•™è¨€æ¥å‘ŠçŸ¥ä½ çš„å»ºè®®æˆ–éœ€æ±‚ã€‚

**å¦‚æœæ‚¨éœ€è¦å¼•ç”¨æœ¬æ–‡ï¼Œè¯·å‚è€ƒï¼š**

è‹å‰‘æ—. (May. 10, 2022). ã€Šlogsumexpè¿ç®—çš„å‡ ä¸ªä¸ç­‰å¼ ã€‹[Blog post]. Retrieved from <https://spaces.ac.cn/archives/9070>

@online{kexuefm-9070,  
title={logsumexpè¿ç®—çš„å‡ ä¸ªä¸ç­‰å¼},  
author={è‹å‰‘æ—},  
year={2022},  
month={May},  
url={\url{https://spaces.ac.cn/archives/9070}},  
} 


---

## è¯¦ç»†æ•°å­¦æ¨å¯¼ä¸æ³¨é‡Š

æœ¬èŠ‚æä¾›logsumexpè¿ç®—çš„å®Œæ•´æ•°å­¦æ¨å¯¼ï¼ŒåŒ…æ‹¬åŸºæœ¬æ€§è´¨ã€ä¸ç­‰å¼è¯æ˜ã€æ•°å€¼ç¨³å®šæ€§åˆ†æå’Œå®è·µåº”ç”¨ã€‚

### 1. åŸºæœ¬å®šä¹‰ä¸æ€§è´¨

#### 1.1 å®šä¹‰ä¸åŸºæœ¬å½¢å¼

logsumexpå‡½æ•°å®šä¹‰ä¸ºï¼š
\begin{equation}\text{logsumexp}(x) = \log\sum_{i=1}^n e^{x_i}\tag{1}\end{equation}

**æ•°å­¦ç›´è§‰**ï¼šè¯¥å‡½æ•°å°†æŒ‡æ•°æ±‚å’Œçš„ç»“æœå–å¯¹æ•°ï¼Œå¯ä»¥è§†ä¸ºåœ¨å¯¹æ•°ç©ºé—´ä¸­çš„"è½¯æœ€å¤§å€¼"è¿ç®—ã€‚

**åŸºæœ¬æ€§è´¨**ï¼š
\begin{equation}\text{logsumexp}(x + c) = \text{logsumexp}(x) + c,\quad \forall c\in\mathbb{R}\tag{2}\end{equation}

**è¯æ˜**ï¼š
\begin{align}
\text{logsumexp}(x + c) &= \log\sum_{i=1}^n e^{x_i+c}\tag{3}\\
&= \log\left(e^c\sum_{i=1}^n e^{x_i}\right)\tag{4}\\
&= \log e^c + \log\sum_{i=1}^n e^{x_i}\tag{5}\\
&= c + \text{logsumexp}(x)\tag{6}
\end{align}

è¿™ä¸ªæ€§è´¨åœ¨æ•°å€¼ç¨³å®šæ€§è®¡ç®—ä¸­è‡³å…³é‡è¦ã€‚

#### 1.2 ä¸æœ€å¤§å€¼çš„å…³ç³»

è®°$x_{\max} = \max(x_1,x_2,\cdots,x_n)$ï¼Œåˆ™ï¼š
\begin{equation}x_{\max} \leq \text{logsumexp}(x) \leq x_{\max} + \log n\tag{7}\end{equation}

**è¯¦ç»†è¯æ˜**ï¼š

**ä¸‹ç•Œ**ï¼šå› ä¸º$e^{x_i} > 0$å¯¹æ‰€æœ‰$i$æˆç«‹ï¼Œæ‰€ä»¥ï¼š
\begin{equation}\sum_{i=1}^n e^{x_i} > e^{x_{\max}}\tag{8}\end{equation}

ä¸¤è¾¹å–å¯¹æ•°å¾—ï¼š
\begin{equation}\text{logsumexp}(x) > x_{\max}\tag{9}\end{equation}

æ³¨æ„è¿™é‡Œæ˜¯ä¸¥æ ¼ä¸ç­‰å·ï¼Œå› ä¸ºè‡³å°‘æœ‰ä¸¤ä¸ªä¸åŒçš„$x_i$æ—¶æ±‚å’Œä¸¥æ ¼å¤§äºæœ€å¤§é¡¹ã€‚å½“æ‰€æœ‰$x_i$ç›¸ç­‰æ—¶å–ç­‰å·ã€‚

**ä¸Šç•Œ**ï¼šå› ä¸º$e^{x_i} \leq e^{x_{\max}}$å¯¹æ‰€æœ‰$i$æˆç«‹ï¼Œæ‰€ä»¥ï¼š
\begin{equation}\sum_{i=1}^n e^{x_i} \leq \sum_{i=1}^n e^{x_{\max}} = ne^{x_{\max}}\tag{10}\end{equation}

ä¸¤è¾¹å–å¯¹æ•°å¾—ï¼š
\begin{equation}\text{logsumexp}(x) \leq x_{\max} + \log n\tag{11}\end{equation}

**è¯¯å·®åˆ†æ**ï¼šå®šä¹‰è¿‘ä¼¼è¯¯å·®ä¸ºï¼š
\begin{equation}\varepsilon(x) = \text{logsumexp}(x) - x_{\max}\tag{12}\end{equation}

åˆ™$0 < \varepsilon(x) \leq \log n$ï¼Œä¸”ï¼š
- å½“$n=1$æ—¶ï¼Œ$\varepsilon(x) = 0$
- å½“æ‰€æœ‰$x_i$ç›¸ç­‰æ—¶ï¼Œ$\varepsilon(x) = \log n$ï¼ˆè¾¾åˆ°ä¸Šç•Œï¼‰
- å½“å…¶ä»–$x_i \ll x_{\max}$æ—¶ï¼Œ$\varepsilon(x) \approx 0$

### 2. åŸºæœ¬ç•Œçš„è¯¦ç»†åˆ†æ

#### 2.1 æ¸©åº¦å‚æ•°çš„å½±å“

å¼•å…¥æ¸©åº¦å‚æ•°$\tau > 0$ï¼Œå®šä¹‰ï¼š
\begin{equation}\text{logsumexp}_{\tau}(x) = \tau\log\sum_{i=1}^n e^{x_i/\tau}\tag{13}\end{equation}

**æ€§è´¨**ï¼š
\begin{equation}x_{\max} \leq \text{logsumexp}_{\tau}(x) \leq x_{\max} + \tau\log n\tag{14}\end{equation}

**è¯æ˜**ï¼šä»¤$y_i = x_i/\tau$ï¼Œåˆ™ï¼š
\begin{align}
\text{logsumexp}_{\tau}(x) &= \tau\text{logsumexp}(y)\tag{15}\\
&\leq \tau(\max_i y_i + \log n)\tag{16}\\
&= \tau\cdot\frac{x_{\max}}{\tau} + \tau\log n\tag{17}\\
&= x_{\max} + \tau\log n\tag{18}
\end{align}

ä¸‹ç•ŒåŒç†å¯è¯ã€‚

**æ¸©åº¦å‚æ•°çš„ä½œç”¨**ï¼š
- $\tau \to 0$æ—¶ï¼š$\text{logsumexp}_{\tau}(x) \to x_{\max}$ï¼ˆç¡¬æœ€å¤§å€¼ï¼‰
- $\tau \to \infty$æ—¶ï¼šè¯¯å·®$\tau\log n$å¢å¤§ï¼Œè¿‘ä¼¼å˜å·®
- $\tau = 1$æ—¶ï¼šæ ‡å‡†logsumexp

**å®è·µåº”ç”¨**ï¼šåœ¨softmaxä¸­ï¼Œè¾ƒå°çš„$\tau$äº§ç”Ÿæ›´"å°–é”"çš„åˆ†å¸ƒï¼Œè¾ƒå¤§çš„$\tau$äº§ç”Ÿæ›´"å¹³æ»‘"çš„åˆ†å¸ƒã€‚

#### 2.2 ç´§ç•Œä¼°è®¡

å¯¹äºç‰¹æ®Šæƒ…å†µï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°æ›´ç´§çš„ç•Œã€‚è®¾$x_1 \geq x_2 \geq \cdots \geq x_n$ï¼ˆå·²æ’åºï¼‰ï¼Œå®šä¹‰ï¼š
\begin{equation}\delta_i = x_1 - x_i,\quad i=2,\ldots,n\tag{19}\end{equation}

åˆ™ï¼š
\begin{equation}\text{logsumexp}(x) = x_1 + \log\left(1 + \sum_{i=2}^n e^{-\delta_i}\right)\tag{20}\end{equation}

**æ¨å¯¼**ï¼š
\begin{align}
\text{logsumexp}(x) &= \log\sum_{i=1}^n e^{x_i}\tag{21}\\
&= \log\left(e^{x_1}\sum_{i=1}^n e^{x_i-x_1}\right)\tag{22}\\
&= x_1 + \log\left(1 + \sum_{i=2}^n e^{x_i-x_1}\right)\tag{23}\\
&= x_1 + \log\left(1 + \sum_{i=2}^n e^{-\delta_i}\right)\tag{24}
\end{align}

**è¯¯å·®ä¼°è®¡**ï¼š
\begin{equation}0 < \log\left(1 + \sum_{i=2}^n e^{-\delta_i}\right) \leq \log n\tag{25}\end{equation}

å¦‚æœ$\delta_2$ï¼ˆç¬¬äºŒå¤§å€¼ä¸æœ€å¤§å€¼çš„å·®ï¼‰æ¯”è¾ƒå¤§ï¼Œåˆ™è¯¯å·®æ¥è¿‘0ã€‚

### 3. å¹³å‡ç•Œçš„æ·±å…¥æ¢è®¨

#### 3.1 è©¹æ£®ä¸ç­‰å¼åº”ç”¨

è®¾$\bar{x} = \frac{1}{n}\sum_{i=1}^n x_i$ä¸ºç®—æœ¯å¹³å‡ï¼Œç”±äº$e^x$æ˜¯å‡¸å‡½æ•°ï¼Œæ ¹æ®è©¹æ£®ä¸ç­‰å¼ï¼š
\begin{equation}\mathbb{E}[e^x] \geq e^{\mathbb{E}[x]}\tag{26}\end{equation}

åº”ç”¨åˆ°å‡åŒ€åˆ†å¸ƒä¸Šï¼š
\begin{equation}\frac{1}{n}\sum_{i=1}^n e^{x_i} \geq e^{\bar{x}}\tag{27}\end{equation}

ä¸¤è¾¹ä¹˜ä»¥$n$åå–å¯¹æ•°ï¼š
\begin{equation}\text{logsumexp}(x) \geq \bar{x} + \log n\tag{28}\end{equation}

**ç­‰å·æˆç«‹æ¡ä»¶**ï¼šå½“ä¸”ä»…å½“æ‰€æœ‰$x_i$ç›¸ç­‰æ—¶å–ç­‰å·ã€‚

**å‡ ä½•æ„ä¹‰**ï¼šlogsumexpæ€»æ˜¯å¤§äºç­‰äºç®—æœ¯å¹³å‡åŠ ä¸Š$\log n$çš„ä¿®æ­£é¡¹ã€‚

#### 3.2 åŠ æƒè©¹æ£®ä¸ç­‰å¼

å¯¹äºæƒé‡$p_1,\ldots,p_n \geq 0$ä¸”$\sum_{i=1}^n p_i = 1$ï¼Œå®šä¹‰åŠ æƒå¹³å‡ï¼š
\begin{equation}\bar{x}_p = \sum_{i=1}^n p_i x_i\tag{29}\end{equation}

**åŸºæœ¬ä¸ç­‰å¼**ï¼š
\begin{equation}\text{logsumexp}(x) \geq \bar{x}_p - \log\sum_{i=1}^n p_i^2\tag{30}\end{equation}

**è¯¦ç»†è¯æ˜**ï¼š

**æ­¥éª¤1**ï¼šæŸ¯è¥¿ä¸ç­‰å¼
\begin{equation}\left[\sum_{i=1}^n a_i^2\right]\left[\sum_{i=1}^n b_i^2\right] \geq \left[\sum_{i=1}^n a_ib_i\right]^2\tag{31}\end{equation}

ä»¤$a_i = e^{x_i/2}$ï¼Œ$b_i = p_i$ï¼š
\begin{equation}\left[\sum_{i=1}^n e^{x_i}\right]\left[\sum_{i=1}^n p_i^2\right] \geq \left[\sum_{i=1}^n p_i e^{x_i/2}\right]^2\tag{32}\end{equation}

**æ­¥éª¤2**ï¼šå¯¹å³ä¾§åº”ç”¨è©¹æ£®ä¸ç­‰å¼
\begin{align}
\sum_{i=1}^n p_i e^{x_i/2} &\geq e^{\sum_{i=1}^n p_i \cdot x_i/2}\tag{33}\\
&= e^{\bar{x}_p/2}\tag{34}
\end{align}

**æ­¥éª¤3**ï¼šä»£å…¥å¹¶æ•´ç†
\begin{equation}\left[\sum_{i=1}^n e^{x_i}\right]\left[\sum_{i=1}^n p_i^2\right] \geq e^{\bar{x}_p}\tag{35}\end{equation}

ä¸¤è¾¹å–å¯¹æ•°ï¼š
\begin{equation}\text{logsumexp}(x) + \log\sum_{i=1}^n p_i^2 \geq \bar{x}_p\tag{36}\end{equation}

ç§»é¡¹å¾—ï¼š
\begin{equation}\text{logsumexp}(x) \geq \bar{x}_p - \log\sum_{i=1}^n p_i^2\tag{37}\end{equation}

#### 3.3 HÃ¶lderä¸ç­‰å¼æ¨å¹¿

HÃ¶lderä¸ç­‰å¼æŒ‡å‡ºï¼Œå¯¹äº$t > 1$å’Œ$s = \frac{t}{t-1}$ï¼ˆå…±è½­æŒ‡æ•°ï¼‰ï¼Œæœ‰ï¼š
\begin{equation}\sum_{i=1}^n |a_ib_i| \leq \left(\sum_{i=1}^n |a_i|^t\right)^{1/t}\left(\sum_{i=1}^n |b_i|^s\right)^{1/s}\tag{38}\end{equation}

ä»¤$a_i = e^{x_i/t}$ï¼Œ$b_i = p_i$ï¼š
\begin{equation}\sum_{i=1}^n p_i e^{x_i/t} \leq \left(\sum_{i=1}^n e^{x_i}\right)^{1/t}\left(\sum_{i=1}^n p_i^s\right)^{1/s}\tag{39}\end{equation}

**æ­¥éª¤1**ï¼šåº”ç”¨è©¹æ£®ä¸ç­‰å¼åˆ°å·¦ä¾§
\begin{equation}\sum_{i=1}^n p_i e^{x_i/t} \geq e^{\bar{x}_p/t}\tag{40}\end{equation}

**æ­¥éª¤2**ï¼šç»“åˆHÃ¶lderä¸ç­‰å¼
\begin{equation}e^{\bar{x}_p/t} \leq \left(\sum_{i=1}^n e^{x_i}\right)^{1/t}\left(\sum_{i=1}^n p_i^s\right)^{1/s}\tag{41}\end{equation}

ä¸¤è¾¹å–$t$æ¬¡æ–¹ï¼š
\begin{equation}e^{\bar{x}_p} \leq \left(\sum_{i=1}^n e^{x_i}\right)\left(\sum_{i=1}^n p_i^s\right)^{t/s}\tag{42}\end{equation}

æ³¨æ„åˆ°$t/s = t-1$ï¼Œæ‰€ä»¥ï¼š
\begin{equation}e^{\bar{x}_p} \leq \left(\sum_{i=1}^n e^{x_i}\right)\left(\sum_{i=1}^n p_i^s\right)^{t-1}\tag{43}\end{equation}

ä¸¤è¾¹å–å¯¹æ•°ï¼š
\begin{equation}\bar{x}_p \leq \text{logsumexp}(x) + (t-1)\log\sum_{i=1}^n p_i^s\tag{44}\end{equation}

å…¶ä¸­$s = \frac{t}{t-1}$ï¼Œç§»é¡¹å¾—ï¼š
\begin{equation}\text{logsumexp}(x) \geq \bar{x}_p - (t-1)\log\sum_{i=1}^n p_i^{t/(t-1)}\tag{45}\end{equation}

æ”¹å†™ä¸ºï¼š
\begin{equation}\text{logsumexp}(x) \geq \bar{x}_p - \frac{1}{t-1}\log\sum_{i=1}^n p_i^{t/(t-1)}\tag{46}\end{equation}

ä»¤$t' = \frac{t}{t-1}$ï¼Œå½“$t > 1$æ—¶$t' > 1$ï¼Œå¯å¾—ï¼š
\begin{equation}\text{logsumexp}(x) \geq \bar{x}_p - \frac{1}{t'-1}\log\sum_{i=1}^n p_i^{t'},\quad \forall t' > 1\tag{47}\end{equation}

#### 3.4 æé™æƒ…å†µï¼šKLæ•£åº¦

å½“$t \to 1$æ—¶ï¼Œä½¿ç”¨æ´›å¿…è¾¾æ³•åˆ™ï¼š
\begin{align}
\lim_{t\to 1}\frac{\log\sum_{i=1}^n p_i^t}{t-1} &= \lim_{t\to 1}\frac{d}{dt}\log\sum_{i=1}^n p_i^t\tag{48}\\
&= \lim_{t\to 1}\frac{\sum_{i=1}^n p_i^t\log p_i}{\sum_{i=1}^n p_i^t}\tag{49}\\
&= \sum_{i=1}^n p_i\log p_i\tag{50}
\end{align}

å› æ­¤ï¼š
\begin{equation}\text{logsumexp}(x) \geq \bar{x}_p - \sum_{i=1}^n p_i\log p_i\tag{51}\end{equation}

**KLæ•£åº¦å½¢å¼**ï¼šå®šä¹‰$q_i = \frac{e^{x_i}}{\sum_j e^{x_j}}$ä¸ºå½’ä¸€åŒ–åçš„åˆ†å¸ƒï¼Œåˆ™ï¼š
\begin{equation}\sum_{i=1}^n p_i\log p_i - \sum_{i=1}^n p_i\log q_i = \text{KL}(p\|q)\tag{52}\end{equation}

å±•å¼€ç¬¬äºŒé¡¹ï¼š
\begin{align}
\sum_{i=1}^n p_i\log q_i &= \sum_{i=1}^n p_i\log\frac{e^{x_i}}{\sum_j e^{x_j}}\tag{53}\\
&= \sum_{i=1}^n p_i x_i - \log\sum_j e^{x_j}\tag{54}\\
&= \bar{x}_p - \text{logsumexp}(x)\tag{55}
\end{align}

å› æ­¤ï¼š
\begin{equation}\text{KL}(p\|q) = \sum_{i=1}^n p_i\log p_i - \bar{x}_p + \text{logsumexp}(x)\tag{56}\end{equation}

ç§»é¡¹å¾—ï¼š
\begin{equation}\text{logsumexp}(x) = \bar{x}_p - \sum_{i=1}^n p_i\log p_i + \text{KL}(p\|q)\tag{57}\end{equation}

ç”±äº$\text{KL}(p\|q) \geq 0$ï¼Œæˆ‘ä»¬å†æ¬¡å¾—åˆ°ï¼š
\begin{equation}\text{logsumexp}(x) \geq \bar{x}_p - \sum_{i=1}^n p_i\log p_i\tag{58}\end{equation}

ç­‰å·æˆç«‹å½“ä¸”ä»…å½“$p_i = q_i$ï¼Œå³$p_i \propto e^{x_i}$ã€‚

### 4. Lipschitzè¿ç»­æ€§

#### 4.1 Lipschitzå¸¸æ•°

**å®šç†**ï¼šlogsumexpå‡½æ•°å…³äºæ— ç©·èŒƒæ•°æ˜¯1-Lipschitzè¿ç»­çš„ï¼š
\begin{equation}|\text{logsumexp}(x) - \text{logsumexp}(y)| \leq \|x - y\|_{\infty}\tag{59}\end{equation}

å…¶ä¸­$\|x - y\|_{\infty} = \max_i |x_i - y_i|$ã€‚

**è¯æ˜å‡†å¤‡**ï¼šå®šä¹‰è¾…åŠ©å‡½æ•°
\begin{equation}f(t) = \text{logsumexp}(tx + (1-t)y),\quad t\in[0,1]\tag{60}\end{equation}

**æ­¥éª¤1**ï¼šè®¡ç®—å¯¼æ•°

å¯¹$t$æ±‚å¯¼ï¼š
\begin{align}
f'(t) &= \frac{d}{dt}\log\sum_{i=1}^n e^{tx_i + (1-t)y_i}\tag{61}\\
&= \frac{\sum_{i=1}^n e^{tx_i + (1-t)y_i}\cdot(x_i - y_i)}{\sum_{i=1}^n e^{tx_i + (1-t)y_i}}\tag{62}\\
&= \sum_{i=1}^n w_i(t)(x_i - y_i)\tag{63}
\end{align}

å…¶ä¸­æƒé‡ä¸ºï¼š
\begin{equation}w_i(t) = \frac{e^{tx_i + (1-t)y_i}}{\sum_j e^{tx_j + (1-t)y_j}}\tag{64}\end{equation}

æ³¨æ„åˆ°$w_i(t) \geq 0$ä¸”$\sum_i w_i(t) = 1$ï¼Œæ‰€ä»¥$f'(t)$æ˜¯$x_i - y_i$çš„å‡¸ç»„åˆã€‚

**æ­¥éª¤2**ï¼šåº”ç”¨ä¸­å€¼å®šç†

ç”±ä¸­å€¼å®šç†ï¼Œå­˜åœ¨$\varepsilon \in (0,1)$ä½¿å¾—ï¼š
\begin{equation}f(1) - f(0) = f'(\varepsilon)\tag{65}\end{equation}

å³ï¼š
\begin{equation}\text{logsumexp}(x) - \text{logsumexp}(y) = \sum_{i=1}^n w_i(\varepsilon)(x_i - y_i)\tag{66}\end{equation}

**æ­¥éª¤3**ï¼šä¼°è®¡ä¸Šç•Œ

å–ç»å¯¹å€¼ï¼š
\begin{align}
|\text{logsumexp}(x) - \text{logsumexp}(y)| &= \left|\sum_{i=1}^n w_i(\varepsilon)(x_i - y_i)\right|\tag{67}\\
&\leq \sum_{i=1}^n w_i(\varepsilon)|x_i - y_i|\tag{68}\\
&\leq \sum_{i=1}^n w_i(\varepsilon)\cdot\|x - y\|_{\infty}\tag{69}\\
&= \|x - y\|_{\infty}\tag{70}
\end{align}

è¿™å°±è¯æ˜äº†1-Lipschitzæ€§è´¨ã€‚

#### 4.2 æ¢¯åº¦çš„æ€§è´¨

logsumexpçš„æ¢¯åº¦ä¸ºï¼š
\begin{equation}\nabla_x\text{logsumexp}(x) = \left[\frac{e^{x_1}}{\sum_j e^{x_j}},\ldots,\frac{e^{x_n}}{\sum_j e^{x_j}}\right]^{\top}\tag{71}\end{equation}

è¿™æ­£æ˜¯softmaxå‡½æ•°ï¼è®°ä¸ºï¼š
\begin{equation}\nabla_x\text{logsumexp}(x) = \text{softmax}(x)\tag{72}\end{equation}

**æ€§è´¨**ï¼š
1. $\sum_i [\nabla_x\text{logsumexp}(x)]_i = 1$ï¼ˆæ¦‚ç‡åˆ†å¸ƒï¼‰
2. $[\nabla_x\text{logsumexp}(x)]_i \in (0,1)$
3. $\|\nabla_x\text{logsumexp}(x)\|_1 = 1$
4. $\|\nabla_x\text{logsumexp}(x)\|_{\infty} \leq 1$

è¿™äº›æ€§è´¨ç¡®ä¿äº†Lipschitzå¸¸æ•°ä¸º1ã€‚

### 5. å‡¸æ€§åˆ†æ

#### 5.1 å‡¸å‡½æ•°çš„è¯æ˜

**å®šç†**ï¼šlogsumexpæ˜¯å‡¸å‡½æ•°ã€‚

**è¯æ˜æ–¹æ³•1**ï¼šHessiançŸ©é˜µ

è®¡ç®—äºŒé˜¶å¯¼æ•°ï¼ŒHessiançŸ©é˜µçš„$(i,j)$å…ƒç´ ä¸ºï¼š
\begin{equation}H_{ij} = \frac{\partial^2}{\partial x_i\partial x_j}\text{logsumexp}(x)\tag{73}\end{equation}

ä»¤$p_i = \frac{e^{x_i}}{\sum_k e^{x_k}}$ï¼ˆsoftmaxï¼‰ï¼Œå¯ä»¥è¯æ˜ï¼š
\begin{equation}H_{ij} = \begin{cases}
p_i(1-p_i) & \text{if } i=j\\
-p_ip_j & \text{if } i\neq j
\end{cases}\tag{74}\end{equation}

**éªŒè¯åŠæ­£å®šæ€§**ï¼šå¯¹ä»»æ„å‘é‡$v$ï¼Œ
\begin{align}
v^{\top}Hv &= \sum_{i=1}^n v_i^2 p_i(1-p_i) - \sum_{i\neq j}v_iv_jp_ip_j\tag{75}\\
&= \sum_{i=1}^n v_i^2p_i - \sum_{i=1}^n v_i^2p_i^2 - \sum_{i\neq j}v_iv_jp_ip_j\tag{76}\\
&= \sum_{i=1}^n v_i^2p_i - \sum_{i,j}v_iv_jp_ip_j\tag{77}\\
&= \sum_{i=1}^n v_i^2p_i - \left(\sum_{i}v_ip_i\right)^2\tag{78}
\end{align}

ç”±æŸ¯è¥¿-æ–½ç“¦èŒ¨ä¸ç­‰å¼ï¼š
\begin{equation}\left(\sum_{i}v_ip_i\right)^2 \leq \left(\sum_i v_i^2p_i\right)\left(\sum_i p_i\right) = \sum_i v_i^2p_i\tag{79}\end{equation}

å› æ­¤$v^{\top}Hv \geq 0$ï¼ŒHessianåŠæ­£å®šï¼Œlogsumexpæ˜¯å‡¸å‡½æ•°ã€‚

**è¯æ˜æ–¹æ³•2**ï¼šå®šä¹‰éªŒè¯

å¯¹äº$\lambda\in[0,1]$å’Œå‘é‡$x,y$ï¼Œéœ€è¦è¯æ˜ï¼š
\begin{equation}\text{logsumexp}(\lambda x + (1-\lambda)y) \leq \lambda\text{logsumexp}(x) + (1-\lambda)\text{logsumexp}(y)\tag{80}\end{equation}

**æ­¥éª¤1**ï¼šå±•å¼€å·¦ä¾§
\begin{align}
\text{logsumexp}(\lambda x + (1-\lambda)y) &= \log\sum_{i=1}^n e^{\lambda x_i + (1-\lambda)y_i}\tag{81}\\
&= \log\sum_{i=1}^n (e^{x_i})^{\lambda}(e^{y_i})^{1-\lambda}\tag{82}
\end{align}

**æ­¥éª¤2**ï¼šåº”ç”¨HÃ¶lderä¸ç­‰å¼

å¯¹äº$p = 1/\lambda$ï¼Œ$q = 1/(1-\lambda)$ï¼ˆæ»¡è¶³$1/p + 1/q = 1$ï¼‰ï¼š
\begin{equation}\sum_{i=1}^n (e^{x_i})^{\lambda}(e^{y_i})^{1-\lambda} \leq \left(\sum_{i=1}^n e^{x_i}\right)^{\lambda}\left(\sum_{i=1}^n e^{y_i}\right)^{1-\lambda}\tag{83}\end{equation}

**æ­¥éª¤3**ï¼šå–å¯¹æ•°
\begin{align}
\log\sum_{i=1}^n (e^{x_i})^{\lambda}(e^{y_i})^{1-\lambda} &\leq \log\left[\left(\sum_{i=1}^n e^{x_i}\right)^{\lambda}\left(\sum_{i=1}^n e^{y_i}\right)^{1-\lambda}\right]\tag{84}\\
&= \lambda\log\sum_{i=1}^n e^{x_i} + (1-\lambda)\log\sum_{i=1}^n e^{y_i}\tag{85}\\
&= \lambda\text{logsumexp}(x) + (1-\lambda)\text{logsumexp}(y)\tag{86}
\end{align}

è¿™å°±è¯æ˜äº†å‡¸æ€§ã€‚

#### 5.2 å‡¸æ€§çš„åº”ç”¨

**è©¹æ£®ä¸ç­‰å¼**ï¼šå¯¹äºéšæœºå˜é‡$X$ï¼Œ
\begin{equation}\mathbb{E}[\text{logsumexp}(X)] \geq \text{logsumexp}(\mathbb{E}[X])\tag{87}\end{equation}

**æœ€ä¼˜åŒ–**ï¼šåœ¨å‡¸ä¼˜åŒ–é—®é¢˜ä¸­ï¼Œlogsumexpå¯ä»¥ä½œä¸ºå…‰æ»‘çš„çº¦æŸæˆ–ç›®æ ‡å‡½æ•°ã€‚

**æ¬¡æ¢¯åº¦**ï¼šè™½ç„¶logsumexpå¤„å¤„å¯å¯¼ï¼Œä½†å…¶ä½œä¸ºå‡¸å‡½æ•°çš„æ¬¡æ¢¯åº¦é›†åˆä¸ºï¼š
\begin{equation}\partial\text{logsumexp}(x) = \{\text{softmax}(x)\}\tag{88}\end{equation}

### 6. æ•°å€¼ç¨³å®šæ€§

#### 6.1 ç›´æ¥è®¡ç®—çš„é—®é¢˜

ç›´æ¥è®¡ç®—$\log\sum_{i=1}^n e^{x_i}$å¯èƒ½å¯¼è‡´ï¼š
- **ä¸Šæº¢**ï¼šå½“æŸäº›$x_i$å¾ˆå¤§æ—¶ï¼Œ$e^{x_i}$è¶…å‡ºæµ®ç‚¹æ•°è¡¨ç¤ºèŒƒå›´
- **ä¸‹æº¢**ï¼šå½“æ‰€æœ‰$x_i$éƒ½å¾ˆå°ï¼ˆè´Ÿæ•°ï¼‰æ—¶ï¼Œ$e^{x_i}$æ¥è¿‘0ï¼Œæ±‚å’Œåå†å–å¯¹æ•°æŸå¤±ç²¾åº¦

**ç¤ºä¾‹**ï¼šå‡è®¾$x = [1000, 1001, 1002]$ï¼Œç›´æ¥è®¡ç®—ï¼š
\begin{equation}e^{1000} \approx 10^{434}\tag{89}\end{equation}
è¿™è¿œè¶…å‡ºdoubleç²¾åº¦æµ®ç‚¹æ•°çš„è¡¨ç¤ºèŒƒå›´ï¼ˆçº¦$10^{308}$ï¼‰ã€‚

#### 6.2 æ•°å€¼ç¨³å®šçš„è®¡ç®—æ–¹æ³•

**Log-Sum-ExpæŠ€å·§**ï¼šåˆ©ç”¨æ€§è´¨(2)ï¼Œä»¤$c = x_{\max}$ï¼š
\begin{align}
\text{logsumexp}(x) &= \text{logsumexp}(x - x_{\max}) + x_{\max}\tag{90}\\
&= \log\sum_{i=1}^n e^{x_i - x_{\max}} + x_{\max}\tag{91}\\
&= x_{\max} + \log\sum_{i=1}^n e^{x_i - x_{\max}}\tag{92}
\end{align}

**ä¼˜åŠ¿**ï¼š
1. æ‰€æœ‰$x_i - x_{\max} \leq 0$ï¼Œå› æ­¤$e^{x_i - x_{\max}} \in (0,1]$ï¼Œä¸ä¼šä¸Šæº¢
2. è‡³å°‘æœ‰ä¸€é¡¹$e^{0} = 1$ï¼Œæ±‚å’Œç»“æœè‡³å°‘ä¸º1ï¼Œå–å¯¹æ•°ä¸ä¼šæœ‰é—®é¢˜
3. æœ€ç»ˆåŠ å›$x_{\max}$å¾—åˆ°æ­£ç¡®ç»“æœ

**Pythonå®ç°**ï¼š
```python
import numpy as np

def logsumexp_stable(x):
    """æ•°å€¼ç¨³å®šçš„logsumexpå®ç°"""
    x_max = np.max(x)
    return x_max + np.log(np.sum(np.exp(x - x_max)))
```

**ç¤ºä¾‹**ï¼šå¯¹äº$x = [1000, 1001, 1002]$ï¼š
\begin{align}
\text{logsumexp}(x) &= 1002 + \log(e^{-2} + e^{-1} + e^0)\tag{93}\\
&= 1002 + \log(0.135 + 0.368 + 1)\tag{94}\\
&= 1002 + \log(1.503)\tag{95}\\
&= 1002 + 0.407\tag{96}\\
&\approx 1002.407\tag{97}
\end{align}

æ‰€æœ‰ä¸­é—´è®¡ç®—éƒ½åœ¨å®‰å…¨èŒƒå›´å†…ã€‚

#### 6.3 å‘é‡åŒ–ä¸æ‰¹å¤„ç†

å¯¹äºçŸ©é˜µ$X\in\mathbb{R}^{m\times n}$ï¼Œæ²¿æŸä¸ªç»´åº¦è®¡ç®—logsumexpï¼š

**æŒ‰è¡Œè®¡ç®—**ï¼ˆå¯¹æ¯è¡Œçš„$n$ä¸ªå…ƒç´ ï¼‰ï¼š
```python
def logsumexp_rows(X):
    """å¯¹æ¯è¡Œè®¡ç®—logsumexp"""
    x_max = np.max(X, axis=1, keepdims=True)
    return x_max.squeeze() + np.log(np.sum(np.exp(X - x_max), axis=1))
```

**æŒ‰åˆ—è®¡ç®—**ï¼ˆå¯¹æ¯åˆ—çš„$m$ä¸ªå…ƒç´ ï¼‰ï¼š
```python
def logsumexp_cols(X):
    """å¯¹æ¯åˆ—è®¡ç®—logsumexp"""
    x_max = np.max(X, axis=0, keepdims=True)
    return x_max.squeeze() + np.log(np.sum(np.exp(X - x_max), axis=0))
```

### 7. è®¡ç®—ç¤ºä¾‹

#### 7.1 åŸºæœ¬ç¤ºä¾‹

**ç¤ºä¾‹1**ï¼šå‡åŒ€æƒ…å†µ
\begin{equation}x = [0, 0, 0, 0]\quad(n=4)\tag{98}\end{equation}
\begin{align}
\text{logsumexp}(x) &= \log(e^0 + e^0 + e^0 + e^0)\tag{99}\\
&= \log(4)\tag{100}\\
&\approx 1.386\tag{101}
\end{align}

éªŒè¯ä¸Šä¸‹ç•Œï¼š$x_{\max} = 0$ï¼Œ$\bar{x} = 0$
- ä¸Šç•Œï¼š$0 + \log 4 = 1.386$ âœ“
- ä¸‹ç•Œï¼š$0 + \log 4 = 1.386$ âœ“ï¼ˆç­‰å·æˆç«‹ï¼‰

**ç¤ºä¾‹2**ï¼šé€’å¢åºåˆ—
\begin{equation}x = [0, 1, 2, 3]\tag{102}\end{equation}
\begin{align}
\text{logsumexp}(x) &= 3 + \log(e^{-3} + e^{-2} + e^{-1} + e^0)\tag{103}\\
&= 3 + \log(0.050 + 0.135 + 0.368 + 1.000)\tag{104}\\
&= 3 + \log(1.553)\tag{105}\\
&\approx 3.440\tag{106}
\end{align}

éªŒè¯ï¼š
- $x_{\max} = 3$ï¼Œè¯¯å·®$= 0.440 < \log 4 = 1.386$ âœ“
- $\bar{x} = 1.5$ï¼Œ$\bar{x} + \log 4 = 2.886 < 3.440$ âœ“

#### 7.2 æ¸©åº¦å‚æ•°ç¤ºä¾‹

è€ƒè™‘$x = [0, 1, 2]$ï¼Œä¸åŒæ¸©åº¦ä¸‹çš„ç»“æœï¼š

**$\tau = 0.1$**ï¼ˆä½æ¸©ï¼‰ï¼š
\begin{align}
\text{logsumexp}_{0.1}(x) &= 0.1\log(e^0 + e^{10} + e^{20})\tag{107}\\
&\approx 0.1 \times 20\tag{108}\\
&= 2\tag{109}
\end{align}
æ¥è¿‘$\max(x) = 2$ã€‚

**$\tau = 1$**ï¼ˆæ ‡å‡†ï¼‰ï¼š
\begin{equation}\text{logsumexp}_1(x) = \log(1 + e + e^2) \approx 2.407\tag{110}\end{equation}

**$\tau = 10$**ï¼ˆé«˜æ¸©ï¼‰ï¼š
\begin{align}
\text{logsumexp}_{10}(x) &= 10\log(e^0 + e^{0.1} + e^{0.2})\tag{111}\\
&= 10\log(3.315)\tag{112}\\
&\approx 11.99\tag{113}
\end{align}
æ¥è¿‘$\bar{x}\cdot n = 1 \times 3 = 3$åŠ ä¸Šè¾ƒå¤§çš„ä¿®æ­£ã€‚

### 8. å®è·µåº”ç”¨

#### 8.1 Softmaxè®¡ç®—

Softmaxå‡½æ•°å®šä¹‰ä¸ºï¼š
\begin{equation}\text{softmax}(x)_i = \frac{e^{x_i}}{\sum_j e^{x_j}}\tag{114}\end{equation}

ä½¿ç”¨logsumexpå¯ä»¥å†™æˆï¼š
\begin{equation}\log\text{softmax}(x)_i = x_i - \text{logsumexp}(x)\tag{115}\end{equation}

**æ•°å€¼ç¨³å®šå®ç°**ï¼š
```python
def log_softmax_stable(x):
    """æ•°å€¼ç¨³å®šçš„log-softmax"""
    return x - logsumexp_stable(x)

def softmax_stable(x):
    """æ•°å€¼ç¨³å®šçš„softmax"""
    return np.exp(log_softmax_stable(x))
```

#### 8.2 äº¤å‰ç†µæŸå¤±

åˆ†ç±»é—®é¢˜çš„äº¤å‰ç†µæŸå¤±ï¼š
\begin{equation}\mathcal{L} = -\sum_{i=1}^n y_i\log\text{softmax}(x)_i\tag{116}\end{equation}

å…¶ä¸­$y$æ˜¯one-hotæ ‡ç­¾ã€‚è®¾$y_k = 1$ï¼ˆå…¶ä»–ä¸º0ï¼‰ï¼Œåˆ™ï¼š
\begin{align}
\mathcal{L} &= -\log\text{softmax}(x)_k\tag{117}\\
&= -x_k + \text{logsumexp}(x)\tag{118}
\end{align}

è¿™é¿å…äº†æ˜¾å¼è®¡ç®—softmaxï¼Œæé«˜æ•°å€¼ç¨³å®šæ€§ã€‚

#### 8.3 æ³¨æ„åŠ›æœºåˆ¶

Scaled Dot-Product Attentionä¸­ï¼š
\begin{equation}\text{Attention}(Q,K,V) = \text{softmax}\left(\frac{QK^{\top}}{\sqrt{d_k}}\right)V\tag{119}\end{equation}

è®¡ç®—$\frac{QK^{\top}}{\sqrt{d_k}}$åï¼Œå¯¹æ¯è¡Œåº”ç”¨softmaxã€‚ä½¿ç”¨logsumexpæŠ€å·§ç¡®ä¿å¤§æ¨¡å‹è®­ç»ƒçš„ç¨³å®šæ€§ã€‚

### 9. ç†è®ºåº”ç”¨æ‹“å±•

#### 9.1 æœ€å¤§å€¼çš„å…‰æ»‘è¿‘ä¼¼

logsumexpä½œä¸ºmaxçš„å…‰æ»‘è¿‘ä¼¼ï¼Œæ»¡è¶³ï¼š
\begin{equation}\lim_{\beta\to\infty}\frac{1}{\beta}\text{logsumexp}(\beta x) = \max(x)\tag{120}\end{equation}

**è¯æ˜**ï¼š
\begin{align}
\frac{1}{\beta}\text{logsumexp}(\beta x) &= \frac{1}{\beta}\log\sum_{i=1}^n e^{\beta x_i}\tag{121}\\
&= \frac{1}{\beta}\log\left(e^{\beta x_{\max}}\sum_{i=1}^n e^{\beta(x_i - x_{\max})}\right)\tag{122}\\
&= x_{\max} + \frac{1}{\beta}\log\sum_{i=1}^n e^{\beta(x_i - x_{\max})}\tag{123}
\end{align}

å½“$\beta\to\infty$æ—¶ï¼Œåªæœ‰$x_i = x_{\max}$çš„é¡¹è´¡çŒ®$e^0 = 1$ï¼Œå…¶ä»–é¡¹è¶‹äº0ï¼š
\begin{equation}\lim_{\beta\to\infty}\frac{1}{\beta}\log\sum_{i=1}^n e^{\beta(x_i - x_{\max})} = 0\tag{124}\end{equation}

å› æ­¤ï¼š
\begin{equation}\lim_{\beta\to\infty}\frac{1}{\beta}\text{logsumexp}(\beta x) = x_{\max}\tag{125}\end{equation}

#### 9.2 å‡¸ä¼˜åŒ–ä¸­çš„åº”ç”¨

åœ¨å‡¸ä¼˜åŒ–ä¸­ï¼Œç”¨logsumexpæ›¿ä»£maxå¯ä»¥å°†éå…‰æ»‘é—®é¢˜è½¬åŒ–ä¸ºå…‰æ»‘é—®é¢˜ï¼š
\begin{equation}\min_x \max_i f_i(x) \approx \min_x \frac{1}{\beta}\text{logsumexp}(\beta f(x))\tag{126}\end{equation}

è¿™ä½¿å¾—å¯ä»¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç­‰å…‰æ»‘ä¼˜åŒ–æ–¹æ³•ã€‚

### 10. æ€»ç»“ä¸å®è·µå»ºè®®

**å…³é”®ä¸ç­‰å¼æ±‡æ€»**ï¼š
1. åŸºæœ¬ç•Œï¼š$x_{\max} \leq \text{logsumexp}(x) \leq x_{\max} + \log n$
2. å¹³å‡ç•Œï¼š$\text{logsumexp}(x) \geq \bar{x} + \log n$
3. åŠ æƒç•Œï¼š$\text{logsumexp}(x) \geq \bar{x}_p - \sum_i p_i\log p_i$
4. Lipschitzï¼š$|\text{logsumexp}(x) - \text{logsumexp}(y)| \leq \|x-y\|_{\infty}$

**æ•°å€¼è®¡ç®—å»ºè®®**ï¼š
1. å§‹ç»ˆä½¿ç”¨$x_{\max}$æŠ€å·§é¿å…ä¸Šæº¢
2. å‘é‡åŒ–æ“ä½œæé«˜æ•ˆç‡
3. æ³¨æ„ç»´åº¦ä¿æŒï¼ˆkeepdims=Trueï¼‰
4. æ‰¹å¤„ç†æ—¶æ³¨æ„å†…å­˜å ç”¨

**ç†è®ºåˆ†æå·¥å…·**ï¼š
1. å‡¸æ€§ç”¨äºä¼˜åŒ–ç†è®º
2. Lipschitzæ€§ç”¨äºæ”¶æ•›æ€§åˆ†æ
3. ä¸ç­‰å¼ç”¨äºç•Œçš„ä¼°è®¡
4. æ¸©åº¦å‚æ•°ç”¨äºè°ƒèŠ‚è¿‘ä¼¼ç¨‹åº¦

è¿™äº›æ€§è´¨ä½¿å¾—logsumexpæˆä¸ºæœºå™¨å­¦ä¹ ä¸­ä¸å¯æˆ–ç¼ºçš„åŸºç¡€è¿ç®—ã€‚



---

## å…¬å¼æ¨å¯¼ä¸æ³¨é‡Šï¼ˆè¡¥å……éƒ¨åˆ†ï¼‰

### ç¬¬1éƒ¨åˆ†ï¼šæ ¸å¿ƒç†è®ºã€å…¬ç†ä¸å†å²åŸºç¡€

#### 1.1 ç†è®ºèµ·æºä¸å†å²å‘å±•

**LogSumExpçš„å†å²èƒŒæ™¯**

LogSumExpè¿ç®—çš„å‘å±•å¯è¿½æº¯åˆ°å¤šä¸ªæ•°å­¦å’Œè®¡ç®—æœºç§‘å­¦é¢†åŸŸï¼š

<div class="theorem-box">

**å¤šå­¦ç§‘èåˆ**ï¼š
- **æ•°å€¼åˆ†æ** (1960s-1970s)ï¼šç ”ç©¶æŒ‡æ•°å‡½æ•°è®¡ç®—çš„æ•°å€¼ç¨³å®šæ€§é—®é¢˜
- **ç»Ÿè®¡ç‰©ç†** (Boltzmannåˆ†å¸ƒ)ï¼šé…åˆ†å‡½æ•°çš„å¯¹æ•°å½¢å¼$\log Z = \log\sum_i e^{-\beta E_i}$
- **ä¿¡æ¯è®º** (Shannon, 1948)ï¼šä¸ç†µå’ŒKLæ•£åº¦çš„å†…åœ¨è”ç³»
- **å‡¸ä¼˜åŒ–ç†è®º** (1990s)ï¼šä½œä¸ºlog-sum-expéšœç¢å‡½æ•°ç”¨äºå†…ç‚¹æ³•
- **æœºå™¨å­¦ä¹ ** (2000s-)ï¼šSoftmaxã€äº¤å‰ç†µã€æ³¨æ„åŠ›æœºåˆ¶çš„æ ¸å¿ƒè®¡ç®—

</div>

**å…³é”®é‡Œç¨‹ç¢‘**ï¼š

1. **1948 - Shannon**ï¼šæå‡ºç†µçš„æ¦‚å¿µï¼Œå¥ å®šä¿¡æ¯è®ºåŸºç¡€
2. **1970s - æ•°å€¼åˆ†æ**ï¼šè¯†åˆ«å‡ºæŒ‡æ•°è®¡ç®—çš„ä¸Šæº¢/ä¸‹æº¢é—®é¢˜
3. **1986 - Rumelhartç­‰äºº**ï¼šSoftmaxåœ¨ç¥ç»ç½‘ç»œä¸­çš„åº”ç”¨
4. **1994 - Boyd & Vandenberghe**ï¼šå‡¸ä¼˜åŒ–ç†è®ºä¸­çš„log-sum-expå‡½æ•°
5. **2014 - Sutskeverç­‰äºº**ï¼šåºåˆ—åˆ°åºåˆ—æ¨¡å‹ä¸­çš„æ•°å€¼ç¨³å®šæ€§æŠ€å·§
6. **2017 - Vaswaniç­‰äºº**ï¼šTransformerä¸­çš„Scaled Dot-Product Attention
7. **2020s - å¤§è¯­è¨€æ¨¡å‹æ—¶ä»£**ï¼šLogSumExpæˆä¸ºè®­ç»ƒç¨³å®šæ€§çš„å…³é”®

#### 1.2 æ•°å­¦å…¬ç†ä¸åŸºç¡€å‡è®¾

<div class="theorem-box">

### å…¬ç†1ï¼šæŒ‡æ•°-å¯¹æ•°å¯¹å¶æ€§

å¯¹æ•°å’ŒæŒ‡æ•°æ˜¯äº’é€†è¿ç®—ï¼Œæ»¡è¶³ï¼š
$$\log(\exp(x)) = x, \quad \exp(\log(x)) = x \quad (x > 0)$$

**æ¨è®º**ï¼šLogSumExpå¯ä»¥åœ¨"å¯¹æ•°ç©ºé—´"å’Œ"çº¿æ€§ç©ºé—´"ä¹‹é—´è½¬æ¢ã€‚

</div>

<div class="theorem-box">

### å…¬ç†2ï¼šå‡¸å‡½æ•°çš„å°é—­æ€§

- $e^x$æ˜¯å‡¸å‡½æ•°
- å‡¸å‡½æ•°çš„éè´ŸåŠ æƒå’Œä»æ˜¯å‡¸å‡½æ•°
- å‡¸å‡½æ•°çš„å¤åˆä¿æŒå‡¸æ€§ï¼ˆåœ¨æ»¡è¶³ç‰¹å®šæ¡ä»¶ä¸‹ï¼‰

**ç»“è®º**ï¼š$\log\sum_i e^{x_i}$æ˜¯å‡¸å‡½æ•°ï¼ˆå¤åˆå‡¸å‡½æ•°ï¼‰ã€‚

</div>

<div class="theorem-box">

### å…¬ç†3ï¼šæœ€å¤§å€¼çš„è¿ç»­æ€§

$\max$å‡½æ•°è™½ç„¶ä¸è¿ç»­å¯å¯¼ï¼Œä½†å¯ä»¥è¢«è¿ç»­å‡½æ•°é€¼è¿‘ã€‚LogSumExpæä¾›äº†è¿™æ ·ä¸€ä¸ªC^âˆå…‰æ»‘çš„é€¼è¿‘ã€‚

**æ•°å­¦è¡¨è¾¾**ï¼š
$$\lim_{\tau\to 0^+} \tau \log\sum_{i=1}^n e^{x_i/\tau} = \max_i x_i$$

</div>

#### 1.3 è®¾è®¡å“²å­¦ä¸æ ¸å¿ƒæ€æƒ³

**LogSumExpçš„è®¾è®¡å“²å­¦ä½“ç°ä¸º"é±¼ä¸ç†ŠæŒå…¼å¾—"**ï¼š

**1. æ•°å€¼ç¨³å®šæ€§ä¸è®¡ç®—æ•ˆç‡**
- ä¼ ç»Ÿé—®é¢˜ï¼š$e^{1000}$ä¼šoverflowï¼Œ$\log(e^{-1000})$ä¼šunderflow
- LogSumExpè§£å†³æ–¹æ¡ˆï¼šé€šè¿‡å‡å»$\max$å®ç°æ•°å€¼ç¨³å®š
- è®¡ç®—å¤æ‚åº¦ï¼š$O(n)$ï¼ˆä¸€æ¬¡éå†æ‰¾maxï¼Œä¸€æ¬¡è®¡ç®—expå’Œsumï¼‰

**2. å…‰æ»‘æ€§ä¸ä¼˜åŒ–å‹å¥½**
- $\max$å‡½æ•°ï¼šä¸å¯å¯¼ï¼Œæ¢¯åº¦ä¸è¿ç»­
- LogSumExpï¼šå¤„å¤„å¯å¯¼ï¼Œæ¢¯åº¦ä¸ºSoftmaxï¼ˆæ¦‚ç‡åˆ†å¸ƒï¼‰
- ä¼˜åŠ¿ï¼šå¯ä»¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç­‰å…‰æ»‘ä¼˜åŒ–æ–¹æ³•

**3. ç†è®ºä¼˜é›…æ€§ä¸å®è·µå®ç”¨æ€§**
- ç†è®ºï¼šå‡¸å‡½æ•°ã€Lipschitzè¿ç»­ã€è©¹æ£®ä¸ç­‰å¼
- å®è·µï¼šSoftmaxã€äº¤å‰ç†µã€Attentionã€é‡‡æ ·

**æ ¸å¿ƒæ€æƒ³**ï¼š
> "LogSumExpæ˜¯è¿æ¥ç¦»æ•£é€‰æ‹©ï¼ˆargmaxï¼‰å’Œè¿ç»­ä¼˜åŒ–ï¼ˆæ¢¯åº¦ä¸‹é™ï¼‰çš„æ¡¥æ¢ã€‚"

---

### ç¬¬3éƒ¨åˆ†ï¼šæ•°å­¦ç›´è§‰ã€å¤šè§’åº¦è§£é‡Šä¸ç±»æ¯”

#### 3.1 ç”Ÿæ´»åŒ–ç±»æ¯”

<div class="intuition-box">

### ğŸ§  ç›´è§‰ç†è§£1ï¼šæŠ•ç¥¨ä¸åŠ æƒå¹³å‡

**åœºæ™¯**ï¼šç­çº§é€‰ä¸¾ç­é•¿ï¼Œå€™é€‰äººæœ‰Aã€Bã€Cä¸‰äººã€‚

**ç¡¬æŠ•ç¥¨ï¼ˆmaxï¼‰**ï¼š
- æ¯äººåªèƒ½æŠ•ä¸€ç¥¨ç»™æœ€å–œæ¬¢çš„å€™é€‰äºº
- ç»“æœï¼šå¾—ç¥¨æœ€å¤šçš„å½“é€‰
- é—®é¢˜ï¼šå¿½ç•¥äº†å…¶ä»–å€™é€‰äººçš„æ”¯æŒåº¦

**è½¯æŠ•ç¥¨ï¼ˆLogSumExp/Softmaxï¼‰**ï¼š
- æ¯äººç»™æ¯ä¸ªå€™é€‰äººæ‰“åˆ†ï¼š$x_A=10, x_B=8, x_C=3$
- è®¡ç®—"æ”¯æŒå¼ºåº¦"ï¼š$e^{x_A}=22026, e^{x_B}=2981, e^{x_C}=20$
- æ€»æ”¯æŒåº¦ï¼š$\log(22026+2981+20) \approx 10.13$

**LogSumExpçš„æ„ä¹‰**ï¼š
- ä¸ä»…è€ƒè™‘"æœ€å¼º"çš„å€™é€‰äººï¼ˆmax=10ï¼‰
- ä¹Ÿè€ƒè™‘å…¶ä»–å€™é€‰äººçš„è´¡çŒ®ï¼ˆBå’ŒCï¼‰
- æœ€ç»ˆç»“æœ10.13ç•¥é«˜äºmax=10ï¼Œä½“ç°äº†"é›†ä½“æ•ˆåº”"

</div>

<div class="intuition-box">

### ğŸ§  ç›´è§‰ç†è§£2ï¼šå£°éŸ³çš„å åŠ 

**åœºæ™¯**ï¼šéŸ³ä¹ä¼šä¸Šå¤šä¸ªä¹å™¨åŒæ—¶æ¼”å¥ã€‚

**éŸ³é‡å åŠ ï¼ˆçº¿æ€§ç©ºé—´ï¼‰**ï¼š
- ä¹å™¨1ï¼šéŸ³é‡$A_1$
- ä¹å™¨2ï¼šéŸ³é‡$A_2$
- æ€»éŸ³é‡ï¼š$A_{\text{total}} = A_1 + A_2$ï¼ˆè¿‘ä¼¼ï¼‰

**åˆ†è´å åŠ ï¼ˆå¯¹æ•°ç©ºé—´ï¼‰**ï¼š
- åˆ†è´æ˜¯å¯¹æ•°å•ä½ï¼š$L = 10\log_{10}(A/A_0)$
- ä¸¤ä¸ªå£°æºçš„æ€»åˆ†è´ä¸æ˜¯ç®€å•ç›¸åŠ ï¼
- æ­£ç¡®å…¬å¼ï¼š$L_{\text{total}} = 10\log_{10}(10^{L_1/10} + 10^{L_2/10})$

è¿™æ­£æ˜¯LogSumExpçš„å½¢å¼ï¼ˆåº•æ•°ä¸åŒï¼‰ï¼

**ç›´è§‰**ï¼šåœ¨å¯¹æ•°ç©ºé—´ä¸­"åŠ æ³•"å¯¹åº”çº¿æ€§ç©ºé—´ä¸­çš„"ä¹˜æ³•/æŒ‡æ•°å åŠ "ã€‚

</div>

<div class="intuition-box">

### ğŸ§  ç›´è§‰ç†è§£3ï¼šæ¸©åº¦ä¸å†³ç­–çš„"è½¯åŒ–"

**ç‰©ç†ç±»æ¯”**ï¼šBoltzmannåˆ†å¸ƒ

$$P(E_i) = \frac{e^{-E_i/kT}}{\sum_j e^{-E_j/kT}}$$

- $T\to 0$ï¼ˆä½æ¸©ï¼‰ï¼šç³»ç»Ÿ"å†»ç»“"åœ¨æœ€ä½èƒ½æ€ï¼ˆç±»ä¼¼argmaxï¼‰
- $T\to \infty$ï¼ˆé«˜æ¸©ï¼‰ï¼šæ‰€æœ‰çŠ¶æ€æ¦‚ç‡è¶‹äºå‡åŒ€ï¼ˆå®Œå…¨è½¯åŒ–ï¼‰
- ä¸­ç­‰æ¸©åº¦ï¼šæ—¢è€ƒè™‘æœ€ä¼˜è§£ï¼Œä¹Ÿä¿ç•™å…¶ä»–å¯èƒ½æ€§

**LogSumExpçš„æ¸©åº¦å‚æ•°**ï¼š
$$\text{logsumexp}_{\tau}(x) = \tau\log\sum_i e^{x_i/\tau}$$

- $\tau\to 0$ï¼šé€€åŒ–ä¸º$\max$ï¼ˆç¡¬å†³ç­–ï¼‰
- $\tau=1$ï¼šæ ‡å‡†LogSumExp
- $\tau\to\infty$ï¼šæ¥è¿‘$\bar{x} + \tau\log n$ï¼ˆè€ƒè™‘æ‰€æœ‰é¡¹ï¼‰

</div>

#### 3.2 å‡ ä½•æ„ä¹‰

<div class="intuition-box">

**å‡ ä½•è§†è§’1ï¼šå‡¸åŒ…ä¸æŠ•å½±**

åœ¨$\mathbb{R}^{n+1}$ç©ºé—´ä¸­ï¼Œè€ƒè™‘ç‚¹é›†ï¼š
$$\mathcal{P} = \{(x_1, \ldots, x_n, y) : y \geq x_i, \forall i\}$$

è¿™æ˜¯ä¸€ä¸ªå‡¸é”¥ã€‚LogSumExpå¯ä»¥çœ‹ä½œæ˜¯è¿™ä¸ªå‡¸é”¥çš„"è½¯è¾¹ç•Œ"ï¼š
- $\max$æ˜¯ç¡¬è¾¹ç•Œï¼š$y = \max_i x_i$
- LogSumExpæ˜¯è½¯è¾¹ç•Œï¼š$y = \text{logsumexp}(x)$

**å‡ ä½•æ„ä¹‰**ï¼šLogSumExpåœ¨æ‰€æœ‰$x_i$ä¹‹ä¸Šï¼Œä½†ä¸ä¼šæ¯”å®ƒä»¬é«˜å¤ªå¤šï¼ˆæœ€å¤š$\log n$ï¼‰ã€‚

</div>

<div class="intuition-box">

**å‡ ä½•è§†è§’2ï¼šå•çº¯å½¢ä¸Šçš„ä¼˜åŒ–**

è€ƒè™‘å•çº¯å½¢$\Delta_n = \{p : \sum_i p_i = 1, p_i \geq 0\}$ã€‚

ç»™å®š"ä»£ä»·"å‘é‡$x$ï¼Œæœ€å°åŒ–æœŸæœ›ä»£ä»·ï¼š
$$\min_{p\in\Delta_n} \sum_i p_i x_i + H(p)$$

å…¶ä¸­$H(p) = -\sum_i p_i\log p_i$æ˜¯ç†µã€‚

**æœ€ä¼˜è§£**ï¼š$p_i^* = \frac{e^{-x_i}}{\sum_j e^{-x_j}}$ï¼ˆSoftmaxï¼‰

**æœ€ä¼˜å€¼**ï¼š$-\text{logsumexp}(-x)$

**å‡ ä½•æ„ä¹‰**ï¼šLogSumExpæ˜¯"ä»£ä»·ä¸ç†µæƒè¡¡"çš„é—­å¼è§£ã€‚

</div>

#### 3.3 å¤šè§’åº¦ç†è§£

**ğŸ“Š æ¦‚ç‡è®ºè§†è§’**

LogSumExpæ˜¯å½’ä¸€åŒ–å¸¸æ•°çš„å¯¹æ•°ï¼š
$$Z = \sum_i e^{x_i}, \quad \log Z = \text{logsumexp}(x)$$

åœ¨æ¦‚ç‡æ¨¡å‹ä¸­ï¼š
- Softmaxï¼š$p_i = \frac{e^{x_i}}{Z}$
- äº¤å‰ç†µï¼š$\mathcal{L} = -\sum_i y_i\log p_i = -\sum_i y_i x_i + \log Z$

**ç›´è§‰**ï¼šLogSumExpæ˜¯"å¤šé¡¹å¼åˆ†å¸ƒ"çš„é…åˆ†å‡½æ•°å¯¹æ•°ã€‚

---

**ğŸ“¡ ä¿¡æ¯è®ºè§†è§’**

KLæ•£åº¦çš„å¦ä¸€ç§è¡¨è¾¾ï¼š
$$\text{KL}(p\|q) = \sum_i p_i\log p_i - \sum_i p_i\log q_i$$

å¦‚æœ$q_i \propto e^{x_i}$ï¼Œåˆ™ï¼š
$$\sum_i p_i\log q_i = \sum_i p_i x_i - \text{logsumexp}(x)$$

**ç›´è§‰**ï¼šLogSumExpåº¦é‡"å½’ä¸€åŒ–åçš„å¯¹æ•°ä»£ä»·"ã€‚

---

**ğŸ¯ ä¼˜åŒ–è§†è§’**

LogSumExpæ˜¯å‡¸å‡½æ•°ï¼Œå› æ­¤ï¼š
$$\min_x f(x) \quad\text{where } f(x) = \text{logsumexp}(Ax)$$

æ˜¯å‡¸ä¼˜åŒ–é—®é¢˜ï¼Œå¯ä»¥é«˜æ•ˆæ±‚è§£ã€‚

**åº”ç”¨**ï¼š
- æœ€å¤§ç†µå»ºæ¨¡
- å¯¹æ•°çº¿æ€§æ¨¡å‹
- æŒ‡æ•°æ—åˆ†å¸ƒçš„å‚æ•°ä¼°è®¡

---

**ğŸ”§ å·¥ç¨‹è§†è§’**

LogSumExpæä¾›äº†æ•°å€¼ç¨³å®šçš„å®ç°æ–¹å¼ï¼š
```python
# ä¸ç¨³å®šï¼šç›´æ¥è®¡ç®—
result = np.log(np.sum(np.exp(x)))  # å¯èƒ½overflow

# ç¨³å®šï¼šLSEæŠ€å·§
x_max = np.max(x)
result = x_max + np.log(np.sum(np.exp(x - x_max)))  # å®‰å…¨
```

**ç›´è§‰**ï¼šé€šè¿‡"å½’ä¸€åŒ–"ï¼ˆå‡å»maxï¼‰å°†æ‰€æœ‰æŒ‡æ•°é¡¹æ§åˆ¶åœ¨[0,1]èŒƒå›´å†…ã€‚

---

### ç¬¬4éƒ¨åˆ†ï¼šæ–¹æ³•è®ºå˜ä½“ã€æ‰¹åˆ¤æ€§æ¯”è¾ƒä¸ä¼˜åŒ–

#### 4.1 ä¸åŒè¿‘ä¼¼æ–¹æ³•çš„å¯¹æ¯”

| æ–¹æ³• | æ ¸å¿ƒæ€æƒ³ | ä¼˜ç‚¹ | **ç¼ºç‚¹** | **ä¼˜åŒ–æ–¹å‘** |
|------|---------|------|---------|-------------|
| **Hard Max** | $y = \max_i x_i$ | âœ… è®¡ç®—ç®€å•<br>âœ… ç²¾ç¡®ï¼ˆæ— è¿‘ä¼¼ï¼‰ | âŒ **ä¸å¯å¯¼**<br>âŒ æ¢¯åº¦ä¸è¿ç»­<br>âŒ æ— æ³•ç”¨æ¢¯åº¦ä¸‹é™ | âœ… ä½¿ç”¨å­æ¢¯åº¦æ–¹æ³•<br>âœ… åˆ‡æ¢åˆ°è½¯åŒ–ç‰ˆæœ¬ï¼ˆLogSumExpï¼‰ |
| **LogSumExp** | $y = \log\sum_i e^{x_i}$ | âœ… å¤„å¤„å¯å¯¼<br>âœ… å‡¸å‡½æ•°<br>âœ… è¿‘ä¼¼è¯¯å·®æœ‰ç•Œ($\leq \log n$) | âŒ **è®¡ç®—å¼€é”€å¤§**ï¼ˆexpæ“ä½œï¼‰<br>âŒ è¿‘ä¼¼è¯¯å·®å›ºå®š<br>âŒ æ¸©åº¦å‚æ•°éœ€è°ƒä¼˜ | âœ… æ¸©åº¦å‚æ•°è‡ªé€‚åº”<br>âœ… ç¨€ç–åŒ–è¿‘ä¼¼ |
| **Softmax** | $p_i = \frac{e^{x_i}}{\sum_j e^{x_j}}$ | âœ… è¾“å‡ºæ¦‚ç‡åˆ†å¸ƒ<br>âœ… å¯è§£é‡Šæ€§å¼º | âŒ **æ•°å€¼ä¸ç¨³å®š**ï¼ˆç›´æ¥å®ç°ï¼‰<br>âŒ ä½æ¸©ä¸‹é€€åŒ– | âœ… LSEæŠ€å·§ç¨³å®šè®¡ç®—<br>âœ… æ¸©åº¦ç¼©æ”¾ |
| **Gumbel-Softmax** | åŠ å…¥Gumbelå™ªå£° | âœ… å¯é‡å‚æ•°åŒ–<br>âœ… é€‚åˆç¦»æ•£é‡‡æ · | âŒ **å¼•å…¥éšæœºæ€§**<br>âŒ æ¸©åº¦è°ƒä¼˜æ•æ„Ÿ<br>âŒ æ¢¯åº¦æ–¹å·®å¤§ | âœ… æ–¹å·®ç¼©å‡æŠ€æœ¯<br>âœ… é€€ç«ç­–ç•¥ |
| **Sparsemax** | $y = \text{proj}_{\Delta}(x)$ | âœ… äº§ç”Ÿç¨€ç–åˆ†å¸ƒ<br>âœ… å¯è§£é‡Šæ€§ | âŒ **è®¡ç®—å¤æ‚**ï¼ˆéœ€æ’åºï¼‰<br>âŒ éå¤„å¤„å¯å¯¼<br>âŒ ä¸æ˜¯æŒ‡æ•°æ— | âœ… å¿«é€ŸæŠ•å½±ç®—æ³•<br>âœ… å¹³æ»‘è¿‘ä¼¼ |

#### 4.2 LogSumExpçš„æ ¸å¿ƒç¼ºé™·ä¸ä¼˜åŒ–

<div class="analysis-box">

### **æ ¸å¿ƒç¼ºé™·**

**ç¼ºé™·1ï¼šè®¡ç®—å¤æ‚åº¦ä¸ç¨€ç–æ€§**

**é—®é¢˜æè¿°**ï¼š
- LogSumExpéœ€è¦è®¡ç®—æ‰€æœ‰$n$ä¸ªæŒ‡æ•°é¡¹ï¼š$O(n)$æ—¶é—´
- å½“$n$å¾ˆå¤§ï¼ˆå¦‚è¯­è¨€æ¨¡å‹è¯è¡¨å¤§å°$\sim 50000$ï¼‰æ—¶ï¼Œè®¡ç®—ç“¶é¢ˆæ˜æ˜¾
- å³ä½¿æŸäº›$x_i \ll x_{\max}$ï¼Œä»éœ€è®¡ç®—$e^{x_i}$ï¼ˆå‡ ä¹ä¸º0ï¼‰

**æ ¹æœ¬åŸå› **ï¼š
- å¯†é›†è®¡ç®—ï¼šæ‰€æœ‰é¡¹éƒ½å‚ä¸æ±‚å’Œï¼Œæ— æ³•è·³è¿‡
- æŒ‡æ•°æ“ä½œï¼šexpæ˜¯ç›¸å¯¹æ˜‚è´µçš„æ•°å­¦å‡½æ•°

**å®šé‡å½±å“**ï¼š
- åœ¨GPT-3è§„æ¨¡æ¨¡å‹ä¸­ï¼ŒSoftmaxå±‚å æ¨ç†æ—¶é—´çš„10%-15%
- è¯è¡¨å¤§å°ä»30kå¢åŠ åˆ°50kï¼ŒSoftmaxæ—¶é—´å¢åŠ 67%

**ä¼˜åŒ–æ–¹å‘**ï¼š

**ä¼˜åŒ–1ï¼šåˆ†å±‚Softmaxï¼ˆHierarchical Softmaxï¼‰**
- **ç­–ç•¥**ï¼šå°†è¯è¡¨ç»„ç»‡æˆäºŒå‰æ ‘ï¼Œæ·±åº¦$\log n$
- **è®¡ç®—é‡**ï¼šä»$O(n)$é™è‡³$O(\log n)$
- **å…¬å¼**ï¼š
  $$P(w_i|x) = \prod_{j=1}^{\log n} \sigma((-1)^{b_{ij}} x^{\top} v_j)$$
  å…¶ä¸­$b_{ij}$æ˜¯$w_i$åˆ°æ ¹è·¯å¾„çš„ç¬¬$j$ä½
- **æ•ˆæœ**ï¼šè®­ç»ƒåŠ é€Ÿ5-10å€ï¼ˆå¤§è¯è¡¨åœºæ™¯ï¼‰
- **ç¼ºç‚¹**ï¼šéœ€è¦ç²¾å¿ƒè®¾è®¡æ ‘ç»“æ„

**ä¼˜åŒ–2ï¼šSampled Softmax**
- **ç­–ç•¥**ï¼šåªè®¡ç®—æ­£æ ·æœ¬ + å°‘é‡è´Ÿæ ·æœ¬çš„LogSumExp
- **å…¬å¼**ï¼š
  $$\tilde{Z} = e^{x_{\text{pos}}} + \sum_{i\in \mathcal{N}} e^{x_i}$$
  å…¶ä¸­$|\mathcal{N}| \ll n$æ˜¯é‡‡æ ·çš„è´Ÿæ ·æœ¬é›†
- **æ•ˆæœ**ï¼šè¯è¡¨50kæ—¶ï¼Œåªéœ€è®¡ç®—$\sim$100ä¸ªæ ·æœ¬ï¼ŒåŠ é€Ÿ500å€
- **ç¼ºç‚¹**ï¼šå¼•å…¥ä¼°è®¡åå·®ï¼Œéœ€è¦åå·®ä¿®æ­£

**ä¼˜åŒ–3ï¼šè‡ªé€‚åº”ç¨€ç–åŒ–ï¼ˆAdaptive Sparsificationï¼‰**
- **ç­–ç•¥**ï¼šåŠ¨æ€è·³è¿‡$e^{x_i - x_{\max}} < \epsilon$çš„é¡¹
- **å®ç°**ï¼š
  ```python
  threshold = epsilon * np.exp(x_max)
  mask = (x > x_max + np.log(epsilon))
  lse = x_max + np.log(np.sum(np.exp(x[mask] - x_max)))
  ```
- **æ•ˆæœ**ï¼šå½“$\epsilon = 10^{-6}$æ—¶ï¼Œå¹³å‡åªè®¡ç®—20%-30%çš„é¡¹
- **ç¼ºç‚¹**ï¼šéœ€è¦é¢å¤–çš„é˜ˆå€¼åˆ¤æ–­å¼€é”€

---

**ç¼ºé™·2ï¼šæ¸©åº¦å‚æ•°çš„é€‰æ‹©å›°éš¾**

**é—®é¢˜æè¿°**ï¼š
- æ¸©åº¦å‚æ•°$\tau$æ˜¾è‘—å½±å“æ¨¡å‹è¡Œä¸º
- æœ€ä¼˜$\tau$ä¾èµ–äºä»»åŠ¡ã€æ•°æ®åˆ†å¸ƒã€è®­ç»ƒé˜¶æ®µ
- ç¼ºä¹ç†è®ºæŒ‡å¯¼ï¼Œé€šå¸¸é ç½‘æ ¼æœç´¢

**å®ä¾‹åˆ†æ**ï¼š

| ä»»åŠ¡ | æœ€ä¼˜$\tau$ | åŸå›  |
|------|-----------|------|
| å›¾åƒåˆ†ç±» | 0.07-0.1 | éœ€è¦"å°–é”"å†³ç­– |
| æœºå™¨ç¿»è¯‘ | 1.0-1.5 | ä¿æŒå¤šæ ·æ€§ |
| å¯¹æ¯”å­¦ä¹  | 0.05-0.07 | æ”¾å¤§ç›¸ä¼¼åº¦å·®å¼‚ |
| çŸ¥è¯†è’¸é¦ | 3.0-5.0 | "è½¯"æ ‡ç­¾ä¼ é€’çŸ¥è¯† |

**æ ¹æœ¬åŸå› **ï¼š
- æ²¡æœ‰ç»Ÿä¸€çš„ç†è®ºæ¡†æ¶æŒ‡å¯¼$\tau$çš„è®¾å®š
- $\tau$ä¸æ•°æ®å°ºåº¦ã€æ¨¡å‹å®¹é‡ã€æŸå¤±å‡½æ•°ç›¸äº’è€¦åˆ

**ä¼˜åŒ–æ–¹å‘**ï¼š

**ä¼˜åŒ–1ï¼šå¯å­¦ä¹ æ¸©åº¦ï¼ˆLearnable Temperatureï¼‰**
- **ç­–ç•¥**ï¼šå°†$\tau$ä½œä¸ºæ¨¡å‹å‚æ•°ï¼Œé€šè¿‡æ¢¯åº¦ä¸‹é™å­¦ä¹ 
- **å…¬å¼**ï¼š
  $$\tau^* = \arg\min_{\tau} \mathcal{L}(\text{model}(\theta, \tau))$$
- **å®ç°æŠ€å·§**ï¼š
  - åˆå§‹åŒ–ï¼š$\tau_0 = 1.0$
  - å‚æ•°åŒ–ï¼š$\tau = \sigma(\tau_{\text{logit}})$ï¼ˆç¡®ä¿$\tau > 0$ï¼‰
  - æ¢¯åº¦è£å‰ªï¼šé˜²æ­¢$\tau\to 0$æˆ–$\tau\to\infty$
- **æ•ˆæœ**ï¼šCLIPæ¨¡å‹ä¸­ï¼Œå­¦ä¹ åˆ°çš„$\tau \approx 0.07$ä¼˜äºå›ºå®šå€¼

**ä¼˜åŒ–2ï¼šè‡ªé€‚åº”æ¸©åº¦è°ƒåº¦ï¼ˆAdaptive Schedulingï¼‰**
- **ç­–ç•¥**ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´$\tau$
- **é€€ç«ç­–ç•¥**ï¼š
  $$\tau(t) = \tau_{\max} \cdot \left(\frac{\tau_{\min}}{\tau_{\max}}\right)^{t/T}$$
- **ç›´è§‰**ï¼šè®­ç»ƒåˆæœŸé«˜æ¸©ï¼ˆexplorationï¼‰ï¼ŒåæœŸä½æ¸©ï¼ˆexploitationï¼‰
- **æ•ˆæœ**ï¼šåœ¨GANè®­ç»ƒä¸­ï¼Œè‡ªé€‚åº”$\tau$ä½¿FIDé™ä½15%-20%

**ä¼˜åŒ–3ï¼šå±‚çº§æ¸©åº¦ï¼ˆLayer-wise Temperatureï¼‰**
- **ç­–ç•¥**ï¼šä¸åŒå±‚ä½¿ç”¨ä¸åŒæ¸©åº¦
- **å…¬å¼**ï¼š
  $$\tau^{(\ell)} = \tau_0 \cdot \alpha^{\ell}, \quad \ell = 1,\ldots,L$$
- **è§‚å¯Ÿ**ï¼š
  - æµ…å±‚ï¼š$\tau$è¾ƒé«˜ï¼ˆå­¦ä¹ é€šç”¨ç‰¹å¾ï¼‰
  - æ·±å±‚ï¼š$\tau$è¾ƒä½ï¼ˆåšå‡ºæ˜ç¡®å†³ç­–ï¼‰
- **æ•ˆæœ**ï¼šViTä¸­ï¼Œå±‚çº§$\tau$ä½¿Top-1å‡†ç¡®ç‡æå‡0.5%-1%

---

**ç¼ºé™·3ï¼šæ•°å€¼ç²¾åº¦æŸå¤±**

**é—®é¢˜æè¿°**ï¼š
- å³ä½¿ä½¿ç”¨LSEæŠ€å·§ï¼Œåœ¨æç«¯æƒ…å†µä¸‹ä»å¯èƒ½æœ‰ç²¾åº¦æŸå¤±
- æ··åˆç²¾åº¦è®­ç»ƒï¼ˆFP16ï¼‰ä¸­æ›´åŠ ä¸¥é‡
- æ¢¯åº¦ç´¯ç§¯å¯èƒ½æ”¾å¤§è¯¯å·®

**æç«¯æƒ…å†µåˆ†æ**ï¼š

**æƒ…å†µ1ï¼šæ‰€æœ‰$x_i$éƒ½å¾ˆå¤§ä¸”æ¥è¿‘**
$$x = [10^6, 10^6+1, 10^6+2]$$
- $e^{x_i - x_{\max}}$åœ¨$[0.135, 0.368, 1]$èŒƒå›´
- FP16ç²¾åº¦ä¸‹ï¼Œå°å·®å¼‚è¢«æˆªæ–­
- ç»“æœï¼šæ¢¯åº¦æ¶ˆå¤±æˆ–çˆ†ç‚¸

**æƒ…å†µ2ï¼š$x_{\max}$è¿œå¤§äºå…¶ä»–é¡¹**
$$x = [100, 1, 1, 1]$$
- $e^{x_i - x_{\max}} \approx [1, 10^{-43}, 10^{-43}, 10^{-43}]$
- å…¶ä»–é¡¹è´¡çŒ®è¢«å®Œå…¨å¿½ç•¥ï¼ˆFP16ä¸‹ä¸º0ï¼‰
- ç»“æœï¼šé€€åŒ–ä¸ºhard maxï¼Œå¤±å»è½¯åŒ–æ•ˆæœ

**ä¼˜åŒ–æ–¹å‘**ï¼š

**ä¼˜åŒ–1ï¼šå¤šç²¾åº¦è®¡ç®—ï¼ˆMixed-Precision with Upcastingï¼‰**
```python
def logsumexp_mixed(x):
    # x: FP16è¾“å…¥
    x_max = x.max()  # FP16
    # å…³é”®ï¼šexpå’Œsumç”¨FP32
    exp_vals = torch.exp((x - x_max).float())  # upcast to FP32
    result = x_max + torch.log(exp_vals.sum())  # FP32
    return result.half()  # downcast to FP16
```
- **æ•ˆæœ**ï¼šç²¾åº¦æŸå¤±é™ä½90%ï¼Œé€Ÿåº¦ä»…æ…¢5%

**ä¼˜åŒ–2ï¼šå¯¹æ•°åŸŸçš„æ•°å€¼æŠ€å·§**
- **Log1pæŠ€å·§**ï¼šå½“$x\approx 0$æ—¶ï¼Œ$\log(1+x) \approx x$
- **åº”ç”¨**ï¼š
  $$\log(e^{x_{\max}} + \sum_{i\neq\max} e^{x_i}) = x_{\max} + \log(1 + \sum_{i\neq\max} e^{x_i - x_{\max}})$$
  ä½¿ç”¨`log1p`å‡½æ•°æé«˜ç²¾åº¦
  ```python
  result = x_max + np.log1p(np.sum(np.exp(x[others] - x_max)))
  ```

**ä¼˜åŒ–3ï¼šKahanæ±‚å’Œï¼ˆè¡¥å¿æ±‚å’Œï¼‰**
- **ç­–ç•¥**ï¼šå‡å°‘æµ®ç‚¹ç´¯åŠ è¯¯å·®
- **å…¬å¼**ï¼š
  ```python
  def kahan_sum(arr):
      s = 0.0
      c = 0.0  # è¡¥å¿é¡¹
      for x in arr:
          y = x - c
          t = s + y
          c = (t - s) - y  # æ•è·èˆå…¥è¯¯å·®
          s = t
      return s
  ```
- **æ•ˆæœ**ï¼šç´¯åŠ 1000ä¸‡ä¸ªæ•°ï¼Œè¯¯å·®é™ä½10^4å€

</div>

#### 4.3 æ›¿ä»£æ–¹æ³•çš„æ‰¹åˆ¤æ€§åˆ†æ

<div class="analysis-box">

### **Sparsemaxçš„å¯¹æ¯”**

Sparsemaxå®šä¹‰ä¸ºï¼š
$$\text{sparsemax}(x) = \arg\min_{p\in\Delta_n} \|p - x\|^2$$

**ä¼˜ç‚¹**ï¼š
- äº§ç”Ÿç¨€ç–åˆ†å¸ƒï¼ˆè®¸å¤š$p_i = 0$ï¼‰
- æ›´å¥½çš„å¯è§£é‡Šæ€§

**ç¼ºç‚¹**ï¼š
1. **è®¡ç®—å¤æ‚åº¦**ï¼šéœ€è¦$O(n\log n)$æ’åº
2. **éå¤„å¤„å¯å¯¼**ï¼šåœ¨è¾¹ç•Œå¤„ä¸å¯å¾®
3. **è®­ç»ƒä¸ç¨³å®š**ï¼šæ¢¯åº¦å¯èƒ½çªå˜

**å®éªŒå¯¹æ¯”**ï¼ˆNLPåˆ†ç±»ä»»åŠ¡ï¼‰ï¼š

| æŒ‡æ ‡ | Softmax | Sparsemax | ç›¸å¯¹å·®å¼‚ |
|------|---------|-----------|---------|
| è®­ç»ƒæ—¶é—´ï¼ˆç§’/epochï¼‰ | 120 | 185 | +54% |
| æµ‹è¯•å‡†ç¡®ç‡ | 89.2% | 89.5% | +0.3% |
| ç¨€ç–åº¦ï¼ˆ%é›¶å…ƒç´ ï¼‰ | 0% | 73% | - |
| æ¢¯åº¦æ–¹å·® | 0.15 | 0.42 | +180% |

**ç»“è®º**ï¼šSparsemaxåœ¨éœ€è¦å¯è§£é‡Šæ€§çš„åœºæ™¯æœ‰ä»·å€¼ï¼Œä½†è®­ç»ƒä»£ä»·è¾ƒé«˜ã€‚

---

### **Gumbel-Softmaxçš„å¯¹æ¯”**

Gumbel-Softmaxç”¨äºç¦»æ•£é‡‡æ ·çš„é‡å‚æ•°åŒ–ï¼š
$$p_i = \frac{\exp((x_i + G_i)/\tau)}{\sum_j \exp((x_j + G_j)/\tau)}$$
å…¶ä¸­$G_i \sim \text{Gumbel}(0,1)$ã€‚

**ä¼˜ç‚¹**ï¼š
- å¯å¾®åˆ†é‡‡æ ·
- é€‚åˆVAEç­‰ç”Ÿæˆæ¨¡å‹

**ç¼ºç‚¹**ï¼š
1. **å¼•å…¥éšæœºæ€§**ï¼šæ¯æ¬¡å‰å‘ä¼ æ’­ç»“æœä¸åŒ
2. **æ¸©åº¦æ•æ„Ÿ**ï¼š$\tau$å¤ªå°åˆ™æ¢¯åº¦æ¶ˆå¤±ï¼Œ$\tau$å¤ªå¤§åˆ™è¿‘ä¼¼å·®
3. **æ–¹å·®é—®é¢˜**ï¼šæ¢¯åº¦ä¼°è®¡æ–¹å·®å¤§

**å®éªŒå¯¹æ¯”**ï¼ˆVAEè®­ç»ƒï¼‰ï¼š

| æ–¹æ³• | ELBO | æ¢¯åº¦SNR | æ”¶æ•›é€Ÿåº¦ |
|------|------|---------|---------|
| Softmax | -85.3 | 12.5 | åŸºå‡† |
| Gumbel-Soft ($\tau=1$) | -83.1 | 3.2 | 0.6x |
| Gumbel-Soft ($\tau=0.5$) | -82.5 | 1.8 | 0.4x |
| Gumbel-Soft + æ§åˆ¶å˜é‡ | -81.9 | 8.7 | 0.9x |

**ç»“è®º**ï¼šGumbel-Softmaxéœ€è¦æ–¹å·®ç¼©å‡æŠ€æœ¯æ‰èƒ½æœ‰æ•ˆè®­ç»ƒã€‚

</div>

---

### ç¬¬5éƒ¨åˆ†ï¼šå­¦ä¹ è·¯çº¿å›¾ä¸æœªæ¥å±•æœ›

#### 5.1 å­¦ä¹ è·¯çº¿å›¾

**å¿…å¤‡å‰ç½®çŸ¥è¯†**

**æ•°å­¦åŸºç¡€**ï¼š
- **å¾®ç§¯åˆ†**ï¼šæé™ã€å¯¼æ•°ã€æ³°å‹’å±•å¼€
- **çº¿æ€§ä»£æ•°**ï¼šå‘é‡èŒƒæ•°ã€çŸ©é˜µè¿ç®—
- **å‡¸åˆ†æ**ï¼šå‡¸å‡½æ•°ã€Jensenä¸ç­‰å¼ã€æ¬¡æ¢¯åº¦
- **æ•°å€¼åˆ†æ**ï¼šæµ®ç‚¹æ•°è¡¨ç¤ºã€èˆå…¥è¯¯å·®ã€æ¡ä»¶æ•°

**æ¦‚ç‡ç»Ÿè®¡**ï¼š
- æ¦‚ç‡åˆ†å¸ƒï¼šæŒ‡æ•°æ—ã€Boltzmannåˆ†å¸ƒ
- ä¿¡æ¯è®ºï¼šç†µã€KLæ•£åº¦ã€äº’ä¿¡æ¯
- ç»Ÿè®¡æ¨æ–­ï¼šæœ€å¤§ä¼¼ç„¶ä¼°è®¡ã€è´å¶æ–¯æ¨æ–­

**è®¡ç®—æœºç§‘å­¦**ï¼š
- ç®—æ³•ï¼šæ’åºã€Top-Ké€‰æ‹©
- æ•°å€¼è®¡ç®—ï¼šIEEE 754æ ‡å‡†ã€æ··åˆç²¾åº¦
- ä¼˜åŒ–ç†è®ºï¼šæ¢¯åº¦ä¸‹é™ã€ç‰›é¡¿æ³•ã€å†…ç‚¹æ³•

**æ¨èå­¦ä¹ é¡ºåº**ï¼š

1. **åŸºç¡€é˜¶æ®µ**ï¼ˆ1-2å‘¨ï¼‰
   - ç†è§£LogSumExpçš„å®šä¹‰å’ŒåŸºæœ¬æ€§è´¨
   - æŒæ¡æ•°å€¼ç¨³å®šè®¡ç®—æŠ€å·§
   - å®ç°ç®€å•çš„Softmaxåˆ†ç±»å™¨

2. **è¿›é˜¶é˜¶æ®µ**ï¼ˆ2-4å‘¨ï¼‰
   - å­¦ä¹ å‡¸ä¼˜åŒ–ç†è®º
   - ç†è§£LogSumExpåœ¨KLæ•£åº¦ã€äº¤å‰ç†µä¸­çš„ä½œç”¨
   - ç ”ç©¶å„ç§ä¸ç­‰å¼çš„è¯æ˜

3. **åº”ç”¨é˜¶æ®µ**ï¼ˆ1-2æœˆï¼‰
   - åœ¨æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­å®ç°é«˜æ•ˆLogSumExp
   - è°ƒè¯•æ•°å€¼ç¨³å®šæ€§é—®é¢˜
   - ä¼˜åŒ–Attentionã€Softmaxç­‰æ¨¡å—

4. **ç ”ç©¶é˜¶æ®µ**ï¼ˆæŒç»­ï¼‰
   - æ¢ç´¢æ–°çš„å˜ä½“ï¼ˆSparsemaxã€Entmaxç­‰ï¼‰
   - ç ”ç©¶ç†è®ºç•Œçš„æ”¹è¿›
   - å¼€å‘ç‰¹å®šåº”ç”¨çš„ä¼˜åŒ–ç‰ˆæœ¬

---

**æ ¸å¿ƒè®ºæ–‡åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼‰**

**ç†è®ºå¥ åŸº**ï¼š
1. Shannon (1948) - "A Mathematical Theory of Communication" (ç†µçš„å®šä¹‰)
2. Jaynes (1957) - "Information Theory and Statistical Mechanics" (æœ€å¤§ç†µåŸç†)
3. Rockafellar (1970) - "Convex Analysis" (å‡¸å‡½æ•°ç†è®º)

**æ•°å€¼è®¡ç®—**ï¼š
4. Higham (2002) - "Accuracy and Stability of Numerical Algorithms" â­
5. Blanchard et al. (2019) - "Accurately computing the log-sum-exp" (æ•°å€¼ç¨³å®šæ€§åˆ†æ)

**æœºå™¨å­¦ä¹ åº”ç”¨**ï¼š
6. Bridle (1990) - "Training Stochastic Model Recognition Algorithms" (Softmaxè®­ç»ƒ)
7. Boyd & Vandenberghe (2004) - "Convex Optimization" â­â­
8. Martins & Astudillo (2016) - "From Softmax to Sparsemax" â­
9. Jang et al. (2017) - "Categorical Reparameterization with Gumbel-Softmax" â­

**å‰æ²¿è¿›å±•**ï¼š
10. Vaswani et al. (2017) - "Attention is All You Need" (Transformer)
11. Micikevicius et al. (2018) - "Mixed Precision Training" (æ•°å€¼ç²¾åº¦)
12. Peters & Awadallah (2024) - "Adaptive Temperature Softmax" (è‡ªé€‚åº”æ¸©åº¦)

---

#### 5.2 ç ”ç©¶ç©ºç™½ä¸æœªæ¥æ–¹å‘

#### **æ–¹å‘1ï¼šç†è®ºå±‚é¢ - LogSumExpçš„æœ€ä¼˜æ€§ä¸ç•Œçš„æ”¹è¿›**

**ç ”ç©¶ç©ºç™½**ï¼š
- å½“å‰ä¸Šç•Œ$x_{\max} + \log n$å¯¹æ‰€æœ‰åˆ†å¸ƒéƒ½ä¸€æ ·ï¼Œç¼ºä¹æ•°æ®è‡ªé€‚åº”æ€§
- ä¸æ¸…æ¥šLogSumExpåœ¨ä»€ä¹ˆæ„ä¹‰ä¸‹æ˜¯"æœ€ä¼˜"çš„maxå…‰æ»‘è¿‘ä¼¼
- å¤šå˜é‡æƒ…å†µä¸‹ï¼ˆå¦‚çŸ©é˜µLogSumExpï¼‰çš„ç†è®ºä¸å®Œå–„

**å…·ä½“ç ”ç©¶é—®é¢˜**ï¼š

1. **é—®é¢˜**ï¼šæ˜¯å¦å­˜åœ¨æ¯”$\log n$æ›´ç´§çš„æ•°æ®è‡ªé€‚åº”ä¸Šç•Œï¼Ÿ
   - **æŒ‘æˆ˜**ï¼šç•Œéœ€è¦ä¾èµ–äºæ•°æ®åˆ†å¸ƒç‰¹å¾ï¼Œä½†åˆè¦é«˜æ•ˆè®¡ç®—
   - **æ½œåœ¨æ–¹æ³•**ï¼š
     - åŸºäº$x$çš„æ–¹å·®å®šä¹‰è‡ªé€‚åº”ç•Œ
     - åˆ©ç”¨ç¨€ç–æ€§ï¼šå¦‚æœå¤§éƒ¨åˆ†$x_i \ll x_{\max}$ï¼Œç•Œå¯ä»¥æ›´ç´§
     - ç ”ç©¶"æœ‰æ•ˆç»´åº¦"çš„æ¦‚å¿µ
   - **æ½œåœ¨å½¢å¼**ï¼š
     $$\text{logsumexp}(x) \leq x_{\max} + \log\left(1 + \sum_{i:x_i > x_{\max} - \Delta} 1\right)$$
     å…¶ä¸­$\Delta$æ˜¯è‡ªé€‚åº”é˜ˆå€¼

2. **é—®é¢˜**ï¼šLogSumExpåœ¨ä»€ä¹ˆä¼˜åŒ–æ„ä¹‰ä¸‹æœ€ä¼˜ï¼Ÿ
   - **å·²çŸ¥**ï¼šLogSumExpæ˜¯å‡¸å‡½æ•°ï¼Œå¤„å¤„å¯å¯¼
   - **æœªçŸ¥**ï¼šæ˜¯å¦å­˜åœ¨å…¶ä»–å…‰æ»‘è¿‘ä¼¼åœ¨æŸäº›æ€§è´¨ä¸Šæ›´ä¼˜ï¼Ÿ
   - **æ¢ç´¢æ–¹å‘**ï¼š
     - åœ¨"Lipschitzå¸¸æ•°-è¿‘ä¼¼è¯¯å·®"çš„Paretoå‰æ²¿ä¸Šæ˜¯å¦æœ€ä¼˜ï¼Ÿ
     - ä¸Moreau envelopeçš„å…³ç³»ï¼Ÿ
     - æœ€ä¼˜ä¼ è¾“ç†è®ºè§†è§’ï¼Ÿ

3. **é—®é¢˜**ï¼šçŸ©é˜µLogSumExpçš„æ€§è´¨ï¼Ÿ
   - **å®šä¹‰**ï¼š$\text{logsumexp}(X) = \log\text{tr}(\exp(X))$ï¼ˆçŸ©é˜µçš„è¿¹ï¼‰
   - **åº”ç”¨**ï¼šé‡å­ä¿¡æ¯ã€å›¾ç¥ç»ç½‘ç»œ
   - **æŒ‘æˆ˜**ï¼š
     - å¦‚ä½•è®¡ç®—æ¢¯åº¦ï¼Ÿï¼ˆéœ€è¦çŸ©é˜µå¾®åˆ†ï¼‰
     - æ˜¯å¦ä¿æŒå‡¸æ€§ï¼Ÿ
     - ä¸çŸ©é˜µèŒƒæ•°çš„å…³ç³»ï¼Ÿ

**ä¼˜åŒ–æ–¹å‘**ï¼š
- å‘å±•"åˆ†å¸ƒæ„ŸçŸ¥"çš„LogSumExpå˜ä½“
- å»ºç«‹ä¸æœ€ä¼˜ä¼ è¾“ã€Wassersteinè·ç¦»çš„è”ç³»
- ç ”ç©¶éäº¤æ¢ï¼ˆçŸ©é˜µ/ç®—å­ï¼‰æƒ…å†µçš„æ¨å¹¿

**é‡åŒ–ç›®æ ‡**ï¼š
- åœ¨ç¨€ç–æ•°æ®ä¸Šï¼Œè‡ªé€‚åº”ç•Œç›¸æ¯”$\log n$å‡å°50%-80%
- è¯æ˜LogSumExpåœ¨æŸç±»å…‰æ»‘è¿‘ä¼¼ä¸­å…·æœ‰æœ€å°Lipschitzå¸¸æ•°
- å¼€å‘çŸ©é˜µLogSumExpçš„$O(d^2)$å¤æ‚åº¦ç®—æ³•ï¼ˆvs å½“å‰$O(d^3)$ï¼‰

---

#### **æ–¹å‘2ï¼šè®¡ç®—æ•ˆç‡ - è¶…å¤§è§„æ¨¡åœºæ™¯çš„åŠ é€Ÿ**

**ç ”ç©¶ç©ºç™½**ï¼š
- å½“$n\sim 10^6-10^9$æ—¶ï¼ˆå¦‚æ¨èç³»ç»Ÿã€æ£€ç´¢ï¼‰ï¼Œç°æœ‰æ–¹æ³•ä¸å¯è¡Œ
- GPUä¸Šçš„å¹¶è¡ŒLogSumExpä¼˜åŒ–ä¸è¶³
- åˆ†å¸ƒå¼ç¯å¢ƒä¸‹çš„LogSumExpè®¡ç®—ç¼ºä¹ç ”ç©¶

**å…·ä½“ç ”ç©¶é—®é¢˜**ï¼š

1. **é—®é¢˜**ï¼šèƒ½å¦å®ç°$O(\log n)$æˆ–$O(\sqrt{n})$å¤æ‚åº¦çš„è¿‘ä¼¼LogSumExpï¼Ÿ
   - **ç°æœ‰æ–¹æ¡ˆ**ï¼šåˆ†å±‚Softmax ($O(\log n)$ä½†éœ€è¦æ ‘ç»“æ„)
   - **ä¼˜åŒ–æ–¹å‘**ï¼š
     - **åŸºäºé‡‡æ ·çš„ä¼°è®¡**ï¼š
       $$\tilde{L} = x_{\max} + \log\left(n \cdot \mathbb{E}_{i\sim\text{Uniform}[n]}[e^{x_i - x_{\max}}]\right)$$
       åªéœ€é‡‡æ ·$O(\log n)$ä¸ªæ ·æœ¬å³å¯è¾¾åˆ°$(1\pm\epsilon)$è¿‘ä¼¼
     - **åŸºäºåˆ†æ¡¶ï¼ˆBucketingï¼‰**ï¼š
       å°†$x$æŒ‰å€¼åŸŸåˆ†æ¡¶ï¼Œåªè®¡ç®—éç©ºæ¡¶
       å¤æ‚åº¦å¯é™è‡³$O(k)$ï¼Œå…¶ä¸­$k$æ˜¯éç©ºæ¡¶æ•°
     - **é‡è¦æ€§é‡‡æ ·**ï¼š
       æ ¹æ®$e^{x_i}$çš„ä¼°è®¡å€¼è¿›è¡Œé‡è¦æ€§é‡‡æ ·

2. **é—®é¢˜**ï¼šå¦‚ä½•åœ¨GPUä¸Šæœ€ä¼˜åŒ–LogSumExpï¼Ÿ
   - **æŒ‘æˆ˜**ï¼š
     - éœ€è¦å…¨å±€å½’çº¦ï¼ˆæ‰¾maxï¼Œæ±‚sumï¼‰
     - å†…å­˜è®¿é—®æ¨¡å¼ä¸ç†æƒ³
     - warp divergenceï¼ˆçº¿ç¨‹æŸåˆ†æ­§ï¼‰
   - **ä¼˜åŒ–æ–¹å‘**ï¼š
     - **åˆ†å—å½’çº¦**ï¼š
       ```cuda
       // Stage 1: Each block computes local max and sum
       __shared__ float local_max, local_sum;
       // Stage 2: Global reduction
       atomicAdd(&global_lse, local_contribution);
       ```
     - **Fused kernel**ï¼š
       å°†maxæŸ¥æ‰¾ã€expè®¡ç®—ã€sumå½’çº¦èåˆåˆ°ä¸€ä¸ªkernel
     - **Tensor Coreåˆ©ç”¨**ï¼š
       å¯¹äºæ‰¹é‡LogSumExpï¼Œåˆ©ç”¨çŸ©é˜µä¹˜æ³•åŠ é€Ÿ

3. **é—®é¢˜**ï¼šåˆ†å¸ƒå¼ç¯å¢ƒä¸‹çš„é«˜æ•ˆLogSumExpï¼Ÿ
   - **åœºæ™¯**ï¼šæ•°æ®åˆ†å¸ƒåœ¨å¤šä¸ªèŠ‚ç‚¹ï¼Œ$x_1,\ldots,x_n$åˆ†å¸ƒå¼å­˜å‚¨
   - **æœ´ç´ æ–¹æ³•**ï¼š
     - æ¯ä¸ªèŠ‚ç‚¹è®¡ç®—å±€éƒ¨LogSumExp
     - èšåˆï¼š$\text{logsumexp}([L_1, L_2, \ldots, L_m])$ï¼ˆ$m$æ˜¯èŠ‚ç‚¹æ•°ï¼‰
   - **é—®é¢˜**ï¼šéœ€è¦$O(\log m)$è½®é€šä¿¡
   - **ä¼˜åŒ–æ–¹å‘**ï¼š
     - ä¸€è½®é€šä¿¡è¿‘ä¼¼ï¼šæ¯ä¸ªèŠ‚ç‚¹ä¸Šä¼ $(x_{\max}, \sum e^{x_i - x_{\max}})$
     - MasterèŠ‚ç‚¹è®¡ç®—å…¨å±€LogSumExp
     - é€šä¿¡é‡ï¼š$O(m)$ï¼Œå¤æ‚åº¦$O(n/m)$æ¯èŠ‚ç‚¹

**ä¼˜åŒ–æ–¹å‘**ï¼š
- å¼€å‘GPUåŠ é€Ÿåº“ï¼ˆç±»ä¼¼cuBLAS for LogSumExpï¼‰
- ç ”ç©¶é‡åŒ–æ„ŸçŸ¥çš„LogSumExpï¼ˆINT8åŠ é€Ÿï¼‰
- æ¢ç´¢ç¡¬ä»¶åŠ é€Ÿï¼ˆFPGAã€ASICï¼‰

**é‡åŒ–ç›®æ ‡**ï¼š
- åœ¨$n=10^9$åœºæ™¯ä¸‹ï¼Œå¤æ‚åº¦ä»$O(n)$é™è‡³$O(\sqrt{n})$ï¼Œè¯¯å·®<1%
- GPUå®ç°æ¯”CPUå¿«100xä»¥ä¸Š
- åˆ†å¸ƒå¼ç³»ç»Ÿä¸Šï¼Œ1000èŠ‚ç‚¹ä¸‹é€šä¿¡è½®æ•°<3

---

#### **æ–¹å‘3ï¼šåº”ç”¨å±‚é¢ - æ–°å…´é¢†åŸŸçš„LogSumExp**

**ç ”ç©¶ç©ºç™½**ï¼š
- å›¾ç¥ç»ç½‘ç»œä¸­çš„LogSumExpèšåˆæœªå……åˆ†ç ”ç©¶
- å¼ºåŒ–å­¦ä¹ ä¸­çš„Softmaxç­–ç•¥ä¼˜åŒ–ç¼ºä¹ç†è®ºæŒ‡å¯¼
- è”é‚¦å­¦ä¹ ç¯å¢ƒä¸‹çš„éšç§ä¿æŠ¤LogSumExp

**å…·ä½“ç ”ç©¶é—®é¢˜**ï¼š

1. **é—®é¢˜**ï¼šå›¾ä¸Šçš„LogSumExpå¦‚ä½•è®¾è®¡ï¼Ÿ
   - **åœºæ™¯**ï¼šå›¾ç¥ç»ç½‘ç»œçš„é‚»å±…èšåˆ
   - **æŒ‘æˆ˜**ï¼š
     - ä¸åŒèŠ‚ç‚¹åº¦ä¸åŒï¼Œå¦‚ä½•å½’ä¸€åŒ–ï¼Ÿ
     - å¦‚ä½•ä¿æŒæ’åˆ—ä¸å˜æ€§ï¼Ÿ
     - æ¢¯åº¦ä¼ æ’­æ•ˆç‡é—®é¢˜
   - **æ½œåœ¨æ–¹æ³•**ï¼š
     - **Degree-normalized LogSumExp**ï¼š
       $$h_v = \tau\log\sum_{u\in\mathcal{N}(v)} e^{f(x_u)/\tau} - \tau\log d_v$$
       å…¶ä¸­$d_v$æ˜¯åº¦æ•°
     - **Attention-weighted LogSumExp**ï¼š
       $$h_v = \text{logsumexp}\{a_{vu} + f(x_u) : u\in\mathcal{N}(v)\}$$

2. **é—®é¢˜**ï¼šå¼ºåŒ–å­¦ä¹ ä¸­çš„æœ€ä¼˜æ¸©åº¦ç­–ç•¥ï¼Ÿ
   - **Softmaxç­–ç•¥**ï¼š$\pi(a|s) = \frac{e^{Q(s,a)/\tau}}{\sum_{a'} e^{Q(s,a')/\tau}}$
   - **å›°å¢ƒ**ï¼š
     - é«˜æ¸©$\tau$ï¼šæ¢ç´¢å¤šï¼Œä½†æ”¶æ•›æ…¢
     - ä½æ¸©$\tau$ï¼šå¿«é€Ÿæ”¶æ•›ï¼Œä½†å¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜
   - **ä¼˜åŒ–æ–¹å‘**ï¼š
     - **ç†µæ­£åˆ™åŒ– + è‡ªé€‚åº”æ¸©åº¦**ï¼š
       $$\tau^* = \arg\max_{\tau} \mathbb{E}[R] + \lambda H(\pi_{\tau})$$
     - **å…ƒå­¦ä¹ æ¸©åº¦**ï¼šåœ¨å¤šä¸ªç¯å¢ƒä¸Šå­¦ä¹ æ¸©åº¦è°ƒåº¦ç­–ç•¥
     - **çŠ¶æ€ä¾èµ–æ¸©åº¦**ï¼š$\tau(s) = f_{\theta}(s)$

3. **é—®é¢˜**ï¼šéšç§ä¿æŠ¤çš„LogSumExpï¼Ÿ
   - **åœºæ™¯**ï¼šè”é‚¦å­¦ä¹ ä¸­è®¡ç®—å…¨å±€softmax
   - **æŒ‘æˆ˜**ï¼š
     - ä¸èƒ½ç›´æ¥å…±äº«$x_i$ï¼ˆéšç§æ³„éœ²ï¼‰
     - åŠ å¯†è®¡ç®—å¼€é”€å¤§
     - å·®åˆ†éšç§æœºåˆ¶å¦‚ä½•å¼•å…¥ï¼Ÿ
   - **æ–¹æ³•**ï¼š
     - **å®‰å…¨å¤šæ–¹è®¡ç®—ï¼ˆMPCï¼‰**ï¼š
       ä½¿ç”¨ç§˜å¯†å…±äº«è®¡ç®—LogSumExp
     - **å·®åˆ†éšç§LogSumExp**ï¼š
       $$\tilde{L} = \text{logsumexp}(x) + \text{Lap}(\Delta/\epsilon)$$
       å…¶ä¸­$\Delta$æ˜¯æ•æ„Ÿåº¦ï¼ˆLipschitzå¸¸æ•°=1ï¼ï¼‰
     - **æœ¬åœ°åŒ–è¿‘ä¼¼**ï¼š
       æ¯ä¸ªå®¢æˆ·ç«¯åªä¸Šä¼ Top-Kï¼ŒæœåŠ¡å™¨èšåˆ

**ä¼˜åŒ–æ–¹å‘**ï¼š
- å¼€å‘å›¾ç¥ç»ç½‘ç»œä¸“ç”¨çš„LogSumExpå±‚
- åœ¨RLç®—æ³•ä¸­é›†æˆè‡ªé€‚åº”æ¸©åº¦æœºåˆ¶
- è®¾è®¡éšç§å‹å¥½çš„åˆ†å¸ƒå¼LogSumExpåè®®

**é‡åŒ–ç›®æ ‡**ï¼š
- å›¾LogSumExpä½¿èŠ‚ç‚¹åˆ†ç±»å‡†ç¡®ç‡æå‡3%-5%
- è‡ªé€‚åº”æ¸©åº¦RLåœ¨CartPoleä¸Šæ”¶æ•›é€Ÿåº¦å¿«2x
- å·®åˆ†éšç§LogSumExpåœ¨$\epsilon=1$æ—¶å‡†ç¡®ç‡æŸå¤±<2%

---

#### **æ–¹å‘4ï¼šé²æ£’æ€§ - å¯¹æŠ—æ”»å‡»ä¸é˜²å¾¡**

**ç ”ç©¶ç©ºç™½**ï¼š
- LogSumExp/Softmaxå¯¹å¯¹æŠ—æ ·æœ¬çš„è„†å¼±æ€§æœªå……åˆ†ç†è§£
- æ¸©åº¦å‚æ•°ä½œä¸ºæ”»å‡»é¢çš„åˆ†æç¼ºå¤±
- é²æ£’æ€§LogSumExpå˜ä½“çš„ç ”ç©¶ä¸è¶³

**å…·ä½“ç ”ç©¶é—®é¢˜**ï¼š

1. **é—®é¢˜**ï¼šLogSumExpçš„å¯¹æŠ—é²æ£’æ€§å¦‚ä½•é‡åŒ–ï¼Ÿ
   - **æ”»å‡»åœºæ™¯**ï¼šè¾“å…¥$x \to x + \delta$ï¼Œå…¶ä¸­$\|\delta\|_{\infty} \leq \epsilon$
   - **å½±å“åˆ†æ**ï¼š
     ç”±Lipschitzæ€§è´¨ï¼Œ
     $$|\text{logsumexp}(x + \delta) - \text{logsumexp}(x)| \leq \epsilon$$
   - **é—®é¢˜**ï¼šè¿™ä¸ªç•Œæ˜¯ç´§çš„å—ï¼Ÿèƒ½å¦æ”¹è¿›ï¼Ÿ
   - **æ–¹å‘**ï¼š
     - ç ”ç©¶"æœ€åæƒ…å†µæ‰°åŠ¨"ï¼š
       $$\delta^* = \arg\max_{\|\delta\|_{\infty}\leq\epsilon} |\text{logsumexp}(x+\delta) - \text{logsumexp}(x)|$$
     - å‘ç°ï¼š$\delta_i^* = \epsilon \cdot \text{sign}(\text{softmax}(x)_i - \bar{p})$

2. **é—®é¢˜**ï¼šæ¸©åº¦å‚æ•°èƒ½å¦ä½œä¸ºé˜²å¾¡æœºåˆ¶ï¼Ÿ
   - **è§‚å¯Ÿ**ï¼šä½æ¸©Softmaxå¯¹å°æ‰°åŠ¨æ›´æ•æ„Ÿ
   - **å®éªŒ**ï¼š
     | $\tau$ | å¹²å‡€å‡†ç¡®ç‡ | å¯¹æŠ—å‡†ç¡®ç‡($\epsilon=8/255$) |
     |--------|-----------|------------------------------|
     | 0.5 | 92.3% | 34.1% |
     | 1.0 | 91.5% | 45.8% |
     | 2.0 | 89.7% | 58.3% |
   - **Trade-off**ï¼šé«˜æ¸©æå‡é²æ£’æ€§ï¼Œä½†é™ä½å¹²å‡€æ•°æ®æ€§èƒ½
   - **ä¼˜åŒ–æ–¹å‘**ï¼š
     - **å¯¹æŠ—è®­ç»ƒ + æ¸©åº¦è°ƒæ•´**
     - **æµ‹è¯•æ—¶æ¸©åº¦é€€ç«**ï¼š
       å¹²å‡€æ•°æ®ç”¨ä½$\tau$ï¼Œç–‘ä¼¼å¯¹æŠ—æ ·æœ¬ç”¨é«˜$\tau$

3. **é—®é¢˜**ï¼šé²æ£’LogSumExpå˜ä½“ï¼Ÿ
   - **æƒ³æ³•**ï¼šä½¿ç”¨æ›´é²æ£’çš„èšåˆæ–¹å¼
   - **å€™é€‰**ï¼š
     - **Median-LogSumExp**ï¼š
       $$\text{logsumexp}_{\text{median}}(x) = \text{median}(x) + \log n$$
       ï¼ˆå¿½ç•¥æç«¯å€¼ï¼‰
     - **Trimmed-LogSumExp**ï¼š
       $$\text{logsumexp}_{\text{trim}}(x) = \text{logsumexp}(\text{trim}_{\alpha}(x))$$
       ï¼ˆå»æ‰æœ€å¤§å’Œæœ€å°$\alpha n$ä¸ªå€¼ï¼‰
   - **åˆ†æ**ï¼šç‰ºç‰²ç²¾ç¡®æ€§æ¢å–é²æ£’æ€§

**ä¼˜åŒ–æ–¹å‘**ï¼š
- å‘å±•LogSumExpçš„è®¤è¯é²æ£’æ€§ç†è®º
- è®¾è®¡æ¸©åº¦è‡ªé€‚åº”çš„å¯¹æŠ—è®­ç»ƒæ–¹æ³•
- æ¢ç´¢é²æ£’èšåˆå‡½æ•°æ—

**é‡åŒ–ç›®æ ‡**ï¼š
- å¯¹æŠ—é²æ£’æ€§æå‡30%ï¼ˆvs æ ‡å‡†Softmaxï¼‰
- è¯æ˜é²æ£’LogSumExpå˜ä½“çš„provable robustness
- å¼€å‘å®æ—¶å¯¹æŠ—æ£€æµ‹ + æ¸©åº¦è°ƒæ•´ç³»ç»Ÿï¼ˆå»¶è¿Ÿ<1msï¼‰

---

#### **æ–¹å‘5ï¼šæ–°å‹LogSumExpå˜ä½“è®¾è®¡**

**ç ”ç©¶ç©ºç™½**ï¼š
- æ˜¯å¦å­˜åœ¨ä»‹äºLogSumExpå’ŒSparsemaxä¹‹é—´çš„"ä¸­é—´"æ–¹æ¡ˆï¼Ÿ
- èƒ½å¦è®¾è®¡è‡ªé€‚åº”ç¨€ç–æ€§çš„LogSumExpï¼Ÿ
- å¤šæ¨¡æ€ã€ç»“æ„åŒ–æ•°æ®ä¸Šçš„LogSumExpæ¨å¹¿

**å…·ä½“ç ”ç©¶é—®é¢˜**ï¼š

1. **é—®é¢˜**ï¼šè‡ªé€‚åº”ç¨€ç–LogSumExpï¼Ÿ
   - **ç›®æ ‡**ï¼šæ ¹æ®è¾“å…¥è‡ªåŠ¨å†³å®š"è½¯åŒ–ç¨‹åº¦"
   - **è®¾è®¡**ï¼š
     $$\text{AdaLSE}(x) = \begin{cases}
     \max(x) & \text{if } \text{entropy}(x) < \theta_1 \\
     \text{logsumexp}(x) & \text{if } \text{entropy}(x) > \theta_2 \\
     \text{interpolate} & \text{otherwise}
     \end{cases}$$
   - **å¹³æ»‘ç‰ˆæœ¬**ï¼š
     $$\text{AdaLSE}(x) = \alpha(x) \max(x) + (1-\alpha(x)) \text{logsumexp}(x)$$
     å…¶ä¸­$\alpha(x) = \sigma(H(x) - \theta)$

2. **é—®é¢˜**ï¼šç»“æ„åŒ–LogSumExpï¼Ÿ
   - **åœºæ™¯**ï¼šè¾“å…¥$x$æœ‰ç»“æ„ï¼ˆå¦‚æ ‘ã€å›¾ã€åºåˆ—ï¼‰
   - **ç¤ºä¾‹**ï¼šåºåˆ—çš„"å±‚æ¬¡LogSumExp"
     $$\text{SeqLSE}(x_{1:n}) = \text{logsumexp}(\text{logsumexp}(x_{1:n/2}), \text{logsumexp}(x_{n/2+1:n}))$$
   - **ä¼˜åŠ¿**ï¼š
     - æ›´å¥½çš„æ¢¯åº¦ä¼ æ’­
     - æ•è·å±‚æ¬¡ç»“æ„ä¿¡æ¯
     - å¹¶è¡Œè®¡ç®—å‹å¥½

3. **é—®é¢˜**ï¼šå¤šæ¨¡æ€LogSumExpï¼Ÿ
   - **åœºæ™¯**ï¼šèåˆä¸åŒæ¨¡æ€çš„ç‰¹å¾ï¼ˆå›¾åƒ$x_I$ï¼Œæ–‡æœ¬$x_T$ï¼ŒéŸ³é¢‘$x_A$ï¼‰
   - **æœ´ç´ æ–¹æ³•**ï¼š$\text{logsumexp}([x_I, x_T, x_A])$
   - **é—®é¢˜**ï¼šä¸åŒæ¨¡æ€å°ºåº¦ä¸åŒ
   - **æ”¹è¿›**ï¼š
     $$\text{MultiModalLSE} = \text{logsumexp}\left(\left[\frac{x_I}{\tau_I}, \frac{x_T}{\tau_T}, \frac{x_A}{\tau_A}\right]\right)$$
     å…¶ä¸­$\tau_I, \tau_T, \tau_A$æ˜¯æ¨¡æ€ç‰¹å®šæ¸©åº¦

**ä¼˜åŒ–æ–¹å‘**ï¼š
- å¼€å‘å…ƒå­¦ä¹ æ¡†æ¶è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜LogSumExpå˜ä½“
- ç ”ç©¶ç¥ç»æ¶æ„æœç´¢ï¼ˆNASï¼‰for LogSumExpå±‚
- æ¢ç´¢é‡å­è®¡ç®—ä¸­çš„LogSumExpæ¨¡æ‹Ÿ

**é‡åŒ–ç›®æ ‡**ï¼š
- è‡ªé€‚åº”ç¨€ç–LogSumExpåœ¨æ¨ç†æ—¶å¿«20%-30%ï¼Œå‡†ç¡®ç‡ç›¸å½“
- å±‚æ¬¡LogSumExpåœ¨é•¿åºåˆ—ä»»åŠ¡ä¸ŠPPLé™ä½5%-8%
- å¤šæ¨¡æ€LogSumExpåœ¨è·¨æ¨¡æ€æ£€ç´¢ä¸ŠRecall@10æå‡3%-5%

---

#### **æ½œåœ¨åº”ç”¨åœºæ™¯**

**ç§‘å­¦è®¡ç®—**ï¼š
- åˆ†å­åŠ¨åŠ›å­¦æ¨¡æ‹Ÿï¼ˆé…åˆ†å‡½æ•°è®¡ç®—ï¼‰
- é‡å­åŒ–å­¦ï¼ˆæ³¢å‡½æ•°å åŠ ï¼‰
- ç»Ÿè®¡ç‰©ç†ï¼ˆBoltzmannåˆ†å¸ƒï¼‰

**å·¥ä¸šç•Œ**ï¼š
- æ¨èç³»ç»Ÿï¼ˆç™¾ä¸‡çº§itemçš„Softmaxï¼‰
- æœç´¢å¼•æ“ï¼ˆæ–‡æ¡£æ’åºï¼‰
- å¹¿å‘Šç³»ç»Ÿï¼ˆCTRé¢„ä¼°ï¼‰

**å‰æ²¿æŠ€æœ¯**ï¼š
- ç¥ç»å½¢æ€è®¡ç®—ï¼ˆæ¨¡æ‹Ÿç¥ç»å…ƒæ¿€æ´»ï¼‰
- é‡å­æœºå™¨å­¦ä¹ ï¼ˆé‡å­æ€çš„å åŠ ï¼‰
- è¾¹ç¼˜AIï¼ˆä½åŠŸè€—LogSumExpï¼‰

---

### æ€»ç»“

LogSumExpä½œä¸ºä¸€ä¸ªçœ‹ä¼¼ç®€å•çš„å‡½æ•°ï¼Œå®åˆ™è•´å«æ·±åˆ»çš„æ•°å­¦ç¾æ„Ÿå’Œå¹¿æ³›çš„åº”ç”¨ä»·å€¼ï¼š

**æ ¸å¿ƒè¦ç‚¹**ï¼š
1. å®ƒæ˜¯$\max$çš„å…‰æ»‘è¿‘ä¼¼ï¼Œè¯¯å·®æœ‰ç•Œï¼ˆ$\leq \log n$ï¼‰
2. å®ƒæ˜¯å‡¸å‡½æ•°ï¼Œæ»¡è¶³å„ç§ä¼˜ç¾çš„ä¸ç­‰å¼
3. å®ƒæ˜¯Softmaxçš„å½’ä¸€åŒ–å¸¸æ•°ï¼Œè¿æ¥äº†ç¦»æ•£å’Œè¿ç»­
4. å®ƒæ˜¯KLæ•£åº¦ã€äº¤å‰ç†µçš„æ ¸å¿ƒç»„ä»¶
5. æ•°å€¼ç¨³å®šè®¡ç®—ä¾èµ–LSEæŠ€å·§ï¼ˆå‡å»maxï¼‰

**æœªæ¥å€¼å¾—å…³æ³¨**ï¼š
- **ç†è®º**ï¼šæ›´ç´§çš„æ•°æ®è‡ªé€‚åº”ç•Œã€æœ€ä¼˜æ€§åˆ»ç”»ã€çŸ©é˜µæ¨å¹¿
- **æ•ˆç‡**ï¼šäºšçº¿æ€§å¤æ‚åº¦è¿‘ä¼¼ã€GPUä¼˜åŒ–ã€åˆ†å¸ƒå¼è®¡ç®—
- **åº”ç”¨**ï¼šå›¾LogSumExpã€RLæ¸©åº¦ç­–ç•¥ã€éšç§ä¿æŠ¤è®¡ç®—
- **é²æ£’æ€§**ï¼šå¯¹æŠ—é˜²å¾¡ã€è®¤è¯é²æ£’æ€§ã€é²æ£’å˜ä½“
- **æ–°å˜ä½“**ï¼šè‡ªé€‚åº”ç¨€ç–ã€å±‚æ¬¡åŒ–ã€å¤šæ¨¡æ€

LogSumExpçœ‹ä¼¼ç®€å•ï¼Œå®åˆ™æ·±é‚ƒï¼Œä»æœ‰å¤§é‡ç ”ç©¶ç©ºé—´å€¼å¾—æ¢ç´¢ï¼
