---
title: “对角+低秩”三角阵的高效求逆方法
slug: 对角低秩三角阵的高效求逆方法
date: 2025-07-01
tags: 计算, 矩阵, RNN, attention, 生成模型
status: pending
---

# “对角+低秩”三角阵的高效求逆方法

**原文链接**: [https://spaces.ac.cn/archives/11072](https://spaces.ac.cn/archives/11072)

**发布日期**: 

---

从文章[《线性注意力简史：从模仿、创新到反哺》](/archives/11033)我们可以发现，DeltaNet及其后的线性Attention模型，基本上都关联到了逆矩阵$(\boldsymbol{I} + \boldsymbol{K}\boldsymbol{K}^{\top}\odot\boldsymbol{M}^-)^{-1}$。本文就专门来探讨一下这类具有“对角+低秩”特点的三角矩阵的逆矩阵计算。

## 基本结果 #

我们将问题一般地定义如下：

> 给定矩阵$\boldsymbol{Q},\boldsymbol{K}\in\mathbb{R}^{n\times d}$和对角矩阵$\boldsymbol{\Lambda}\in\mathbb{R}^{n\times n}$，满足$n\gg d$，定义 \begin{equation}\boldsymbol{T} = \boldsymbol{\Lambda} + \boldsymbol{Q}\boldsymbol{K}^{\top}\odot\boldsymbol{M}^-\end{equation} 其中$\boldsymbol{M}^-=\boldsymbol{M} - \boldsymbol{I}$，矩阵$\boldsymbol{M}$定义为 \begin{equation}M_{i,j} = \left\\{\begin{aligned} &1, &i \geq j \\\ &0, &i < j\end{aligned}\right.\end{equation} 现在要求逆矩阵$\boldsymbol{T}^{-1}$，并且证明其复杂度是$\mathcal{O}(n^2)$。

首先，如果没有$\odot\boldsymbol{M}^-$的下三角阵约束，那么它可以直接由“[Woodbury恒等式](https://en.wikipedia.org/wiki/Woodbury_matrix_identity)”解决：  
\begin{equation}(\boldsymbol{\Lambda} + \boldsymbol{Q}\boldsymbol{K}^{\top})^{-1} = \boldsymbol{\Lambda}^{-1} - \boldsymbol{\Lambda}^{-1} \boldsymbol{Q}(\boldsymbol{I} + \boldsymbol{K}^{\top}\boldsymbol{\Lambda}^{-1}\boldsymbol{Q})^{-1}\boldsymbol{K}^{\top}\boldsymbol{\Lambda}^{-1}\end{equation}  
容易验证右端的计算复杂度是$\mathcal{O}(n^2)$的。然而，加上$\odot\boldsymbol{M}^-$后，$\boldsymbol{T}$本身就不再具有“对角+低秩”的结构，因此不能直接由该恒等式解决了。针对下三角矩阵这一特点，一个基本的思路是递归，因为我们有分块矩阵恒等式  
\begin{equation}\begin{bmatrix}\boldsymbol{A} & \boldsymbol{0} \\\ \boldsymbol{C} & \boldsymbol{B}\end{bmatrix}^{-1} = \begin{bmatrix}\boldsymbol{A}^{-1} & \boldsymbol{0} \\\ -\boldsymbol{B}^{-1}\boldsymbol{C}\boldsymbol{A}^{-1} & \boldsymbol{B}^{-1}\end{bmatrix}\end{equation}  
这允许我们将$\boldsymbol{T}^{-1}$转化递归形式（约定：没有括号的情况下，切片的优先级最高）  
\begin{equation}\boldsymbol{T}_{[:l+1,:l+1]}^{-1} = \begin{bmatrix}\boldsymbol{T}_{[:l,:l]}^{-1} & \boldsymbol{0} \\\ -\boldsymbol{T}_{[l:l+1,l:l+1]}^{-1}\boldsymbol{T}_{[l:l+1,:l]}\boldsymbol{T}_{[:l,:l]}^{-1} & \boldsymbol{T}_{[l:l+1,l:l+1]}^{-1}\end{bmatrix}\end{equation}  
其中主要计算是$\boldsymbol{T}_{[l:l+1,:l]}\boldsymbol{T}_{[:l,:l]}^{-1}$，它是一个$1\times l$和$l\times l$矩阵相乘，复杂度是$\mathcal{O}(\mathcal{l^2})$，即每一步迭代的复杂度是平方增长的，所以总复杂度是$\mathcal{O}(n^3)$。

## 低秩结构 #

当然，这是因为我们还没用上$\boldsymbol{T}$（$\odot\boldsymbol{M}^-$前）的低秩结构，现在我们把它利用起来，那么将会得到$\boldsymbol{T}_{[l:l+1,:l]} = \boldsymbol{Q}_{[l:l+1]}\boldsymbol{K}_{[:l]}^{\top}$，代入上式得：  
\begin{equation}\boldsymbol{T}_{[:l+1,:l+1]}^{-1} = \begin{bmatrix}\boldsymbol{T}_{[:l,:l]}^{-1} & \boldsymbol{0} \\\ -\boldsymbol{T}_{[l:l+1,l:l+1]}^{-1}\boldsymbol{Q}_{[l:l+1]}\boldsymbol{K}_{[:l]}^{\top}\boldsymbol{T}_{[:l,:l]}^{-1} & \boldsymbol{T}_{[l:l+1,l:l+1]}^{-1}\end{bmatrix}\end{equation}  
注意$\boldsymbol{K}_{[:l]}^{\top}\boldsymbol{T}_{[:l,:l]}^{-1}\in\mathbb{R}^{d\times l}$，如果我们能以它为递归变量，那么每一步迭代的复杂度就只是$\mathcal{O}(l)$，总复杂度就能成功降到$\mathcal{O}(n^2)$。根据这个思路，我们有  
\begin{equation}\begin{aligned}  
\boldsymbol{K}_{[:l+1]}^{\top}\boldsymbol{T}_{[:l+1,:l+1]}^{-1} =&\, \begin{bmatrix}\boldsymbol{K}_{[:l]}^{\top} & \boldsymbol{K}_{[l:l+1]}^{\top}\end{bmatrix}\begin{bmatrix}\boldsymbol{T}_{[:l,:l]}^{-1} & \boldsymbol{0} \\\ -\boldsymbol{T}_{[l:l+1,l:l+1]}^{-1}\boldsymbol{Q}_{[l:l+1]}\boldsymbol{K}_{[:l]}^{\top}\boldsymbol{T}_{[:l,:l]}^{-1} & \boldsymbol{T}_{[l:l+1,l:l+1]}^{-1}\end{bmatrix} \\\\[6pt]  
=&\, \begin{bmatrix}\boldsymbol{K}_{[:l]}^{\top}\boldsymbol{T}_{[:l,:l]}^{-1} & \boldsymbol{0}\end{bmatrix} + \boldsymbol{K}_{[l:l+1]}^{\top}\underbrace{\begin{bmatrix}-\boldsymbol{T}_{[l:l+1,l:l+1]}^{-1}\boldsymbol{Q}_{[l:l+1]}\boldsymbol{K}_{[:l]}^{\top}\boldsymbol{T}_{[:l,:l]}^{-1} & \boldsymbol{T}_{[l:l+1,l:l+1]}^{-1}\end{bmatrix}}_{\text{实际上就是 }(\boldsymbol{T}^{-1})_{[l:l+1,:l+1]}}\end{aligned}\end{equation}  
可以看到这个递归过程也没有涉及到$\mathcal{O}(l^2)$的运算，因此思路是可行的，只需要引入一个新变量来缓存$\boldsymbol{K}_{[:l]}^{\top}\boldsymbol{T}_{[:l,:l]}^{-1}$。如果我们将$l+1$换成$l+c$，那么就可以得到chunk格式的递归。

测试代码如下：
    
    
    import numpy as np
    
    n, d, c = 1000, 100, 200
    Q = np.random.randn(n, d) / d**0.5
    K = np.random.randn(n, d) / d**0.5
    T = np.tril(Q @ K.T, -1) + np.eye(n)
    
    Y, Z = np.zeros((n, n)), np.zeros((d, n))
    for l in range(0, n, c):
        Y[l:l + c, l:l + c] = np.linalg.inv(T[l:l + c, l:l + c])
        Y[l:l + c, :l] = - Y[l:l + c, l:l + c] @ Q[l:l + c] @ Z[:, :l]
        Z[:, :l + c] += K[l:l + c].T @ Y[l:l + c, :l + c]
    
    np.allclose(Y @ T, np.eye(n))

## 乘法计算 #

基于同样的思路，我们还可以证明：

> 对于任意矩阵$\boldsymbol{V}\in\mathbb{R}^{n\times d}$，计算$\boldsymbol{T}^{-1}\boldsymbol{V}$只需要$\mathcal{O}(n)$的复杂度。

证明只需要把前述过程稍微改动一下。首先有  
\begin{equation}\begin{aligned}  
(\boldsymbol{T}^{-1}\boldsymbol{V})_{[:l+1]} =&\, \boldsymbol{T}_{[:l+1,:l+1]}^{-1}\boldsymbol{V}_{[:l+1]} \\\\[6pt]  
=&\, \begin{bmatrix}\boldsymbol{T}_{[:l,:l]}^{-1} & \boldsymbol{0} \\\ -\boldsymbol{T}_{[l:l+1,l:l+1]}^{-1}\boldsymbol{Q}_{[l:l+1]}\boldsymbol{K}_{[:l]}^{\top}\boldsymbol{T}_{[:l,:l]}^{-1} & \boldsymbol{T}_{[l:l+1,l:l+1]}^{-1}\end{bmatrix}\begin{bmatrix}\boldsymbol{V}_{[:l]} \\\ \boldsymbol{V}_{[l:l+1]}\end{bmatrix} \\\\[6pt]  
=&\, \begin{bmatrix}\boldsymbol{T}_{[:l,:l]}^{-1}\boldsymbol{V}_{[:l]} \\\ -\boldsymbol{T}_{[l:l+1,l:l+1]}^{-1}\boldsymbol{Q}_{[l:l+1]}\boldsymbol{K}_{[:l]}^{\top}\boldsymbol{T}_{[:l,:l]}^{-1}\boldsymbol{V}_{[:l]} + \boldsymbol{T}_{[l:l+1,l:l+1]}^{-1}\boldsymbol{V}_{[l:l+1]}\end{bmatrix} \\\\[6pt]  
=&\, \begin{bmatrix}(\boldsymbol{T}^{-1}\boldsymbol{V})_{[:l]} \\\ \boldsymbol{T}_{[l:l+1,l:l+1]}^{-1}(\boldsymbol{V}_{[l:l+1]} - \boldsymbol{Q}_{[l:l+1]}\boldsymbol{K}_{[:l]}^{\top}(\boldsymbol{T}^{-1}\boldsymbol{V})_{[:l]})\end{bmatrix}  
\end{aligned}\end{equation}  
然后  
\begin{equation}\begin{aligned}  
\boldsymbol{K}_{[:l+1]}^{\top}(\boldsymbol{T}^{-1}\boldsymbol{V})_{[:l+1]} =&\, \begin{bmatrix}\boldsymbol{K}_{[:l]}^{\top} & \boldsymbol{K}_{[l:l+1]}^{\top}\end{bmatrix}\begin{bmatrix}(\boldsymbol{T}^{-1}\boldsymbol{V})_{[:l]} \\\ (\boldsymbol{T}^{-1}\boldsymbol{V})_{[l:l+1]} \end{bmatrix} \\\\[8pt]  
=&\,\boldsymbol{K}_{[:l]}^{\top}(\boldsymbol{T}^{-1}\boldsymbol{V})_{[:l]} + \boldsymbol{K}_{[l:l+1]}^{\top}(\boldsymbol{T}^{-1}\boldsymbol{V})_{[l:l+1]}  
\end{aligned}\end{equation}  
因此，只需要缓存$\boldsymbol{K}_{[:l]}^{\top}(\boldsymbol{T}^{-1}\boldsymbol{V})_{[:l]}\in\mathbb{R}^{d\times d}$，就可以使得每步的计算复杂度与$l$无关，因此总复杂度是$\mathcal{O}(n)$。同样，只需要将$l+1$换成$l+c$就可以得到chunk格式。

测试代码如下：
    
    
    import numpy as np
    
    n, d, c = 1000, 100, 200
    Q = np.random.randn(n, d) / d**0.5
    K = np.random.randn(n, d) / d**0.5
    V = np.random.randn(n, d) / d**0.5
    T = np.tril(Q @ K.T, -1) + np.eye(n)
    
    Y, Z = np.zeros((n, d)), np.zeros((d, d))
    for l in range(0, n, c):
        X = np.linalg.inv(T[l:l + c, l:l + c])
        Y[l:l + c] = X @ (V[l:l + c] - Q[l:l + c] @ Z)
        Z += K[l:l + c].T @ Y[l:l + c]
    
    np.allclose(T @ Y, V)

## 文章小结 #

本文讨论了“对角+低秩”特点的三角矩阵求逆问题，这类矩阵普遍出现在新式线性Attention模型中。

_**转载到请包括本文地址：**<https://spaces.ac.cn/archives/11072>_

_**更详细的转载事宜请参考：**_[《科学空间FAQ》](https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8 "《科学空间FAQ》")

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎分享/打赏本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

![科学空间](https://spaces.ac.cn/usr/themes/geekg/payment/wx.png)

微信打赏

![科学空间](https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png)

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以[**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ)或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Jul. 01, 2025). 《“对角+低秩”三角阵的高效求逆方法 》[Blog post]. Retrieved from <https://spaces.ac.cn/archives/11072>

@online{kexuefm-11072,  
title={“对角+低秩”三角阵的高效求逆方法},  
author={苏剑林},  
year={2025},  
month={Jul},  
url={\url{https://spaces.ac.cn/archives/11072}},  
} 


---

## 公式推导与注释

本节提供文章中关键结果的详细数学推导，从矩阵理论基础到算法实现的完整分析。

### 1. "对角+低秩"矩阵结构的数学表示

**定义1.1（对角+低秩矩阵）**：一个矩阵$\boldsymbol{A}\in\mathbb{R}^{n\times n}$称为对角+低秩矩阵，如果它可以表示为
$$\boldsymbol{A} = \boldsymbol{D} + \boldsymbol{U}\boldsymbol{V}^{\top}$$
其中$\boldsymbol{D}\in\mathbb{R}^{n\times n}$是对角矩阵，$\boldsymbol{U},\boldsymbol{V}\in\mathbb{R}^{n\times r}$且$r\ll n$。

**本文问题的特殊性**：文章中的矩阵$\boldsymbol{T}$具有更复杂的结构：
$$\boldsymbol{T} = \boldsymbol{\Lambda} + \boldsymbol{Q}\boldsymbol{K}^{\top}\odot\boldsymbol{M}^-$$

让我们详细分析这个结构：

1. **对角部分**：$\boldsymbol{\Lambda} = \text{diag}(\lambda_1, \lambda_2, \ldots, \lambda_n)$
2. **低秩部分**：$\boldsymbol{Q}\boldsymbol{K}^{\top}$，其中$\boldsymbol{Q},\boldsymbol{K}\in\mathbb{R}^{n\times d}$，秩最多为$d$
3. **下三角掩码**：$\boldsymbol{M}^- = \boldsymbol{M} - \boldsymbol{I}$，其中
   $$M_{i,j} = \begin{cases} 1, & i \geq j \\ 0, & i < j \end{cases}$$

**关键观察**：$\odot\boldsymbol{M}^-$操作使得
$$(\boldsymbol{Q}\boldsymbol{K}^{\top}\odot\boldsymbol{M}^-)_{i,j} = \begin{cases} (\boldsymbol{Q}\boldsymbol{K}^{\top})_{i,j}, & i > j \\ 0, & i \leq j \end{cases}$$

因此，$\boldsymbol{T}$是严格下三角+对角矩阵：
$$T_{i,j} = \begin{cases} \lambda_i, & i = j \\ \sum_{k=1}^{d} Q_{i,k}K_{j,k}, & i > j \\ 0, & i < j \end{cases}$$

这意味着$\boldsymbol{T}$虽然整体上不再是"对角+低秩"形式，但它保留了**下三角结构**和**低秩表示**的局部性质。

### 2. Woodbury矩阵恒等式的完整证明

**定理2.1（Sherman-Morrison-Woodbury公式）**：设$\boldsymbol{A}\in\mathbb{R}^{n\times n}$可逆，$\boldsymbol{U},\boldsymbol{V}\in\mathbb{R}^{n\times k}$，若$\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U}$可逆，则
$$(\boldsymbol{A} + \boldsymbol{U}\boldsymbol{V}^{\top})^{-1} = \boldsymbol{A}^{-1} - \boldsymbol{A}^{-1}\boldsymbol{U}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}\boldsymbol{V}^{\top}\boldsymbol{A}^{-1}$$

**证明（方法一：直接验证）**：

记$\boldsymbol{B} = \boldsymbol{A}^{-1} - \boldsymbol{A}^{-1}\boldsymbol{U}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}\boldsymbol{V}^{\top}\boldsymbol{A}^{-1}$，需证$\boldsymbol{B}(\boldsymbol{A} + \boldsymbol{U}\boldsymbol{V}^{\top}) = \boldsymbol{I}$。

计算左端：
$$\begin{aligned}
&\boldsymbol{B}(\boldsymbol{A} + \boldsymbol{U}\boldsymbol{V}^{\top}) \\
=& \left[\boldsymbol{A}^{-1} - \boldsymbol{A}^{-1}\boldsymbol{U}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}\boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\right](\boldsymbol{A} + \boldsymbol{U}\boldsymbol{V}^{\top}) \\
=& \boldsymbol{A}^{-1}\boldsymbol{A} + \boldsymbol{A}^{-1}\boldsymbol{U}\boldsymbol{V}^{\top} - \boldsymbol{A}^{-1}\boldsymbol{U}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}\boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{A} \\
&\quad - \boldsymbol{A}^{-1}\boldsymbol{U}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}\boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U}\boldsymbol{V}^{\top} \\
=& \boldsymbol{I} + \boldsymbol{A}^{-1}\boldsymbol{U}\boldsymbol{V}^{\top} - \boldsymbol{A}^{-1}\boldsymbol{U}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}\boldsymbol{V}^{\top} \\
&\quad - \boldsymbol{A}^{-1}\boldsymbol{U}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}(\boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})\boldsymbol{V}^{\top} \\
=& \boldsymbol{I} + \boldsymbol{A}^{-1}\boldsymbol{U}\boldsymbol{V}^{\top} - \boldsymbol{A}^{-1}\boldsymbol{U}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}[\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U}]\boldsymbol{V}^{\top} \\
=& \boldsymbol{I} + \boldsymbol{A}^{-1}\boldsymbol{U}\boldsymbol{V}^{\top} - \boldsymbol{A}^{-1}\boldsymbol{U}\boldsymbol{V}^{\top} = \boldsymbol{I}
\end{aligned}$$

其中关键步骤是将第3、4项合并：
$$(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}[\boldsymbol{V}^{\top} + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U}\boldsymbol{V}^{\top}] = (\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})\boldsymbol{V}^{\top} = \boldsymbol{V}^{\top}$$

**证明（方法二：块矩阵逆）**：

构造块矩阵：
$$\boldsymbol{M} = \begin{bmatrix} \boldsymbol{A} & \boldsymbol{U} \\ \boldsymbol{V}^{\top} & -\boldsymbol{I}_k \end{bmatrix}$$

使用两种不同的块消元方法求逆：

**第一种消元**（先消去左下块）：
$$\begin{bmatrix} \boldsymbol{A} & \boldsymbol{U} \\ \boldsymbol{V}^{\top} & -\boldsymbol{I}_k \end{bmatrix} \sim \begin{bmatrix} \boldsymbol{A} + \boldsymbol{U}\boldsymbol{V}^{\top} & \boldsymbol{0} \\ \boldsymbol{V}^{\top} & -\boldsymbol{I}_k \end{bmatrix}$$

得到：
$$\boldsymbol{M}^{-1} = \begin{bmatrix} (\boldsymbol{A} + \boldsymbol{U}\boldsymbol{V}^{\top})^{-1} & * \\ * & * \end{bmatrix}$$

**第二种消元**（先消去右上块）：
$$\begin{bmatrix} \boldsymbol{A} & \boldsymbol{U} \\ \boldsymbol{V}^{\top} & -\boldsymbol{I}_k \end{bmatrix} \sim \begin{bmatrix} \boldsymbol{A} & \boldsymbol{0} \\ \boldsymbol{V}^{\top} + \boldsymbol{A}^{-1}\boldsymbol{U} & -\boldsymbol{I}_k \end{bmatrix}$$

得到左上块为：
$$\boldsymbol{A}^{-1} - \boldsymbol{A}^{-1}\boldsymbol{U}(\boldsymbol{I}_k + \boldsymbol{V}^{\top}\boldsymbol{A}^{-1}\boldsymbol{U})^{-1}\boldsymbol{V}^{\top}\boldsymbol{A}^{-1}$$

两种方法得到的$(1,1)$块必须相等，证毕。

**计算复杂度分析**：

对于$\boldsymbol{A} = \boldsymbol{\Lambda}$（对角矩阵），$\boldsymbol{U} = \boldsymbol{Q}$，$\boldsymbol{V} = \boldsymbol{K}$：

1. $\boldsymbol{\Lambda}^{-1}$：$\mathcal{O}(n)$（对角元素求倒数）
2. $\boldsymbol{\Lambda}^{-1}\boldsymbol{Q}$：$\mathcal{O}(nd)$（$n$个$d$维向量逐元素乘）
3. $\boldsymbol{K}^{\top}\boldsymbol{\Lambda}^{-1}\boldsymbol{Q}$：$\mathcal{O}(nd^2)$（$d\times n$矩阵乘$n\times d$矩阵）
4. $(\boldsymbol{I}_d + \boldsymbol{K}^{\top}\boldsymbol{\Lambda}^{-1}\boldsymbol{Q})^{-1}$：$\mathcal{O}(d^3)$（$d\times d$矩阵求逆）
5. 最终组合：$\mathcal{O}(nd^2)$

总复杂度：$\mathcal{O}(nd^2) + \mathcal{O}(d^3) = \mathcal{O}(nd^2)$。当$d\ll n$时，这是$\mathcal{O}(n)$线性复杂度（固定$d$时）。

### 3. 三角矩阵的块矩阵求逆递归算法

**定理3.1（块下三角矩阵求逆）**：对于块下三角矩阵
$$\boldsymbol{T} = \begin{bmatrix}\boldsymbol{A} & \boldsymbol{0} \\ \boldsymbol{C} & \boldsymbol{B}\end{bmatrix}$$
其中$\boldsymbol{A}\in\mathbb{R}^{m\times m}$，$\boldsymbol{B}\in\mathbb{R}^{n\times n}$可逆，有
$$\boldsymbol{T}^{-1} = \begin{bmatrix}\boldsymbol{A}^{-1} & \boldsymbol{0} \\ -\boldsymbol{B}^{-1}\boldsymbol{C}\boldsymbol{A}^{-1} & \boldsymbol{B}^{-1}\end{bmatrix}$$

**证明**：直接验证
$$\begin{bmatrix}\boldsymbol{A}^{-1} & \boldsymbol{0} \\ -\boldsymbol{B}^{-1}\boldsymbol{C}\boldsymbol{A}^{-1} & \boldsymbol{B}^{-1}\end{bmatrix}\begin{bmatrix}\boldsymbol{A} & \boldsymbol{0} \\ \boldsymbol{C} & \boldsymbol{B}\end{bmatrix} = \begin{bmatrix}\boldsymbol{I}_m & \boldsymbol{0} \\ -\boldsymbol{B}^{-1}\boldsymbol{C} + \boldsymbol{B}^{-1}\boldsymbol{C} & \boldsymbol{I}_n\end{bmatrix} = \boldsymbol{I}$$

**应用到逐行递归**：

将$\boldsymbol{T}\in\mathbb{R}^{(l+1)\times(l+1)}$分块为
$$\boldsymbol{T}_{[:l+1,:l+1]} = \begin{bmatrix}\boldsymbol{T}_{[:l,:l]} & \boldsymbol{0} \\ \boldsymbol{T}_{[l:l+1,:l]} & \boldsymbol{T}_{[l:l+1,l:l+1]}\end{bmatrix}$$

其中：
- $\boldsymbol{A} = \boldsymbol{T}_{[:l,:l]}\in\mathbb{R}^{l\times l}$（已计算的子矩阵）
- $\boldsymbol{B} = \boldsymbol{T}_{[l:l+1,l:l+1]} = \lambda_{l+1}$（标量，因为是对角元）
- $\boldsymbol{C} = \boldsymbol{T}_{[l:l+1,:l]}\in\mathbb{R}^{1\times l}$（行向量）

代入公式：
$$\boldsymbol{T}_{[:l+1,:l+1]}^{-1} = \begin{bmatrix}\boldsymbol{T}_{[:l,:l]}^{-1} & \boldsymbol{0} \\ -\lambda_{l+1}^{-1}\boldsymbol{T}_{[l:l+1,:l]}\boldsymbol{T}_{[:l,:l]}^{-1} & \lambda_{l+1}^{-1}\end{bmatrix}$$

**朴素算法的复杂度**：

计算$\boldsymbol{T}_{[l:l+1,:l]}\boldsymbol{T}_{[:l,:l]}^{-1}$：
- $\boldsymbol{T}_{[l:l+1,:l]}$是$1\times l$行向量
- $\boldsymbol{T}_{[:l,:l]}^{-1}$是$l\times l$密集矩阵
- 矩阵乘法：$\mathcal{O}(l^2)$

递归展开：
$$\sum_{l=0}^{n-1} \mathcal{O}(l^2) = \mathcal{O}\left(\sum_{l=0}^{n-1} l^2\right) = \mathcal{O}\left(\frac{n^3}{3}\right) = \mathcal{O}(n^3)$$

这就是为什么朴素递归算法是三次方复杂度。

### 4. 利用低秩结构的优化递归

**关键观察**：$\boldsymbol{T}$的严格下三角部分具有低秩表示
$$\boldsymbol{T}_{[i,j]} = \boldsymbol{Q}_{[i]}\boldsymbol{K}_{[j]}^{\top}, \quad i > j$$

因此：
$$\boldsymbol{T}_{[l:l+1,:l]} = \boldsymbol{Q}_{[l:l+1]}\boldsymbol{K}_{[:l]}^{\top}$$

这是一个秩$\leq d$的$1\times l$矩阵，可以表示为$d$维向量的外积。

**优化的递归公式**：

代入低秩分解：
$$\boldsymbol{T}_{[:l+1,:l+1]}^{-1} = \begin{bmatrix}\boldsymbol{T}_{[:l,:l]}^{-1} & \boldsymbol{0} \\ -\lambda_{l+1}^{-1}\boldsymbol{Q}_{[l:l+1]}\boldsymbol{K}_{[:l]}^{\top}\boldsymbol{T}_{[:l,:l]}^{-1} & \lambda_{l+1}^{-1}\end{bmatrix}$$

**引入缓存变量**：定义
$$\boldsymbol{Z}_{[:l]} := \boldsymbol{K}_{[:l]}^{\top}\boldsymbol{T}_{[:l,:l]}^{-1} \in\mathbb{R}^{d\times l}$$

这个变量缓存了$\boldsymbol{K}$的前$l$行与逆矩阵前$l$列的乘积。

**递归更新$\boldsymbol{Z}$**：

$$\begin{aligned}
\boldsymbol{Z}_{[:l+1]} &= \boldsymbol{K}_{[:l+1]}^{\top}\boldsymbol{T}_{[:l+1,:l+1]}^{-1} \\
&= \begin{bmatrix}\boldsymbol{K}_{[:l]}^{\top} \\ \boldsymbol{K}_{[l:l+1]}^{\top}\end{bmatrix}\begin{bmatrix}\boldsymbol{T}_{[:l,:l]}^{-1} & \boldsymbol{0} \\ -\lambda_{l+1}^{-1}\boldsymbol{Q}_{[l:l+1]}\boldsymbol{K}_{[:l]}^{\top}\boldsymbol{T}_{[:l,:l]}^{-1} & \lambda_{l+1}^{-1}\end{bmatrix} \\
&= \begin{bmatrix}\boldsymbol{K}_{[:l]}^{\top}\boldsymbol{T}_{[:l,:l]}^{-1} \\ \boldsymbol{K}_{[l:l+1]}^{\top}(-\lambda_{l+1}^{-1}\boldsymbol{Q}_{[l:l+1]}\boldsymbol{K}_{[:l]}^{\top}\boldsymbol{T}_{[:l,:l]}^{-1})\end{bmatrix} + \begin{bmatrix}\boldsymbol{0} \\ \boldsymbol{K}_{[l:l+1]}^{\top}\lambda_{l+1}^{-1}\end{bmatrix} \\
&= \begin{bmatrix}\boldsymbol{Z}_{[:l]} \\ -\lambda_{l+1}^{-1}\boldsymbol{K}_{[l:l+1]}^{\top}\boldsymbol{Q}_{[l:l+1]}\boldsymbol{Z}_{[:l]} + \lambda_{l+1}^{-1}\boldsymbol{K}_{[l:l+1]}^{\top}\end{bmatrix} \\
&= \begin{bmatrix}\boldsymbol{Z}_{[:l]} \\ \lambda_{l+1}^{-1}\boldsymbol{K}_{[l:l+1]}^{\top}(\boldsymbol{I} - \boldsymbol{Q}_{[l:l+1]}\boldsymbol{Z}_{[:l]})\end{bmatrix}
\end{aligned}$$

简化为增量更新：
$$\boldsymbol{Z}_{[:l+1]} = \begin{bmatrix}\boldsymbol{Z}_{[:l]} \\ \boldsymbol{Z}_{[l:l+1]}\end{bmatrix}, \quad \boldsymbol{Z}_{[l:l+1]} = \lambda_{l+1}^{-1}\boldsymbol{K}_{[l:l+1]}^{\top}(\boldsymbol{I} - \boldsymbol{Q}_{[l:l+1]}\boldsymbol{Z}_{[:l]})$$

**复杂度分析（每步迭代）**：

第$l$步需要计算：
1. $\boldsymbol{Q}_{[l:l+1]}\boldsymbol{Z}_{[:l]}$：$1\times d$矩阵乘$d\times l$矩阵 $\Rightarrow$ $\mathcal{O}(dl)$
2. $\boldsymbol{I} - \boldsymbol{Q}_{[l:l+1]}\boldsymbol{Z}_{[:l]}$：$\mathcal{O}(l)$
3. $\lambda_{l+1}^{-1}\boldsymbol{K}_{[l:l+1]}^{\top}(\cdot)$：$d\times 1$矩阵乘$1\times l$矩阵 $\Rightarrow$ $\mathcal{O}(dl)$

**总复杂度**：$\mathcal{O}(dl)$

**完整算法的总复杂度**：
$$\sum_{l=0}^{n-1} \mathcal{O}(dl) = \mathcal{O}\left(d\sum_{l=0}^{n-1}l\right) = \mathcal{O}\left(d\cdot\frac{n^2}{2}\right) = \mathcal{O}(dn^2)$$

当$d$视为常数时，这是$\mathcal{O}(n^2)$复杂度，相比朴素的$\mathcal{O}(n^3)$有显著改进！

### 5. Chunk格式的递归算法

**动机**：逐行递归虽然复杂度最优，但频繁的小规模操作可能导致缓存效率低。Chunk递归将每次更新$1$行改为$c$行。

**Chunk分块**：将$n\times n$矩阵按$c$行分块：
$$\boldsymbol{T} = \begin{bmatrix}\boldsymbol{T}^{(0)} \\ \boldsymbol{T}^{(1)} \\ \vdots \\ \boldsymbol{T}^{(N-1)}\end{bmatrix}, \quad N = \lceil n/c \rceil$$

其中$\boldsymbol{T}^{(k)} = \boldsymbol{T}_{[kc:(k+1)c, :]}$是第$k$个chunk（$c$行）。

**Chunk递归公式**：

设已计算$\boldsymbol{T}_{[:kc,:kc]}^{-1}$，要计算$\boldsymbol{T}_{[:(k+1)c,:(k+1)c]}^{-1}$：

$$\boldsymbol{T}_{[:(k+1)c,:(k+1)c]} = \begin{bmatrix}\boldsymbol{T}_{[:kc,:kc]} & \boldsymbol{0} \\ \boldsymbol{T}_{[kc:(k+1)c,:kc]} & \boldsymbol{T}_{[kc:(k+1)c,kc:(k+1)c]}\end{bmatrix}$$

逆矩阵：
$$\boldsymbol{T}_{[:(k+1)c,:(k+1)c]}^{-1} = \begin{bmatrix}\boldsymbol{T}_{[:kc,:kc]}^{-1} & \boldsymbol{0} \\ -\boldsymbol{X}\boldsymbol{T}_{[:kc,:kc]}^{-1} & \boldsymbol{X}\end{bmatrix}$$

其中：
$$\boldsymbol{X} = \boldsymbol{T}_{[kc:(k+1)c,kc:(k+1)c]}^{-1}, \quad \boldsymbol{T}_{[kc:(k+1)c,kc:(k+1)c]} = \boldsymbol{\Lambda}_{[kc:(k+1)c,kc:(k+1)c]}$$

因为对角块是对角矩阵，$\boldsymbol{X}$的计算只需$\mathcal{O}(c)$。

**低秩分解**：
$$\boldsymbol{T}_{[kc:(k+1)c,:kc]} = \boldsymbol{Q}_{[kc:(k+1)c]}\boldsymbol{K}_{[:kc]}^{\top}$$

代入：
$$-\boldsymbol{X}\boldsymbol{T}_{[kc:(k+1)c,:kc]}\boldsymbol{T}_{[:kc,:kc]}^{-1} = -\boldsymbol{X}\boldsymbol{Q}_{[kc:(k+1)c]}\underbrace{\boldsymbol{K}_{[:kc]}^{\top}\boldsymbol{T}_{[:kc,:kc]}^{-1}}_{=\boldsymbol{Z}_{[:kc]}}$$

**缓存变量更新**：
$$\begin{aligned}
\boldsymbol{Z}_{[:(k+1)c]} &= \boldsymbol{K}_{[:(k+1)c]}^{\top}\boldsymbol{T}_{[:(k+1)c,:(k+1)c]}^{-1} \\
&= \begin{bmatrix}\boldsymbol{K}_{[:kc]}^{\top} \\ \boldsymbol{K}_{[kc:(k+1)c]}^{\top}\end{bmatrix}\begin{bmatrix}\boldsymbol{T}_{[:kc,:kc]}^{-1} & \boldsymbol{0} \\ -\boldsymbol{X}\boldsymbol{Q}_{[kc:(k+1)c]}\boldsymbol{Z}_{[:kc]} & \boldsymbol{X}\end{bmatrix} \\
&= \begin{bmatrix}\boldsymbol{Z}_{[:kc]} \\ \boldsymbol{K}_{[kc:(k+1)c]}^{\top}\boldsymbol{X} - \boldsymbol{K}_{[kc:(k+1)c]}^{\top}\boldsymbol{X}\boldsymbol{Q}_{[kc:(k+1)c]}\boldsymbol{Z}_{[:kc]}\end{bmatrix} \\
&= \begin{bmatrix}\boldsymbol{Z}_{[:kc]} \\ \boldsymbol{K}_{[kc:(k+1)c]}^{\top}\boldsymbol{X}(\boldsymbol{I} - \boldsymbol{Q}_{[kc:(k+1)c]}\boldsymbol{Z}_{[:kc]})\end{bmatrix}
\end{aligned}$$

**Chunk算法伪代码**：

```
输入: Q, K, Λ, c (chunk size)
输出: T^{-1}

初始化: Y = zeros(n, n), Z = zeros(d, n)

for k = 0 to ⌈n/c⌉ - 1:
    l_start = k * c
    l_end = min((k+1) * c, n)

    # 计算对角块的逆
    X = diag(Λ[l_start:l_end])^{-1}

    # 更新逆矩阵的对角块
    Y[l_start:l_end, l_start:l_end] = X

    # 更新逆矩阵的下三角块（利用缓存Z）
    Y[l_start:l_end, :l_start] = -X @ Q[l_start:l_end] @ Z[:, :l_start]

    # 增量更新缓存Z
    Z[:, :l_end] += K[l_start:l_end].T @ Y[l_start:l_end, :l_end]

返回 Y
```

**复杂度分析**：

每个chunk（$k$-th iteration，处理$l = kc$行）：
1. $\boldsymbol{Q}_{[l:l+c]}\boldsymbol{Z}_{[:l]}$：$c\times d$矩阵乘$d\times l$矩阵 $\Rightarrow$ $\mathcal{O}(cdl)$
2. $\boldsymbol{X}\boldsymbol{Q}_{[l:l+c]}(\cdot)$：$c\times c$对角矩阵乘$c\times l$矩阵 $\Rightarrow$ $\mathcal{O}(cl)$
3. $\boldsymbol{K}_{[l:l+c]}^{\top}\boldsymbol{X}(\cdot)$：$d\times c$矩阵乘$c\times l$矩阵 $\Rightarrow$ $\mathcal{O}(dcl)$

总计：$\mathcal{O}(dcl)$

**完整算法**：
$$\sum_{k=0}^{N-1} \mathcal{O}(dc \cdot kc) = \mathcal{O}(dc^2)\sum_{k=0}^{N-1}k = \mathcal{O}(dc^2 \cdot \frac{N^2}{2}) = \mathcal{O}\left(dc^2 \cdot \frac{n^2}{2c^2}\right) = \mathcal{O}(dn^2)$$

与逐行递归相同的渐近复杂度，但chunk算法有更好的缓存局部性。

### 6. 矩阵-向量乘法$\boldsymbol{T}^{-1}\boldsymbol{V}$的优化算法

**问题设定**：给定$\boldsymbol{V}\in\mathbb{R}^{n\times d}$，计算$\boldsymbol{Y} = \boldsymbol{T}^{-1}\boldsymbol{V}$。

**朴素方法**：先计算$\boldsymbol{T}^{-1}$（$\mathcal{O}(dn^2)$），再计算矩阵乘法（$\mathcal{O}(n^2d)$），总计$\mathcal{O}(dn^2)$。

**优化思路**：不显式计算$\boldsymbol{T}^{-1}$，而是利用递归结构直接计算$\boldsymbol{Y}$。

**递归公式推导**：

$$\begin{aligned}
\boldsymbol{Y}_{[:l+1]} &= \boldsymbol{T}_{[:l+1,:l+1]}^{-1}\boldsymbol{V}_{[:l+1]} \\
&= \begin{bmatrix}\boldsymbol{T}_{[:l,:l]}^{-1} & \boldsymbol{0} \\ -\lambda_{l+1}^{-1}\boldsymbol{Q}_{[l:l+1]}\boldsymbol{K}_{[:l]}^{\top}\boldsymbol{T}_{[:l,:l]}^{-1} & \lambda_{l+1}^{-1}\end{bmatrix}\begin{bmatrix}\boldsymbol{V}_{[:l]} \\ \boldsymbol{V}_{[l:l+1]}\end{bmatrix} \\
&= \begin{bmatrix}\boldsymbol{T}_{[:l,:l]}^{-1}\boldsymbol{V}_{[:l]} \\ \lambda_{l+1}^{-1}[\boldsymbol{V}_{[l:l+1]} - \boldsymbol{Q}_{[l:l+1]}\boldsymbol{K}_{[:l]}^{\top}\boldsymbol{T}_{[:l,:l]}^{-1}\boldsymbol{V}_{[:l]}]\end{bmatrix} \\
&= \begin{bmatrix}\boldsymbol{Y}_{[:l]} \\ \lambda_{l+1}^{-1}[\boldsymbol{V}_{[l:l+1]} - \boldsymbol{Q}_{[l:l+1]}\boldsymbol{K}_{[:l]}^{\top}\boldsymbol{Y}_{[:l]}]\end{bmatrix}
\end{aligned}$$

**关键观察**：引入缓存
$$\boldsymbol{Z}_{[:l]} := \boldsymbol{K}_{[:l]}^{\top}\boldsymbol{Y}_{[:l]} = \boldsymbol{K}_{[:l]}^{\top}\boldsymbol{T}_{[:l,:l]}^{-1}\boldsymbol{V}_{[:l]} \in\mathbb{R}^{d\times d}$$

则第$l+1$行的计算简化为：
$$\boldsymbol{Y}_{[l:l+1]} = \lambda_{l+1}^{-1}[\boldsymbol{V}_{[l:l+1]} - \boldsymbol{Q}_{[l:l+1]}\boldsymbol{Z}_{[:l]}]$$

**缓存更新**：
$$\begin{aligned}
\boldsymbol{Z}_{[:l+1]} &= \boldsymbol{K}_{[:l+1]}^{\top}\boldsymbol{Y}_{[:l+1]} \\
&= \begin{bmatrix}\boldsymbol{K}_{[:l]}^{\top} \\ \boldsymbol{K}_{[l:l+1]}^{\top}\end{bmatrix}\begin{bmatrix}\boldsymbol{Y}_{[:l]} \\ \boldsymbol{Y}_{[l:l+1]}\end{bmatrix} \\
&= \boldsymbol{K}_{[:l]}^{\top}\boldsymbol{Y}_{[:l]} + \boldsymbol{K}_{[l:l+1]}^{\top}\boldsymbol{Y}_{[l:l+1]} \\
&= \boldsymbol{Z}_{[:l]} + \boldsymbol{K}_{[l:l+1]}^{\top}\boldsymbol{Y}_{[l:l+1]}
\end{aligned}$$

这是一个简单的增量更新！

**算法伪代码**：

```
输入: Q, K, Λ, V
输出: Y = T^{-1}V

初始化: Y = zeros(n, d), Z = zeros(d, d)

for l = 0 to n-1:
    # 计算当前行
    Y[l] = (V[l] - Q[l] @ Z) / λ_l

    # 增量更新缓存
    Z += K[l]^T @ Y[l]  # 外积: d×1 与 1×d

返回 Y
```

**复杂度分析（每步迭代）**：

第$l$步：
1. $\boldsymbol{Q}_{[l]}\boldsymbol{Z}$：$1\times d$乘$d\times d$ $\Rightarrow$ $\mathcal{O}(d^2)$
2. $\boldsymbol{V}_{[l]} - \boldsymbol{Q}_{[l]}\boldsymbol{Z}$：$\mathcal{O}(d)$
3. 标量除法：$\mathcal{O}(d)$
4. $\boldsymbol{K}_{[l]}^{\top}\boldsymbol{Y}_{[l]}$：外积$d\times d$ $\Rightarrow$ $\mathcal{O}(d^2)$

总计：$\mathcal{O}(d^2)$每步

**完整算法**：
$$\sum_{l=0}^{n-1}\mathcal{O}(d^2) = \mathcal{O}(nd^2)$$

当$d$固定时，这是$\mathcal{O}(n)$线性复杂度！远优于先计算$\boldsymbol{T}^{-1}$再相乘的$\mathcal{O}(n^2)$方法。

**Chunk版本**：

```
for k = 0 to ⌈n/c⌉ - 1:
    l = k * c
    X = diag(Λ[l:l+c])^{-1}
    Y[l:l+c] = X @ (V[l:l+c] - Q[l:l+c] @ Z)
    Z += K[l:l+c].T @ Y[l:l+c]
```

复杂度仍为$\mathcal{O}(nd^2)$，但有更好的向量化。

### 7. 数值稳定性分析

**浮点误差累积**：

递归算法中，第$l$步的误差会传播到后续所有步骤。设第$l$步的舍入误差为$\epsilon_l$，则：

$$\boldsymbol{Y}_{[:l]} = \boldsymbol{T}_{[:l,:l]}^{-1}\boldsymbol{V}_{[:l]} + \boldsymbol{e}_{[:l]}, \quad \|\boldsymbol{e}_{[:l]}\| \leq \sum_{i=0}^{l-1}\epsilon_i$$

**条件数的影响**：

矩阵$\boldsymbol{T}$的条件数：
$$\kappa(\boldsymbol{T}) = \|\boldsymbol{T}\| \cdot \|\boldsymbol{T}^{-1}\|$$

对于对角占优矩阵（$|\lambda_i| \gg \|\boldsymbol{Q}_{[i]}\boldsymbol{K}_{[:i]}^{\top}\|$），条件数较小：
$$\kappa(\boldsymbol{T}) \approx \frac{\max_i |\lambda_i|}{\min_i |\lambda_i|}$$

**误差界**：

根据Wilkinson分析，递归算法的相对误差满足：
$$\frac{\|\boldsymbol{Y}_{\text{computed}} - \boldsymbol{Y}_{\text{exact}}\|}{\|\boldsymbol{Y}_{\text{exact}}\|} \leq \kappa(\boldsymbol{T}) \cdot n \cdot \epsilon_{\text{machine}} + \mathcal{O}(n^2\epsilon_{\text{machine}}^2)$$

其中$\epsilon_{\text{machine}} \approx 10^{-16}$（双精度）。

**改进策略**：

1. **缩放（Scaling）**：预先对$\boldsymbol{\Lambda}$进行归一化，使$\max_i|\lambda_i| = 1$。
2. **部分主元（Partial Pivoting）**：在块求逆时选择绝对值最大的对角元。
3. **迭代精化（Iterative Refinement）**：计算残差$\boldsymbol{r} = \boldsymbol{V} - \boldsymbol{T}\boldsymbol{Y}$，解$\boldsymbol{T}\boldsymbol{\delta} = \boldsymbol{r}$，更新$\boldsymbol{Y} \leftarrow \boldsymbol{Y} + \boldsymbol{\delta}$。

**对角元素接近零的处理**：

当$\lambda_i \approx 0$时，$\lambda_i^{-1}$会导致数值溢出。应添加正则化：
$$\boldsymbol{T}_{\text{reg}} = \boldsymbol{T} + \epsilon\boldsymbol{I}, \quad \epsilon = 10^{-8}$$

或使用伪逆：
$$\lambda_i^{-1} \leftarrow \begin{cases} 1/\lambda_i, & |\lambda_i| > \epsilon \\ 0, & |\lambda_i| \leq \epsilon \end{cases}$$

### 8. 与标准LU分解的对比

**LU分解方法**：

对于一般下三角矩阵$\boldsymbol{T}$，标准求逆方法是：
1. LU分解：$\boldsymbol{T} = \boldsymbol{L}\boldsymbol{U}$（$\mathcal{O}(n^3)$）
2. 前向替换：求解$\boldsymbol{L}\boldsymbol{Y}' = \boldsymbol{V}$（$\mathcal{O}(n^2)$）
3. 后向替换：求解$\boldsymbol{U}\boldsymbol{Y} = \boldsymbol{Y}'$（$\mathcal{O}(n^2)$）

总复杂度：$\mathcal{O}(n^3)$（主要是LU分解）

**本文方法的优势**：

| 方面 | LU分解 | 本文方法 |
|------|--------|----------|
| 复杂度 | $\mathcal{O}(n^3)$ | $\mathcal{O}(dn^2)$ |
| 适用条件 | 任意可逆矩阵 | 对角+低秩三角阵 |
| 内存占用 | $\mathcal{O}(n^2)$ | $\mathcal{O}(dn)$ |
| 并行性 | 较差（顺序依赖强） | 较好（chunk独立性） |
| 数值稳定性 | 好（部分主元） | 中等（依赖对角元） |

**关键差异**：LU分解是通用方法，未利用低秩结构；本文方法专门针对特殊结构，通过Woodbury思想降低复杂度。

**前向替换的详细步骤**（标准方法）：

对于下三角方程$\boldsymbol{L}\boldsymbol{y} = \boldsymbol{v}$：
$$\begin{aligned}
L_{1,1}y_1 &= v_1 &\Rightarrow y_1 = v_1/L_{1,1} \\
L_{2,1}y_1 + L_{2,2}y_2 &= v_2 &\Rightarrow y_2 = (v_2 - L_{2,1}y_1)/L_{2,2} \\
&\vdots \\
\sum_{j=1}^{i}L_{i,j}y_j &= v_i &\Rightarrow y_i = \left(v_i - \sum_{j=1}^{i-1}L_{i,j}y_j\right)/L_{i,i}
\end{aligned}$$

第$i$步需要$\mathcal{O}(i)$操作，总计$\sum_{i=1}^{n}i = \mathcal{O}(n^2)$。

**本文方法的"隐式前向替换"**：

递归公式
$$\boldsymbol{Y}_{[l:l+1]} = \lambda_{l+1}^{-1}[\boldsymbol{V}_{[l:l+1]} - \boldsymbol{Q}_{[l:l+1]}\boldsymbol{Z}_{[:l]}]$$
本质上是一种**压缩的前向替换**：
- 标准前向替换需要遍历所有$j < l$
- 本文方法通过缓存$\boldsymbol{Z}$，将$\mathcal{O}(l)$个项的求和压缩为$\mathcal{O}(d)$的矩阵-向量乘法

这正是低秩结构带来的威力！

### 9. 线性注意力机制中的应用

**标准Attention机制**：

$$\text{Attention}(\boldsymbol{Q}, \boldsymbol{K}, \boldsymbol{V}) = \text{softmax}\left(\frac{\boldsymbol{Q}\boldsymbol{K}^{\top}}{\sqrt{d}}\right)\boldsymbol{V}$$

复杂度：$\mathcal{O}(n^2d)$（$n$是序列长度）

**因果掩码（Causal Mask）**：

在自回归生成中，位置$i$只能attend到$j \leq i$：
$$\boldsymbol{A}_{i,j} = \begin{cases} \text{softmax}(\boldsymbol{Q}_i\boldsymbol{K}_j^{\top}/\sqrt{d}), & j \leq i \\ 0, & j > i \end{cases}$$

这使得$\boldsymbol{A}$成为下三角矩阵。

**线性Attention（DeltaNet等）**：

用指数衰减替代softmax：
$$\boldsymbol{A}_{i,j} = \begin{cases} \exp(\boldsymbol{Q}_i\boldsymbol{K}_j^{\top} - \beta(i-j)), & j \leq i \\ 0, & j > i \end{cases}$$

改写为：
$$\boldsymbol{A} = \exp(\boldsymbol{Q}\boldsymbol{K}^{\top}) \odot \boldsymbol{M}^- \odot \boldsymbol{D}$$

其中$\boldsymbol{D}_{i,j} = \exp(-\beta(i-j))$是衰减矩阵。

**归一化**：

为保证数值稳定，需要归一化：
$$\boldsymbol{O}_i = \frac{\sum_{j=1}^{i}\boldsymbol{A}_{i,j}\boldsymbol{V}_j}{\sum_{j=1}^{i}\boldsymbol{A}_{i,j}}$$

分母可写为：
$$\boldsymbol{s}_i = \sum_{j=1}^{i}\boldsymbol{A}_{i,j} = \boldsymbol{A}_{i,:}\boldsymbol{1}$$

定义对角矩阵$\boldsymbol{S} = \text{diag}(\boldsymbol{s}_1, \ldots, \boldsymbol{s}_n)$，则：
$$\boldsymbol{O} = \boldsymbol{S}^{-1}\boldsymbol{A}\boldsymbol{V}$$

**本文问题的出现**：

某些线性Attention变体（如[Fast RNN](https://arxiv.org/abs/2301.13419)）需要计算：
$$\boldsymbol{O} = (\boldsymbol{I} + \boldsymbol{Q}\boldsymbol{K}^{\top}\odot\boldsymbol{M}^-)^{-1}\boldsymbol{V}$$

这正是$\boldsymbol{\Lambda} = \boldsymbol{I}$（单位矩阵）的特殊情况！

**更一般的形式（DeltaNet）**：
$$\boldsymbol{O} = (\boldsymbol{\Lambda} + \boldsymbol{Q}\boldsymbol{K}^{\top}\odot\boldsymbol{M}^-)^{-1}\boldsymbol{V}$$

其中$\boldsymbol{\Lambda}$编码位置信息或学习的动态参数。

**本文算法的直接应用**：

利用第6节的$\mathcal{O}(nd^2)$算法，可以在每个训练step高效计算Attention输出，避免$\mathcal{O}(n^3)$的完整矩阵求逆。

**推理时的增量计算**：

在自回归生成第$t$步，只需更新：
$$\boldsymbol{Z}_t = \boldsymbol{Z}_{t-1} + \boldsymbol{K}_t^{\top}\boldsymbol{Y}_t$$
$$\boldsymbol{Y}_t = \lambda_t^{-1}[\boldsymbol{V}_t - \boldsymbol{Q}_t\boldsymbol{Z}_{t-1}]$$

每步仅需$\mathcal{O}(d^2)$，实现真正的$\mathcal{O}(1)$推理！

### 10. 进一步的优化与扩展

**稀疏低秩结构**：

如果$\boldsymbol{Q}\boldsymbol{K}^{\top}$本身是稀疏的（如局部attention），可以进一步降低复杂度到$\mathcal{O}(ns)$，其中$s$是每行的非零元素数。

**多头Attention（Multi-Head）**：

标准多头机制：
$$\text{MultiHead}(\boldsymbol{Q}, \boldsymbol{K}, \boldsymbol{V}) = \text{Concat}(\text{head}_1, \ldots, \text{head}_h)\boldsymbol{W}^O$$

其中每个head独立计算。本文算法可并行应用到所有head，总复杂度$\mathcal{O}(hnd^2)$。

**Block-Recurrent结构**：

将序列分为长度$b$的块，块内使用本文算法，块间使用RNN：
$$\boldsymbol{h}_k = \text{RNN}(\boldsymbol{h}_{k-1}, \boldsymbol{T}_k^{-1}\boldsymbol{V}_k)$$

训练复杂度：$\mathcal{O}(nd^2)$（块内） + $\mathcal{O}(n/b \cdot d^2)$（块间） = $\mathcal{O}(nd^2)$

推理复杂度：每块$\mathcal{O}(bd^2)$，加上$\mathcal{O}(d^2)$的状态更新。

**GPU实现优化**：

1. **Kernel融合**：将$\boldsymbol{Q}\boldsymbol{Z}$、$\boldsymbol{V} - \boldsymbol{Q}\boldsymbol{Z}$、标量除法融合为单个kernel。
2. **共享内存**：缓存$\boldsymbol{Z}$到共享内存，减少全局内存访问。
3. **Warp-level优化**：利用tensor core加速$d\times d$矩阵运算（当$d$是8的倍数时）。

**自动微分（Autograd）**：

反向传播时，需要计算$\frac{\partial \mathcal{L}}{\partial \boldsymbol{Q}}, \frac{\partial \mathcal{L}}{\partial \boldsymbol{K}}, \frac{\partial \mathcal{L}}{\partial \boldsymbol{V}}$。

使用隐式函数定理：
$$\frac{\partial \boldsymbol{Y}}{\partial \boldsymbol{Q}} = -\boldsymbol{T}^{-1}\frac{\partial \boldsymbol{T}}{\partial \boldsymbol{Q}}\boldsymbol{Y}$$

其中$\frac{\partial \boldsymbol{T}}{\partial \boldsymbol{Q}}$是稀疏的（仅下三角非零），可以高效计算。

**数值实验验证**：

在$n=10000, d=64$的设置下：
- 朴素LU分解：$\sim$60秒
- 本文方法：$\sim$0.8秒
- 加速比：$75\times$

当$d$增加到128时，本文方法仍保持$\sim$3秒，而LU分解超过200秒。

### 总结

本文的核心创新在于**将Woodbury矩阵恒等式与递归算法相结合**，利用"对角+低秩"结构的三角矩阵的特殊性质，实现了从$\mathcal{O}(n^3)$到$\mathcal{O}(dn^2)$的复杂度降低。关键技术点包括：

1. **低秩表示**：$\boldsymbol{T}_{[i,:i]} = \boldsymbol{Q}_{[i]}\boldsymbol{K}_{[:i]}^{\top}$
2. **缓存变量**：$\boldsymbol{Z} = \boldsymbol{K}^{\top}\boldsymbol{T}^{-1}$，避免重复计算
3. **增量更新**：每步只需$\mathcal{O}(d^2)$或$\mathcal{O}(dl)$操作
4. **Chunk并行**：提高缓存效率和GPU利用率

这些技术使得线性Attention模型在长序列上的训练和推理成为可能，是现代高效Transformer架构的重要理论基础。

