---
title: 缓解交叉熵过度自信的一个简明方案
slug: 缓解交叉熵过度自信的一个简明方案
date: 2023-03-14
tags: 优化, 损失函数, 光滑, 生成模型, attention
status: completed
---

# 缓解交叉熵过度自信的一个简明方案

**原文链接**: [https://spaces.ac.cn/archives/9526](https://spaces.ac.cn/archives/9526)

**发布日期**: 

---

众所周知，分类问题的常规评估指标是正确率，而标准的损失函数则是交叉熵，交叉熵有着收敛快的优点，但它并非是正确率的光滑近似，这就带来了训练和预测的不一致性问题。另一方面，当训练样本的预测概率很低时，交叉熵会给出一个非常巨大的损失（趋于$-\log 0^{+}=\infty$），这意味着交叉熵会特别关注预测概率低的样本——哪怕这个样本可能是“脏数据”。所以，交叉熵训练出来的模型往往有过度自信现象，即每个样本都给出较高的预测概率，这会带来两个副作用：一是对脏数据的过度拟合带来的效果下降，二是预测的概率值无法作为不确定性的良好指标。

围绕交叉熵的改进，学术界一直都有持续输出，目前这方面的研究仍处于“八仙过海，各显神通”的状态，没有标准答案。在这篇文章中，我们来学习一下论文[《Tailoring Language Generation Models under Total Variation Distance》](https://papers.cool/arxiv/2302.13344)给出的该问题的又一种简明的候选方案。

## 结果简介 #

顾名思义，原论文的改动是针对文本生成任务的，理论基础是Total Variation距离（参考[《Designing GANs：又一个GAN生产车间》](/archives/7210#Total%20Variation)）。但事实上，经过原论文的一系列放缩和简化后，最终结果已经跟Total Variation距离没有明显联系，并且理论上也不限于文本生成任务。所以，本文将它作为一般分类任务的损失函数来看待。

对于数据对$(x,y)$，交叉熵给出的损失函数为  
\begin{equation}-\log p_{\theta}(y|x)\end{equation}  
原论文的改动很简单，改为  
\begin{equation}-\frac{\log \big[\gamma + (1 - \gamma)p_{\theta}(y|x)\big]}{1-\gamma}\label{eq:gamma-ce}\end{equation}  
其中$\gamma\in[0,1]$。当$\gamma=0$时，就是普通的交叉熵；当$\gamma=1$时，按极限来算，结果是$-p_{\theta}(y|x)$。

在原论文的实验中，不同任务的$\gamma$选取差别比较大，比如语言模型任务中取到了$\gamma=10^{-7}$，机器翻译任务中取了$\gamma=0.1$，文本摘要任务中取了$\gamma=0.8$。一个可以参考的规律是，如果是从零训练，那么需要选择比较接近于0的$\gamma$，如果是微调训练，那么可以考虑相对大一点的$\gamma$。此外，还有一种比较直观的方案，就是将$\gamma$视为动态参数，从$\gamma=0$开始，随着训练的推进慢慢转向$\gamma=1$，但这样就多了个schedule要调试。

效果上，由于多了个可调的$\gamma$参数，并且原本的交叉熵也包含在里边，所以只要用心去调，一般总有机会调出比交叉熵更好的结果的，这个倒不用太担心。

## 个人推导 #

怎么理解式$\eqref{eq:gamma-ce}$呢？在[《函数光滑化杂谈：不可导函数的可导逼近》](/archives/6620#%E6%AD%A3%E7%A1%AE%E7%8E%87)中的“正确率”一节，我们推导过正确率的光滑近似是  
\begin{equation}\mathbb{E}_{(x,y)\sim \mathcal{D}}[p_{\theta}(y|x)]\end{equation}  
所以，如果我们的评估指标是正确率，那么直觉上以$-p_{\theta}(y|x)$为损失函数才对，因为这时候损失函数跟正确率的变化更加同步。然而，事实上是交叉熵的表现往往更好。但交叉熵的出发点只是“更好训练”，所以有时候就会“训过头”了，导致过拟合。所以一个直观的想法就是能否将两个结果“插值”一下，以兼顾两者的优点。

为此，我们考虑两者的梯度【准确率指的是它的负光滑近似$-p_{\theta}(y|x)$】：  
\begin{equation}\begin{aligned}  
\text{准确率：}&\,\quad-\nabla_{\theta} p_{\theta}(y|x) \\\  
\text{交叉熵：}&\,\quad-\frac{1}{p_{\theta}(y|x)}\nabla_{\theta} p_{\theta}(y|x)  
\end{aligned}\end{equation}  
两者就差个$\frac{1}{p_{\theta}(y|x)}$。怎么把$\frac{1}{p_{\theta}(y|x)}$变为1呢？原论文的方案是：  
\begin{equation}\frac{1}{\gamma + (1 - \gamma)p_{\theta}(y|x)}\end{equation}  
当然这个构造方式不是唯一的，原论文选的这个方式，尽可能地保留了交叉熵的梯度特性，也就尽可能保留了交叉熵收敛快的特点。根据这个构造，我们就希望新损失函数的梯度为  
\begin{equation}-\frac{\nabla_{\theta}p_{\theta}(y|x)}{\gamma + (1 - \gamma)p_{\theta}(y|x)} = \nabla_{\theta}\left(-\frac{\log \big[\gamma + (1 - \gamma)p_{\theta}(y|x)\big]}{1-\gamma}\right)\label{eq:gamma-ce-g}\end{equation}  
这就找出了损失函数$\eqref{eq:gamma-ce}$，在这个过程中，我们先设计新的梯度，然后通过积分找原函数的方式找到了对应的损失函数。

## 多扯几句 #

为什么要从梯度角度去设计损失函数呢？大概有两方面的原因。

第一，很多损失函数求了梯度后会得到简化，所以在梯度空间设计，往往有更多的灵感和自由度，比如本文的例子中，在梯度空间设计$\frac{1}{p_{\theta}(y|x)}$与$1$的过渡函数$\frac{1}{\gamma + (1 - \gamma)p_{\theta}(y|x)}$不算太复杂，但如果直接在损失函数空间设计$p_{\theta}(y|x)$和$\log p_{\theta}(y|x)$的过渡函数$\frac{\log \big[\gamma + (1 - \gamma)p_{\theta}(y|x)\big]}{1-\gamma}$就复杂多了。

第二，目前使用的优化器都是基于梯度的，所以很多时候我们设计好梯度就行了，甚至都不必要找出原函数。论文的原始结果实际上就是只给出了梯度：  
\begin{equation}-\max\left(b, \frac{p_{\theta}(y|x)}{\gamma + (1 - \gamma)p_{\theta}(y|x)}\right)\nabla_{\theta}\log p_{\theta}(y|x)\end{equation}  
当$b=0$时，它就等价于式$\eqref{eq:gamma-ce}$。也就是说，原论文在设计梯度的时候还加了个阈值，这时候就很难写出简单的原函数了。但上式实现上并不困难，只要考虑损失函数  
\begin{equation}-\max\left(b, \frac{p_{\theta}(y|x)}{\gamma + (1 - \gamma)p_{\theta}(y|x)}\right)_{\text{stop_grad}}\log p_{\theta}(y|x)\end{equation}  
这里边的$\text{stop_grad}$就是直接断掉这部分结果的梯度，在tensorflow中对应着`tf.stop_gradient`算子。

## 文章小结 #

本文主要介绍了缓解交叉熵过度自信的一个简明方案。

_**转载到请包括本文地址：**<https://spaces.ac.cn/archives/9526>_

_**更详细的转载事宜请参考：**_[《科学空间FAQ》](https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8 "《科学空间FAQ》")

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎分享/打赏本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

![科学空间](https://spaces.ac.cn/usr/themes/geekg/payment/wx.png)

微信打赏

![科学空间](https://spaces.ac.cn/usr/themes/geekg/payment/zfb.png)

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以[**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ)或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Mar. 14, 2023). 《缓解交叉熵过度自信的一个简明方案 》[Blog post]. Retrieved from <https://spaces.ac.cn/archives/9526>

@online{kexuefm-9526,  
title={缓解交叉熵过度自信的一个简明方案},  
author={苏剑林},  
year={2023},  
month={Mar},  
url={\url{https://spaces.ac.cn/archives/9526}},  
} 


---

## 详细数学推导与理论分析

### 1. 交叉熵的过度自信问题

**标准交叉熵损失**：

对于分类问题，给定样本$(x, y)$，模型预测概率为$p_\theta(y|x)$，交叉熵损失为：
\begin{equation}
\mathcal{L}_{\text{CE}} = -\log p_\theta(y|x) \tag{1}
\end{equation}

**梯度分析**：

对于模型参数$\theta$，梯度为：
\begin{equation}
\nabla_\theta \mathcal{L}_{\text{CE}} = -\frac{1}{p_\theta(y|x)} \nabla_\theta p_\theta(y|x) \tag{2}
\end{equation}

**关键观察**：当$p_\theta(y|x) \to 0$时，梯度趋向无穷大！

\begin{equation}
p_\theta(y|x) \to 0^+ \Rightarrow |\nabla_\theta \mathcal{L}_{\text{CE}}| \to \infty \tag{3}
\end{equation}

这导致模型对低概率样本给予极大关注，即使这些样本可能是：
- **噪声标签**（label noise）
- **异常值**（outliers）
- **边界样本**（borderline cases）

**过度自信现象**：

优化交叉熵会推动模型给出极端的概率预测：
\begin{equation}
p_\theta(y|x) \to 1 \quad \text{对于训练样本} \tag{4}
\end{equation}

这会导致：
1. **校准性差**：预测概率不能很好地反映真实置信度
2. **过拟合**：对脏数据过度拟合
3. **泛化性差**：在测试集上表现下降

### 2. γ-交叉熵的定义与推导

**原论文的γ-交叉熵**：

\begin{equation}
\mathcal{L}_{\gamma\text{-CE}} = -\frac{\log[\gamma + (1-\gamma)p_\theta(y|x)]}{1-\gamma} \tag{5}
\end{equation}

其中$\gamma \in [0, 1]$是超参数。

**特殊情况分析**：

**情况1**：$\gamma = 0$
\begin{equation}
\mathcal{L}_{0\text{-CE}} = -\frac{\log p_\theta(y|x)}{1} = -\log p_\theta(y|x) = \mathcal{L}_{\text{CE}} \tag{6}
\end{equation}

退化为标准交叉熵。

**情况2**：$\gamma = 1$（利用洛必达法则）
\begin{equation}
\begin{aligned}
\mathcal{L}_{1\text{-CE}} &= \lim_{\gamma \to 1} -\frac{\log[\gamma + (1-\gamma)p_\theta(y|x)]}{1-\gamma} \\
&= \lim_{\gamma \to 1} -\frac{\frac{d}{d\gamma}\log[\gamma + (1-\gamma)p_\theta(y|x)]}{\frac{d}{d\gamma}(1-\gamma)} \\
&= \lim_{\gamma \to 1} -\frac{\frac{1 - p_\theta(y|x)}{\gamma + (1-\gamma)p_\theta(y|x)}}{-1} \\
&= \frac{1 - p_\theta(y|x)}{1} = 1 - p_\theta(y|x)
\end{aligned} \tag{7}
\end{equation}

这是**负的准确率平滑近似**！

**中间情况**：$\gamma \in (0, 1)$

\begin{equation}
\mathcal{L}_{\gamma\text{-CE}} \text{ 在 } \mathcal{L}_{\text{CE}} \text{ 和 } 1 - p_\theta(y|x) \text{ 之间插值} \tag{8}
\end{equation}

### 3. 从梯度视角理解γ-交叉熵

**准确率的平滑近似**：

如原文所述，分类准确率的平滑近似为：
\begin{equation}
\text{Accuracy} \approx \mathbb{E}_{(x,y)\sim\mathcal{D}}[p_\theta(y|x)] \tag{9}
\end{equation}

因此，最小化$-p_\theta(y|x)$等价于最大化准确率。

**两种损失的梯度对比**：

准确率损失的梯度：
\begin{equation}
\nabla_\theta[-p_\theta(y|x)] = -\nabla_\theta p_\theta(y|x) \tag{10}
\end{equation}

交叉熵损失的梯度：
\begin{equation}
\nabla_\theta[-\log p_\theta(y|x)] = -\frac{1}{p_\theta(y|x)} \nabla_\theta p_\theta(y|x) \tag{11}
\end{equation}

**关键差异**：权重因子$\frac{1}{p_\theta(y|x)}$

**设计目标**：找到一个权重函数$w(p)$，使得：
\begin{equation}
w(p) \text{ 在 } 1 \text{ 和 } \frac{1}{p} \text{ 之间插值} \tag{12}
\end{equation}

**原论文的选择**：
\begin{equation}
w_\gamma(p) = \frac{1}{\gamma + (1-\gamma)p} \tag{13}
\end{equation}

验证：
- $w_0(p) = \frac{1}{p}$（交叉熵）
- $w_1(p) = 1$（准确率）

**寻找对应的损失函数**：

我们希望找到$\mathcal{L}$使得：
\begin{equation}
\nabla_\theta \mathcal{L} = -\frac{1}{\gamma + (1-\gamma)p_\theta(y|x)} \nabla_\theta p_\theta(y|x) \tag{14}
\end{equation}

**积分反推**：

记$p = p_\theta(y|x)$，我们需要：
\begin{equation}
\frac{d\mathcal{L}}{dp} = -\frac{1}{\gamma + (1-\gamma)p} \tag{15}
\end{equation}

积分：
\begin{equation}
\begin{aligned}
\mathcal{L} &= -\int \frac{1}{\gamma + (1-\gamma)p} dp \\
&= -\frac{1}{1-\gamma} \int \frac{1}{\gamma + (1-\gamma)p} d[\gamma + (1-\gamma)p] \\
&= -\frac{1}{1-\gamma} \log[\gamma + (1-\gamma)p] + C
\end{aligned} \tag{16}
\end{equation}

选择常数$C=0$，得到式(5)！

### 4. γ-交叉熵的性质

**性质1：单调性**

对于固定的$p$，$\mathcal{L}_{\gamma\text{-CE}}$关于$\gamma$单调递增：
\begin{equation}
\frac{\partial \mathcal{L}_{\gamma\text{-CE}}}{\partial \gamma} = \frac{\log[\gamma + (1-\gamma)p]}{(1-\gamma)^2} - \frac{1-p}{(1-\gamma)[\gamma + (1-\gamma)p]} \tag{17}
\end{equation}

当$p < 1$时，可以证明：
\begin{equation}
\frac{\partial \mathcal{L}_{\gamma\text{-CE}}}{\partial \gamma} > 0 \tag{18}
\end{equation}

**性质2：有界性**

当$\gamma > 0$时，损失有上界：
\begin{equation}
\mathcal{L}_{\gamma\text{-CE}} \leq -\frac{\log \gamma}{1-\gamma} \tag{19}
\end{equation}

这避免了交叉熵在$p \to 0$时趋向无穷的问题！

**性质3：梯度有界性**

梯度的大小为：
\begin{equation}
|\nabla_\theta \mathcal{L}_{\gamma\text{-CE}}| = \frac{1}{\gamma + (1-\gamma)p_\theta(y|x)} |\nabla_\theta p_\theta(y|x)| \tag{20}
\end{equation}

有上界：
\begin{equation}
|\nabla_\theta \mathcal{L}_{\gamma\text{-CE}}| \leq \frac{1}{\gamma} |\nabla_\theta p_\theta(y|x)| \tag{21}
\end{equation}

而交叉熵的梯度可以无界！

### 5. 与Label Smoothing的联系

**标准Label Smoothing**：

对于$K$类分类问题，硬标签为one-hot向量$\boldsymbol{y} = [0, \ldots, 1, \ldots, 0]$。

Label smoothing定义软标签为：
\begin{equation}
\tilde{y}_i = \begin{cases}
1 - \alpha + \frac{\alpha}{K}, & i = y \\
\frac{\alpha}{K}, & i \neq y
\end{cases} \tag{22}
\end{equation}

其中$\alpha \in [0, 1]$是平滑参数。

**等价写法**：
\begin{equation}
\tilde{\boldsymbol{y}} = (1-\alpha)\boldsymbol{y} + \alpha \boldsymbol{u} \tag{23}
\end{equation}

其中$\boldsymbol{u} = [\frac{1}{K}, \ldots, \frac{1}{K}]$是均匀分布。

**Label Smoothing的损失**：
\begin{equation}
\mathcal{L}_{\text{LS}} = -\sum_{i=1}^K \tilde{y}_i \log p_\theta(i|x) \tag{24}
\end{equation}

**展开**：
\begin{equation}
\begin{aligned}
\mathcal{L}_{\text{LS}} &= -(1-\alpha)\log p_\theta(y|x) - \frac{\alpha}{K}\sum_{i=1}^K \log p_\theta(i|x) \\
&= (1-\alpha)\mathcal{L}_{\text{CE}} + \alpha \mathcal{L}_{\text{unif}}
\end{aligned} \tag{25}
\end{equation}

其中$\mathcal{L}_{\text{unif}} = -\frac{1}{K}\sum_i \log p_\theta(i|x)$是与均匀分布的交叉熵。

**与γ-交叉熵的对比**：

| 方法 | 形式 | 插值对象 |
|------|------|---------|
| Label Smoothing | $(1-\alpha)\mathcal{L}_{\text{CE}} + \alpha \mathcal{L}_{\text{unif}}$ | 损失函数的线性组合 |
| γ-交叉熵 | $-\frac{\log[\gamma + (1-\gamma)p]}{1-\gamma}$ | 梯度的插值 |

**区别**：
- Label Smoothing在**损失空间**插值
- γ-交叉熵在**梯度空间**插值

### 6. 校准理论（Calibration）

**什么是校准？**

一个模型是**完美校准**的，如果：
\begin{equation}
\mathbb{P}(Y = y | p_\theta(Y|X) = p) = p \quad \forall p \in [0, 1] \tag{26}
\end{equation}

即：对于所有预测概率为$p$的样本，真实的准确率也是$p$。

**Expected Calibration Error (ECE)**：

将预测概率分为$M$个区间$B_1, \ldots, B_M$，ECE定义为：
\begin{equation}
\text{ECE} = \sum_{m=1}^M \frac{|B_m|}{N} |\text{acc}(B_m) - \text{conf}(B_m)| \tag{27}
\end{equation}

其中：
- $\text{conf}(B_m) = \frac{1}{|B_m|} \sum_{i \in B_m} \hat{p}_i$（平均置信度）
- $\text{acc}(B_m) = \frac{1}{|B_m|} \sum_{i \in B_m} \mathbb{1}[\hat{y}_i = y_i]$（准确率）

**可靠性图（Reliability Diagram）**：

横轴为$\text{conf}(B_m)$，纵轴为$\text{acc}(B_m)$。完美校准对应于对角线$y=x$。

**交叉熵的校准问题**：

交叉熵训练的模型通常是**过度自信**的（overconfident）：
\begin{equation}
\text{conf}(B_m) > \text{acc}(B_m) \tag{28}
\end{equation}

即：预测概率高于真实准确率。

**γ-交叉熵的校准效果**：

通过减小梯度权重，γ-交叉熵缓解了过度自信问题，使得：
\begin{equation}
\text{conf}(B_m) \approx \text{acc}(B_m) \tag{29}
\end{equation}

### 7. 正则化效应的数学证明

**定理**：γ-交叉熵等价于在交叉熵上添加一个隐式的正则项。

**证明思路**：

Taylor展开式(5)在$p = p_\theta(y|x)$附近：
\begin{equation}
\begin{aligned}
\mathcal{L}_{\gamma\text{-CE}} &= -\frac{\log[\gamma + (1-\gamma)p]}{1-\gamma} \\
&\approx -\frac{\log[(1-\gamma)p] + \log[1 + \frac{\gamma}{(1-\gamma)p}]}{1-\gamma}
\end{aligned} \tag{30}
\end{equation}

利用$\log(1+x) \approx x - \frac{x^2}{2}$（当$x$小时）：
\begin{equation}
\log\left[1 + \frac{\gamma}{(1-\gamma)p}\right] \approx \frac{\gamma}{(1-\gamma)p} - \frac{1}{2}\left(\frac{\gamma}{(1-\gamma)p}\right)^2 \tag{31}
\end{equation}

代入：
\begin{equation}
\begin{aligned}
\mathcal{L}_{\gamma\text{-CE}} &\approx -\frac{1}{1-\gamma}\left[\log p + \frac{\gamma}{(1-\gamma)p} - \frac{\gamma^2}{2(1-\gamma)^2 p^2}\right] \\
&= -\log p - \frac{\gamma}{(1-\gamma)^2 p} + \frac{\gamma^2}{2(1-\gamma)^3 p^2}
\end{aligned} \tag{32}
\end{equation}

第一项是交叉熵，后面两项是**正则项**！

**直觉解释**：
- $-\frac{\gamma}{(1-\gamma)^2 p}$：惩罚小概率（防止过度自信）
- $+\frac{\gamma^2}{2(1-\gamma)^3 p^2}$：二阶修正项

### 8. 与其他鲁棒损失函数的对比

**Mean Absolute Error (MAE)**：
\begin{equation}
\mathcal{L}_{\text{MAE}} = \sum_{i=1}^K |y_i - p_\theta(i|x)| \tag{33}
\end{equation}

**Focal Loss**：
\begin{equation}
\mathcal{L}_{\text{Focal}} = -(1 - p_\theta(y|x))^\beta \log p_\theta(y|x) \tag{34}
\end{equation}

**Generalized Cross Entropy (GCE)**：
\begin{equation}
\mathcal{L}_{\text{GCE}} = \frac{1 - p_\theta(y|x)^q}{q} \tag{35}
\end{equation}

**对比表**：

| 损失函数 | 梯度权重 | 鲁棒性来源 | 超参数 |
|---------|---------|-----------|--------|
| CE | $\frac{1}{p}$ | 无 | 无 |
| γ-CE | $\frac{1}{\gamma + (1-\gamma)p}$ | 梯度裁剪 | $\gamma$ |
| Focal | $\frac{(1-p)^\beta}{p}$ | 降低易分样本权重 | $\beta$ |
| GCE | $p^{q-1}$ | 有界损失 | $q$ |

### 9. 梯度裁剪的几何解释

**梯度空间的视角**：

在参数空间$\Theta$中，梯度$\nabla_\theta \mathcal{L}$定义了一个向量场。

交叉熵的梯度：
\begin{equation}
\boldsymbol{g}_{\text{CE}} = -\frac{1}{p_\theta(y|x)} \nabla_\theta p_\theta(y|x) \tag{36}
\end{equation}

γ-交叉熵的梯度：
\begin{equation}
\boldsymbol{g}_{\gamma\text{-CE}} = -\frac{1}{\gamma + (1-\gamma)p_\theta(y|x)} \nabla_\theta p_\theta(y|x) \tag{37}
\end{equation}

**比例关系**：
\begin{equation}
\boldsymbol{g}_{\gamma\text{-CE}} = \frac{\gamma + (1-\gamma)p_\theta(y|x)}{p_\theta(y|x)} \boldsymbol{g}_{\text{CE}} = \left[\gamma + (1-\gamma)p_\theta(y|x)\right] \frac{\boldsymbol{g}_{\text{CE}}}{p_\theta(y|x)} \tag{38}
\end{equation}

定义**裁剪因子**：
\begin{equation}
c(\gamma, p) = \gamma + (1-\gamma)p = (1-\gamma)\left(p + \frac{\gamma}{1-\gamma}\right) \tag{39}
\end{equation}

**关键性质**：
\begin{equation}
c(\gamma, p) \geq \gamma \quad \forall p \in [0, 1] \tag{40}
\end{equation}

因此：
\begin{equation}
\|\boldsymbol{g}_{\gamma\text{-CE}}\| \leq \frac{1}{\gamma} \|\boldsymbol{g}_{\text{CE}} \cdot p_\theta(y|x)\| = \frac{1}{\gamma} \|\nabla_\theta p_\theta(y|x)\| \tag{41}
\end{equation}

**几何直觉**：γ-交叉熵相当于对交叉熵的梯度进行了**自适应裁剪**，裁剪强度取决于当前预测概率$p$。

### 10. Hessian分析与收敛性

**交叉熵的Hessian**：

对于单个样本，记$\boldsymbol{p} = [p_1, \ldots, p_K]$为预测概率向量（$\sum_i p_i = 1$）。

对于参数$\theta_i$和$\theta_j$：
\begin{equation}
\frac{\partial^2 \mathcal{L}_{\text{CE}}}{\partial \theta_i \partial \theta_j} = -\frac{1}{p_y}\frac{\partial^2 p_y}{\partial \theta_i \partial \theta_j} + \frac{1}{p_y^2}\frac{\partial p_y}{\partial \theta_i}\frac{\partial p_y}{\partial \theta_j} \tag{42}
\end{equation}

当$p_y \to 0$时，Hessian的第二项趋向无穷！

**γ-交叉熵的Hessian**：

\begin{equation}
\frac{\partial^2 \mathcal{L}_{\gamma\text{-CE}}}{\partial \theta_i \partial \theta_j} = -\frac{1}{\gamma + (1-\gamma)p_y}\frac{\partial^2 p_y}{\partial \theta_i \partial \theta_j} + \frac{1-\gamma}{[\gamma + (1-\gamma)p_y]^2}\frac{\partial p_y}{\partial \theta_i}\frac{\partial p_y}{\partial \theta_j} \tag{43}
\end{equation}

**关键区别**：第二项被$[\gamma + (1-\gamma)p_y]^2 \geq \gamma^2$界住，因此Hessian是**有界的**！

**收敛速度**：

在凸优化中，Hessian的条件数决定了收敛速度。交叉熵的Hessian条件数可能很大（当$p_y$很小时），而γ-交叉熵的Hessian条件数更加温和。

### 11. 贝叶斯视角

**最大后验估计（MAP）**：

假设模型参数$\theta$有先验分布$p(\theta)$，MAP估计为：
\begin{equation}
\hat{\theta}_{\text{MAP}} = \arg\max_\theta p(\theta | \mathcal{D}) = \arg\max_\theta p(\mathcal{D} | \theta) p(\theta) \tag{44}
\end{equation}

等价于最小化：
\begin{equation}
\mathcal{L}_{\text{MAP}} = -\log p(\mathcal{D} | \theta) - \log p(\theta) \tag{45}
\end{equation}

**γ-交叉熵的先验解释**：

可以证明，γ-交叉熵等价于使用某种隐式先验的MAP估计。

具体地，如果我们假设：
\begin{equation}
p(\theta) \propto \exp\left(-\lambda \sum_i \frac{1}{p_\theta(y_i | x_i)}\right) \tag{46}
\end{equation}

那么MAP等价于最小化：
\begin{equation}
-\log p(\mathcal{D} | \theta) + \lambda \sum_i \frac{1}{p_\theta(y_i | x_i)} \tag{47}
\end{equation}

这与γ-交叉熵的形式类似（见式32）。

### 12. 信息论视角

**KL散度分解**：

交叉熵可以分解为：
\begin{equation}
\mathcal{L}_{\text{CE}} = H(q, p_\theta) = H(q) + D_{\text{KL}}(q \| p_\theta) \tag{48}
\end{equation}

其中$q$是真实分布（one-hot），$H(q) = 0$，所以：
\begin{equation}
\mathcal{L}_{\text{CE}} = D_{\text{KL}}(q \| p_\theta) \tag{49}
\end{equation}

**γ-交叉熵的信息论解释**：

γ-交叉熵可以理解为最小化一个**修正的KL散度**：
\begin{equation}
D_{\gamma\text{-KL}}(q \| p_\theta) = -\frac{1}{1-\gamma}\sum_i q_i \log[\gamma + (1-\gamma)p_{\theta,i}] \tag{50}
\end{equation}

这不是标准的Bregman散度，但具有类似的性质。

**互信息最大化**：

从信息论角度，学习目标是最大化输入$X$和标签$Y$之间的互信息：
\begin{equation}
I(X; Y) = H(Y) - H(Y|X) \tag{51}
\end{equation}

交叉熵直接最小化条件熵$H(Y|X)$，而γ-交叉熵通过正则化防止过度减小$H(Y|X)$，从而保持一定的不确定性。

### 13. 与Mixup和Cutout的关系

**Mixup**：

对于两个样本$(x_1, y_1)$和$(x_2, y_2)$，生成：
\begin{equation}
\tilde{x} = \lambda x_1 + (1-\lambda)x_2, \quad \tilde{y} = \lambda y_1 + (1-\lambda)y_2 \tag{52}
\end{equation}

其中$\lambda \sim \text{Beta}(\alpha, \alpha)$。

**Mixup的损失**：
\begin{equation}
\mathcal{L}_{\text{Mixup}} = -\tilde{y} \log p_\theta(\tilde{y} | \tilde{x}) - (1-\tilde{y})\log(1 - p_\theta(\tilde{y} | \tilde{x})) \tag{53}
\end{equation}

这是一个**软标签**损失！

**与γ-交叉熵结合**：

可以将两者结合：
\begin{equation}
\mathcal{L}_{\gamma\text{-Mixup}} = -\frac{\log[\gamma + (1-\gamma)\tilde{y} p_\theta(\tilde{y} | \tilde{x})]}{1-\gamma} \tag{54}
\end{equation}

**Cutout**：

Cutout随机遮挡输入图像的一部分。这可以理解为一种**数据增强**，增加了输入的不确定性。

与γ-交叉熵的协同效应：
- Cutout增加输入不确定性
- γ-交叉熵保持输出不确定性

两者互补，进一步提高泛化性能。

### 14. 超参数选择策略

**γ的选择依据**：

1. **任务类型**：
   - 从零训练：$\gamma \in [0, 10^{-4}]$（接近标准交叉熵）
   - 微调预训练模型：$\gamma \in [0.1, 0.8]$（更大的平滑）

2. **数据质量**：
   - 干净标签：小$\gamma$
   - 噪声标签：大$\gamma$（如$\gamma \geq 0.5$）

3. **模型容量**：
   - 大模型：大$\gamma$（防止过拟合）
   - 小模型：小$\gamma$（保持拟合能力）

**自适应γ策略**：

定义**动态γ**：
\begin{equation}
\gamma(t) = \gamma_{\min} + (\gamma_{\max} - \gamma_{\min}) \cdot \frac{t}{T} \tag{55}
\end{equation}

其中$t$是当前epoch，$T$是总epoch数。

**直觉**：开始时用小$\gamma$快速收敛，后期用大$\gamma$提高泛化。

**自适应调整（基于验证集）**：
\begin{equation}
\gamma \leftarrow \gamma + \eta \cdot \text{sign}(\text{ECE}_{\text{val}}) \tag{56}
\end{equation}

其中ECE是验证集上的校准误差。

### 15. 梯度累积与批量大小的影响

**批量梯度**：

对于batch $\mathcal{B}$，总梯度为：
\begin{equation}
\nabla_\theta \mathcal{L}_{\text{batch}} = \frac{1}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \nabla_\theta \mathcal{L}_{\gamma\text{-CE}}(x_i, y_i) \tag{57}
\end{equation}

**大batch vs. 小batch**：

- **大batch**：梯度更稳定，但可能陷入尖锐的极小值（泛化差）
- **小batch**：梯度有噪声，倾向于平坦的极小值（泛化好）

**γ-交叉熵的影响**：

γ-交叉熵通过减小梯度幅度，起到了类似**小batch**的正则化效果，即使在大batch下也能找到平坦的极小值。

### 16. 温度缩放与后处理校准

**Temperature Scaling**：

对于已训练的模型，可以通过温度参数$T$校准输出：
\begin{equation}
p_T(y|x) = \frac{e^{z_y / T}}{\sum_i e^{z_i / T}} \tag{58}
\end{equation}

其中$z_i$是logits。通过最小化验证集上的负对数似然来优化$T$。

**与γ-交叉熵的比较**：

| 方法 | 时机 | 额外参数 | 效果 |
|------|------|---------|------|
| γ-交叉熵 | 训练时 | $\gamma$（每个任务） | 同时提高准确率和校准 |
| Temperature Scaling | 后处理 | $T$（单个标量） | 只改善校准，不改变准确率 |

**结合使用**：

可以先用γ-交叉熵训练，再用Temperature Scaling微调，进一步提高校准性能。

### 17. 理论收敛性分析

**假设**：损失函数$\mathcal{L}$是$L$-smooth的，即：
\begin{equation}
\|\nabla \mathcal{L}(\theta_1) - \nabla \mathcal{L}(\theta_2)\| \leq L \|\theta_1 - \theta_2\| \tag{59}
\end{equation}

**定理**（SGD的收敛）：

对于$L$-smooth且凸的损失函数，使用学习率$\eta < \frac{1}{L}$的SGD，经过$T$步后：
\begin{equation}
\mathbb{E}[\mathcal{L}(\bar{\theta}_T)] - \mathcal{L}(\theta^*) \leq \frac{L \|\theta_0 - \theta^*\|^2}{2T} + \frac{\eta \sigma^2}{2} \tag{60}
\end{equation}

其中$\bar{\theta}_T = \frac{1}{T}\sum_{t=1}^T \theta_t$，$\sigma^2$是梯度方差。

**γ-交叉熵的优势**：

由于梯度有界（式21），$\sigma^2$更小，因此收敛误差更小！

### 18. 数值稳定性实现

**LogSumExp技巧**：

对于softmax，标准实现：
\begin{equation}
p_i = \frac{e^{z_i}}{\sum_j e^{z_j}} \tag{61}
\end{equation}

数值稳定版本：
\begin{equation}
p_i = \frac{e^{z_i - z_{\max}}}{\sum_j e^{z_j - z_{\max}}} \tag{62}
\end{equation}

**γ-交叉熵的实现**：

\begin{equation}
\mathcal{L}_{\gamma\text{-CE}} = -\frac{\log[\gamma + (1-\gamma)p_y]}{1-\gamma} \tag{63}
\end{equation}

当$\gamma \to 0$时，分子分母都趋向0，需要特殊处理：

```python
def gamma_cross_entropy(y_true, y_pred, gamma, epsilon=1e-10):
    """
    y_true: 真实标签 (batch_size,)
    y_pred: 预测logits (batch_size, num_classes)
    gamma: 平滑参数
    """
    # 计算softmax概率
    p = tf.nn.softmax(y_pred, axis=-1)

    # 获取真实类别的概率
    p_y = tf.gather_nd(p, tf.stack([tf.range(tf.shape(y_true)[0]), y_true], axis=1))

    # 避免数值问题
    p_y = tf.clip_by_value(p_y, epsilon, 1.0)

    if gamma < epsilon:
        # 当gamma接近0时，使用标准交叉熵
        loss = -tf.math.log(p_y)
    else:
        # γ-交叉熵
        loss = -tf.math.log(gamma + (1 - gamma) * p_y) / (1 - gamma)

    return tf.reduce_mean(loss)
```

### 19. 实验设计与消融研究

**消融实验设置**：

1. **Baseline**: 标准交叉熵（$\gamma = 0$）
2. **变体1**: 小γ（$\gamma = 0.01$）
3. **变体2**: 中γ（$\gamma = 0.1$）
4. **变体3**: 大γ（$\gamma = 0.5$）
5. **变体4**: 动态γ（从0到0.5）

**评估指标**：

1. **准确率**：$\text{Acc} = \frac{1}{N}\sum_i \mathbb{1}[y_i = \hat{y}_i]$
2. **ECE**：预期校准误差（式27）
3. **负对数似然**：$\text{NLL} = -\frac{1}{N}\sum_i \log p_\theta(y_i | x_i)$
4. **Brier分数**：$\text{BS} = \frac{1}{N}\sum_i \|\boldsymbol{y}_i - \boldsymbol{p}_i\|^2$

**可视化**：

1. **可靠性图**：置信度vs.准确率
2. **损失曲线**：训练/验证损失随epoch变化
3. **梯度范数**：$\|\nabla_\theta \mathcal{L}\|$随训练变化

### 20. 理论开放问题

**问题1**：γ-交叉熵的最优$\gamma$选择

是否存在理论最优的$\gamma^*$作为数据分布和模型架构的函数？

**问题2**：与其他散度的关系

γ-交叉熵是否可以理解为某种f-散度或Bregman散度的特例？

**问题3**：泛化界

能否为γ-交叉熵推导更紧的泛化界（generalization bound）？

**问题4**：多任务学习

在多任务学习中，不同任务是否应该使用不同的$\gamma$？如何自动确定？

### 21. 扩展：多分类到多标签

**多标签γ-交叉熵**：

对于多标签分类，每个类别独立，可以定义：
\begin{equation}
\mathcal{L}_{\gamma\text{-BCE}} = -\sum_{i=1}^K \frac{\log[\gamma + (1-\gamma)\sigma(z_i)^{y_i}(1-\sigma(z_i))^{1-y_i}]}{1-\gamma} \tag{64}
\end{equation}

其中$\sigma(z_i)$是第$i$个类别的sigmoid输出。

**简化形式**：

对于每个类别$i$：
\begin{equation}
\mathcal{L}_{\gamma\text{-BCE},i} = \begin{cases}
-\frac{\log[\gamma + (1-\gamma)\sigma(z_i)]}{1-\gamma}, & y_i = 1 \\
-\frac{\log[\gamma + (1-\gamma)(1-\sigma(z_i))]}{1-\gamma}, & y_i = 0
\end{cases} \tag{65}
\end{equation}

### 22. 连接：从stop_gradient到γ-交叉熵

**原论文的stop_gradient版本**：

\begin{equation}
\mathcal{L}_{\text{sg}} = -\underbrace{\frac{p_\theta(y|x)}{\gamma + (1-\gamma)p_\theta(y|x)}}_{\text{stop\_grad}} \log p_\theta(y|x) \tag{66}
\end{equation}

**梯度**：
\begin{equation}
\nabla_\theta \mathcal{L}_{\text{sg}} = -\frac{p_\theta(y|x)}{\gamma + (1-\gamma)p_\theta(y|x)} \cdot \frac{1}{p_\theta(y|x)} \nabla_\theta p_\theta(y|x) = -\frac{\nabla_\theta p_\theta(y|x)}{\gamma + (1-\gamma)p_\theta(y|x)} \tag{67}
\end{equation}

这正是式(14)！

**与γ-交叉熵的区别**：
- stop_gradient版本：直接定义梯度，损失函数本身没有意义
- γ-交叉熵：损失函数有明确意义，梯度是自然导出的

### 23. 实践建议总结

**推荐配置**：

1. **图像分类（从零训练）**：
   - $\gamma \in [0, 0.01]$
   - 结合Label Smoothing ($\alpha = 0.1$)

2. **图像分类（微调）**：
   - $\gamma \in [0.1, 0.3]$
   - 可选：动态γ schedule

3. **NLP任务**：
   - 语言模型：$\gamma \approx 10^{-7}$（接近标准CE）
   - 机器翻译：$\gamma \approx 0.1$
   - 文本摘要：$\gamma \approx 0.8$

4. **噪声标签场景**：
   - 轻度噪声（<10%）：$\gamma \approx 0.2$
   - 中度噪声（10-30%）：$\gamma \approx 0.5$
   - 重度噪声（>30%）：$\gamma \approx 0.7$

**调试checklist**：
- [ ] 验证损失单调下降
- [ ] 检查梯度范数是否有界
- [ ] 在验证集上评估ECE
- [ ] 绘制可靠性图
- [ ] 与baseline（$\gamma=0$）对比

---

## 参考文献

1. Müller et al., "When Does Label Smoothing Help?", NeurIPS 2019
2. Guo et al., "On Calibration of Modern Neural Networks", ICML 2017
3. Zhang & Sabuncu, "Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels", NeurIPS 2018
4. Pereyra et al., "Regularizing Neural Networks by Penalizing Confident Output Distributions", ICLR 2017
5. Szegedy et al., "Rethinking the Inception Architecture for Computer Vision", CVPR 2016

## 总结

本文深入分析了γ-交叉熵损失函数，关键洞察包括：

1. **梯度视角**：γ-CE在交叉熵和准确率的梯度之间插值
2. **正则化**：等价于添加隐式正则项，防止过度自信
3. **校准性**：改善模型的概率校准，降低ECE
4. **鲁棒性**：梯度和Hessian有界，对噪声标签更鲁棒
5. **灵活性**：超参数$\gamma$可根据任务和数据质量调整

γ-交叉熵是一个简洁而强大的工具，在实践中值得尝试！

