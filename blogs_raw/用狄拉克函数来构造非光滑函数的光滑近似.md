---
title: 用狄拉克函数来构造非光滑函数的光滑近似
slug: 用狄拉克函数来构造非光滑函数的光滑近似
date: 2021-10-10
tags: 函数, 近似, 分析, 光滑, 生成模型, 狄拉克函数, 卷积, 激活函数
status: completed
tags_reviewed: true
---

# 用狄拉克函数来构造非光滑函数的光滑近似

**原文链接**: [https://spaces.ac.cn/archives/8718](https://spaces.ac.cn/archives/8718)

**发布日期**: 2021-10-10

---

<div class="theorem-box">

### 核心思想

通过狄拉克函数的光滑近似与目标函数卷积，可以系统性地构造**任意非光滑函数的光滑近似**。这种方法：

- ✅ **通用性强**：适用于有可数个间断点的函数
- ✅ **理论保证**：基于狄拉克函数的筛选性质（sifting property）
- ✅ **可调节性**：通过参数控制近似精度
- ✅ **实用性高**：可推导出所有常见激活函数的光滑版本

</div>

---

## 一、问题的提出

在机器学习中，我们经常会碰到不光滑的函数，但我们的优化方法通常是基于梯度的，这意味着光滑的模型可能更利于优化（梯度是连续的），所以就有了寻找非光滑函数的光滑近似的需求。

### 已有方法的局限性

本博客已经多次讨论过相关主题，比如《寻求一个光滑的最大值函数》、《函数光滑化杂谈：不可导函数的可导逼近》等，但以往的讨论在方法上并没有什么**通用性**。

### 新的通用框架

笔者从论文 [《SAU: Smooth activation function using convolution with approximate identities》](https://papers.cool/arxiv/2109.13210) 学习到了一种比较通用的思路：**用狄拉克函数来构造光滑近似**。

<div class="intuition-box">

### 🧠 为什么这个方法通用？

**核心机制**：狄拉克函数在卷积中起到"筛选"作用：
$$\int_{-\infty}^{\infty} f(y)\delta(x-y) dy = f(x)$$

如果用光滑函数 $\varphi(x) \approx \delta(x)$ 替代：
$$g(x) = \int_{-\infty}^{\infty} f(y)\varphi(x-y) dy \approx f(x)$$

则 $g(x)$ 自动继承 $\varphi(x)$ 的光滑性！

</div>

---

## 二、狄拉克函数的理论基础

在很早之前的文章《诡异的Dirac函数》中，我们就介绍过狄拉克函数了。在现代数学中，狄拉克函数被定义为一个"泛函"而不是"函数"，但对于大多数读者来说，将它当作函数来理解是比较容易接受的。

### 2.1 定义与性质

<div class="theorem-box">

### 狄拉克函数的三个定义条件

$$
\delta(x) = \begin{cases}
0, & x \neq 0 \\
\infty, & x = 0
\end{cases}
\tag{1}
$$

且满足归一化条件：

$$
\int_{-\infty}^{\infty} \delta(x) \, dx = 1
\tag{2}
$$

</div>

<div class="derivation-box">

### 筛选性质（Sifting Property）

狄拉克函数最重要的性质是它的**筛选能力**：

<div class="formula-explanation">

<div class="formula-step">
<div class="step-label">性质1：在原点筛选</div>

$$
\int_{-\infty}^{\infty} f(x)\delta(x) \, dx = f(0)
\tag{3}
$$

<div class="step-explanation">

**直观理解**：由于 $\delta(x)$ 仅在 $x=0$ 处非零，积分只"看到"$f(0)$ 的值。

**形式化证明**：
$$
\begin{aligned}
\int_{-\infty}^{\infty} f(x)\delta(x) \, dx
&= \lim_{\epsilon \to 0} \int_{-\epsilon}^{\epsilon} f(x)\delta(x) \, dx \\
&= \lim_{\epsilon \to 0} f(\xi) \cdot \underbrace{\int_{-\epsilon}^{\epsilon} \delta(x) \, dx}_{=1} \\
&= f(0)
\end{aligned}
$$

其中用到了积分中值定理。

</div>
</div>

<div class="formula-step">
<div class="step-label">性质2：在任意点筛选（平移不变性）</div>

$$
\int_{-\infty}^{\infty} f(y)\delta(x-y) \, dy = f(x)
\tag{4}
$$

<div class="step-explanation">

**推导**：令 $t = x - y$，则 $dt = -dy$：
$$
\begin{aligned}
\int_{-\infty}^{\infty} f(y)\delta(x-y) \, dy
&= \int_{\infty}^{-\infty} f(x-t)\delta(t) \, (-dt) \\
&= \int_{-\infty}^{\infty} f(x-t)\delta(t) \, dt \\
&\stackrel{\text{(3)}}{=} f(x-0) = f(x)
\end{aligned}
$$

**意义**：这是恒等卷积，$\delta(x)$ 是卷积的**单位元**。

</div>
</div>

</div>

</div>

### 2.2 概率论视角

<div class="intuition-box">

### 🎲 从概率分布理解狄拉克函数

直观来看，$\delta(x)$ 可以看成一个连续型的概率密度函数：

- **支撑集**：全体实数 $\mathbb{R}$
- **非零点**：仅在 $x=0$ 处
- **统计性质**：均值为0、方差也为0

**采样性质**：从 $\delta(x)$ 中采样**必然**只能采样到0，这正是筛选性质的概率解释。

**数学形式化**：设 $X \sim \delta(x)$，则对任意可测函数 $f$：
$$
\mathbb{E}[f(X)] = \int_{-\infty}^{\infty} f(x)\delta(x) \, dx = f(0)
$$

</div>

---

## 三、构造光滑近似的通用方法

### 3.1 核心策略

如果我们能找到 $\delta(x)$ 的一个光滑近似 $\varphi(x) \approx \delta(x)$，那么根据公式 (4)，我们就有：

$$
g(x) = \int_{-\infty}^{\infty} f(y)\varphi(x-y) \, dy \approx f(x)
\tag{5}
$$

<div class="theorem-box">

### 光滑近似的继承性定理

**定理**：若 $\varphi(x)$ 是 $C^k$ 类光滑函数（$k$ 阶连续可导），则卷积 $g(x)$ 也是 $C^k$ 类光滑函数。

**证明**：利用求导与积分可交换顺序：
$$
\frac{d^n g}{dx^n} = \frac{d^n}{dx^n} \int_{-\infty}^{\infty} f(y)\varphi(x-y) \, dy
= \int_{-\infty}^{\infty} f(y) \frac{\partial^n \varphi}{\partial x^n}(x-y) \, dy
$$

由于 $\varphi \in C^k$，所以 $\frac{\partial^n \varphi}{\partial x^n}$ 连续（$n \leq k$），从而 $g \in C^k$。

</div>

<div class="note-box">

**关键洞察**：这个方法对 $f(x)$ 的要求**极其宽松**：
- ✅ 允许有**可数个间断点**（如取整函数 $\lfloor x \rfloor$）
- ✅ 允许有**尖点**（如 $|x|$、$\max(x,0)$）
- ✅ 允许是**分段定义**的函数
- ✅ 只需在积分意义下有定义即可

</div>

### 3.2 常用的狄拉克近似

<div class="derivation-box">

### 方法1：高斯近似（最常用）

<div class="formula-explanation">

<div class="formula-step">
<div class="step-label">极限定义</div>

$$
\delta(x) = \lim_{\sigma\to 0} \frac{1}{\sqrt{2\pi}\sigma} e^{-x^2/(2\sigma^2)}
\tag{6}
$$

<div class="step-explanation">

**验证归一化**：
$$
\int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi}\sigma} e^{-x^2/(2\sigma^2)} \, dx = 1 \quad \forall \sigma > 0
$$

**极限行为**：
- 当 $\sigma \to 0$ 时，峰值 $\frac{1}{\sqrt{2\pi}\sigma} \to \infty$
- 宽度（标准差）$\sigma \to 0$
- 积分保持为1 → 形成狄拉克函数

**光滑性**：高斯函数是 $C^\infty$ 类（无穷次可微）

</div>
</div>

<div class="formula-step">
<div class="step-label">优点</div>

- ✅ 无穷次可微
- ✅ 计算友好（指数函数）
- ✅ 傅里叶变换仍是高斯（自对偶性）
- ✅ 中心极限定理的自然出现

</div>

</div>

</div>

<div class="derivation-box">

### 方法2：Cauchy近似

<div class="formula-explanation">

<div class="formula-step">
<div class="step-label">极限定义</div>

$$
\delta(x) = \frac{1}{\pi} \lim_{a \to 0}\frac{a}{x^2+a^2}
\tag{7}
$$

<div class="step-explanation">

**验证**：
$$
\int_{-\infty}^{\infty} \frac{a}{\pi(x^2+a^2)} \, dx
= \frac{1}{\pi} \left[\arctan\left(\frac{x}{a}\right)\right]_{-\infty}^{\infty}
= \frac{1}{\pi} \cdot \pi = 1
$$

**特点**：
- 重尾分布（衰减慢于高斯）
- 在复分析中有特殊意义（Cauchy主值）

</div>
</div>

</div>

</div>

<div class="derivation-box">

### 方法3：Sigmoid导数近似

<div class="formula-explanation">

<div class="formula-step">
<div class="step-label">从阶跃函数出发</div>

留意到：
$$
\int_{-\infty}^x \delta(t)\,dt = \theta(x) = \begin{cases}
1, & x > 0 \\
0, & x < 0
\end{cases}
\tag{8}
$$

也就是说，狄拉克函数的积分是**单位阶跃函数** $\theta(x)$。

</div>

<div class="formula-step">
<div class="step-label">光滑近似</div>

$\theta(x)$ 的光滑近似就是S形曲线，比如sigmoid函数：
$$
\sigma(x) = \frac{1}{1+e^{-x}}
$$

因此：
$$
\delta(x) = \lim_{t\to \infty} \frac{d}{dx}\sigma(tx) = \lim_{t\to \infty} \frac{e^{tx} \cdot t}{(1+e^{tx})^2}
\tag{9}
$$

<div class="step-explanation">

**推导细节**：
$$
\frac{d}{dx}\sigma(tx) = \sigma(tx) \cdot (1-\sigma(tx)) \cdot t
= \frac{1}{1+e^{-tx}} \cdot \frac{e^{-tx}}{1+e^{-tx}} \cdot t
= \frac{t e^{tx}}{(1+e^{tx})^2}
$$

**参数 $t$ 的作用**：控制陡峭程度
- $t$ 越大，$\sigma(tx)$ 越接近阶跃函数
- $t \to \infty$ 时，导数趋近狄拉克函数

</div>
</div>

</div>

</div>

### 3.3 三种近似的对比

<details>
<summary><strong>📊 点击查看：不同近似方法的性能对比</strong></summary>
<div markdown="1">

| 方法 | 公式 | 光滑度 | 计算复杂度 | 尾部衰减 | 适用场景 |
|------|------|--------|-----------|---------|---------|
| **高斯** | $\frac{1}{\sqrt{2\pi}\sigma} e^{-x^2/(2\sigma^2)}$ | $C^\infty$ | 中等（exp） | 超快（$e^{-x^2}$） | 通用，尤其概率/信号处理 |
| **Cauchy** | $\frac{a}{\pi(x^2+a^2)}$ | $C^\infty$ | 低（代数） | 慢（$1/x^2$） | 需要重尾性质 |
| **Sigmoid导数** | $\frac{t e^{tx}}{(1+e^{tx})^2}$ | $C^\infty$ | 高（exp×2） | 中等（$e^{-\|x\|}$） | 机器学习中的激活函数 |

<div class="note-box">

**选择建议**：
- **默认选择**：高斯近似（最常用，性质最好）
- **需要重尾**：Cauchy近似
- **激活函数设计**：Sigmoid导数近似（与神经网络架构一致）

</div>

</div>
</details>

---

## 四、应用实例：ReLU激活函数的光滑近似

现在，我们就以上述思路为工具，推导ReLU激活函数 $\max(x,0)$ 的各种光滑近似。

### 4.1 方法1：直接卷积法（Sigmoid核）

<div class="derivation-box">

### 推导SoftPlus激活函数

<div class="formula-explanation">

<div class="formula-step">
<div class="step-label">步骤1：应用卷积公式</div>

利用公式 (9)（Sigmoid导数近似）：
$$
\begin{aligned}
\max(x,0)
&\approx \int_{-\infty}^{\infty} \frac{e^{t(x-y)}t}{(1+e^{t(x-y)})^2} \max(y,0) \, dy \\
&= \int_0^{\infty} \frac{e^{t(x-y)}ty}{(1+e^{t(x-y)})^2} \, dy
\end{aligned}
\tag{10}
$$

<div class="step-explanation">

**化简理由**：
- $\max(y,0)$ 在 $y < 0$ 时为0，所以积分下限改为0
- 在 $y > 0$ 时，$\max(y,0) = y$

</div>
</div>

<div class="formula-step">
<div class="step-label">步骤2：变量代换</div>

令 $u = t(x-y)$，则 $du = -t \, dy$：
$$
\begin{aligned}
\int_0^{\infty} \frac{e^{t(x-y)}ty}{(1+e^{t(x-y)})^2} \, dy
&= \int_{tx}^{-\infty} \frac{e^u (x - u/t)}{(1+e^u)^2} \, \left(-\frac{du}{t}\right) \\
&= \int_{-\infty}^{tx} \frac{e^u (x - u/t)}{t(1+e^u)^2} \, du
\end{aligned}
$$

</div>

<div class="formula-step">
<div class="step-label">步骤3：计算积分（技巧）</div>

注意到：
$$
\frac{d}{du}\left[\frac{1}{1+e^{-u}}\right] = \frac{e^{-u}}{(1+e^{-u})^2} = \frac{e^u}{(1+e^u)^2}
$$

因此：
$$
\int_{-\infty}^{tx} \frac{e^u}{(1+e^u)^2} \, du
= \left[\frac{1}{1+e^{-u}}\right]_{-\infty}^{tx}
= \frac{1}{1+e^{-tx}}
$$

**完整计算**（详细版，这里省略繁琐步骤）后得到：

$$
\boxed{\max(x,0) \approx \frac{\log(1+e^{tx})}{t}}
\tag{11}
$$

</div>

<div class="formula-step">
<div class="step-label">特例：SoftPlus</div>

当 $t=1$ 时：
$$
\text{SoftPlus}(x) = \log(1+e^x)
$$

**性质验证**：
- $x \to \infty$：$\log(1+e^x) \approx \log(e^x) = x$ ✓
- $x \to -\infty$：$\log(1+e^x) \approx \log(1) = 0$ ✓
- 导数：$\frac{d}{dx}\log(1+e^x) = \frac{e^x}{1+e^x} = \sigma(x)$（Sigmoid）

</div>

</div>

</div>

### 4.2 方法2：直接卷积法（高斯核）

<div class="derivation-box">

### 推导基于误差函数的光滑ReLU

<div class="formula-explanation">

<div class="formula-step">
<div class="step-label">步骤1：应用高斯卷积</div>

利用公式 (6)（高斯近似）：
$$
\begin{aligned}
\max(x,0)
&\approx \int_{-\infty}^{\infty} \frac{e^{-(x-y)^2/(2\sigma^2)}}{\sqrt{2\pi}\sigma} \max(y,0) \, dy \\
&= \int_0^{\infty} \frac{e^{-(x-y)^2/(2\sigma^2)} y}{\sqrt{2\pi}\sigma} \, dy
\end{aligned}
\tag{12}
$$

</div>

<div class="formula-step">
<div class="step-label">步骤2：计算积分（使用误差函数）</div>

经过复杂的积分计算（涉及分部积分和误差函数的定义），得到：

$$
\boxed{\max(x,0) \approx \frac{1}{2} \left[x \,\text{erf}\left(\frac{x}{\sqrt{2} \sigma}\right)+x+\sqrt{\frac{2}{\pi }} \sigma e^{-\frac{x^2}{2 \sigma^2}}\right]}
\tag{13}
$$

其中 $\text{erf}(z) = \frac{2}{\sqrt{\pi}}\int_0^z e^{-t^2} dt$ 是**误差函数**。

<div class="step-explanation">

**积分技巧概述**：
1. 分解为两部分：$\int_0^\infty y \cdot \varphi(x-y) dy = x \int_0^\infty \varphi(x-y) dy + \int_0^\infty (y-x) \varphi(x-y) dy$
2. 第一部分：用误差函数的定义
3. 第二部分：利用高斯函数的对称性和积分性质

</div>
</div>

<div class="formula-step">
<div class="step-label">新颖性</div>

这个ReLU的光滑近似貌似还没被研究过，具有以下特点：
- 基于高斯核，衰减更快
- 涉及特殊函数（erf），计算稍复杂
- 在某些情况下可能比SoftPlus更光滑

</div>

</div>

</div>

### 4.3 方法3：分解法（阶跃函数近似）

当然，如果仅仅是ReLU函数的光滑近似，那么还有更简单的思路。

<div class="derivation-box">

### 利用分解：$\max(x,0) = x \cdot \theta(x)$

<div class="formula-explanation">

<div class="formula-step">
<div class="step-label">分解策略</div>

注意到：
$$
\max(x,0) = x \cdot \theta(x)
$$

其中 $\theta(x)$ 是单位阶跃函数。因此，问题转化为：找到 $\theta(x)$ 的光滑近似。

</div>

<div class="formula-step">
<div class="step-label">Sigmoid近似 → Swish</div>

Sigmoid是 $\theta(x)$ 的经典光滑近似：
$$
\max(x,0) \approx x \cdot \sigma(tx) = x \cdot \frac{1}{1+e^{-tx}}
\tag{14}
$$

当 $t=1$ 时，这就是**Swish激活函数**（也称SiLU）：
$$
\text{Swish}(x) = x \cdot \sigma(x) = \frac{x}{1+e^{-x}}
$$

**性质**：
- 自门控（self-gated）结构
- 在Google的搜索中表现优于ReLU
- 导数：$\text{Swish}'(x) = \sigma(x) + x\sigma(x)(1-\sigma(x))$

</div>

<div class="formula-step">
<div class="step-label">高斯近似 → GELU</div>

如果用高斯核的积分（即标准正态分布的CDF）：
$$
\begin{aligned}
\max(x,0)
&\approx x \int_{-\infty}^{\infty} \frac{e^{-(x-y)^2/(2\sigma^2)}}{\sqrt{2\pi}\sigma} \theta(y) \, dy \\
&= x \int_0^{\infty} \frac{e^{-(x-y)^2/(2\sigma^2)}}{\sqrt{2\pi}\sigma} \, dy \\
&= \frac{1}{2}\left[x + x\,\text{erf}\left(\frac{x}{\sqrt{2}\sigma}\right)\right]
\end{aligned}
\tag{15}
$$

当 $\sigma=1$ 时，就是**GELU激活函数**：
$$
\text{GELU}(x) = \frac{x}{2}\left[1 + \text{erf}\left(\frac{x}{\sqrt{2}}\right)\right]
= x \cdot \Phi(x)
$$

其中 $\Phi(x)$ 是标准正态分布的CDF。

**直观解释**：输入 $x$ 乘以它在标准正态分布下的累积概率。

</div>

</div>

</div>

### 4.4 可视化对比

下图展示了ReLU函数及其几个光滑近似的图像：

<div class="note-box">

**图像说明**（参考原文图）：

- **ReLU**：在 $x=0$ 处有尖点
- **SoftPlus** ($t=1$)：最平滑的近似之一
- **Swish** ($t=1$)：自门控结构，有微小下凹
- **GELU** ($\sigma=1$)：介于SoftPlus和Swish之间

**参数调节效果**：
- SoftPlus和Swish中的 $t$ 越大，越接近ReLU
- GELU中的 $\sigma$ 越小，越接近ReLU

</div>

---

## 五、挑战性实例：取整函数的光滑近似

可能读者觉得还不够意思，毕竟上面推导出来的都是现成的东西，而且不借助狄拉克函数也能推导出来。现在我们就来补充一个**不怎么平凡**的例子：取整函数的光滑近似。

### 5.1 取整函数的定义

取整函数分上取整和下取整两种，它们定义上有所不同，但是没有本质区别。这里以**下取整**为例，记为：

$$
\lfloor x \rfloor = n, \quad \text{当且仅当存在} \, n\in\mathbb{Z} \, \text{使得} \, x\in[n, n + 1)
\tag{16}
$$

<div class="intuition-box">

### 🧠 取整函数的挑战

取整函数 $\lfloor x \rfloor$ 有**可数无穷多个间断点**（每个整数点）！

传统方法很难处理这种情况，但狄拉克卷积方法能够**系统性地解决**。

</div>

### 5.2 推导过程

<div class="derivation-box">

### 取整函数的光滑近似推导

<div class="formula-explanation">

<div class="formula-step">
<div class="step-label">步骤1：应用卷积公式</div>

假设 $\varphi(x)$ 为狄拉克函数的某个光滑近似，那么：
$$
\lfloor x \rfloor \approx \int_{-\infty}^{\infty} \varphi(x-y)\lfloor y \rfloor \, dy
= \sum_{n=-\infty}^{\infty}n\int_n^{n+1} \varphi(x-y) \, dy
\tag{17}
$$

<div class="step-explanation">

**分解理由**：
- 将实数轴分解为 $[n, n+1)$ 的并集
- 在每个区间上，$\lfloor y \rfloor = n$（常数）
- 将积分转化为级数

</div>
</div>

<div class="formula-step">
<div class="step-label">步骤2：引入原函数</div>

设 $\varphi(x)$ 的原函数为 $\Phi(x)$，即 $\Phi'(x) = \varphi(x)$。

则 $\varphi(x-y)$ 关于 $y$ 的原函数是 $-\Phi(x-y)$（链式法则），于是：
$$
\int_n^{n+1} \varphi(x-y) \, dy = -\Phi(x-y) \Big|_{y=n}^{y=n+1}
= \Phi(x-n) - \Phi(x-n-1)
$$

代入公式 (17)：
$$
\lfloor x \rfloor \approx \sum_{n=-\infty}^{\infty}n\big[\Phi(x-n) - \Phi(x-n-1)\big]
\tag{18}
$$

</div>

<div class="formula-step">
<div class="step-label">步骤3：Abel求和变换</div>

使用Abel求和公式：$\sum a_n b_n = \sum (a_n - a_{n+1}) B_n + a_N B_N - a_{-M} B_{-M}$

设 $a_n = n$，$b_n = \Phi(x-n) - \Phi(x-n-1)$，则：
$$
\begin{aligned}
\sum_{n=-M}^{N}n\big[\Phi(x-n) - \Phi(x-n-1)\big]
&= \sum_{n=-M}^{N}(n-1-n)\Phi(x-n-1) \\
&\quad + N\Phi(x-N-1) + (M+1)\Phi(x+M) + \sum_{n=-M}^{N} \Phi(x-n)
\end{aligned}
$$

化简（利用 $n-1-n = -1$）：
$$
= -\sum_{n=-M}^{N}\Phi(x-n-1) + N\Phi(x-N-1) + (M+1)\Phi(x+M) + \sum_{n=-M}^{N} \Phi(x-n)
$$

</div>

<div class="formula-step">
<div class="step-label">步骤4：取极限</div>

对于 $\Phi(x)$（作为Sigmoid或高斯积分），我们有：
$$
\Phi(-\infty)=0, \quad \Phi(\infty)=1
$$

假设我们关心的范围满足 $-M\ll x \ll N$（即 $M, N$ 足够大），那么：
- $\Phi(x-N-1) \approx 0$（$x-N-1 \to -\infty$）
- $\Phi(x+M) \approx 1$（$x+M \to +\infty$）

因此：
$$
\lfloor x \rfloor \approx -M-1 + \sum_{n=-M}^{N} \Phi(x-n)
\tag{19}
$$

进一步整理：
$$
\boxed{\lfloor x \rfloor \approx \sum_{n=-M}^0 \big[\Phi(x-n)-1\big] + \sum_{n=1}^N \Phi(x-n)}
\tag{20}
$$

</div>

<div class="formula-step">
<div class="step-label">特例：Sigmoid原函数</div>

使用 $\Phi(x)=\sigma(tx) = \frac{1}{1+e^{-tx}}$，取 $t=10, M=5, N=10$：

$$
\lfloor x \rfloor \approx \sum_{n=-5}^0 \left[\frac{1}{1+e^{-10(x-n)}}-1\right] + \sum_{n=1}^{10} \frac{1}{1+e^{-10(x-n)}}
$$

**数值效果**（见原文图）：
- 在 $x \in [-5, 10]$ 范围内近似非常好
- 增大 $t$ 能进一步提高近似程度（但在间断点附近振荡增加）

</div>

</div>

</div>

### 5.3 代码实现

<details>
<summary><strong>💻 点击查看：Python实现代码</strong></summary>
<div markdown="1">

```python
import numpy as np
import matplotlib.pyplot as plt

def sigmoid(x, t=1):
    """Sigmoid函数"""
    return 1 / (1 + np.exp(-t * x))

def smooth_floor(x, t=10, M=5, N=10):
    """取整函数的光滑近似

    参数:
        x: 输入值（可以是数组）
        t: 陡峭度参数（越大越接近真实取整函数）
        M: 左边界（负方向的求和范围）
        N: 右边界（正方向的求和范围）

    返回:
        光滑近似的取整值
    """
    result = np.zeros_like(x, dtype=float)

    # 负部分：sum_{n=-M}^{0} [Phi(x-n) - 1]
    for n in range(-M, 1):
        result += sigmoid(x - n, t) - 1

    # 正部分：sum_{n=1}^{N} Phi(x-n)
    for n in range(1, N+1):
        result += sigmoid(x - n, t)

    return result

# 可视化
x = np.linspace(-3, 8, 1000)
y_true = np.floor(x)
y_smooth_t5 = smooth_floor(x, t=5)
y_smooth_t10 = smooth_floor(x, t=10)
y_smooth_t20 = smooth_floor(x, t=20)

plt.figure(figsize=(12, 6))
plt.plot(x, y_true, 'k-', linewidth=2, label='True floor(x)', alpha=0.7)
plt.plot(x, y_smooth_t5, 'b--', label='t=5', alpha=0.8)
plt.plot(x, y_smooth_t10, 'r--', label='t=10', alpha=0.8)
plt.plot(x, y_smooth_t20, 'g--', label='t=20', alpha=0.8)
plt.xlabel('x', fontsize=14)
plt.ylabel('floor(x)', fontsize=14)
plt.title('Smooth Approximation of Floor Function', fontsize=16)
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3)
plt.show()
```

**超参数调节建议**：
- **$t$ (陡峭度)**：
  - 小值（$t=1\sim 5$）：非常光滑，但偏差较大
  - 中值（$t=10\sim 20$）：平衡光滑性和准确性（推荐）
  - 大值（$t>50$）：接近真实函数，但在间断点附近可能振荡（Gibbs现象）

- **$M, N$ (求和范围)**：
  - 覆盖你关心的 $x$ 范围即可
  - 例如：若 $x \in [-3, 8]$，则 $M \geq 3, N \geq 8$

</div>
</details>

---

## 六、理论深化：多角度分析

### 6.1 信息论视角

<div class="intuition-box">

### 📡 卷积作为信息传递

**狄拉克卷积**：完美信息传递（无失真）
$$
g(x) = (f * \delta)(x) = f(x)
$$

**近似卷积**：有限带宽通信
$$
g(x) = (f * \varphi_\epsilon)(x) \approx f(x)
$$

其中 $\varphi_\epsilon$ 是带宽为 $1/\epsilon$ 的核。

**熵的视角**：
- 原函数 $f$ 的信息熵：$H(f)$
- 卷积后 $g$ 的信息熵：$H(g) \geq H(f)$（光滑化增加了不确定性）
- $\epsilon \to 0$ 时，$H(g) \to H(f)$

</div>

### 6.2 傅里叶分析视角

<div class="theorem-box">

### 频域解释

**卷积定理**：
$$
\mathcal{F}[f * \varphi] = \mathcal{F}[f] \cdot \mathcal{F}[\varphi]
$$

**狄拉克函数的傅里叶变换**：
$$
\mathcal{F}[\delta(x)] = 1 \quad (\text{所有频率分量都保留})
$$

**高斯近似的傅里叶变换**：
$$
\mathcal{F}\left[\frac{1}{\sqrt{2\pi}\sigma}e^{-x^2/(2\sigma^2)}\right] = e^{-\omega^2 \sigma^2/2}
$$

**物理意义**：
- 高斯卷积相当于低通滤波器
- $\sigma$ 越小，截止频率越高，保留更多高频（细节）
- $\sigma \to 0$ 时，变为全通滤波器（即狄拉克函数）

</div>

### 6.3 优化理论视角

<div class="derivation-box">

### 光滑化作为正则化

<div class="formula-explanation">

<div class="formula-step">
<div class="step-label">Moreau包络（Moreau Envelope）</div>

对于非光滑函数 $f(x)$，其Moreau包络定义为：
$$
f_\lambda(x) = \inf_y \left\{ f(y) + \frac{1}{2\lambda}\|x-y\|^2 \right\}
\tag{21}
$$

**性质**：
- $f_\lambda$ 是光滑的（即使 $f$ 不光滑）
- $\lambda \to 0$ 时，$f_\lambda \to f$
- 梯度：$\nabla f_\lambda(x) = \frac{1}{\lambda}(x - \text{prox}_{\lambda f}(x))$

<div class="step-explanation">

**与狄拉克卷积的联系**：

当 $f$ 是凸函数时，Moreau包络可以表示为：
$$
f_\lambda(x) = (f * \varphi_\lambda)(x)
$$

其中 $\varphi_\lambda$ 是适当的光滑核。

</div>
</div>

<div class="formula-step">
<div class="step-label">在梯度下降中的应用</div>

用 $f_\lambda$ 替代 $f$ 进行优化：
$$
x_{k+1} = x_k - \alpha \nabla f_\lambda(x_k)
$$

**好处**：
- 梯度连续，收敛性更好
- 避免在尖点处的振荡
- 可以证明：在适当条件下，$x_k \to x^*$（原问题的最优解）

</div>

</div>

</div>

### 6.4 几何视角

<div class="intuition-box">

### 📐 从流形到光滑流形

**原函数 $f$**：可能是分段线性的，对应一个"折叠"的流形

**光滑化 $g = f * \varphi_\epsilon$**：将流形"熨平"

**几何测度**：
- **曲率**：光滑化减小了曲率的极值
- **测地距离**：在光滑流形上更容易计算
- **法向量**：光滑后法向量连续变化

**应用**：在神经网络中，光滑的损失函数对应更"友好"的优化landscape。

</div>

---

## 七、数值稳定性分析

<div class="note-box">

### ⚠️ 实现时的注意事项

**1. 指数函数的上溢/下溢**

在计算 $e^{tx}$ 时（如SoftPlus），需要注意：
- 当 $tx > 100$ 时，$e^{tx}$ 上溢
- 当 $tx < -100$ 时，$e^{tx}$ 下溢（但通常可以忽略）

**解决方案**：利用对数空间计算
```python
import numpy as np

def softplus_stable(x, t=1):
    """数值稳定的SoftPlus"""
    tx = t * x
    # 利用：log(1 + exp(tx)) = max(0, tx) + log(1 + exp(-abs(tx)))
    return np.maximum(0, tx) + np.log1p(np.exp(-np.abs(tx)))
```

**2. 误差函数的精度**

`scipy.special.erf` 在 $|x| > 6$ 时精度下降，使用渐近展开：
$$
\text{erf}(x) \approx \text{sign}(x) \left[1 - \frac{e^{-x^2}}{\sqrt{\pi}|x|}\left(1 - \frac{1}{2x^2} + \cdots\right)\right]
$$

**3. 无穷级数的截断误差**

在取整函数的光滑近似中，级数 $\sum_{n=-M}^{N}$ 需要截断。

**误差估计**：
$$
\left|\lfloor x \rfloor - \sum_{n=-M}^{N} \cdots \right| \leq C \cdot e^{-t \min(x+M, N-x)}
$$

其中 $C$ 是常数，$t$ 是Sigmoid的陡峭度参数。

**建议**：取 $M, N$ 使得 $e^{-t \min(x+M, N-x)} < 10^{-10}$。

</div>

---

## 八、扩展应用

### 8.1 其他常见函数的光滑近似

<details>
<summary><strong>🔧 点击查看：更多光滑近似公式</strong></summary>
<div markdown="1">

**1. 绝对值函数 $|x|$**

分解：$|x| = x \cdot \text{sign}(x)$

光滑近似（使用 $\tanh$）：
$$
|x| \approx x \cdot \tanh(tx)
\quad \text{或} \quad
|x| \approx \sqrt{x^2 + \epsilon^2}
$$

**2. 最大值函数 $\max(x_1, x_2, \ldots, x_n)$**

LogSumExp近似：
$$
\max_i x_i \approx \frac{1}{t}\log\left(\sum_{i=1}^n e^{t x_i}\right)
$$

**3. 符号函数 $\text{sign}(x)$**

$$
\text{sign}(x) \approx \tanh(tx)
$$

**4. 示性函数 $\mathbb{1}_{x \in A}$**

若 $A = [a, b]$：
$$
\mathbb{1}_{[a,b]}(x) \approx \sigma(t(x-a)) - \sigma(t(x-b))
$$

</div>
</details>

### 8.2 在机器学习中的应用

<div class="example-box">

### 实际应用案例

**1. 可微分的排序/选择**

传统排序不可微，但可以用SoftMax近似：
$$
\text{argsort}(x) \approx \text{softmax}(tx)
$$

**2. 可微分的离散决策**

在强化学习中，离散动作选择可以用Gumbel-Softmax技巧：
$$
a \sim \text{Categorical}(p) \quad \Rightarrow \quad a \approx \text{softmax}((p + g) / \tau)
$$

其中 $g$ 是Gumbel噪声，$\tau$ 是温度参数。

**3. 神经架构搜索（NAS）**

离散的架构选择可以通过光滑化变成连续优化问题。

**4. 约束优化**

硬约束 $f(x) \leq 0$ 可以用光滑惩罚项代替：
$$
\text{penalty}(x) = \max(0, f(x))^2 \approx \text{SoftPlus}(f(x))^2
$$

</div>

---

## 九、总结与展望

<div class="note-box">

### 核心要点回顾

**理论贡献**：
1. ✅ 建立了基于狄拉克函数的**通用光滑化框架**
2. ✅ 适用于有可数间断点的函数（甚至广义函数）
3. ✅ 提供了明确的误差控制机制（通过核函数的参数）

**实践价值**：
1. ✅ 统一解释了SoftPlus、Swish、GELU等激活函数的来源
2. ✅ 提供了设计新激活函数的系统方法
3. ✅ 可应用于优化、信号处理、数值分析等多个领域

**关键技巧**：
- **卷积公式**：$g(x) = (f * \varphi)(x)$
- **核函数选择**：高斯核（通用）、Sigmoid核（机器学习）、Cauchy核（重尾）
- **参数调节**：平衡光滑性与近似精度

</div>

### 未来研究方向

<div class="intuition-box">

### 🔬 开放问题

**1. 最优核函数设计**

对于特定的函数类（如单调函数、凸函数），是否存在"最优"的光滑化核？

**标准**：
- 最小化 $L^2$ 误差 $\|f - f * \varphi_\epsilon\|_2$
- 保持某些性质（单调性、凸性）
- 计算复杂度最低

**2. 高维推广**

本文主要讨论一维函数，如何推广到 $\mathbb{R}^d$？

**挑战**：
- 高维狄拉克函数：$\delta(\mathbf{x}) = \prod_{i=1}^d \delta(x_i)$
- 各向异性的光滑化（不同维度不同的 $\sigma_i$）
- 计算复杂度：$O(d)$ vs $O(2^d)$

**3. 自适应光滑化**

能否根据函数的局部性质自动调整 $\sigma(x)$？
- 在间断点附近：较大的 $\sigma$（更光滑）
- 在光滑区域：较小的 $\sigma$（更精确）

</div>

---

## 参考文献

1. SAU: Smooth activation function using convolution with approximate identities. arXiv:2109.13210
2. Goodfellow et al. (2016). Deep Learning. MIT Press.
3. Rudin, W. (1991). Functional Analysis. McGraw-Hill.
4. Stein, E. M., & Shakarchi, R. (2011). Functional Analysis: Introduction to Further Topics in Analysis.

---

**相关文章**：
- [寻求一个光滑的最大值函数](https://spaces.ac.cn/archives/3290)
- [函数光滑化杂谈：不可导函数的可导逼近](https://spaces.ac.cn/archives/6620)
- [SquarePlus：可能是运算最简单的ReLU光滑近似](squareplus可能是运算最简单的relu光滑近似.html)

---

_**转载到请包括本文地址：**<https://spaces.ac.cn/archives/8718>_

_**更详细的转载事宜请参考：**_[《科学空间FAQ》](https://spaces.ac.cn/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8 "《科学空间FAQ》")

**如果您需要引用本文，请参考：**

苏剑林. (Oct. 10, 2021). 《用狄拉克函数来构造非光滑函数的光滑近似 》[Blog post]. Retrieved from <https://spaces.ac.cn/archives/8718>

@online{kexuefm-8718,
title={用狄拉克函数来构造非光滑函数的光滑近似},
author={苏剑林},
year={2021},
month={Oct},
url={\url{https://spaces.ac.cn/archives/8718}},
}
