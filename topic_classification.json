{
  "随机矩阵/概率": [
    {
      "title": "CAN：借助先验分布提升分类性能的简单后处理技巧",
      "slug": "can借助先验分布提升分类性能的简单后处理技巧",
      "number": 6
    },
    {
      "title": "变分自编码器（八）：估计样本概率密度",
      "slug": "变分自编码器八估计样本概率密度",
      "number": 13
    },
    {
      "title": "概率分布的熵归一化（Entropy Normalization）",
      "slug": "概率分布的熵归一化entropy-normalization",
      "number": 17
    },
    {
      "title": "从重参数的角度看离散概率分布的构建",
      "slug": "从重参数的角度看离散概率分布的构建",
      "number": 43
    },
    {
      "title": "圆内随机n点在同一个圆心角为θ的扇形的概率",
      "slug": "圆内随机n点在同一个圆心角为θ的扇形的概率",
      "number": 63
    },
    {
      "title": "随机分词浅探：从Viterbi Decoding到Viterbi Sampling",
      "slug": "随机分词浅探从viterbi-decoding到viterbi-sampling",
      "number": 109
    },
    {
      "title": "随机分词再探：从Viterbi Sampling到完美采样算法",
      "slug": "随机分词再探从viterbi-sampling到完美采样算法",
      "number": 114
    },
    {
      "title": "通向概率分布之路：盘点Softmax及其替代品",
      "slug": "通向概率分布之路盘点softmax及其替代品",
      "number": 122
    },
    {
      "title": "用傅里叶级数拟合一维概率密度函数",
      "slug": "用傅里叶级数拟合一维概率密度函数",
      "number": 134
    },
    {
      "title": "通向最优分布之路：概率空间的最小化",
      "slug": "通向最优分布之路概率空间的最小化",
      "number": 153
    },
    {
      "title": "一道概率不等式：盯着它到显然成立为止！",
      "slug": "一道概率不等式盯着它到显然成立为止",
      "number": 194
    },
    {
      "title": "MoE环游记：5、均匀分布的反思",
      "slug": "moe环游记5均匀分布的反思",
      "number": 197
    },
    {
      "title": "随机矩阵的谱范数的快速估计",
      "slug": "随机矩阵的谱范数的快速估计",
      "number": 229
    },
    {
      "title": "n个正态随机数的最大值的渐近估计",
      "slug": "n个正态随机数的最大值的渐近估计",
      "number": 234
    }
  ],
  "优化理论": [
    {
      "title": "指数梯度下降 + 元学习 = 自适应学习率",
      "slug": "指数梯度下降-元学习-自适应学习率",
      "number": 28
    },
    {
      "title": "基于Amos优化器思想推导出来的一些“炼丹策略”",
      "slug": "基于amos优化器思想推导出来的一些炼丹策略",
      "number": 66
    },
    {
      "title": "Google新搜出的优化器Lion：效率与效果兼得的“训练狮”",
      "slug": "google新搜出的优化器lion效率与效果兼得的训练狮",
      "number": 78
    },
    {
      "title": "Tiger：一个“抠”到极致的优化器",
      "slug": "tiger一个抠到极致的优化器",
      "number": 81
    },
    {
      "title": "Lion/Tiger优化器训练下的Embedding异常和对策",
      "slug": "liontiger优化器训练下的embedding异常和对策",
      "number": 106
    },
    {
      "title": "让炼丹更科学一些（一）：SGD的平均损失收敛",
      "slug": "让炼丹更科学一些一sgd的平均损失收敛",
      "number": 124
    },
    {
      "title": "配置不同的学习率，LoRA还能再涨一点？",
      "slug": "配置不同的学习率lora还能再涨一点",
      "number": 133
    },
    {
      "title": "当Batch Size增大时，学习率该如何随之变化？",
      "slug": "当batch-size增大时学习率该如何随之变化",
      "number": 169
    },
    {
      "title": "Adam的epsilon如何影响学习率的Scaling Law？",
      "slug": "adam的epsilon如何影响学习率的scaling-law",
      "number": 170
    },
    {
      "title": "从Hessian近似看自适应学习率优化器",
      "slug": "从hessian近似看自适应学习率优化器",
      "number": 172
    },
    {
      "title": "Muon优化器赏析：从向量到矩阵的本质跨越",
      "slug": "muon优化器赏析从向量到矩阵的本质跨越",
      "number": 173
    },
    {
      "title": "Muon续集：为什么我们选择尝试Muon？",
      "slug": "muon续集为什么我们选择尝试muon",
      "number": 184
    },
    {
      "title": "QK-Clip：让Muon在Scaleup之路上更进一步",
      "slug": "qk-clip让muon在scaleup之路上更进一步",
      "number": 208
    },
    {
      "title": "流形上的最速下降：1.  SGD + 超球面",
      "slug": "流形上的最速下降1-sgd-超球面",
      "number": 211
    },
    {
      "title": "流形上的最速下降：2. Muon + 正交",
      "slug": "流形上的最速下降2-muon-正交",
      "number": 213
    },
    {
      "title": "流形上的最速下降：3. Muon + Stiefel",
      "slug": "流形上的最速下降3-muon-stiefel",
      "number": 214
    },
    {
      "title": "流形上的最速下降：4. Muon + 谱球面",
      "slug": "流形上的最速下降4-muon-谱球面",
      "number": 216
    },
    {
      "title": "重新思考学习率与Batch Size（一）：现状",
      "slug": "重新思考学习率与batch-size一现状",
      "number": 218
    },
    {
      "title": "为什么Adam的Update RMS是0.2？",
      "slug": "为什么adam的update-rms是02",
      "number": 219
    },
    {
      "title": "重新思考学习率与Batch Size（二）：平均场",
      "slug": "重新思考学习率与batch-size二平均场",
      "number": 220
    },
    {
      "title": "重新思考学习率与Batch Size（三）：Muon",
      "slug": "重新思考学习率与batch-size三muon",
      "number": 221
    },
    {
      "title": "重新思考学习率与Batch Size（四）：EMA",
      "slug": "重新思考学习率与batch-size四ema",
      "number": 222
    },
    {
      "title": "重新思考学习率与Batch Siz...",
      "slug": "重新思考学习率与batch-siz",
      "number": 223
    },
    {
      "title": "AdamW的Weight RMS的...",
      "slug": "adamw的weight-rms的",
      "number": 224
    },
    {
      "title": "AdamW的Weight RMS的渐近估计",
      "slug": "adamw的weight-rms的渐近估计",
      "number": 225
    }
  ],
  "扩散模型": [
    {
      "title": "生成扩散模型漫谈（一）：DDPM = 拆楼 + 建楼",
      "slug": "生成扩散模型漫谈一ddpm-拆楼-建楼",
      "number": 46
    },
    {
      "title": "生成扩散模型漫谈（二）：DDPM = 自回归式VAE",
      "slug": "生成扩散模型漫谈二ddpm-自回归式vae",
      "number": 49
    },
    {
      "title": "生成扩散模型漫谈（三）：DDPM = 贝叶斯 + 去噪",
      "slug": "生成扩散模型漫谈三ddpm-贝叶斯-去噪",
      "number": 51
    },
    {
      "title": "生成扩散模型漫谈（四）：DDIM = 高观点DDPM",
      "slug": "生成扩散模型漫谈四ddim-高观点ddpm",
      "number": 52
    },
    {
      "title": "生成扩散模型漫谈（五）：一般框架之SDE篇",
      "slug": "生成扩散模型漫谈五一般框架之sde篇",
      "number": 53
    },
    {
      "title": "生成扩散模型漫谈（六）：一般框架之ODE篇",
      "slug": "生成扩散模型漫谈六一般框架之ode篇",
      "number": 54
    },
    {
      "title": "生成扩散模型漫谈（七）：最优扩散方差估计（上）",
      "slug": "生成扩散模型漫谈七最优扩散方差估计上",
      "number": 55
    },
    {
      "title": "生成扩散模型漫谈（八）：最优扩散方差估计（下）",
      "slug": "生成扩散模型漫谈八最优扩散方差估计下",
      "number": 56
    },
    {
      "title": "生成扩散模型漫谈（九）：条件控制生成结果",
      "slug": "生成扩散模型漫谈九条件控制生成结果",
      "number": 57
    },
    {
      "title": "生成扩散模型漫谈（十）：统一扩散模型（理论篇）",
      "slug": "生成扩散模型漫谈十统一扩散模型理论篇",
      "number": 58
    },
    {
      "title": "生成扩散模型漫谈（十一）：统一扩散模型（应用篇）",
      "slug": "生成扩散模型漫谈十一统一扩散模型应用篇",
      "number": 59
    },
    {
      "title": "生成扩散模型漫谈（十二）：“硬刚”扩散ODE",
      "slug": "生成扩散模型漫谈十二硬刚扩散ode",
      "number": 60
    },
    {
      "title": "生成扩散模型漫谈（十三）：从万有引力到扩散模型",
      "slug": "生成扩散模型漫谈十三从万有引力到扩散模型",
      "number": 62
    },
    {
      "title": "生成扩散模型漫谈（十四）：构建ODE的一般步骤（上）",
      "slug": "生成扩散模型漫谈十四构建ode的一般步骤上",
      "number": 70
    },
    {
      "title": "生成扩散模型漫谈（十五）：构建ODE的一般步骤（中）",
      "slug": "生成扩散模型漫谈十五构建ode的一般步骤中",
      "number": 71
    },
    {
      "title": "测试函数法推导连续性方程和Fokker-Planck方程",
      "slug": "测试函数法推导连续性方程和fokker-planck方程",
      "number": 76
    },
    {
      "title": "生成扩散模型漫谈（十六）：W距离 ≤ 得分匹配",
      "slug": "生成扩散模型漫谈十六w距离-得分匹配",
      "number": 77
    },
    {
      "title": "生成扩散模型漫谈（十七）：构建ODE的一般步骤（下）",
      "slug": "生成扩散模型漫谈十七构建ode的一般步骤下",
      "number": 79
    },
    {
      "title": "生成扩散模型漫谈（十八）：得分匹配 = 条件得分匹配",
      "slug": "生成扩散模型漫谈十八得分匹配-条件得分匹配",
      "number": 80
    },
    {
      "title": "生成扩散模型漫谈（十九）：作为扩散ODE的GAN",
      "slug": "生成扩散模型漫谈十九作为扩散ode的gan",
      "number": 97
    },
    {
      "title": "生成扩散模型漫谈（二十）：从ReFlow到WGAN-GP",
      "slug": "生成扩散模型漫谈二十从reflow到wgan-gp",
      "number": 98
    },
    {
      "title": "生成扩散模型漫谈（二十一）：中值定理加速ODE采样",
      "slug": "生成扩散模型漫谈二十一中值定理加速ode采样",
      "number": 121
    },
    {
      "title": "生成扩散模型漫谈（二十二）：信噪比与大图生成（上）",
      "slug": "生成扩散模型漫谈二十二信噪比与大图生成上",
      "number": 137
    },
    {
      "title": "生成扩散模型漫谈（二十三）：信噪比与大图生成（下）",
      "slug": "生成扩散模型漫谈二十三信噪比与大图生成下",
      "number": 138
    },
    {
      "title": "生成扩散模型漫谈（二十四）：少走捷径，更快到达",
      "slug": "生成扩散模型漫谈二十四少走捷径更快到达",
      "number": 139
    },
    {
      "title": "生成扩散模型漫谈（二十五）：基于恒等式的蒸馏（上）",
      "slug": "生成扩散模型漫谈二十五基于恒等式的蒸馏上",
      "number": 140
    },
    {
      "title": "“闭门造车”之多模态思路浅谈（二）：自回归",
      "slug": "闭门造车之多模态思路浅谈二自回归",
      "number": 148
    },
    {
      "title": "生成扩散模型漫谈（二十六）：基于恒等式的蒸馏（下）",
      "slug": "生成扩散模型漫谈二十六基于恒等式的蒸馏下",
      "number": 171
    },
    {
      "title": "生成扩散模型漫谈（二十七）：将步长作为条件输入",
      "slug": "生成扩散模型漫谈二十七将步长作为条件输入",
      "number": 174
    },
    {
      "title": "生成扩散模型漫谈（二十八）：分步理解一致性模型",
      "slug": "生成扩散模型漫谈二十八分步理解一致性模型",
      "number": 175
    },
    {
      "title": "生成扩散模型漫谈（二十九）：用DDPM来离散编码",
      "slug": "生成扩散模型漫谈二十九用ddpm来离散编码",
      "number": 182
    },
    {
      "title": "生成扩散模型漫谈（三十）：从瞬时速度到平均速度",
      "slug": "生成扩散模型漫谈三十从瞬时速度到平均速度",
      "number": 198
    }
  ],
  "Transformer": [
    {
      "title": "从熵不变性看Attention的Scale操作",
      "slug": "从熵不变性看attention的scale操作",
      "number": 16
    },
    {
      "title": "FLASH：可能是近来最有意思的高效Transformer设计",
      "slug": "flash可能是近来最有意思的高效transformer设计",
      "number": 27
    },
    {
      "title": "训练1000层的Transformer究竟有什么困难？",
      "slug": "训练1000层的transformer究竟有什么困难",
      "number": 29
    },
    {
      "title": "听说Attention与Softmax更配哦～",
      "slug": "听说attention与softmax更配哦",
      "number": 34
    },
    {
      "title": "GAU-α：尝鲜体验快好省的下一代Attention",
      "slug": "gau-α尝鲜体验快好省的下一代attention",
      "number": 38
    },
    {
      "title": "相对位置编码Transformer的一个理论缺陷与对策",
      "slug": "相对位置编码transformer的一个理论缺陷与对策",
      "number": 45
    },
    {
      "title": "Transformer升级之路：6、旋转位置编码的完备性分析",
      "slug": "transformer升级之路6旋转位置编码的完备性分析",
      "number": 72
    },
    {
      "title": "Transformer升级之路：7、长度外推性与局部注意力",
      "slug": "transformer升级之路7长度外推性与局部注意力",
      "number": 74
    },
    {
      "title": "Transformer升级之路：8、长度外推性与位置鲁棒性",
      "slug": "transformer升级之路8长度外推性与位置鲁棒性",
      "number": 75
    },
    {
      "title": "Bias项的神奇作用：RoPE + Bias = 更好的长度外推性",
      "slug": "bias项的神奇作用rope-bias-更好的长度外推性",
      "number": 86
    },
    {
      "title": "从JL引理看熵不变性Attention",
      "slug": "从jl引理看熵不变性attention",
      "number": 87
    },
    {
      "title": "Transformer升级之路：9、一种全局长度外推的新思路",
      "slug": "transformer升级之路9一种全局长度外推的新思路",
      "number": 91
    },
    {
      "title": "Transformer升级之路：10、RoPE是一种β进制编码",
      "slug": "transformer升级之路10rope是一种β进制编码",
      "number": 99
    },
    {
      "title": "Transformer升级之路：11、将β进制位置进行到底",
      "slug": "transformer升级之路11将β进制位置进行到底",
      "number": 102
    },
    {
      "title": "Transformer升级之路：12、无限外推的ReRoPE？",
      "slug": "transformer升级之路12无限外推的rerope",
      "number": 103
    },
    {
      "title": "Transformer升级之路：13、逆用Leaky ReRoPE",
      "slug": "transformer升级之路13逆用leaky-rerope",
      "number": 104
    },
    {
      "title": "Transformer升级之路：14、当HWFA遇见ReRoPE",
      "slug": "transformer升级之路14当hwfa遇见rerope",
      "number": 105
    },
    {
      "title": "预训练一下，Transformer的长序列成绩还能涨不少！",
      "slug": "预训练一下transformer的长序列成绩还能涨不少",
      "number": 112
    },
    {
      "title": "从梯度最大化看Attention的Scale操作",
      "slug": "从梯度最大化看attention的scale操作",
      "number": 115
    },
    {
      "title": "VQ一下Key，Transformer的复杂度就变成线性了",
      "slug": "vq一下keytransformer的复杂度就变成线性了",
      "number": 117
    },
    {
      "title": "Transformer升级之路：15、Key归一化助力长度外推",
      "slug": "transformer升级之路15key归一化助力长度外推",
      "number": 119
    },
    {
      "title": "我在Performer中发现了Transformer-VQ的踪迹",
      "slug": "我在performer中发现了transformer-vq的踪迹",
      "number": 120
    },
    {
      "title": "Transformer升级之路：16、“复盘”长度外推技术",
      "slug": "transformer升级之路16复盘长度外推技术",
      "number": 129
    },
    {
      "title": "时空之章：将Attention视为平方复杂度的RNN",
      "slug": "时空之章将attention视为平方复杂度的rnn",
      "number": 135
    },
    {
      "title": "Transformer升级之路：17、多模态位置编码的简单思考",
      "slug": "transformer升级之路17多模态位置编码的简单思考",
      "number": 136
    },
    {
      "title": "Transformer升级之路：18、RoPE的底数选择原则",
      "slug": "transformer升级之路18rope的底数选择原则",
      "number": 144
    },
    {
      "title": "Decoder-only的LLM为什么需要位置编码？",
      "slug": "decoder-only的llm为什么需要位置编码",
      "number": 157
    },
    {
      "title": "“闭门造车”之多模态思路浅谈（三）：位置编码",
      "slug": "闭门造车之多模态思路浅谈三位置编码",
      "number": 158
    },
    {
      "title": "Transformer升级之路：20、MLA好在哪里?（上）",
      "slug": "transformer升级之路20mla好在哪里上",
      "number": 195
    },
    {
      "title": "Transformer升级之路：21、MLA好在哪里?（下）",
      "slug": "transformer升级之路21mla好在哪里下",
      "number": 207
    },
    {
      "title": "低精度Attention可能存在有...",
      "slug": "低精度attention可能存在有",
      "number": 231
    },
    {
      "title": "低精度Attention可能存在有偏的舍入误差",
      "slug": "低精度attention可能存在有偏的舍入误差",
      "number": 232
    }
  ],
  "矩阵理论": [
    {
      "title": "重温SSM（一）：线性系统和HiPPO矩阵",
      "slug": "重温ssm一线性系统和hippo矩阵",
      "number": 143
    },
    {
      "title": "Monarch矩阵：计算高效的稀疏型矩阵分解",
      "slug": "monarch矩阵计算高效的稀疏型矩阵分解",
      "number": 151
    },
    {
      "title": "低秩近似之路（二）：SVD",
      "slug": "低秩近似之路二svd",
      "number": 162
    },
    {
      "title": "矩阵的有效秩（Effective Rank）",
      "slug": "矩阵的有效秩effective-rank",
      "number": 190
    },
    {
      "title": "SVD的导数",
      "slug": "svd的导数",
      "number": 193
    },
    {
      "title": "通过msign来计算奇异值裁剪mclip（上）",
      "slug": "通过msign来计算奇异值裁剪mclip上",
      "number": 201
    },
    {
      "title": "通过msign来计算奇异值裁剪mclip（下）",
      "slug": "通过msign来计算奇异值裁剪mclip下",
      "number": 204
    },
    {
      "title": "矩阵符号函数mcsgn能计算什么？",
      "slug": "矩阵符号函数mcsgn能计算什么",
      "number": 205
    },
    {
      "title": "矩阵平方根和逆平方根的高效计算",
      "slug": "矩阵平方根和逆平方根的高效计算",
      "number": 209
    },
    {
      "title": "矩阵r次方根和逆r次方根的高效计算",
      "slug": "矩阵r次方根和逆r次方根的高效计算",
      "number": 210
    }
  ],
  "梯度分析": [
    {
      "title": "WGAN新方案：通过梯度归一化来实现L约束",
      "slug": "wgan新方案通过梯度归一化来实现l约束",
      "number": 9
    },
    {
      "title": "ChildTuning：试试把Dropout加到梯度上去？",
      "slug": "childtuning试试把dropout加到梯度上去",
      "number": 10
    },
    {
      "title": "输入梯度惩罚与参数梯度惩罚的一个不等式",
      "slug": "输入梯度惩罚与参数梯度惩罚的一个不等式",
      "number": 14
    },
    {
      "title": "多任务学习漫谈（二）：行梯度之事",
      "slug": "多任务学习漫谈二行梯度之事",
      "number": 24
    },
    {
      "title": "梯度视角下的LoRA：简介、分析、猜测及推广",
      "slug": "梯度视角下的lora简介分析猜测及推广",
      "number": 88
    },
    {
      "title": "梯度流：探索通向最小值之路",
      "slug": "梯度流探索通向最小值之路",
      "number": 96
    },
    {
      "title": "VQ的旋转技巧：梯度直通估计的一般推广",
      "slug": "vq的旋转技巧梯度直通估计的一般推广",
      "number": 166
    },
    {
      "title": "从谱范数梯度到新式权重衰减的思考",
      "slug": "从谱范数梯度到新式权重衰减的思考",
      "number": 176
    },
    {
      "title": "为什么梯度裁剪的默认模长是1？",
      "slug": "为什么梯度裁剪的默认模长是1",
      "number": 177
    },
    {
      "title": "通过梯度近似寻找Normalization的替代品",
      "slug": "通过梯度近似寻找normalization的替代品",
      "number": 189
    },
    {
      "title": "msign的导数",
      "slug": "msign的导数",
      "number": 202
    },
    {
      "title": "流形上的最速下降：5. 对偶梯度下降",
      "slug": "流形上的最速下降5-对偶梯度下降",
      "number": 233
    }
  ],
  "其他": [
    {
      "title": "观测ISS",
      "slug": "观测iss",
      "number": 1
    },
    {
      "title": "个性邮箱",
      "slug": "个性邮箱",
      "number": 2
    },
    {
      "title": "关于WhiteningBERT原创性的疑问和沟通",
      "slug": "关于whiteningbert原创性的疑问和沟通",
      "number": 3
    },
    {
      "title": "用狄拉克函数来构造非光滑函数的光滑近似",
      "slug": "用狄拉克函数来构造非光滑函数的光滑近似",
      "number": 4
    },
    {
      "title": "初始化方法中非方阵的维度平均策略思考",
      "slug": "初始化方法中非方阵的维度平均策略思考",
      "number": 5
    },
    {
      "title": "bert4keras在手，baseline我有：CLUE基准代码",
      "slug": "bert4keras在手baseline我有clue基准代码",
      "number": 7
    },
    {
      "title": "模型优化漫谈：BERT的初始标准差为什么是0.02？",
      "slug": "模型优化漫谈bert的初始标准差为什么是002",
      "number": 8
    },
    {
      "title": "Dropout视角下的MLM和MAE：一些新的启发",
      "slug": "dropout视角下的mlm和mae一些新的启发",
      "number": 11
    },
    {
      "title": "开局一段扯，数据全靠编？真被一篇“神论文”气到了",
      "slug": "开局一段扯数据全靠编真被一篇神论文气到了",
      "number": 12
    },
    {
      "title": "Seq2Seq+前缀树：检索任务新范式（以KgCLUE为例）",
      "slug": "seq2seq前缀树检索任务新范式以kgclue为例",
      "number": 15
    },
    {
      "title": "SquarePlus：可能是运算最简单的ReLU光滑近似",
      "slug": "squareplus可能是运算最简单的relu光滑近似",
      "number": 18
    },
    {
      "title": "CoSENT（一）：比Sentence-BERT更有效的句向量方案",
      "slug": "cosent一比sentence-bert更有效的句向量方案",
      "number": 19
    },
    {
      "title": "CoSENT（二）：特征式匹配与交互式匹配有多大差距？",
      "slug": "cosent二特征式匹配与交互式匹配有多大差距",
      "number": 20
    },
    {
      "title": "多任务学习漫谈（一）：以损失之名",
      "slug": "多任务学习漫谈一以损失之名",
      "number": 21
    },
    {
      "title": "Efficient GlobalPointer：少点参数，多点效果",
      "slug": "efficient-globalpointer少点参数多点效果",
      "number": 22
    },
    {
      "title": "GPLinker：基于GlobalPointer的实体关系联合抽取",
      "slug": "gplinker基于globalpointer的实体关系联合抽取",
      "number": 23
    },
    {
      "title": "多任务学习漫谈（三）：分主次之序",
      "slug": "多任务学习漫谈三分主次之序",
      "number": 25
    },
    {
      "title": "GPLinker：基于GlobalPointer的事件联合抽取",
      "slug": "gplinker基于globalpointer的事件联合抽取",
      "number": 26
    },
    {
      "title": "门控注意力单元（GAU）还需要Warmup吗？",
      "slug": "门控注意力单元gau还需要warmup吗",
      "number": 30
    },
    {
      "title": "为什么需要残差？一个来自DeepNet的视角",
      "slug": "为什么需要残差一个来自deepnet的视角",
      "number": 31
    },
    {
      "title": "RoFormerV2：自然语言理解的极限探索",
      "slug": "roformerv2自然语言理解的极限探索",
      "number": 32
    },
    {
      "title": "为什么Pre Norm的效果不如Post Norm？",
      "slug": "为什么pre-norm的效果不如post-norm",
      "number": 33
    },
    {
      "title": "熵不变性Softmax的一个快速推导",
      "slug": "熵不变性softmax的一个快速推导",
      "number": 35
    },
    {
      "title": "GlobalPointer下的“KL散度”应该是怎样的？",
      "slug": "globalpointer下的kl散度应该是怎样的",
      "number": 36
    },
    {
      "title": "你的语言模型有没有“无法预测的词”？",
      "slug": "你的语言模型有没有无法预测的词",
      "number": 37
    },
    {
      "title": "在bert4keras中使用混合精度和XLA加速训练",
      "slug": "在bert4keras中使用混合精度和xla加速训练",
      "number": 39
    },
    {
      "title": "多标签“Softmax+交叉熵”的软标签版本",
      "slug": "多标签softmax交叉熵的软标签版本",
      "number": 40
    },
    {
      "title": "logsumexp运算的几个不等式",
      "slug": "logsumexp运算的几个不等式",
      "number": 41
    },
    {
      "title": "当BERT-whitening引入超参数：总有一款适合你",
      "slug": "当bert-whitening引入超参数总有一款适合你",
      "number": 42
    },
    {
      "title": "如何训练你的准确率？",
      "slug": "如何训练你的准确率",
      "number": 44
    },
    {
      "title": "Ladder Side-Tuning：预训练模型的“过墙梯”",
      "slug": "ladder-side-tuning预训练模型的过墙梯",
      "number": 47
    },
    {
      "title": "“维度灾难”之Hubness现象浅析",
      "slug": "维度灾难之hubness现象浅析",
      "number": 48
    },
    {
      "title": "不成功的尝试：将多标签交叉熵推广到“n个m分类”上去",
      "slug": "不成功的尝试将多标签交叉熵推广到n个m分类上去",
      "number": 50
    },
    {
      "title": "“十字架”组合计数问题浅试",
      "slug": "十字架组合计数问题浅试",
      "number": 61
    },
    {
      "title": "利用CUR分解加速交互式相似度模型的检索",
      "slug": "利用cur分解加速交互式相似度模型的检索",
      "number": 64
    },
    {
      "title": "CoSENT（三）：作为交互式相似度的损失函数",
      "slug": "cosent三作为交互式相似度的损失函数",
      "number": 65
    },
    {
      "title": "用热传导方程来指导自监督学习",
      "slug": "用热传导方程来指导自监督学习",
      "number": 67
    },
    {
      "title": "智能家居之小爱同学控制极米投影仪的简单方案",
      "slug": "智能家居之小爱同学控制极米投影仪的简单方案",
      "number": 68
    },
    {
      "title": "从局部到全局：语义相似度的测地线距离",
      "slug": "从局部到全局语义相似度的测地线距离",
      "number": 69
    },
    {
      "title": "智能家居之热水器零冷水技术原理浅析",
      "slug": "智能家居之热水器零冷水技术原理浅析",
      "number": 73
    },
    {
      "title": "缓解交叉熵过度自信的一个简明方案",
      "slug": "缓解交叉熵过度自信的一个简明方案",
      "number": 82
    },
    {
      "title": "为什么现在的LLM都是Decoder-only的架构？",
      "slug": "为什么现在的llm都是decoder-only的架构",
      "number": 83
    },
    {
      "title": "《为什么现在的LLM都是Decoder-only的架构？》FAQ",
      "slug": "为什么现在的llm都是decoder-only的架构faq",
      "number": 84
    },
    {
      "title": "Google新作试图“复活”RNN：RNN能否再次辉煌？",
      "slug": "google新作试图复活rnnrnn能否再次辉煌",
      "number": 85
    },
    {
      "title": "注意力和Softmax的两点有趣发现：鲁棒性和信息量",
      "slug": "注意力和softmax的两点有趣发现鲁棒性和信息量",
      "number": 89
    },
    {
      "title": "如何度量数据的稀疏程度？",
      "slug": "如何度量数据的稀疏程度",
      "number": 90
    },
    {
      "title": "基于量子化假设推导模型的尺度定律（Scaling Law）",
      "slug": "基于量子化假设推导模型的尺度定律scaling-law",
      "number": 92
    },
    {
      "title": "NBCE：使用朴素贝叶斯扩展LLM的Context处理长度",
      "slug": "nbce使用朴素贝叶斯扩展llm的context处理长度",
      "number": 93
    },
    {
      "title": "关于NBCE方法的一些补充说明和分析",
      "slug": "关于nbce方法的一些补充说明和分析",
      "number": 94
    },
    {
      "title": "Naive Bayes is all you need ?",
      "slug": "naive-bayes-is-all-you-need",
      "number": 95
    },
    {
      "title": "当生成模型肆虐：互联网将有“疯牛病”之忧？",
      "slug": "当生成模型肆虐互联网将有疯牛病之忧",
      "number": 100
    },
    {
      "title": "语言模型输出端共享Embedding的重新探索",
      "slug": "语言模型输出端共享embedding的重新探索",
      "number": 101
    },
    {
      "title": "BytePiece：更纯粹、更高压缩率的Tokenizer",
      "slug": "bytepiece更纯粹更高压缩率的tokenizer",
      "number": 107
    },
    {
      "title": "大词表语言模型在续写任务上的一个问题及对策",
      "slug": "大词表语言模型在续写任务上的一个问题及对策",
      "number": 108
    },
    {
      "title": "自然数集中 N = ab + c 时 a + b + c 的最小值",
      "slug": "自然数集中-n-ab-c-时-a-b-c-的最小值",
      "number": 110
    },
    {
      "title": "脑洞大开：非线性RNN居然也可以并行计算？",
      "slug": "脑洞大开非线性rnn居然也可以并行计算",
      "number": 111
    },
    {
      "title": "EMO：基于最优传输思想设计的分类损失函数",
      "slug": "emo基于最优传输思想设计的分类损失函数",
      "number": 113
    },
    {
      "title": "简单得令人尴尬的FSQ：“四舍五入”超越了VQ-VAE",
      "slug": "简单得令人尴尬的fsq四舍五入超越了vq-vae",
      "number": 116
    },
    {
      "title": "【生活杂记】炒锅的尽头是铁锅",
      "slug": "生活杂记炒锅的尽头是铁锅",
      "number": 118
    },
    {
      "title": "注意力机制真的可以“集中注意力”吗？",
      "slug": "注意力机制真的可以集中注意力吗",
      "number": 123
    },
    {
      "title": "写了个刷论文的辅助网站：Cool Papers",
      "slug": "写了个刷论文的辅助网站cool-papers",
      "number": 125
    },
    {
      "title": "新年快乐！记录一下 Cool Papers 的开发体验",
      "slug": "新年快乐记录一下-cool-papers-的开发体验",
      "number": 126
    },
    {
      "title": "局部余弦相似度大，全局余弦相似度一定也大吗？",
      "slug": "局部余弦相似度大全局余弦相似度一定也大吗",
      "number": 127
    },
    {
      "title": "旁门左道之如何让Python的重试代码更加优雅",
      "slug": "旁门左道之如何让python的重试代码更加优雅",
      "number": 128
    },
    {
      "title": "幂等生成网络IGN：试图将判别和生成合二为一的GAN",
      "slug": "幂等生成网络ign试图将判别和生成合二为一的gan",
      "number": 130
    },
    {
      "title": "更便捷的Cool Papers打开方式：Chrome重定向扩展",
      "slug": "更便捷的cool-papers打开方式chrome重定向扩展",
      "number": 131
    },
    {
      "title": "“闭门造车”之多模态思路浅谈（一）：无损输入",
      "slug": "闭门造车之多模态思路浅谈一无损输入",
      "number": 132
    },
    {
      "title": "Cool Papers更新：简单搭建了一个站内检索系统",
      "slug": "cool-papers更新简单搭建了一个站内检索系统",
      "number": 141
    },
    {
      "title": "缓存与效果的极限拉扯：从MHA、MQA、GQA到MLA",
      "slug": "缓存与效果的极限拉扯从mhamqagqa到mla",
      "number": 142
    },
    {
      "title": "重温SSM（二）：HiPPO的一些遗留问题",
      "slug": "重温ssm二hippo的一些遗留问题",
      "number": 145
    },
    {
      "title": "重温SSM（三）：HiPPO的高效计算（S4）",
      "slug": "重温ssm三hippo的高效计算s4",
      "number": 146
    },
    {
      "title": "重温SSM（四）：有理生成函数的新视角",
      "slug": "重温ssm四有理生成函数的新视角",
      "number": 147
    },
    {
      "title": "对齐全量微调！这是我看过最精彩的LoRA改进（一）",
      "slug": "对齐全量微调这是我看过最精彩的lora改进一",
      "number": 149
    },
    {
      "title": "【生活杂记】用电饭锅来煮米汤",
      "slug": "生活杂记用电饭锅来煮米汤",
      "number": 150
    },
    {
      "title": "对齐全量微调！这是我看过最精彩的LoRA改进（二）",
      "slug": "对齐全量微调这是我看过最精彩的lora改进二",
      "number": 152
    },
    {
      "title": "“Cool Papers + 站内搜索”的一些新尝试",
      "slug": "cool-papers-站内搜索的一些新尝试",
      "number": 154
    },
    {
      "title": "让MathJax更好地兼容谷歌翻译和延时加载",
      "slug": "让mathjax更好地兼容谷歌翻译和延时加载",
      "number": 155
    },
    {
      "title": "近乎完美地解决MathJax与Marked的冲突",
      "slug": "近乎完美地解决mathjax与marked的冲突",
      "number": 156
    },
    {
      "title": "低秩近似之路（一）：伪逆",
      "slug": "低秩近似之路一伪逆",
      "number": 159
    },
    {
      "title": "Softmax后传：寻找Top-K的光滑近似",
      "slug": "softmax后传寻找top-k的光滑近似",
      "number": 160
    },
    {
      "title": "利用“熄火保护 + 通断器”实现燃气灶智能关火",
      "slug": "利用熄火保护-通断器实现燃气灶智能关火",
      "number": 161
    },
    {
      "title": "低秩近似之路（三）：CR",
      "slug": "低秩近似之路三cr",
      "number": 163
    },
    {
      "title": "让MathJax的数学公式随窗口大小自动缩放",
      "slug": "让mathjax的数学公式随窗口大小自动缩放",
      "number": 164
    },
    {
      "title": "Cool Papers浏览器扩展升级至v0.2.0",
      "slug": "cool-papers浏览器扩展升级至v020",
      "number": 165
    },
    {
      "title": "低秩近似之路（四）：ID",
      "slug": "低秩近似之路四id",
      "number": 167
    },
    {
      "title": "VQ的又一技巧：给编码表加一个线性变换",
      "slug": "vq的又一技巧给编码表加一个线性变换",
      "number": 168
    },
    {
      "title": "低秩近似之路（五）：CUR",
      "slug": "低秩近似之路五cur",
      "number": 178
    },
    {
      "title": "细水长flow之TARFLOW：流模型满血归来？",
      "slug": "细水长flow之tarflow流模型满血归来",
      "number": 179
    },
    {
      "title": "三个球的交点坐标（三球交会定位）",
      "slug": "三个球的交点坐标三球交会定位",
      "number": 180
    },
    {
      "title": "MoE环游记：1、从几何意义出发",
      "slug": "moe环游记1从几何意义出发",
      "number": 181
    },
    {
      "title": "MoE环游记：2、不患寡而患不均",
      "slug": "moe环游记2不患寡而患不均",
      "number": 183
    },
    {
      "title": "MoE环游记：3、换个思路来分配",
      "slug": "moe环游记3换个思路来分配",
      "number": 185
    },
    {
      "title": "初探MuP：超参数的跨模型尺度迁移规律",
      "slug": "初探mup超参数的跨模型尺度迁移规律",
      "number": 186
    },
    {
      "title": "高阶MuP：更简明但更高明的谱条件缩放",
      "slug": "高阶mup更简明但更高明的谱条件缩放",
      "number": 187
    },
    {
      "title": "MoE环游记：4、难处应当多投入",
      "slug": "moe环游记4难处应当多投入",
      "number": 188
    },
    {
      "title": "苏剑林: 我的pretrain的小模型，暂时没有链接。",
      "slug": "苏剑林-我的pretrain的小模型暂时没有链接",
      "number": 191
    },
    {
      "title": "智能家居之手搓一套能接入米家的零冷水装置",
      "slug": "智能家居之手搓一套能接入米家的零冷水装置",
      "number": 192
    },
    {
      "title": "msign算子的Newton-Schulz迭代（上）",
      "slug": "msign算子的newton-schulz迭代上",
      "number": 196
    },
    {
      "title": "等值振荡定理：最优多项式逼近的充要条件",
      "slug": "等值振荡定理最优多项式逼近的充要条件",
      "number": 199
    },
    {
      "title": "msign算子的Newton-Schulz迭代（下）",
      "slug": "msign算子的newton-schulz迭代下",
      "number": 200
    },
    {
      "title": "苏剑林: 就是反向构造出来的。",
      "slug": "苏剑林-就是反向构造出来的",
      "number": 203
    },
    {
      "title": "“对角+低秩”三角阵的高效求逆方法",
      "slug": "对角低秩三角阵的高效求逆方法",
      "number": 206
    },
    {
      "title": "基于树莓派Zero2W搭建一个随身旁路由",
      "slug": "基于树莓派zero2w搭建一个随身旁路由",
      "number": 212
    },
    {
      "title": "ReLU/GeLU/Swish的一个恒等式",
      "slug": "relugeluswish的一个恒等式",
      "number": 215
    },
    {
      "title": "Cool Papers更新：简单适配Zotero Connector",
      "slug": "cool-papers更新简单适配zotero-connector",
      "number": 217
    },
    {
      "title": "为什么线性注意力要加Short C...",
      "slug": "为什么线性注意力要加short-c",
      "number": 226
    },
    {
      "title": "为什么线性注意力要加Short Conv？",
      "slug": "为什么线性注意力要加short-conv",
      "number": 227
    },
    {
      "title": "DiVeQ：一种非常简洁的VQ训练方案",
      "slug": "diveq一种非常简洁的vq训练方案",
      "number": 228
    },
    {
      "title": "MuP之上：1. 好模型的三个特征",
      "slug": "mup之上1-好模型的三个特征",
      "number": 230
    }
  ]
}